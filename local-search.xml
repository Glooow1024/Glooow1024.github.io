<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>IEEE论文爬虫及数据统计</title>
    <link href="/2022/03/19/diy/paper-collector/"/>
    <url>/2022/03/19/diy/paper-collector/</url>
    
    <content type="html"><![CDATA[<h2 id="ieee论文爬虫">1. IEEE论文爬虫</h2><p>爬虫代码网上有很多了，这部分是直接用的网上可以跑通的<sup id="fnref:1" class="footnote-ref"><a href="#fn:1" rel="footnote"><spanclass="hint--top hint--rounded"aria-label="https://blog.csdn.net/wp7xtj98/article/details/112711465">[1]</span></a></sup>。使用的时候直接调用<code>get_article_info()</code>，其中参数 <code>conferenceID</code>需要手动在 IEEE 上查询会议的 ID 号，参数 <code>saceFileName</code>为希望保存的 <code>csv</code> 文件名。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 获取issueNumber</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">get_issueNumber</span>(<span class="hljs-params">conferenceID</span>):</span><br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    Get the issueNumber from the website.</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    conferenceID = <span class="hljs-built_in">str</span>(conferenceID)<br>    gheaders = &#123;<br>        <span class="hljs-string">&#x27;Referer&#x27;</span>: <span class="hljs-string">&#x27;https://ieeexplore.ieee.org/xpl/conhome/&#x27;</span>+conferenceID+<span class="hljs-string">&#x27;/proceeding&#x27;</span>,<br>        <span class="hljs-string">&#x27;User-Agent&#x27;</span>: <span class="hljs-string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.97 Safari/537.36&#x27;</span><br>    &#125;<br>    md_url = <span class="hljs-string">&#x27;https://ieeexplore.ieee.org/rest/publication/home/metadata?pubid=&#x27;</span>+conferenceID<br>    md_res = requests.get(md_url, headers = gheaders)<br>    md_dic = json.loads(md_res.text)<br>    issueNumber = <span class="hljs-built_in">str</span>(md_dic[<span class="hljs-string">&#x27;currentIssue&#x27;</span>][<span class="hljs-string">&#x27;issueNumber&#x27;</span>])<br>    <span class="hljs-keyword">return</span> issueNumber<br><br><span class="hljs-comment"># 爬取论文及其下载链接</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">get_article_info</span>(<span class="hljs-params">conferenceID, saveFileName</span>):</span><br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    Collect the published paper data, and save into the csv file &quot;saveFileName&quot;.</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    <span class="hljs-comment"># 获取issueNumber</span><br>    issueNumber = <span class="hljs-built_in">str</span>(get_issueNumber(conferenceID))<br>    conferenceID = <span class="hljs-built_in">str</span>(conferenceID)<br><br>    <span class="hljs-comment"># 记录论文数据</span><br>    dataframe = pd.DataFrame(&#123;&#125;)<br>    paper_title = []<br>    paper_author = []<br>    paper_year = []<br>    paper_citation = []<br>    paper_abstract = []<br>    paper_ieee_kwd = []<br><br>    <span class="hljs-comment"># 从第一页开始下载</span><br>    pageNumber = <span class="hljs-number">1</span><br>    count = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">while</span>(<span class="hljs-literal">True</span>):<br>        <span class="hljs-comment"># 获取会议文章目录</span><br>        toc_url = <span class="hljs-string">&#x27;https://ieeexplore.ieee.org/rest/search/pub/&#x27;</span>+conferenceID+<span class="hljs-string">&#x27;/issue/&#x27;</span>+issueNumber+<span class="hljs-string">&#x27;/toc&#x27;</span><br>        payload = <span class="hljs-string">&#x27;&#123;&quot;pageNumber&quot;:&#x27;</span>+<span class="hljs-built_in">str</span>(pageNumber)+<span class="hljs-string">&#x27;,&quot;punumber&quot;:&quot;&#x27;</span>+conferenceID+<span class="hljs-string">&#x27;&quot;,&quot;isnumber&quot;:&#x27;</span>+issueNumber+<span class="hljs-string">&#x27;&#125;&#x27;</span><br>        headers = &#123;<br>            <span class="hljs-string">&#x27;Host&#x27;</span>: <span class="hljs-string">&#x27;ieeexplore.ieee.org&#x27;</span>,<br>            <span class="hljs-string">&#x27;User-Agent&#x27;</span>:<span class="hljs-string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.190 Safari/537.36&#x27;</span>,<br>            <span class="hljs-string">&#x27;Referer&#x27;</span>: <span class="hljs-string">&#x27;https://ieeexplore.ieee.org/xpl/conhome/&#x27;</span>+conferenceID+<span class="hljs-string">&#x27;/proceeding?pageNumber=&#x27;</span>+<span class="hljs-built_in">str</span>(pageNumber),<br>        &#125;<br>        toc_res = requests.post(toc_url, headers = headers, data=payload)<br>        toc_dic = json.loads(toc_res.text)<br>        <span class="hljs-keyword">try</span>:<br>            articles = toc_dic[<span class="hljs-string">&#x27;records&#x27;</span>]<br>        <span class="hljs-keyword">except</span> KeyError:<br>            <span class="hljs-keyword">break</span><br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-keyword">for</span> article <span class="hljs-keyword">in</span> articles:<br>                title = article[<span class="hljs-string">&#x27;highlightedTitle&#x27;</span>]<br>                paper_link = IEEE_root_url + article[<span class="hljs-string">&#x27;htmlLink&#x27;</span>]<br>                paper_info = requests.get(url=paper_link, headers=headers, timeout=<span class="hljs-number">10</span>)<br>                soup = BeautifulSoup(paper_info.text, <span class="hljs-string">&#x27;lxml&#x27;</span>)                  <span class="hljs-comment"># 解析</span><br>                <span class="hljs-comment"># 正则表达式 创建模式对象</span><br>                pattern = re.<span class="hljs-built_in">compile</span>(<span class="hljs-string">r&#x27;xplGlobal.document.metadata=(.*?)&quot;&#125;;&#x27;</span>, re.MULTILINE | re.DOTALL)<br>                script = soup.find(<span class="hljs-string">&quot;script&quot;</span>, text=pattern)                     <span class="hljs-comment"># 根据模式对象进行搜索</span><br>                <span class="hljs-keyword">try</span>:<br>                    res_dic = pattern.search(script.string).group(<span class="hljs-number">1</span>)+<span class="hljs-string">&#x27;&quot;&#125;&#x27;</span>      <span class="hljs-comment"># 配合search找到字典，匹配结尾字符串，降低文章摘要中也出现这种字符串的概率</span><br>                    <span class="hljs-comment"># 解析异常，一般是因为文章 abstract 中出现了字符串 &#x27;&quot;&#125;;&#x27;</span><br>                    json_data = json.loads(res_dic)                            <span class="hljs-comment"># 将json格式数据转换为字典</span><br>                <span class="hljs-keyword">except</span> Exception <span class="hljs-keyword">as</span> e:<br>                    <span class="hljs-built_in">print</span>(pattern.search(script.string).group(<span class="hljs-number">0</span>))<br>                    <span class="hljs-built_in">print</span>(res_dic)<br>                <span class="hljs-comment"># 保存文章信息</span><br>                paper_title.append(title)<br>                paper_year.append(json_data[<span class="hljs-string">&#x27;publicationYear&#x27;</span>])<br>                <span class="hljs-built_in">print</span>(json_data.keys())<br>                <span class="hljs-comment">#a = input(&#x27;input anything...&#x27;)</span><br>                <span class="hljs-keyword">if</span> <span class="hljs-string">&#x27;author&#x27;</span> <span class="hljs-keyword">in</span> json_data.keys():<br>                    paper_author.append(json_data[<span class="hljs-string">&#x27;author&#x27;</span>])<br>                <span class="hljs-keyword">else</span>:<br>                    paper_author.append(<span class="hljs-literal">None</span>)<br>                <span class="hljs-keyword">if</span> <span class="hljs-string">&#x27;abstract&#x27;</span> <span class="hljs-keyword">in</span> json_data.keys():<br>                    paper_abstract.append(json_data[<span class="hljs-string">&#x27;abstract&#x27;</span>])<br>                <span class="hljs-keyword">else</span>:<br>                    paper_abstract.append(<span class="hljs-literal">None</span>)<br>                <span class="hljs-keyword">if</span> <span class="hljs-string">&#x27;keywords&#x27;</span> <span class="hljs-keyword">in</span> json_data.keys():<br>                    paper_ieee_kwd.append(json_data[<span class="hljs-string">&#x27;keywords&#x27;</span>][<span class="hljs-number">0</span>][<span class="hljs-string">&#x27;kwd&#x27;</span>])       <span class="hljs-comment"># ieee有三种 key words</span><br>                <span class="hljs-keyword">else</span>:<br>                    paper_ieee_kwd.append(<span class="hljs-literal">None</span>)<br>                count=count+<span class="hljs-number">1</span><br>                <span class="hljs-comment">#link = &#x27;https://ieeexplore.ieee.org/stampPDF/getPDF.jsp?tp=&amp;arnumber=&#x27;+article[&#x27;articleNumber&#x27;]+&#x27;&amp;ref=&#x27;</span><br>                <span class="hljs-comment">#alf.write(title.replace(&#x27;\n&#x27;,&#x27;&#x27;)+&#x27;&gt;_&lt;&#x27;+link+&#x27;\n&#x27;)</span><br>            <br>            <span class="hljs-comment"># 写入csv文件</span><br>            dataframe = pd.DataFrame(&#123;<span class="hljs-string">&#x27;title&#x27;</span>:paper_title, <span class="hljs-string">&#x27;year&#x27;</span>:paper_year, <span class="hljs-string">&#x27;abstract&#x27;</span>:paper_abstract, <span class="hljs-string">&#x27;key words&#x27;</span>:paper_ieee_kwd&#125;)<br>            dataframe.to_csv(saveFileName, index=<span class="hljs-literal">True</span>, sep=<span class="hljs-string">&#x27;,&#x27;</span>)<br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Page &#x27;</span>, pageNumber, <span class="hljs-string">&#x27;, total &#x27;</span>, count, <span class="hljs-string">&#x27;papers.&#x27;</span>)<br>            pageNumber = pageNumber+<span class="hljs-number">1</span><br>            <span class="hljs-comment"># 停一下防禁ip</span><br>            <span class="hljs-keyword">import</span> time<br>            time.sleep(<span class="hljs-number">3</span>)<br><br>    <span class="hljs-comment"># 写入csv文件</span><br>    dataframe = pd.DataFrame(&#123;<span class="hljs-string">&#x27;title&#x27;</span>:paper_title, <span class="hljs-string">&#x27;year&#x27;</span>:paper_year, <span class="hljs-string">&#x27;abstract&#x27;</span>:paper_abstract, <span class="hljs-string">&#x27;key words&#x27;</span>:paper_ieee_kwd&#125;)<br>    dataframe.to_csv(saveFileName, index=<span class="hljs-literal">True</span>, sep=<span class="hljs-string">&#x27;,&#x27;</span>)<br>    <span class="hljs-keyword">return</span><br></code></pre></td></tr></table></figure><h2 id="ieee论文数据统计">2. IEEE论文数据统计</h2><h2 id="写一个图形界面">3. 写一个图形界面</h2><h3 id="弹出提示窗口">3.1 弹出提示窗口</h3><p>在写代码过程中有时候需要测试功能是否成功实现，于是想要加一个弹出窗口的函数可以显示调试信息，用以验证想要的功能是否正常实现。主要难点在于根据内容自动调整窗口大小，以获得较好的显示效果。</p><p>采用的方法是利用 <code>QLabel.adjust()</code>函数获取文本显示的宽度，并据此调整窗口的大小<sup id="fnref:2" class="footnote-ref"><a href="#fn:2" rel="footnote"><spanclass="hint--top hint--rounded" aria-label="PyQt中文教程 (gitbook.io)">[2]</span></a></sup>。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> PyQt6.QtWidgets <span class="hljs-keyword">import</span> (QWidget, QDialog, QLabel, QPushButton)<br><span class="hljs-keyword">from</span> PyQt6.QtCore <span class="hljs-keyword">import</span> (QSize, QRect)<br><br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">PaperCollector</span>(<span class="hljs-params">QWidget</span>):</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self</span>):</span><br>        <span class="hljs-built_in">super</span>().__init__()<br>        self.initUI()<br>        <br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">initUI</span>(<span class="hljs-params">self</span>):</span><br>        self.dialog_btn = QPushButton(<span class="hljs-string">&#x27;Click&#x27;</span>)<br>        self.dialog_btn.clicked.connect(self.click_callback)<br>        self.setGeometry(<span class="hljs-number">300</span>, <span class="hljs-number">300</span>, <span class="hljs-number">300</span>, <span class="hljs-number">200</span>)<br>        self.setWindowTitle(<span class="hljs-string">&#x27;IEEE paper collector (by Glooow)&#x27;</span>)<br>        self.show()<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">click_callback</span>(<span class="hljs-params">self</span>):</span><br>        self.show_dialog(<span class="hljs-string">&#x27;You clicked me!&#x27;</span>)<br>        <br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">show_dialog</span>(<span class="hljs-params">self, info</span>):</span><br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        Pop up dialogs for debug.</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        hint_dialog = QDialog()<br>        hint_dialog.setWindowTitle(<span class="hljs-string">&#x27;Hint info&#x27;</span>)<br>        <span class="hljs-comment">#hint_dialog.setWindowModality(PyQt6.QtCore.Qt.NonModal)</span><br><br>        hint_info = QLabel(info, hint_dialog)<br>        hint_info.adjustSize()<br>        padding = <span class="hljs-number">20</span><br>        max_width = <span class="hljs-number">360</span><br>        <span class="hljs-comment"># set the maximum width</span><br>        <span class="hljs-keyword">if</span> hint_info.size().width() &gt; max_width:<br>            hint_info.setGeometry(QRect(<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, max_width, <span class="hljs-number">80</span>))<br>            hint_info.setWordWrap(<span class="hljs-literal">True</span>)<br>        hint_info.move(padding, padding)<br><br>        hint_dialog.resize(hint_info.size() + QSize(padding*<span class="hljs-number">2</span>, padding*<span class="hljs-number">2</span>))<br>        hint_dialog.<span class="hljs-built_in">exec</span>()<br></code></pre></td></tr></table></figure><h3 id="文本框显示爬取日志">3.2 文本框显示爬取日志</h3><p>我希望在窗口中增加一个文本框，将爬取过程中的日志信息打印出来，便于用户实时监测。</p><p>采用的思路是定义一个<code>logging.Logger</code>，将其日志信息同时输出到窗口的文本框和控制台中打印，通过自定义<code>logging.Handler</code>可以实现这一功能<sup id="fnref:3" class="footnote-ref"><a href="#fn:3" rel="footnote"><spanclass="hint--top hint--rounded"aria-label="https://zhuanlan.gitbook.io/p/360306588">[3]</span></a></sup><sup id="fnref:5" class="footnote-ref"><a href="#fn:5" rel="footnote"><spanclass="hint--top hint--rounded"aria-label="https://stackoverflow.com/questions/41176319/python-logging-output-on-both-gui-and-console">[5]</span></a></sup><sup id="fnref:6" class="footnote-ref"><a href="#fn:6" rel="footnote"><spanclass="hint--top hint--rounded"aria-label="https://stackoverflow.com/questions/24371274/how-to-dynamically-update-qtextedit">[6]</span></a></sup>。实现方式为：</p><ol type="1"><li><p>继承 <code>logging.Handler</code>类，并初始化阶段将整个窗口(<code>QWidget</code>类)作为参数传入，便于后续修改窗口的信息；</p></li><li><p>自定义实现 <code>emit</code> 函数，在 <code>emit</code> 函数中将log 信息同时输出到窗口文本框、打印到控制台；</p></li><li><p>创建 <code>logger</code> 的时候设置Handler<sup id="fnref:4" class="footnote-ref"><a href="#fn:4" rel="footnote"><spanclass="hint--top hint--rounded"aria-label="https://blog.csdn.net/qq_37541097/article/details/108317762">[4]</span></a></sup></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">ex = PaperCollector()<br>logger = logging.getLogger(<span class="hljs-string">&quot;logger&quot;</span>)<br>handler = LogHandler(ex)<br>logger.addHandler(handler)<br></code></pre></td></tr></table></figure></li></ol><p>下面是这部分功能相关的代码。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> logging<br><br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">LogHandler</span>(<span class="hljs-params">logging.Handler</span>):</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self, parent</span>):</span><br>        <span class="hljs-built_in">super</span>().__init__()<br>        self.parent = parent<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">emit</span>(<span class="hljs-params">self, record</span>):</span><br>        <span class="hljs-keyword">try</span>:<br>            <span class="hljs-built_in">print</span>(self.<span class="hljs-built_in">format</span>(record))<br>            self.parent.print_log(self.<span class="hljs-built_in">format</span>(record))<br>            QApplication.processEvents()<br>        <span class="hljs-keyword">except</span> Exception:<br>            self.handleError(record)<br>            <br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">PaperCollector</span>(<span class="hljs-params">QWidget</span>):</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self</span>):</span><br>        <span class="hljs-built_in">super</span>().__init__()<br>        self.initUI()<br>        <br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">initUI</span>(<span class="hljs-params">self</span>):</span><br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        Define the UI playout.</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        <span class="hljs-comment"># button to start crawing</span><br>        self.startCrawling_button = QPushButton(<span class="hljs-string">&#x27;Start&#x27;</span>)<br>        self.startCrawling_button.setToolTip(<span class="hljs-string">&#x27;Click and wait for collecting published paper data.&#x27;</span>)<br>        self.startCrawling_button.clicked.connect(self.start_collect_paper)<br>        <span class="hljs-comment"># print log</span><br>        self.process = QTextEdit(readOnly=<span class="hljs-literal">True</span>)<br>        self.process.setFont(QFont(<span class="hljs-string">&quot;Source Code Pro&quot;</span>,<span class="hljs-number">9</span>))<br>        <br>        grid = QGridLayout()<br>        grid.setSpacing(<span class="hljs-number">10</span>)<br>        grid.addWidget(self.startCrawling_button, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>)<br>        grid.addWidget(self.process, <span class="hljs-number">2</span>, <span class="hljs-number">0</span>, <span class="hljs-number">3</span>, <span class="hljs-number">3</span>)<br>        self.setLayout(grid)<br>        <br>        self.setGeometry(<span class="hljs-number">300</span>, <span class="hljs-number">300</span>, <span class="hljs-number">700</span>, <span class="hljs-number">300</span>)<br>        self.setWindowTitle(<span class="hljs-string">&#x27;IEEE paper collector (by Glooow)&#x27;</span>)<br>        self.show()<br>        <br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">start_collect_paper</span>(<span class="hljs-params">self</span>):</span><br>        <span class="hljs-keyword">global</span> logger<br>        <span class="hljs-comment">#self.show_dialog(&#x27;start!&#x27;)</span><br>        get_article_info(self.conferenceID_edit.text(), self.saveFile_edit.text(), logger)<br>        <br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">print_log</span>(<span class="hljs-params">self, s</span>):</span><br>        self.process.append(s)<br>        <br>logger = <span class="hljs-literal">None</span><br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">main</span>():</span><br>    app = QApplication(sys.argv)<br>    ex = PaperCollector()<br><br>    <span class="hljs-keyword">global</span> logger<br>    logger = logging.getLogger(<span class="hljs-string">&quot;logger&quot;</span>)<br>    logger.setLevel(logging.INFO)<br>    formater = logging.Formatter(fmt=<span class="hljs-string">&quot;%(asctime)s [%(levelname)s] : %(message)s&quot;</span><br>                ,datefmt=<span class="hljs-string">&quot;%Y/%m/%d %H:%M:%S&quot;</span>)<br>    handler = LogHandler(ex)<br>    handler.setFormatter(formater)<br>    logger.addHandler(handler)<br><br>    sys.exit(app.<span class="hljs-built_in">exec</span>())<br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    main()<br></code></pre></td></tr></table></figure><p>爬取论文的主函数如下，其中一个参数为<code>logger</code>，在函数内部需要打印日志信息的地方添加<code>logger.info(...)</code> 即可。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">get_article_info</span>(<span class="hljs-params">conferenceID, saveFileName, logger</span>):</span><br>    logger.info(<span class="hljs-string">&#x27;collecting paper......&#x27;</span>)<br></code></pre></td></tr></table></figure><h3 id="多线程避免卡顿">3.3 多线程避免卡顿</h3><p>上述打印日志的方法不能做到实时输出信息到窗口文本框，而是会等到所有论文爬取完毕之后再一股脑的更新，这是因为PyQt的界面线程是主线程，当爬虫开始工作时，也是运行在主线程中，这时主界面就无法更新，看起来就像是卡死了。解决方法就是开一个子线程运行爬虫工作<sup id="fnref:7" class="footnote-ref"><a href="#fn:7" rel="footnote">&lt;spanclass="hint--top hint--rounded" aria-label="<ahref="https://blog.csdn.net/bailang_zhizun/article/details/109240670">PyQt- 使用多线程避免界面卡顿 - bailang zhizun的博客 - CSDN博客"&gt;[7]</span></a></sup>。</p><p>具体实现细节为：</p><ol type="1"><li>新建类 <code>SpiderThread</code> 继承 <code>QObject</code>，自定义<code>run</code> 函数，在其中运行爬虫程序；</li><li>在 <code>SpiderThread</code> 类中定义一个 <code>_spider_finish =pyqtSignal()</code>，该信号用于告知主线程爬虫子线程已完成工作</li><li>在 <code>PaperCollector</code> 类中定义一个 <code>_start_spider =pyqtSignal(str, str,logging.Logger)</code>，该信号用于启动爬虫子线程<sup id="fnref:8" class="footnote-ref"><a href="#fn:8" rel="footnote"><spanclass="hint--top hint--rounded"aria-label="https://blog.csdn.net/gong_xufei/article/details/89786272">[8]</span></a></sup><sup id="fnref:9" class="footnote-ref"><a href="#fn:9" rel="footnote"><spanclass="hint--top hint--rounded"aria-label="https://blog.csdn.net/qq_39560620/article/details/105711799">[9]</span></a></sup>；</li><li>通过 <code>pyqtSignal.connect</code>分别将各个信号连接到对应的槽（处理函数）上；</li></ol><p>下面是这部分功能相关的代码。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> PyQt6.QtCore <span class="hljs-keyword">import</span> (QObject, pyqtSignal, QThread)<br><br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">SpiderThread</span>(<span class="hljs-params">QObject</span>):</span><br>    _spider_finish = pyqtSignal()<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self</span>):</span><br>        <span class="hljs-built_in">super</span>().__init__()<br>        self.flag_running = <span class="hljs-literal">False</span><br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__del__</span>(<span class="hljs-params">self</span>):</span><br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;&gt;&gt;&gt; __del__&#x27;</span>)<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">run</span>(<span class="hljs-params">self, conference_ID, save_filename, logger</span>):</span><br>        get_article_info(conference_ID, save_filename, logger)<br>        self._spider_finish.emit()<br><br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">PaperCollector</span>(<span class="hljs-params">QWidget</span>):</span><br>    _start_spider = pyqtSignal(<span class="hljs-built_in">str</span>, <span class="hljs-built_in">str</span>, logging.Logger)<br>    <br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self</span>):</span><br>        <span class="hljs-built_in">super</span>().__init__()<br>        self.initUI()<br>        <span class="hljs-comment">#sys.stdout = LogStream(newText=self.onUpdateText)</span><br><br>        self.spiderT = SpiderThread()<br>        self.thread = QThread(self)<br>        self.spiderT.moveToThread(self.thread)<br>        self._start_spider.connect(self.spiderT.run)        <span class="hljs-comment"># 只能通过信号槽启动线程处理函数</span><br>        self.spiderT._spider_finish.connect(self.finish_collect_paper)<br>        <br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">start_collect_paper</span>(<span class="hljs-params">self</span>):</span><br>        <span class="hljs-keyword">if</span> self.thread.isRunning():<br>            <span class="hljs-keyword">return</span><br>        <br>        self.startCrawling_button.setEnabled(<span class="hljs-literal">False</span>)<br>        self.startCrawling_button.setToolTip(<span class="hljs-string">&#x27;I\&#x27;m trying very hard to collect papers &gt;_&lt;&#x27;</span>)<br>        <span class="hljs-comment"># 先启动QThread子线程</span><br>        self.thread.start()<br>        <span class="hljs-comment"># 发送信号，启动线程处理函数</span><br>        <span class="hljs-comment"># 不能直接调用，否则会导致线程处理函数和主线程是在同一个线程，同样操作不了主界面</span><br>        <span class="hljs-keyword">global</span> logger<br>        self._start_spider.emit(self.conferenceID_edit.text(), self.saveFile_edit.text(), logger)<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">finish_collect_paper</span>(<span class="hljs-params">self</span>):</span><br>        self.startCrawling_button.setEnabled(<span class="hljs-literal">True</span>)<br>        self.startCrawling_button.setToolTip(<span class="hljs-string">&#x27;Click and wait for collecting published paper data ^o^&#x27;</span>)<br>        self.thread.quit()<br>        <br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">stop_collect_paper</span>(<span class="hljs-params">self</span>):</span><br>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> self.thread.isRunning():<br>            <span class="hljs-keyword">return</span><br>        self.thread.quit()      <span class="hljs-comment"># 退出</span><br>        self.thread.wait()      <span class="hljs-comment"># 回收资源</span><br>        self.show_dialog(<span class="hljs-string">&#x27;stop!&#x27;</span>)<br></code></pre></td></tr></table></figure><h3 id="流畅中止子线程">3.4 流畅中止子线程</h3><p>有时候我们需要中途停止爬虫工作，比如发现会议ID设置错误、希望先对已经爬取的部分数据进行统计分析等。在上面的实现中，尽管线程正常运行很流畅，但是如果在爬虫运行中途点击停止按钮，程序就会卡死。</p><p>在原本的爬虫脚本中，<code>get_article_info()</code>函数内部的爬虫采用了 <code>while(True)</code> 死循环，主线程中直接用<code>self.thread.quit()</code>强制退出，从控制台来看这样确实可以停掉，但是Qt窗口却总是会卡死。原因我也不太清楚，采用的解决方法是：</p><ol type="1"><li>定义一个爬虫类 <code>IEEESpider</code>，设置成员变量<code>flag_running</code>，将函数 <code>get_article_info</code>也设置为类成员函数；</li><li>将 <code>get_article_info</code> 中的循环改为<code>while(self.flag_running)</code>；</li><li>在主线程中想要停止爬虫子线程的时候，只需要首先设置<code>flag_running=False</code>，那么爬虫子线程在当前一次循环结束后就自动结束，这个时候主线程调用<code>self.thread.quit()</code> 就不会导致界面卡死。需要注意的是设置<code>flag_running=False</code> 一定要 <code>sleep</code>一段时间，以保证爬虫子线程能够结束当前循环，否则还是容易卡死。</li></ol><p>下面是这部分功能的代码。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">IEEESpider</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self</span>):</span><br>        self.flag_running = <span class="hljs-literal">False</span><br>        <br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">get_article_info</span>(<span class="hljs-params">self, conferenceID, saveFileName, logger</span>):</span><br>        <span class="hljs-keyword">while</span>(self.flag_running):<br>            <span class="hljs-keyword">pass</span><br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">SpiderThread</span>(<span class="hljs-params">QObject</span>):</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self</span>):</span><br>        <span class="hljs-built_in">super</span>().__init__()<br>        <span class="hljs-comment">#self.flag_running = False</span><br>        self.ieee_spider = IEEESpider()<br>        <br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">run</span>(<span class="hljs-params">self, conference_ID, save_filename, logger</span>):</span><br>        self.ieee_spider.flag_running = <span class="hljs-literal">True</span><br>        self.ieee_spider.get_article_info(conference_ID, save_filename, logger)<br>        self._spider_finish.emit()<br>        <br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">PaperCollector</span>(<span class="hljs-params">QWidget</span>):</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">stop_collect_paper</span>(<span class="hljs-params">self</span>):</span><br>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> self.thread.isRunning():<br>            <span class="hljs-keyword">return</span><br>        self.spiderT.ieee_spider.flag_running = <span class="hljs-literal">False</span><br>        time.sleep(<span class="hljs-number">15</span>)<br>        self.thread.quit()      <span class="hljs-comment"># 退出</span><br>        <span class="hljs-comment">#self.thread.wait()      # 回收资源</span><br>        self.show_dialog(<span class="hljs-string">&#x27;stop!&#x27;</span>)<br></code></pre></td></tr></table></figure><h3 id="增加侧边导航栏">3.5 增加侧边导航栏</h3><p>前面只有爬取论文的页面，现在我想加上数据分析的页面，那么就需要设置一个侧边导航栏，以切换两种不同的任务。</p><p>实现方式为左侧设置多个按钮，右侧添加一个<code>QTabWidget()</code>，将不同的页面设置为子标签页，通过按钮的点击回调函数切换不同的标签页<sup id="fnref:10" class="footnote-ref"><a href="#fn:10" rel="footnote"><spanclass="hint--top hint--rounded" aria-label="PyQt5侧边栏布局 • Chang Luo (luochang.ink)">[10]</span></a></sup>。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">PaperCollector</span>(<span class="hljs-params">QWidget</span>):</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">sidebarUI</span>(<span class="hljs-params">self</span>):</span><br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        Define the UI playout of sidebar.</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        self.sidebar_btn_1 = QPushButton(<span class="hljs-string">&#x27;Collector&#x27;</span>, self)<br>        self.sidebar_btn_1.clicked.connect(self.sidebar_button_1)<br>        self.sidebar_btn_2 = QPushButton(<span class="hljs-string">&#x27;Analyzer&#x27;</span>, self)<br>        self.sidebar_btn_2.clicked.connect(self.sidebar_button_2)<br>        self.sidebar_btn_3 = QPushButton(<span class="hljs-string">&#x27;Reserved&#x27;</span>, self)<br>        self.sidebar_btn_3.clicked.connect(self.sidebar_button_3)<br><br>        sidebar_layout = QVBoxLayout()<br>        sidebar_layout.addWidget(self.sidebar_btn_1)<br>        sidebar_layout.addWidget(self.sidebar_btn_2)<br>        sidebar_layout.addWidget(self.sidebar_btn_3)<br>        sidebar_layout.addStretch(<span class="hljs-number">5</span>)<br>        sidebar_layout.setSpacing(<span class="hljs-number">20</span>)<br><br>        self.sidebar_widget = QWidget()<br>        self.sidebar_widget.setLayout(sidebar_layout)<br>        <br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">sidebar_button_1</span>(<span class="hljs-params">self</span>):</span><br>        self.right_widget.setCurrentIndex(<span class="hljs-number">0</span>)<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">sidebar_button_2</span>(<span class="hljs-params">self</span>):</span><br>        self.right_widget.setCurrentIndex(<span class="hljs-number">1</span>)<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">sidebar_button_3</span>(<span class="hljs-params">self</span>):</span><br>        self.right_widget.setCurrentIndex(<span class="hljs-number">2</span>)<br>        <br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">initUI</span>(<span class="hljs-params">self</span>):</span><br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        Define the overall UI playout.</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        self.sidebarUI()<br>        self.spiderUI()<br>        self.analyzerUI()<br>        self.reservedUI()<br>        <br>        <span class="hljs-comment"># 多个标签页</span><br>        self.right_widget = QTabWidget()<br>        self.right_widget.tabBar().setObjectName(<span class="hljs-string">&quot;mainTab&quot;</span>)<br><br>        self.right_widget.addTab(self.spider_widget, <span class="hljs-string">&#x27;&#x27;</span>)<br>        self.right_widget.addTab(self.analyzer_widget, <span class="hljs-string">&#x27;&#x27;</span>)<br>        self.right_widget.addTab(self.reserved_widget, <span class="hljs-string">&#x27;&#x27;</span>)<br><br>        <span class="hljs-comment"># 隐藏标签部件的标签并初始化显示页面</span><br>        self.right_widget.setCurrentIndex(<span class="hljs-number">0</span>)<br>        self.right_widget.setStyleSheet(<span class="hljs-string">&#x27;&#x27;&#x27;QTabBar::tab&#123;width: 0; height: 0; margin: 0; padding: 0; border: none;&#125;&#x27;&#x27;&#x27;</span>)<br><br>        <span class="hljs-comment"># overall layout</span><br>        main_layout = QHBoxLayout()<br>        main_layout.addWidget(self.sidebar_widget)<br>        main_layout.addWidget(self.right_widget)<br>        main_layout.setStretch(<span class="hljs-number">0</span>, <span class="hljs-number">40</span>)<br>        main_layout.setStretch(<span class="hljs-number">1</span>, <span class="hljs-number">200</span>)<br>        self.setLayout(main_layout)<br><br>        self.setGeometry(<span class="hljs-number">300</span>, <span class="hljs-number">300</span>, <span class="hljs-number">850</span>, <span class="hljs-number">300</span>)<br>        self.setWindowTitle(<span class="hljs-string">&#x27;IEEE paper collector (by Glooow)&#x27;</span>)<br>        self.show()<br></code></pre></td></tr></table></figure><h3 id="next-...">3.6 next ...</h3><p>接下来考虑：写数据分析页面 ......</p><h1 id="referencce">Referencce</h1><p>这里关于参考文献的部分，本来我想按照下面格式来写，希望实现的效果是都像<sup id="fnref:2" class="footnote-ref"><a href="#fn:2" rel="footnote"><spanclass="hint--top hint--rounded" aria-label="PyQt中文教程 (gitbook.io)">[2]</span></a></sup><sup id="fnref:10" class="footnote-ref"><a href="#fn:10" rel="footnote"><spanclass="hint--top hint--rounded" aria-label="PyQt5侧边栏布局 • Chang Luo (luochang.ink)">[10]</span></a></sup>一样，每一条引用列出来的是超链接，而不是直接写出来链接地址，但是我发现除了第<sup id="fnref:2" class="footnote-ref"><a href="#fn:2" rel="footnote"><spanclass="hint--top hint--rounded" aria-label="PyQt中文教程 (gitbook.io)">[2]</span></a></sup><sup id="fnref:10" class="footnote-ref"><a href="#fn:10" rel="footnote"><spanclass="hint--top hint--rounded" aria-label="PyQt5侧边栏布局 • Chang Luo (luochang.ink)">[10]</span></a></sup>条，其他条这么写话都会像现在的第<sup id="fnref:7" class="footnote-ref"><a href="#fn:7" rel="footnote">&lt;spanclass="hint--top hint--rounded" aria-label="<ahref="https://blog.csdn.net/bailang_zhizun/article/details/109240670">PyQt- 使用多线程避免界面卡顿 - bailang zhizun的博客 - CSDN博客"&gt;[7]</span></a></sup>条一样，格式会乱，也不知道为什么。有人知道的话可以告诉我嘛&gt;_&lt;</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs awk">[^<span class="hljs-number">1</span>]:[Python爬虫——爬取IEEE论文 - 乐 ShareLe的博客 - CSDN博客](https:<span class="hljs-regexp">//</span>blog.csdn.net<span class="hljs-regexp">/wp7xtj98/</span>article<span class="hljs-regexp">/details/</span><span class="hljs-number">112711465</span>)<br>[^<span class="hljs-number">2</span>]:[PyQt 中文教程 (gitbook.io)](https:<span class="hljs-regexp">//m</span>aicss.gitbook.io<span class="hljs-regexp">/pyqt-chinese-tutoral/</span>)<br>[^<span class="hljs-number">3</span>]:[python日志：logging模块使用 - 知乎](https:<span class="hljs-regexp">//</span>zhuanlan.zhihu.com<span class="hljs-regexp">/p/</span><span class="hljs-number">360306588</span>)<br>[^<span class="hljs-number">4</span>]:[python3 自定义logging.Handler, Formatter, Filter模块 - 太阳花的小绿豆的博客 - CSDN博客](https:<span class="hljs-regexp">//</span>blog.csdn.net<span class="hljs-regexp">/qq_37541097/</span>article<span class="hljs-regexp">/details/</span><span class="hljs-number">108317762</span>)<br>[^<span class="hljs-number">5</span>]:[python logging output on both GUI and console - stackoverflow](https:<span class="hljs-regexp">//</span>stackoverflow.com<span class="hljs-regexp">/questions/</span><span class="hljs-number">41176319</span>/python-logging-output-on-both-gui-and-console)<br>[^<span class="hljs-number">6</span>]:[How to dynamically update QTextEdit - stackoverflow](https:<span class="hljs-regexp">//</span>stackoverflow.com<span class="hljs-regexp">/questions/</span><span class="hljs-number">24371274</span>/how-to-dynamically-update-qtextedit)<br>[^<span class="hljs-number">7</span>]:[PyQt - 使用多线程避免界面卡顿 - bailang zhizun的博客 - CSDN博客](https:<span class="hljs-regexp">//</span>blog.csdn.net<span class="hljs-regexp">/bailang_zhizun/</span>article<span class="hljs-regexp">/details/</span><span class="hljs-number">109240670</span>)<br>[^<span class="hljs-number">8</span>]:[pyqt 带单个参数<span class="hljs-regexp">/多个参数信号&amp;槽总结 - gong xufei的博客 - CSDN博客](https:/</span><span class="hljs-regexp">/blog.csdn.net/g</span>ong_xufei<span class="hljs-regexp">/article/</span>details/<span class="hljs-number">89786272</span>)<br>[^<span class="hljs-number">9</span>]:[PyQt5 pyqtSignal: 自定义信号传入的参数方法 - Mic28的博客 - CSDN博客](https:<span class="hljs-regexp">//</span>blog.csdn.net<span class="hljs-regexp">/qq_39560620/</span>article<span class="hljs-regexp">/details/</span><span class="hljs-number">105711799</span>)<br>[^<span class="hljs-number">10</span>]:[PyQt5 侧边栏布局 • Chang Luo (luochang.ink)](https:<span class="hljs-regexp">//</span>www.luochang.ink<span class="hljs-regexp">/posts/</span>pyqt5_layout_sidebar/)<br></code></pre></td></tr></table></figure><section class="footnotes"><div class="footnote-list"><ol><li><span id="fn:1"class="footnote-text"><span>https://blog.csdn.net/wp7xtj98/article/details/112711465<a href="#fnref:1" rev="footnote" class="footnote-backref">↩︎</a></span></span></li><li><span id="fn:2"class="footnote-text"><span><a href="https://maicss.gitbook.io/pyqt-chinese-tutoral/">PyQt中文教程 (gitbook.io)</a><a href="#fnref:2" rev="footnote" class="footnote-backref">↩︎</a></span></span></li><li><span id="fn:3"class="footnote-text"><span>https://zhuanlan.gitbook.io/p/360306588<a href="#fnref:3" rev="footnote" class="footnote-backref">↩︎</a></span></span></li><li><span id="fn:4"class="footnote-text"><span>https://blog.csdn.net/qq_37541097/article/details/108317762<a href="#fnref:4" rev="footnote" class="footnote-backref">↩︎</a></span></span></li><li><span id="fn:5"class="footnote-text"><span>https://stackoverflow.com/questions/41176319/python-logging-output-on-both-gui-and-console<a href="#fnref:5" rev="footnote" class="footnote-backref">↩︎</a></span></span></li><li><span id="fn:6"class="footnote-text"><span>https://stackoverflow.com/questions/24371274/how-to-dynamically-update-qtextedit<a href="#fnref:6" rev="footnote" class="footnote-backref">↩︎</a></span></span></li><li><span id="fn:7" class="footnote-text"><span><ahref="https://blog.csdn.net/bailang_zhizun/article/details/109240670">PyQt- 使用多线程避免界面卡顿 - bailang zhizun的博客 - CSDN博客</a><a href="#fnref:7" rev="footnote" class="footnote-backref">↩︎</a></span></span></li><li><span id="fn:8"class="footnote-text"><span>https://blog.csdn.net/gong_xufei/article/details/89786272<a href="#fnref:8" rev="footnote" class="footnote-backref">↩︎</a></span></span></li><li><span id="fn:9"class="footnote-text"><span>https://blog.csdn.net/qq_39560620/article/details/105711799<a href="#fnref:9" rev="footnote" class="footnote-backref">↩︎</a></span></span></li><li><span id="fn:10"class="footnote-text"><span><a href="https://www.luochang.ink/posts/pyqt5_layout_sidebar/">PyQt5侧边栏布局 • Chang Luo (luochang.ink)</a><a href="#fnref:10" rev="footnote" class="footnote-backref">↩︎</a></span></span></li></ol></div></section>]]></content>
    
    
    <categories>
      
      <category>DIY</category>
      
    </categories>
    
    
    <tags>
      
      <tag>spider</tag>
      
      <tag>PyQt</tag>
      
      <tag>多线程</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>SLAM综述</title>
    <link href="/2022/03/02/research/SLAM-survey/"/>
    <url>/2022/03/02/research/SLAM-survey/</url>
    
    <content type="html"><![CDATA[<blockquote><p>关于SLAM（simultaneous localization andmapping）问题一个很粗糙的总结。</p></blockquote><p>对于SLAM的发展历程，Leonard和Reid大佬将SLAM到目前为止的发展过程总结为三个阶段：</p><ol type="1"><li>classicalage（1986-2004）：早期阶段，SLAM问题的定义、基于概率框架的建模和求解方法；</li><li>algorithm-analysisage（2004-2015）：深入研究SLAM问题的一些性质，比如稀疏性、收敛性、一致性等，更多样、更高效的算法也被相继提出；</li><li>robust-perceptionage（2015-）：开始考虑算法的鲁棒性、可扩展性、资源约束下的高效算法、高层语义认知任务导向等；</li></ol><p>SALM系统主要包括前端和后端两部分，前端负责从传感器数据中提取特征、dataassociation（如特征提取、回环检测）等，后端负责最大后验估计、滤波等；</p><figure><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2022/slam-1.png"alt="SLAM" /><figcaption aria-hidden="true">SLAM</figcaption></figure><p>根据<strong>感知手段</strong>可以分为几类：</p><ul><li>测距测角：传感器比如毫米波雷达、声纳等；</li><li>视觉相机：各种相机，比如RGB-D相机等；需要从图像中提取特征点，例如SIFT等；纯视觉导航有专门的研究方向，即VO（VisualOdometry），VO+全局地图优化（例如回环检测）=visual SLAM；</li><li>激光雷达；</li><li>惯性导航：IMU，配合视觉传感器可以实现VIO；</li></ul><p>根据<strong>地图结构</strong>可以分为几类（地图结构与感知手段紧密相关）：</p><ul><li>基于landmarkd的，传感器通常是测距测角的，或者视觉中提取特征点；</li><li>栅格地图（2D）、点云地图（3D），主要是激光雷达；</li><li>基于边/表面的几何地图；</li></ul><p>根据<strong>求解方法</strong>可以分为几类：</p><ul><li>基于贝叶斯框架递归滤波的：如EKF、PF、Information Filter等；</li><li>基于优化的：一种是光束平差法（用于视觉，实际上是最小二乘）；另一种是图优化（graphSLAM，实际上就是概率图模型，似乎是现在的主流）；</li><li>Set Membership 类的方法、以及定性方法等；</li></ul><p>要考虑的科学问题包括：</p><ul><li>地图构建和机器人位姿估计，因此实际上是参数估计/求解问题；</li><li>多传感器数据融合，以及与已有地图信息的融合；</li><li>回环检测，纠正累积误差；</li><li>降低复杂度，比如每次只更新相关的部分地图和状态，而不是所有参数一起更新；</li><li>数据关联；</li></ul><figure><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2022/slam-2.jpg"alt="SLAM" /><figcaption aria-hidden="true">SLAM</figcaption></figure><p>除了基本的SLAM问题，还有一些发展方向：</p><ul><li>ActiveSLAM：同时考虑机器人的运动控制，与exploration-exploitation问题相关；</li><li>多机SLAM，相比于单机需要考虑的问题：<ul><li>多机协作的架构：集中式（online or offline？）、分布式；</li><li>相邻机器之间的数据交互，防止数据伦理问题，即一个数据在多个机器上重复使用多次；</li><li>每个机器的地图更新方法；</li><li>数据关联问题；</li><li>通信负载、数据压缩、地图结构优化等；</li></ul></li></ul><h2 id="reference">Reference</h2><ol type="1"><li>Dissanayake, MWM Gamini, et al. "A solution to the simultaneouslocalization and map building (SLAM) problem." <em>IEEE Transactions onrobotics and automation</em> 17.3 (2001): 229-241.</li><li>Durrant-Whyte, Hugh, and Tim Bailey. "Simultaneous localization andmapping: part I." <em>IEEE robotics &amp; automation magazine</em> 13.2(2006): 99-110.</li><li>Bailey, Tim, and Hugh Durrant-Whyte. "Simultaneous localization andmapping (SLAM): Part II." <em>IEEE robotics &amp; automationmagazine</em> 13.3 (2006): 108-117.</li><li>Bresson, Guillaume, et al. "Simultaneous localization and mapping: Asurvey of current trends in autonomous driving." <em>IEEE Transactionson Intelligent Vehicles</em> 2.3 (2017): 194-220.</li><li>Taketomi, Takafumi, Hideaki Uchiyama, and Sei Ikeda. "Visual SLAMalgorithms: A survey from 2010 to 2016." <em>IPSJ Transactions onComputer Vision and Applications</em> 9.1 (2017): 1-11.</li><li>Cadena, Cesar, et al. "Past, present, and future of simultaneouslocalization and mapping: Toward the robust-perception age." <em>IEEETransactions on robotics</em> 32.6 (2016): 1309-1332.</li></ol>]]></content>
    
    
    <categories>
      
      <category>Research</category>
      
    </categories>
    
    
    <tags>
      
      <tag>SLAM</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>我的电脑（不时更新）</title>
    <link href="/2022/01/24/software/prepare-my-pc/"/>
    <url>/2022/01/24/software/prepare-my-pc/</url>
    
    <content type="html"><![CDATA[<p>最近换了电脑，很多软件都要重装，遂记录一下自己电脑常用的软件。</p><h2 id="日常必备">1. 日常必备</h2><ul><li><strong>通讯类</strong>：微信、TIM、Foxmail；</li><li><strong>办公类</strong>：Office、Onenote、Foxit、腾讯会议；</li><li><strong>浏览器</strong>：Edge、Chrome；</li><li><strong>影音娱乐</strong>：网易云音乐、PotPlayer、Irfan View；</li><li><strong>其他</strong>：WinRAR、KeePass2；</li></ul><h2 id="学习科研">2. 学习科研</h2><ul><li><strong>编程</strong>：VSCode、Matlab、Python、Emeditor、Git；</li><li><strong>阅读器</strong>：知云文献翻译、Pdf Xodo、CAJ Viewer；</li><li><strong>写作</strong>：Typora、Texlive + Summatra、Mathpix SnippingTool、IguanaTex（ppt插件）、Aurora（word插件）；</li><li><strong>云盘</strong>：百度云盘、Seafile、坚果云；</li></ul><h2 id="效率工具">3. 效率工具</h2><ul><li>MobaXterm：远程连接工具；</li><li>向日葵：远程桌面；</li><li>Everything：文件搜索；</li><li>Calibre：电子书阅读器；</li><li>Beyond Compare：文本文件对比；</li><li>Space Sniffer：磁盘空间统计；</li><li>Captura：录屏；</li><li>Hexo：个人静态博客（需要nodejs，最好装个nvm）；</li><li>Pic Go：图床管理工具；</li><li>Gitbook：个人书籍；</li></ul>]]></content>
    
    
    <categories>
      
      <category>Software</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>【高等数值分析】Krylov子空间方法</title>
    <link href="/2022/01/24/advanced-numerical-analysis/ada-krylov/"/>
    <url>/2022/01/24/advanced-numerical-analysis/ada-krylov/</url>
    
    <content type="html"><![CDATA[<h2 id="预备理论">1. 预备理论</h2><p>现在需要求解一个大规模稀疏方程组 <spanclass="math inline">\(Ax=b\)</span>，可以用迭代法比如 Jacobi迭代法、Gauss-Seidel 迭代法等，不过这一节要讨论的是 Krylov子空间方法，核心部分是 Arnoldi 迭代。</p><span id="more"></span><h3 id="krylov-子空间">1.1 Krylov 子空间</h3><p><strong>定理（Cayley-Hamilton）</strong>：设 <spanclass="math inline">\(A\in{\mathbb C}^{n\times n}\)</span>，则 <spanclass="math inline">\(A\)</span> 的特征多项式 <spanclass="math inline">\(\chi(z)\)</span> 是 <spanclass="math inline">\(A\)</span> 的零化多项式，也即 <spanclass="math inline">\(\chi(A)=0\)</span>。</p><p>假设特征多项式 <span class="math inline">\(\chi(z)=z^n +c_{n-1}z^{n-1} + \cdots + c_1 z+ c_0=(-1)^n\operatorname{det}(A)\)</span>，那么根据 <spanclass="math inline">\(\chi(A)=0\)</span> 可以得到 <spanclass="math display">\[A^{-1} = -\frac{1}{c_0} A^{n-1} - \frac{c_{n-1}}{c_0} A^{n-2} + \cdots-\frac{c_1}{c_0} I = q_{n-1}(A)\]</span> 利用这个等式，在求解线性方程组的时候，给定任意初值 <spanclass="math inline">\(x_0\)</span>，都有 <spanclass="math inline">\(Ax^{\ast}-Ax_0=b-Ax_0 \equiv r_0\)</span>，于是<span class="math inline">\(x^{\ast} = x_0 +q_{n-1}(A)r_0\)</span>，因此理论上可以在空间 <spanclass="math display">\[\mathcal{K}=\left\{\boldsymbol{r}_{0}, A \boldsymbol{r}_{0}, \cdots,A^{m} \boldsymbol{r}_{0}, \cdots, A^{n-1} \boldsymbol{r}_{0}\right\}\]</span> 中找到方程组的准确解，但是科学与工程计算问题中 <spanclass="math inline">\(n\)</span> 可以达到 <spanclass="math inline">\(10^6\)</span>量级，直接求解代价太高。因此希望在其一个低维子空间中搜索近似解。</p><p>定义 <span class="math inline">\(m\)</span> 维 <strong>Krylov子空间</strong>为 <span class="math display">\[\mathcal{K}_{m}=\operatorname{span}\left(\boldsymbol{r}_{0}, A\boldsymbol{r}_{0}, A^{2} \boldsymbol{r}_{0}, \cdots, A^{m-1}\boldsymbol{r}_{0}\right)\]</span> 方程组求解问题转化为 <span class="math display">\[\min_{x\in x_0+{\mathcal K}_m} \Vert x^{\ast} - x\Vert.\]</span></p><h3 id="最佳逼近">1.2 最佳逼近</h3><p>现在的问题就是在何种范数意义下求解问题 <spanclass="math inline">\(\min_{x\in x_0+{\mathcal K}_m} \Vert x^{\ast} -x\Vert\)</span>。假设 <span class="math inline">\({\mathcalK}_m\)</span> 的一组基作为列向量构成矩阵 <spanclass="math inline">\(V_m\)</span>，最优解为 <spanclass="math inline">\(x_m = x_0 + V_m y^{\ast} \in x_0 + {\mathcal K}_m,~ y^{\ast}\in{\mathbb R}^{m}\)</span>。</p><h4 id="方法一最佳平方逼近">1.2.1 方法一：最佳平方逼近</h4><p>取 <span class="math inline">\(2\)</span> 范数 <spanclass="math inline">\(\min_{x\in x_0+{\mathcal K}_m} \Vert x^{\ast} -x\Vert_2\)</span>，那么根据最佳平方逼近条件（对<spanclass="math inline">\(x\)</span>求导，取零点），或者 <strong>Galerkin正交条件</strong>，可以推出<strong>法方程</strong>为 <spanclass="math display">\[\begin{align}&amp;\langle x^{\ast} - x_m, y \rangle = 0, ~ \forall y\in {\mathcalK}_m \\\iff &amp; V_m^{\rm T}(x^{\ast}-x_m) = 0\end{align}\]</span> 但是这个方法<strong>不可行</strong>！因为要求 <spanclass="math inline">\(x_m\)</span> 就需要知道 <spanclass="math inline">\(x^{\ast}\)</span>。</p><h4 id="方法二假设-a-对称正定">1.2.2 方法二：假设 <spanclass="math inline">\(A\)</span> 对称正定</h4><p>若 <span class="math inline">\(A\)</span>对称正定，那么可以改求解问题 <span class="math inline">\(\min_{x\inx_0+{\mathcal K}_m} \langle A(x-x^{\ast}),x-x^{\ast}\rangle\)</span>，根据<strong>Galerkin正交条件</strong>有法方程 <span class="math display">\[\begin{align}&amp;\langle A(x^{\ast} - x_m), y \rangle = 0, ~ \forall y\in {\mathcalK}_m \\\iff &amp; r_m = A(x^{\ast}-x_m) \perp {\mathcal K}_m \\\iff &amp; V_m^{\rm T}(r_0 - Ax_m) = 0\end{align}\]</span>这个方法<strong>可行</strong>！后面需要做两件事情：1）求出一组基 <spanclass="math inline">\(V_m\)</span>；2）解法方程。</p><blockquote><p><strong>Note</strong>：这里为了得到法方程，需要假设 <spanclass="math inline">\(A\)</span> 对称正定。但是在后面的 FOM 方法中，不论<span class="math inline">\(A\)</span> 是否正定，都基于 Galerkin条件直接采用了这一法方程来求解线性方程组。至于这么做是否有理论支持我也不太清楚，就姑且相信它是合理的。</p></blockquote><h4 id="方法三残差2范数">1.2.3 方法三：残差2范数</h4><p>当 <span class="math inline">\(A\)</span> 非奇异，不去求解 <spanclass="math inline">\(\min \Vert x^{\ast} - x\Vert\)</span>，而是求解<span class="math inline">\(\min_{x\in x_0+{\mathcal K}_m} \VertA(x^{\ast} - x)\Vert_2\)</span>，那么再次根据 <strong>Galerkin条件</strong>，可以导出<strong>法方程</strong> <spanclass="math display">\[\begin{align}&amp;\langle A(x^{\ast} - x_m), Ay \rangle = 0, ~ \forall y\in {\mathcalK}_m \\\iff &amp; r_m = A(x^{\ast}-x_m) \perp A{\mathcal K}_m \\\iff &amp; V_m^{\rm T}A^{\rm T}(r_0 - Ax_m) = 0\end{align}\]</span> 这个方法也是<strong>可行</strong>的。</p><p>不论如何，上面几种方法最后都归结为两个问题：</p><ol type="1"><li>获得 <span class="math inline">\({\mathcal K}_m\)</span> 的基底<span class="math inline">\(V_m\)</span>：Gram-Schmidt 正交化方法；</li><li>求解法方程，并且计算残差：低维线性方程组求解。</li></ol><h2 id="基底正交化">2. 基底正交化</h2><p>获得正交基底的方法主要有 Arnoldi 过程（CGS）、改进 Arnoldi过程（MGS）、以及 Lanczos 过程。名字起的很fancy，别被吓到，其实他们都只是 Gram-Schmidt 正交化方法。</p><h3 id="arnoldi-过程cgs">2.1 Arnoldi 过程（CGS）</h3><p>迭代过程可以归结为 <span class="math display">\[\begin{aligned}\boldsymbol{v}_{1} &amp;= \boldsymbol{r}_{0} / \Vert \boldsymbol{r}_{0}\Vert \\\boldsymbol{w}_{j} &amp;=A \boldsymbol{v}_{j}-\langle A\boldsymbol{v}_{j}, \boldsymbol{v}_{1}\rangle \boldsymbol{v}_{1}-\langleA \boldsymbol{v}_{j},\boldsymbol{v}_{2}\rangle  \boldsymbol{v}_{2}-\cdots-\langle A\boldsymbol{v}_{j}, \boldsymbol{v}_{j}\rangle \boldsymbol{v}_{j} \\\boldsymbol{v}_{j+1}&amp;=\frac{\boldsymbol{w}_{j}}{\left\|\boldsymbol{w}_{j}\right\|_{2}},j=1,2, \cdots \\h_{i,j} &amp;= \langle A \boldsymbol{v}_{j}, \boldsymbol{v}_{i}\rangle\end{aligned}\]</span> 得到的 <span class="math inline">\(\{ v_1, v_2, ..., v_m,...,v_n \}\)</span> 是单位正交基。由 <spanclass="math inline">\(h_{i,j}\)</span> 作为元素构成矩阵 <spanclass="math inline">\(H_m \in {\mathbb R}^{m\times m}\)</span>，可以验证<span class="math inline">\(H_m\)</span> 为 Hessenberg 阵，并且 <spanclass="math inline">\(h_{i+1,i}=\Vert \boldsymbol{w}_{i}\Vert_2\)</span>。在 <span class="math inline">\(H_m\)</span>的基础上可以定义 <span class="math inline">\(\bar{H}_m \in {\mathbbR}^{(m+1)\times m}\)</span>，也就是在最后一行下面再加一行 <spanclass="math inline">\([0,...,0,h_{m+1,m}]\)</span>。</p><figure><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2021/ada-cgs.png"alt="CGS-psudocode" /><figcaption aria-hidden="true">CGS-psudocode</figcaption></figure><p>可以验证他们满足如下等式，这三个式子在后面会频繁用到，极其重要！<span class="math display">\[\begin{align}AV_m &amp;= V_m H_m + \boldsymbol{w}_{m} \boldsymbol{e}_{m}^{\rm T} \\&amp;= V_{m+1} \bar{H}_m \\V_m^{\rm T} A V_m &amp;= H_m\end{align}\]</span> <imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2021/ada-arnoldi.png"alt="Arnoldi" /></p><h3 id="改进-arnoldi-过程mgs">2.2 改进 Arnoldi 过程（MGS）</h3><p>前面的 Arnoldi 过程在计算 <spanclass="math inline">\(\boldsymbol{w}_{j}\)</span> 的时候，相当于把 <spanclass="math inline">\(A \boldsymbol{v}_{j}\)</span> 分别计算了 <spanclass="math inline">\(j\)</span> 次投影，每次都是向一个一维的子空间<span class="math inline">\(\operatorname{span}\{ \boldsymbol{v}_{i}\}\)</span>投影，可能会有计算不稳定的问题。对其进行改进的方法如下，交换顺序之后，每次都是向一个<span class="math inline">\(n-1\)</span> 维子空间投影。</p><figure><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2021/ada-mgs.png"alt="MGS-psudocode" /><figcaption aria-hidden="true">MGS-psudocode</figcaption></figure><h3 id="lanczos过程">2.3 Lanczos过程</h3><p>是 Arnoldi 过程的特殊情况，当 <span class="math inline">\(A=A^{\rmT}\)</span>，那么 <span class="math inline">\(H_m\)</span>为三对角矩阵，那么 <spanclass="math inline">\(\boldsymbol{w}_{j}\)</span> 的计算简化为 <spanclass="math display">\[\boldsymbol{w}_{j} = A \boldsymbol{v}_{j}-\langle A \boldsymbol{v}_{j},\boldsymbol{v}_{j-1}\rangle \boldsymbol{v}_{j-1}-\langle A\boldsymbol{v}_{j}, \boldsymbol{v}_{j}\rangle \boldsymbol{v}_{j}\]</span></p><h2 id="方程组求解">3. 方程组求解</h2><p>针对上面几种不同的迭代过程，可以有不同的求解方法。</p><h3 id="全正交方法-fom">3.1 全正交方法 (FOM)</h3><p>FOM (Full orthogonalization method) 根据 Galerkin 条件，<spanclass="math inline">\(r_m\perp {\mathcal K}_m\)</span>，根据法方程 <spanclass="math inline">\(V_m^{\rm T}(r_0 - AV_my)=0\)</span>，因此有 <spanclass="math display">\[\begin{align}&amp; r_m\perp {\mathcal K}_m \iff V_m^{\rm T}(r_0 - AV_my)=0\Longrightarrow H_m y = \Vert r_0\Vert \boldsymbol{e}_1\end{align}\]</span> 伪代码为</p><figure><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2021/ada-fom.png"alt="FOM" /><figcaption aria-hidden="true">FOM</figcaption></figure><p>根据 <span class="math inline">\(x_m = x_0 + V_m y\)</span>，残差有<span class="math inline">\(r_m = r_0-AV_my=r_0-(V_m H_m +\boldsymbol{w}_{m} \boldsymbol{e}_{m}^{\rm T})y = -\boldsymbol{w}_{m}\boldsymbol{e}_{m}^{\rm T} y\)</span>。</p><h3 id="d-lanczos方法">3.2 D-Lanczos方法</h3><p>若 <span class="math inline">\(A\)</span> 对称，那么 <spanclass="math inline">\(H_m\)</span> 为三对角阵，特别地记为 <spanclass="math inline">\(T_m\)</span> <span class="math display">\[T_{m}=\left(\begin{array}{ccccc}\alpha_{1} &amp; \beta_{2} &amp; &amp; &amp; \\\beta_{2} &amp; \alpha_{2} &amp; \beta_{3} &amp; &amp; \\&amp; \ddots &amp; \ddots &amp; \ddots &amp; \\&amp; &amp; \beta_{m-1} &amp; \alpha_{m-1} &amp; \beta_{m} \\&amp; &amp; &amp; \beta_{m} &amp; \alpha_{m}\end{array}\right) \in \mathbb{R}^{m \times m}\]</span> 记 <span class="math inline">\(T_m\)</span> 的 LU 分解为 <spanclass="math display">\[T_{m}=L_{m} U_{m}=\left(\begin{array}{ccccc}1 &amp; &amp; &amp; &amp; \\\lambda_{2} &amp; 1 &amp; &amp; &amp; \\&amp; \ddots &amp; \ddots &amp; &amp; \\&amp; &amp; \lambda_{m-1} &amp; 1 &amp; \\&amp; &amp; &amp; \lambda_{m} &amp; 1\end{array}\right)\left(\begin{array}{ccccc}\eta_{1} &amp; \omega_{2} &amp; &amp; &amp; \\&amp; \eta_{2} &amp; \omega_{3} &amp; &amp; \\&amp; &amp; \ddots &amp; \ddots &amp; \\&amp; &amp; &amp; \eta_{m-1} &amp; \omega_{m} \\&amp; &amp; &amp; &amp; \eta_{m}\end{array}\right)\]</span> 其中 <spanclass="math inline">\(\omega_{m}=\beta_{m}\)</span>, <spanclass="math inline">\(\quad\lambda_{m}=\frac{\beta_{m}}{\eta_{m-1}}\)</span>, <spanclass="math inline">\(\quad \eta_{m}=\alpha_{m}-\lambda_{m}\omega_{m}\)</span>。那么根据下面这一性质，Lanczos过程可以迭代进行 <spanclass="math display">\[\begin{align}L_{m}=\left(\begin{array}{c|c}L_{m-1} &amp; \mathbf{0} \\\hline \boldsymbol{l}_{m-1}^{T} &amp; 1\end{array}\right), \quad&amp;U_{m}=\left(\begin{array}{c|c}U_{m-1} &amp; \boldsymbol{y}_{m-1} \\\hline \mathbf{0}^{T} &amp; \eta_{m}\end{array}\right) \\L_{m}^{-1} = \left(\begin{array}{c|c}L_{m-1}^{-1} &amp; \mathbf{0} \\\hline -\boldsymbol{l}_{m-1}^{T}L_{m-1}^{-1} &amp; 1\end{array}\right), \quad&amp; U_{m}^{-1}=\left(\begin{array}{c|c}U_{m-1}^{-1} &amp; -\frac{1}{\eta_m} U_{m-1}^{-1} \boldsymbol{y}_{m-1}\\\hline \mathbf{0}^{T} &amp; 1/\eta_{m}\end{array}\right)\end{align}\]</span>根据这个方法，还可以到处<strong>CG（共轭梯度）法</strong>的形式。</p><h3 id="广义极小残量法gmres">3.3 广义极小残量法（GMRES）</h3><p>Generalized minimal residual method (GMRES)实际上就是最小化参量的二范数，即 <span class="math inline">\(\min \Vertr_m \Vert_2 = \min_{x\in x_0+{\mathcal K}_m} \Vert A(x^{\ast} -x)\Vert_2\)</span>，根据 Galerkin 条件，应有 <spanclass="math inline">\(r_m\perp A{\mathcal K}_m \iff V_m^{\rm T}A^{\rmT}AV_my = V_m^{\rm T}A^{\rm T}r_0, ~ y\in{\mathbb R}^m\)</span>。</p><p>另个一思路是 <span class="math inline">\(\min\Vert r_0-AV_my\Vert =\min \Vert V_{m+1} (\Vert r_0\Vert e_1 - \bar{H}_my)\Vert = \min \Vert\Vert r_0\Vert e_1 - \bar{H}_my\Vert\)</span>，最小二乘解 <spanclass="math inline">\(\bar{H}_m^{\rm T}(\bar{H}_my - \Vert r_0\Verte_1)=0\)</span>。</p><h3 id="minres-方法">3.4 MINRES 方法</h3><p>是 GMRES 的特殊情况，当 <span class="math inline">\(A=A^{\rmT}\)</span> 的时候，<span class="math inline">\(H_m\)</span> 为三对角阵<span class="math inline">\(T_m\)</span>，<spanclass="math inline">\(\min \Vert r_m\Vert_2 = \min \Vert \Vert r_0\Verte_1 - T_m y \Vert\)</span>。</p>]]></content>
    
    
    <categories>
      
      <category>高等数值分析</category>
      
    </categories>
    
    
    <tags>
      
      <tag>线性方程组</tag>
      
      <tag>Arnoldi过程</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【随机过程2】连续参数马尔可夫链</title>
    <link href="/2022/01/24/stochastic-process-2/ch7-s1-continuous-markov/"/>
    <url>/2022/01/24/stochastic-process-2/ch7-s1-continuous-markov/</url>
    
    <content type="html"><![CDATA[<h2 id="定义与基本概念">7.1 定义与基本概念</h2><p><strong>定义</strong>：设随机过程 <spanclass="math inline">\(X=\{X(t),t\ge0\}\)</span>，状态空间 <spanclass="math inline">\(S\)</span>，对任意 <spanclass="math inline">\(0\le t_0 &lt; t_1 &lt; \cdots &lt; t_n &lt;t_{n+1}\)</span>，<span class="math inline">\(i_k\in S\)</span>，若<span class="math inline">\(P(X(T_k)=i_k,0\le k\le n) &gt; 0\)</span> 有<span class="math display">\[P(X(t_{n+1})=i_{n+1} | X(t_k)=i_k,0\le k\le n) = P(X(t_{n+1})=i_{n+1} |X(t_n)=i_n)\]</span> 则称 <span class="math inline">\(X\)</span>为<strong>连续参数的马氏链</strong>。若对任意的 <spanclass="math inline">\(s,t\ge0\)</span>，<spanclass="math inline">\(i,j\in S\)</span> 有 <span class="math display">\[P(X(s+t)=j | X(s)=i) = P(X(t)=j|X(0)=i) = P_{ij}(t)\]</span> 称 <span class="math inline">\(X\)</span>为<strong>齐次马氏链</strong>。</p><p>对于连续参数马氏链，在原点处有 <spanclass="math inline">\(P_{ij}(0)=\delta_{ij}\)</span>，因此 <spanclass="math inline">\(P(0)=I\)</span>。除此之外假设其在原点处连续，即<span class="math inline">\(\lim_{t\to 0}P_{ij}(t)=\delta_{ij},\lim_{t\to0}P(t)=I\)</span>。类比离散参数的马氏链，可以得到类似的C-K 方程 <span class="math inline">\(P(s+t)=P(s)P(t)\)</span>。</p><h2 id="转移概率矩阵">7.2 转移概率矩阵</h2><p>根据 C-K 方程可以猜测 <spanclass="math inline">\(P(t)=e^{tQ}\)</span>，泰勒展开表示为 <spanclass="math inline">\(P(t)=I + \sum_{n=1}^{\infty}\frac{t^n}{n!}Q^n\)</span>，<span class="math inline">\(P(t)\)</span>完全由 <span class="math inline">\(Q\)</span> 确定，并且有 <spanclass="math inline">\(P&#39;(0)=\lim_{t\to0}\frac{P(t)-I}{t}=Q\)</span>。</p><p>上面只是猜测，那么是否真的存在这样一个 <spanclass="math inline">\(Q\)</span> 呢？下面两个定理给出结论。</p><p><strong>定理 7.1</strong>：对 <span class="math inline">\(i\inS\)</span>，极限 <spanclass="math inline">\(-q_{ii}=\lim_{t\to0}\frac{1-P_{ii}(t)}{t}\)</span>存在，但可能是无穷。</p><p><strong>定理 7.2</strong>：对 <span class="math inline">\(i\inS\)</span>，极限 <spanclass="math inline">\(q_{ij}=\lim_{t\to0}\frac{P_{ij}(t)}{t}\)</span>存在且有限。</p><p>证明：略。</p><p><strong>Remark</strong>：实际应用中，<spanclass="math inline">\(P(t)\)</span> 很难获得，一般可以求得 <spanclass="math inline">\(Q\)</span>，此时 <spanclass="math inline">\(e^{tQ} = \lim_{n\to\infty}(I +Qt/n)^n\)</span>。如果取 <span class="math inline">\(n=2^k\)</span>的形式，只需要 <span class="math inline">\(k\)</span>次矩阵乘法即可。</p><p><strong>推论 7.1</strong>：对任意 <span class="math inline">\(i\inS\)</span>，<span class="math inline">\(0\le \sum_{i\ne j}q_{ij}\leq_{ii}\)</span>。</p><p>证明： <span class="math display">\[q_{ii}=\varliminf_{t\to0} \frac{1-P_{ii}(t)}{t} = \varliminf_{t\to0}\sum_{j\ne i}\frac{P_{ij}(t)}{t} \ge \sum_{j\nei}\varliminf_{t\to0}\frac{P_{ij}(t)}{t} = \sum_{j\ne i}q_{ij}\]</span> <strong>推论 7.2</strong>：当 <spanclass="math inline">\(S\)</span> 为有限状态空间时，<spanclass="math inline">\(\sum_{i\ne j}q_{ij}= q_{ii} &lt;\infty\)</span>。</p><h2 id="kolmogorov前向后向微分方程">7.3 Kolmogorov前向后向微分方程</h2><p><strong>定义</strong>：如果 <span class="math inline">\(Q\)</span>满足 <span class="math inline">\(\forall i\in S\)</span>，<spanclass="math inline">\(\sum_{j\ne i}q_{ij} = q_{ii} &lt;\infty\)</span>，则称 <span class="math inline">\(Q\)</span>为保守矩阵。</p><p><strong>定理 7.3</strong>：设马氏链 <spanclass="math inline">\(X=\{X(t),t\ge0\}\)</span>，<spanclass="math inline">\(Q=P&#39;(0)\)</span>，当 <spanclass="math inline">\(S\)</span> 为<strong>有限集</strong>时，<spanclass="math inline">\(P&#39;(t)=P(t)Q=QP(t)\)</span>。</p><p><strong>Remark</strong>：当 <span class="math inline">\(S\)</span>为可数状态时，前向方程与后向方程不一定成立，根据 Fatu 引理有 <spanclass="math inline">\(P&#39;(t)\ge P(t)Q,P&#39;(t)\ge QP(t)\)</span></p><p><strong>定理 7.4</strong>：当 <span class="math inline">\(S\)</span>为<strong>可列个状态</strong>，<span class="math inline">\(Q\)</span>为保守矩阵时，后向方程 <spanclass="math inline">\(P&#39;(t)=QP(t)\)</span> 成立。</p><h2 id="平稳分布与极限分布及其矩阵计算">7.4平稳分布与极限分布及其矩阵计算</h2><p>类似离散马氏链，可以定义状态的连通关系。</p><p><strong>定义</strong>：若 <span class="math inline">\(\int_0^\inftyP_{ii}(t)dt = +\infty\)</span>，则称状态 <spanclass="math inline">\(i\)</span>为<strong>常返态</strong>，否则称为非常返态。</p><p><strong>定义</strong>：设 <span class="math inline">\(i\)</span>为常返态，若 <span class="math inline">\(\lim_{t\to\infty}P_{ii}(t) &gt;0\)</span>，则称为正常返态，若 <spanclass="math inline">\(\lim_{t\to\infty}P_{ii}(t) =0\)</span>，称为零常返态。</p><p><strong>定义</strong>：若概率分布 <spanclass="math inline">\(\pi=\{\pi_i,i\in S\}\)</span> 满足 <spanclass="math inline">\(\pi=\pi P(t)\)</span>，称 <spanclass="math inline">\(\pi\)</span> 为 <spanclass="math inline">\(X\)</span> 的平稳分布。</p><p><strong>定理 7.5</strong>：设 <span class="math inline">\(X\)</span>是有限不可约连续马氏链，对任意 <span class="math inline">\(i,j\inS\)</span>，有 <spanclass="math inline">\(\lim_{t\to\infty}P_{ij}(t)=p_j\)</span>存在，且与状态 <span class="math inline">\(i\)</span> 无关。</p><p>证明：略。</p>]]></content>
    
    
    <categories>
      
      <category>随机过程2</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Markov过程</tag>
      
      <tag>平稳分布</tag>
      
      <tag>极限分布</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【随机过程2】马尔可夫过程2 | 状态空间</title>
    <link href="/2022/01/24/stochastic-process-2/ch6-s2-states/"/>
    <url>/2022/01/24/stochastic-process-2/ch6-s2-states/</url>
    
    <content type="html"><![CDATA[<h2 id="状态空间的分解">6.4 状态空间的分解</h2><p><strong>定义</strong>：设 <span class="math inline">\(A\subsetS\)</span>，若对任意 <span class="math inline">\(i\in A\)</span> 及<span class="math inline">\(j\notin A\)</span>，都有 <spanclass="math inline">\(p_{ij}=0\)</span>，称 <spanclass="math inline">\(A\)</span> 为<strong>闭集</strong>。若 <spanclass="math inline">\(A\)</span> 的状态是相通的，则 <spanclass="math inline">\(A\)</span> 为<strong>不可约</strong>的。</p><p><strong>引理 6.1</strong>：<span class="math inline">\(A\)</span>为闭集的充要条件为：任意 <span class="math inline">\(i\in A\)</span> 及<span class="math inline">\(j\notin A\)</span> 都有 <spanclass="math inline">\(p_{ij}^{(n)}=0,n\ge1\)</span>。</p><p><strong>推论</strong>：若 <span class="math inline">\(A\)</span>是闭集，对任意状态 <span class="math inline">\(i\in A\)</span> 恒有<span class="math inline">\(\sum_{j\in A}p_{ij}^{(n)}=1\)</span>。</p><blockquote><p><strong>定理 6.5</strong>：所有常返态构成一个闭集。</p><p><strong>推论</strong>：不可约马尔科夫链，所有状态都是常返的，或者所有状态都是非常返的。</p></blockquote><p><strong>定理 6.6</strong>：状态空间 <spanclass="math inline">\(S\)</span> 可以分解为 <spanclass="math inline">\(S = T\cup C = T\cup C_1 \cdots \cup C_h\cdots\)</span>，其中 <span class="math inline">\(T\)</span>表示非常返状态的集合，<span class="math inline">\(C_i\)</span>为基本的常返闭集，且有</p><ol type="1"><li>对任一确定的 <span class="math inline">\(k,C_k\)</span>中任意两个状态互通；</li><li><span class="math inline">\(C_k\cap C_l = \varnothing,\forall h\nel\)</span>。</li></ol><blockquote><p><strong>定理 6.7</strong>：有限状态马尔科夫链具有如下性质：</p><ol type="1"><li>状态空间 <span class="math inline">\(S\)</span> 可分解为 <spanclass="math inline">\(S = T\cup C = T\cup C_1 \cdots \cupC_h\)</span>，其中 <span class="math inline">\(T\)</span>表示非常返状态的集合，<span class="math inline">\(C_i\)</span>为基本的常返闭集；</li><li>非常返状态集合 <span class="math inline">\(T\)</span>一定不是闭集；</li><li>没有零常返状态；</li><li>必有正常返状态；</li><li>不可约马氏链的的状态都是正常返态；</li><li>任意闭集 <span class="math inline">\(C_i\)</span> 上的 <spanclass="math inline">\(n\)</span> 步转移矩阵为随机矩阵。</li></ol></blockquote><h2 id="极限特性与平稳分布">6.5 极限特性与平稳分布</h2><h3 id="极限特性">6.5.1 极限特性</h3><p><strong>定理 6.7</strong>：若状态 <spanclass="math inline">\(j\)</span> 为非常返态或零常返态，则对任意 <spanclass="math inline">\(i \in S\)</span>，有 <spanclass="math inline">\(\lim_{n\to\infty}p_{ij}^{(n)}=0\)</span>。</p><p><strong>推论6.7.1</strong>：若马尔科夫链有一个零常返态，则必有无穷多个零常返态。</p><h3 id="平稳分布">6.5.2 平稳分布</h3><p><strong>定义</strong>：一个定义在 <spanclass="math inline">\(S\)</span> 上的概率分布 <spanclass="math inline">\(\pi=(\pi_1,\pi_2,...,\pi_i,...)\)</span>称为马尔科夫链的平稳分布，如果有 <span class="math inline">\(\pi=\piP\)</span>。</p><p><strong>定理 6.9</strong>：若马尔科夫链是不可约的遍历链，则 <spanclass="math inline">\(\{\pi_i = 1 / \mu_i\}\)</span> 是 <spanclass="math inline">\(\pi=\pi P(\pi_i\ge0,\sum_{i\in S}\pi_i=1)\)</span>的<strong>唯一解</strong>。</p><p><strong>推论 6.9.1</strong>：不可约遍历链恒有唯一的平稳分布，且 <spanclass="math inline">\(\pi_j=\lim_{n\to\infty}p_{ij}^{(n)}\)</span>。</p><p><strong>定理 6.10</strong>：令 <spanclass="math inline">\(C_+\)</span>为马尔科夫链中全体正常返状态构成的集合，则有</p><ol type="1"><li>平稳分布不存在的充要条件为 <spanclass="math inline">\(C_+=\varnothing\)</span>；</li><li>平稳分布唯一存在的充要条件为只有一个基本正常返闭集；</li><li>若马尔科夫链有多于一个基本正常返闭集，则其平稳分布有无穷多个。</li></ol><p><strong>定理 6.11</strong>：关于有限状态的马尔科夫链</p><ol type="1"><li>有限状态马尔科夫链的平稳分布总存在；</li><li>有限不可约非周期的马尔科夫链存在唯一的平稳分布；</li><li>若有多于一个基本正常返闭集，则其平稳分布有无穷多个；</li></ol><p><em>栗子</em>（平衡方程及其应用）：对非周期正常返的离散马氏链，平稳分布存在且满足<span class="math inline">\(\pi P=\pi\)</span>，可以写成 <spanclass="math inline">\(\pi_j(1-P_{jj}) = \sum_{i\ne j,i\in S} \pi_iP_{ij}\)</span>，这被称为离散马氏链的平衡方程。左边表示从状态 <spanclass="math inline">\(j\)</span> 流出的量，右边表示从其他状态流入状态<span class="math inline">\(j\)</span>的量，在讨论一些实际工程问题时，可以借助平衡方程求解系统平稳分布。</p><h2 id="转移矩阵的平均极限">6.6 转移矩阵的平均极限</h2><p>一般情况下，<span class="math inline">\(n\to\infty\)</span> 时 <spanclass="math inline">\(P^n\)</span> 的极限未必存在，主要是因为 <spanclass="math inline">\(P^n\)</span>可能有周期性。为了消除周期性，最直接的方法就是取平均。</p><p><strong>定理 6.12</strong>：设 <span class="math inline">\(P\)</span>为有限马氏链的转移矩阵，则 <spanclass="math inline">\(L:=\lim_{n\to\infty}\frac{1}{n}(I+P+\cdots+P^{n-1})\)</span> 存在，且满足 <spanclass="math inline">\(LP = PL = L = L^2\)</span>。</p><p><strong>推论</strong>：设有限不可约马氏链的转移矩阵为 <spanclass="math inline">\(P\)</span>，平稳分布为 <spanclass="math inline">\(\pi\)</span>，<spanclass="math inline">\(L=(l_{ij})=\lim_{n\to\infty}\frac{1}{n}(I+P+\cdots+P^{n-1})\)</span>，则 <spanclass="math inline">\(\pi L=\pi\)</span>，且 <spanclass="math inline">\(\pi_j=l_{ij} / \sum_{k=1}^N l_{ik}\)</span>。</p><p><strong>定理 6.13</strong>：设 <span class="math inline">\(P\)</span>是有 <span class="math inline">\(m\)</span>个状态的不可约马氏链的转移矩阵，则平稳分布概率为</p><p><span class="math inline">\(\pi = (1,...,1)(I-P+{\mathbb1})^{-1}\)</span>，其中 <span class="math inline">\({\mathbb 1}\)</span>为全 1 的 <span class="math inline">\(m\times m\)</span> 矩阵。</p><p>证明：关键是要证明矩阵 <span class="math inline">\((I-P+{\mathbb1})\)</span> 可逆。</p><blockquote><p><strong>Note</strong>：马尔科夫链在随机过程里面是比较简单的部分，大部分结论都很直观，凭直观感觉就能得到。</p><p>实际上这章马尔科夫链的主要内容就是在讨论几种状态：非常返态、正常返态、零常返态。归结起来，现在想象一个马尔可夫链的状态转移图，有很多节点（状态）和有向边（转移概率）。</p><p>首先对于几种状态的区别：</p><ol type="1"><li>正常返态就是说从一个状态开始，经过有限步总能再次回到当前状态，并且这个平均回转时间是有限的（中华好男人，常回家看看）；</li><li>零常返态就是说从一个状态开始，经过有限步总能再次回到当前状态，但这个平均回转时间是无穷的（渣男海王，开空头支票）；</li><li>非常返态就是说从一个状态开始，经过有限步之后就再也不能返回当前状态了（恩断义绝）；</li></ol><p>如何判断每个节点的状态类型，基本只需要下面两条原则：</p><ol type="1"><li>如果两个状态相通，那么他们同为常返态或非常返态。<ol type="1"><li>那么如果两个节点之间有双向边，他们一定是同一类型态；要出现常返态和非常返态的区别一定是由于单向边的存在；</li><li>进一步的，一个连通子图里面的所有状态一定是同一类型；要出现常返态和非常返态的区别，一定是两个连通子图<span class="math inline">\(A,B\)</span> 之间只有单向边；</li><li>假如只有 <span class="math inline">\(A\)</span> 到 <spanclass="math inline">\(B\)</span> 的单向边，那么连通子图 <spanclass="math inline">\(B\)</span> 中的节点一定都是非常返态。</li></ol></li><li>零常返态只可能出现在状态个数为无穷的时候。</li></ol><p>极限分布/平稳分布是怎样：</p><ol type="1"><li>极限分布与初始分布有关，平稳分布只与状态转移链本身的性质有关；</li><li>由于最终一定会收敛到常返态，平稳分布一定是只对常返态非零；</li><li>只考虑常返态的集合，平稳分布就是转移概率矩阵 <spanclass="math inline">\(P\)</span> 的左特征向量；</li></ol><p>下面讲个故事。</p><p>把概率想象成手里的money，初始分布概率就是每个节点手里的本钱；一个（不可约的）连通子图就是一个家族，家族里的每个人之间可以相互借钱来回周转；不同连通子图就是不同的家族。</p><p>（不可约的）连通子图内部，一个家族里面的钱再怎么周转也都是内部消化，每个人借出去的总能还回来，所以钱不会消失，总会有一个平衡。</p><p>如果有两个连通子图，并且它们之间只有单向边，相当于 <spanclass="math inline">\(A\)</span> 总是把一部分 money 白送给 <spanclass="math inline">\(B\)</span>，再厚的家底也得被掏空了。最后 <spanclass="math inline">\(A\)</span>家族就破产了（非常返态，不是闭集）。</p><p>如果 <span class="math inline">\(B\)</span>家族的钱只进不出，也就是没有向外的有向边（闭集），那么他们就会完成资本的积累，最终钱总会聚集到他们那里（常返态）。</p><p>如果有两个连通子图，他们相互之间没有任何边相联系，那就是他们互不打扰，两不相欠（各自有一个平稳分布）。100年之后各自有多少钱取决于现在各自有多少钱，不多不少（联合组成无穷个平稳分布，因为初始分布有无穷种情况）。</p></blockquote>]]></content>
    
    
    <categories>
      
      <category>随机过程2</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Markov过程</tag>
      
      <tag>平稳分布</tag>
      
      <tag>极限分布</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【随机过程2】马尔可夫过程1 | 基本概念</title>
    <link href="/2022/01/24/stochastic-process-2/ch6-s1-concepts/"/>
    <url>/2022/01/24/stochastic-process-2/ch6-s1-concepts/</url>
    
    <content type="html"><![CDATA[<h2 id="基本概念">6.1 基本概念</h2><p>马尔科夫链的定义很常见了，在此不再赘述。简单而言就是 <spanclass="math display">\[P(X_{n+1}=s_{n+1}|X_0=s_0,...,X_{n}=s_n) = P(X_{n+1}=s_{n+1}|X_{n}=s_n)\]</span>还可以定义一步转移概率、转移概率矩。如果转移概率不随时间变化，就是时间齐次马尔科夫链。</p><p><strong>定理 6.1</strong>：设随机过程 <spanclass="math inline">\(\{X_n,n\ge0\}\)</span> 满足</p><ol type="1"><li><span class="math inline">\(X_n =f(X_{n-1},\xi_n)(n\ge1)\)</span>，其中 <spanclass="math inline">\(f:S\times S\to S\)</span>；</li><li><span class="math inline">\(\{\xi_n,n\ge1 \}\)</span>为独立同分布随机序列，且 <span class="math inline">\(X_0\)</span> 与<span class="math inline">\(\{\xi_n,n\ge1\}\)</span> 也相互独立；</li></ol><p>则 <span class="math inline">\(\{X_n,n\ge0\}\)</span>是马尔科夫链，并且一步转移概率为 <spanclass="math inline">\(p_{ij}=P(f(i,\xi_n)=j)\)</span>.</p><p>证明：根据条件 1 可知 <span class="math inline">\(\xi_{n+1}\)</span>与 <span class="math inline">\(X_0,...,X_n\)</span> 独立，从而有 <spanclass="math display">\[\begin{aligned}&amp;P(X_{n+1}=s_{n+1} | X_0=s_0,...,X_n=s_n) \\=&amp; P(f(X_n,\xi_{n+1})=s_{n+1} | X_0=s_0,...,X_n=s_n) \\=&amp; P(f(s_n,\xi_{n+1})=s_{n+1}) = P(X_{n+1}=s_{n+1} | X_n = s_n)\end{aligned}\]</span> 证毕。</p><blockquote><p><strong>Note</strong>：这个定理实际上是在说 <spanclass="math inline">\(X_n\)</span> 只由 <spanclass="math inline">\(X_{n-1}\)</span> 和一个与之完全独立的随机变量<span class="math inline">\(\xi_n\)</span>决定，这与马尔可夫性质异曲同工。并且如果 <spanclass="math inline">\(\xi_n,n\ge1\)</span>同分布，那么这个马尔可夫过程是时间齐次的，否则是非齐次的。</p><p>如果把随机变量看作是信息的话，<spanclass="math inline">\(\xi_n\)</span> 就可以看成是从 <spanclass="math inline">\(X_{n-1}\)</span> 到 <spanclass="math inline">\(X_n\)</span> 变化的信息量。</p></blockquote><p><em>栗子 1</em>：设 <spanclass="math inline">\(\{\xi_n,n\ge0\}\)</span>独立同分布，取值为非负整数，<spanclass="math inline">\(P(\xi_n=i)=a_i\)</span>。令 <spanclass="math inline">\(X_0=0,X_n=\sum_{k=1}^n \xi_k\)</span>，则易证<span class="math inline">\(\{X_n,n\ge0\}\)</span>是一个马尔科夫链，因为有 <span class="math inline">\(f(X_n,\xi_{n+1}) =X_n+\xi_{n+1}\)</span>。还可以得到转移概率为 <spanclass="math inline">\(p_{ij} = \begin{cases}a_{j-i}, &amp; i\ge i \\ 0,&amp; i &lt; i \end{cases}.\)</span></p><p><em>栗子2</em>（带吸收壁的随机游动）：对称随机游动，每次只能向左或向右移动一个单位，或者原地不动，随机移动限制在<span class="math inline">\(S=\{0,1,...,b\}\)</span> 内。用 <spanclass="math inline">\(\xi_n\)</span> 表示第 <spanclass="math inline">\(n\)</span> 次移动的距离，<spanclass="math inline">\(X_n\)</span> 为 <spanclass="math inline">\(n\)</span> 次移动后的位置，则 <spanclass="math inline">\(X_{n+1} = f(X_n,\xi_{n+1}) = X_n +(1-\delta(X_n-b)-\delta(X_n))\xi_{n+1}\)</span>。</p><p><em>栗子3</em>（G/M/1排队模型）：G表示顾客到达服务台的时间间隔，一般假设为独立同分布，分布函数为<spanclass="math inline">\(G(x)\)</span>；M表示服务时间，假设为独立同指数分布，且与顾客到达过程独立；1表示单个服务员。</p><p>记 <span class="math inline">\(X_n\)</span> 表示第 <spanclass="math inline">\(n\)</span> 个顾客到达服务台时系统内的顾客数，<spanclass="math inline">\(T_n\)</span> 表示第 <spanclass="math inline">\(n\)</span> 个顾客到达时刻。易证 <spanclass="math inline">\(X_n\)</span> 为一个马尔科夫链。</p><p>各顾客服务时间独立，且服从参数为 <spanclass="math inline">\(\mu\)</span> 的指数分布，<spanclass="math inline">\((0,t)\)</span> 时间内服务完的顾客服从参数为 <spanclass="math inline">\(\mu\)</span> 的泊松分布，因此 <spanclass="math display">\[P(X_{n+1}=i+1-j | X_n=i) = \int_0^\infty e^{-\mu t}\frac{(\mu t)^j}{j!}dG(t)\]</span></p><h2 id="转移概率矩阵">6.2 转移概率矩阵</h2><p><strong>定义</strong>：若 <span class="math inline">\(a_{ij}\ge0, ~i,j\in S\)</span> 且满足 <span class="math inline">\(\sum_{j\in S}a_{ij} = 1\)</span>，则称矩阵 <spanclass="math inline">\(A=(a_{ij})\)</span> 为随机矩阵。</p><p>记 <span class="math inline">\(\pi_i(n)=P(X_n=i)\)</span>，向量 <spanclass="math inline">\(\pi(n)=(\pi_1(n),\pi_2(n),...)\)</span> 表示 <spanclass="math inline">\(n\)</span>时刻的概率分布向量。一个马尔科夫链的性质完全由初始分布向量和一步转移概率矩阵决定。</p><p><strong>定理 6.2（C-K方程）</strong>：<spanclass="math inline">\(P^{(m+n)} = P^{(m)} P^{(n)}\)</span>.</p><p><strong>Remark</strong>：上面的C-K方程可以联想到卷积形式，即 <spanclass="math inline">\(P_{ij}^{(n)}=\sum_{k}P_{ik}^{(l)}P_{kj}^{(n-l)}\)</span>，于是又可以联想到用傅里叶变换/ z变换进行处理，以避免卷积。</p><h2 id="markov链状态的分类">6.3 Markov链状态的分类</h2><h3 id="状态分类">6.3.1 状态分类</h3><p><strong>定义</strong>：对于 <span class="math inline">\(i,j\inS\)</span>，若存在自然数 <span class="math inline">\(n\)</span> 使得<span class="math inline">\(p_{ij}^{(n)} &gt; 0\)</span>，则称自状态<span class="math inline">\(i\)</span> 出发可达状态 <spanclass="math inline">\(j\)</span>，记为 <span class="math inline">\(i\toj\)</span>。若 <span class="math inline">\(i\to j\)</span> 且 <spanclass="math inline">\(j\to i\)</span>，则称 <spanclass="math inline">\(i,j\)</span> <strong>相通</strong>，记为 <spanclass="math inline">\(i\leftrightarrow j\)</span>。如果 Markov链的任意两个状态都相通，则称为<strong>不可约链</strong>。</p><p><strong>定义</strong>：<strong>首达时间</strong> <spanclass="math display">\[\tau_{ij}=\min \{n:n\ge1,X_n=j,X_0=i \}\]</span> 若右边为空集，则令 <spanclass="math inline">\(\tau_{ij}=\infty\)</span>。</p><p><strong>定义</strong>：<strong>首达概率</strong> <spanclass="math display">\[f_{ij}^{(n)}=P(\tau_{ij}=n | X_0=i)=P(X_n=j,X_k\ne j,1\le k\le n-1 |X_0=i)\]</span> <span class="math inline">\(f_{ij}=\sum_{n=1}^\inftyf_{ij}^{(n)}\)</span> 表示从 <span class="math inline">\(i\)</span>出发，经有限步首次到达 <span class="math inline">\(j\)</span>的概率。</p><p><strong>定义</strong>：若 <spanclass="math inline">\(f_{ii}=1\)</span>，则称 <spanclass="math inline">\(i\)</span> 为<strong>常返态</strong>；若 <spanclass="math inline">\(f_{ii} &lt; 1\)</span>，称状态 <spanclass="math inline">\(i\)</span> 为非常返态。</p><p><strong>定义</strong>：若 <spanclass="math inline">\(f_{ii}=1\)</span>，此时定义 <spanclass="math inline">\(\mu_i=\sum_{n=1}^\infty nf_{ii}^{(n)}\)</span>，则<span class="math inline">\(\mu_i\)</span> 表示从状态 <spanclass="math inline">\(i\)</span> 出发再回到状态 <spanclass="math inline">\(i\)</span> 的<strong>平均回转时间</strong>。若<span class="math inline">\(\mu_i &lt; \infty\)</span> 称 <spanclass="math inline">\(i\)</span> 为<strong>正常返态</strong>；若 <spanclass="math inline">\(\mu_i=\infty\)</span>称为<strong>零常返态</strong>。</p><p><strong>定义</strong>：若集合 <spanclass="math inline">\(\{n:n\ge1,p_{ii}^{(n)} &gt;0\}\ne\varnothing\)</span>，称该数集的最大公约数 <spanclass="math inline">\(d(i)\)</span> 为状态 <spanclass="math inline">\(i\)</span> 的周期。若 <spanclass="math inline">\(d(i) &gt; 1\)</span> 称状态 <spanclass="math inline">\(i\)</span> 为<strong>周期</strong>的；若 <spanclass="math inline">\(d(i)=1\)</span>称为<strong>非周期</strong>的。</p><p><strong>定义</strong>：若状态 <span class="math inline">\(i\)</span>为正常返态且为非周期的，则称状态 <span class="math inline">\(i\)</span>为<strong>遍历状态</strong>（ergodic state）。</p><h3 id="一些基本关系式">6.3.2 一些基本关系式</h3><p><strong>定理 6.3</strong>：对 <span class="math inline">\(\foralli,j\in S,n\ge1\)</span> 有</p><ol type="1"><li><span class="math inline">\(p_{ij}^{(n)} = \sum_{l=1}^nf_{ij}^{(l)}p_{jj}^{(n-l)}\)</span></li><li><span class="math inline">\(f_{ij}^{(n)} = \sum_{k\nej}p_{ik}f_{kj}^{(n-1)}I_{\{n &gt; 1\}} + p_{ij}I_{\{n=1\}}\)</span>.</li></ol><p>下面给出一些关于该定理的讨论。</p><p><strong>Discussion（常返性判定准则）</strong>：对于特殊情况 <spanclass="math inline">\(i=j\)</span> 时，上面的第 1 条变成 <spanclass="math inline">\(p_{ii}^{(n)} = \sum_{l=1}^nf_{ii}^{(l)}p_{ii}^{(n-l)}\)</span>，这是卷积的形式，取 z 变换 <spanclass="math inline">\(P_i(z)=\sum_{n=1}^{\infty}p_{ii}^{(n)}z^{-n}\)</span>，<spanclass="math inline">\(F_i(z)=\sum_{n=1}^{\infty}f_{ii}^{(n)}z^{-n}\)</span>，那么根据上式有<span class="math inline">\(P_i(z)=1+F_i(z)P_i(z)\)</span>，从而 <spanclass="math inline">\(P_i(z)=\frac{1}{1-F_i(z)}\)</span>。当 <spanclass="math inline">\(z\to1\)</span>时，有 <spanclass="math inline">\(P_i(z)\to\sum_{n=1}^{\infty}p_{ii}^{(n)}\)</span>，<spanclass="math inline">\(F_i(z)\to \sum_{n=1}^{\infty}f_{ii}^{(n)} =f_{ii}\)</span>。</p><p><strong>推论 6.3.1</strong>：状态 <spanclass="math inline">\(i\)</span> 为常返的充要条件为 <spanclass="math inline">\(\sum_{n=1}^{\infty}p_{ii}^{(n)}=+\infty\)</span>；状态<span class="math inline">\(i\)</span> 非常返的充要条件为 <spanclass="math inline">\(\sum_{n=1}^{\infty}p_{ii}^{(n)} &lt;\infty\)</span>。</p><p>如果记 <span class="math inline">\(I_n(i)=\begin{cases}0,&amp;X_n\nei \\ 1,&amp; X_n=i \end{cases}\)</span>，<spanclass="math inline">\(S(i)=\sum_{n=1}^\infty I_n(i)\)</span> 为到达状态<span class="math inline">\(i\)</span> 的次数，那么 <spanclass="math inline">\({\mathbb E}[S(i) |X_0=i]=\sum_{n=1}^{\infty}p_{ii}^{(n)}\)</span> 即表示从状态 <spanclass="math inline">\(i\)</span> 出发返回 <spanclass="math inline">\(i\)</span> 的平均次数。当 <spanclass="math inline">\(i\)</span> 为常返态，直观上即平均返回 <spanclass="math inline">\(i\)</span>的次数为无穷，与上面的推论是一致的。对于非常返态，平均返回次数有限。</p><p><strong>Discussion（<spanclass="math inline">\(p_{ii}^{(n)}\)</span>与正常返、零常返的关系）</strong>：</p><p>（1）当状态是非周期的，定义 <spanclass="math inline">\(v_n=p_{ii}^{(n)} - p_{ii}^{(n-1)},n &gt;1\)</span>，<spanclass="math inline">\(v_0=p_{ii}^{(0)}\)</span>，于是有 <spanclass="math inline">\(V(z)=\sum_{n=0}^{\infty} v_nz^{-n} =\frac{1-z^{-1} }{1-F_i(z)}\)</span>，利用洛必达法则有 <spanclass="math inline">\(\lim_{z\to 1}V(z) = -1/F_i&#39;(1) =1/\mu_i\)</span>。另一方面 <spanclass="math inline">\(\lim_{z\to1}V(z)=\lim_{n\to\infty}\sum_{k=0}^\inftyv_k=\lim_{n\to\infty} p_{ii}^{(n)}\)</span>，因此有 <spanclass="math display">\[\lim_{n\to\infty} p_{ii}^{(n)}=1/\mu_i\]</span></p><blockquote><p>根据正常返和零常返的定义知道：</p><p>当 <span class="math inline">\(i\)</span> 是正常返时，<spanclass="math inline">\(\lim_{n\to\infty}p_{ii}^{(n)}=1/\mu_i\ne0\)</span>；</p><p>当 <span class="math inline">\(i\)</span> 是零常返时，<spanclass="math inline">\(\lim_{n\to\infty}p_{ii}^{(n)}=1/\mu_i=0\)</span>。</p></blockquote><p>（2）当状态是周期的，记状态 <span class="math inline">\(i\)</span>的周期为 <span class="math inline">\(T\)</span>，当 <spanclass="math inline">\(n\)</span> 不是 <spanclass="math inline">\(T\)</span> 的整数倍时有 <spanclass="math inline">\(f_{ii}^{(n)}=0\)</span>，<spanclass="math inline">\(F_i(z)=\sum_{k=0}^\inftyf_{ii}^{(kT)}z^{-kT}=\psi(z^T)\)</span>，相应的 <spanclass="math inline">\(P_i(z)=\frac{1}{1-\psi(z^T)}\)</span>。类似非周期情况的讨论可以得到<span class="math display">\[p_{ii}^{(nT)}\to T/\mu_i\]</span></p><blockquote><p>当 <span class="math inline">\(i\)</span> 是正常返时，<spanclass="math inline">\(\lim_{n\to\infty}p_{ii}^{(nT)}=T/\mu_i\ne0\)</span>，<spanclass="math inline">\(\lim_{n\to\infty} p_{ii}^{(nT+k)}=0,0 &lt; k &lt;T\)</span>；</p><p>当 <span class="math inline">\(i\)</span> 是零常返时，<spanclass="math inline">\(\lim_{n\to\infty}p_{ii}^{(n)}=1/\mu_i=0\)</span>。</p></blockquote><p><strong>Discussion（<spanclass="math inline">\(p_{ij}^{(n)}\)</span>与正常返、零常返的关系）</strong>：由于<span class="math inline">\(p_{ij}^{(n)} = \sum_{l=1}^nf_{ij}^{(l)}p_{jj}^{(n-l)}\)</span>，定义相应的 z 变换可以得到 <spanclass="math inline">\(P_{ij}(z)=F_{ij}(z)P_j(z) =\frac{F_{ij}(z)}{1-F_j(z)}\)</span>。当 <spanclass="math inline">\(j\)</span> 为常返态时，利用洛必达法则有 <spanclass="math inline">\(\lim_{z\to1+}(1-z^{-1})P_{ij}(z) =\lim_{z\to1+}\frac{1}{F_j&#39;(z)}\lim_{z\to1+}F_{ij}(z) =f_{ij}/\mu_j\)</span>，而左端等于（利用Hardy-Littlewood引理） <spanclass="math inline">\(\lim_{z\to1+}(1-z^{-1})P_{ij}(z) =\lim_{n\to\infty} \frac{1}{n+1}\sum_{k=0}^\inftyp_{ij}^{(k)}\)</span>，因此有 <span class="math display">\[\lim_{n\to\infty} \frac{1}{n+1}\sum_{k=0}^\infty p_{ij}^{(k)} =\frac{f_{ij} }{\mu_j}\]</span></p><blockquote><p>当 <span class="math inline">\(j\)</span> 是正常返时，<spanclass="math inline">\(\lim_{n\to\infty} \frac{1}{n+1}\sum_{k=0}^\inftyp_{ij}^{(k)} = {f_{ij} }/{\mu_j}\)</span> 为有限值；</p><p>当 <span class="math inline">\(j\)</span> 是零常返时，<spanclass="math inline">\(\lim_{n\to\infty} \frac{1}{n+1}\sum_{k=0}^\inftyp_{ij}^{(k)}=0\)</span>。</p></blockquote><h3 id="状态间的等价关系">6.3.3 状态间的等价关系</h3><p>对马尔科夫链而言，状态互通是一种等价关系，对于状态进行归类有助于简化后续分析过程。</p><p><strong>定理 6.4</strong>：</p><ol type="1"><li>若状态 <span class="math inline">\(i\)</span> 常返，并且 <spanclass="math inline">\(i\to j\)</span>，则状态 <spanclass="math inline">\(j\)</span> 也是常返的，并且 <spanclass="math inline">\(f_{ji}=1\)</span>；</li><li>如果 <span class="math inline">\(i\leftrightarrow j\)</span>，则状态<span class="math inline">\(i,j\)</span>同为常返或非常返态；若为常返态，则他们同为正常返或零常返；</li><li>如果 <span class="math inline">\(i\leftrightarrow j\)</span>，则状态<span class="math inline">\(i,j\)</span> 有相同的周期。</li></ol><p>证明：（1）存在 <span class="math inline">\(N\)</span> 使得 <spanclass="math inline">\(p_{ij}^{(N)} &gt; 0\)</span>，从 <spanclass="math inline">\(i\)</span> 出发到 <spanclass="math inline">\(j\)</span> 不返回 <spanclass="math inline">\(i\)</span> 的概率为 <spanclass="math inline">\(p_{ij}^{(N)}(1-f_{ji})=0\)</span>，因此 <spanclass="math inline">\(f_{ji}=1\)</span>。由于 <spanclass="math inline">\(i\leftrightarrow j\)</span>，存在 <spanclass="math inline">\(N_1,N_2\)</span> 有 <spanclass="math inline">\(p_{ij}^{(N_1)} &gt; 0,p_{ji}^{(N_2)} &gt;0\)</span>，那么 <span class="math inline">\(p_{jj}^{(N_1+n+N_2)} \gep_{ij}^{(N_1)}p_{ii}^{(n)}p_{ji}^{(N_2)}=abp_{ii}^{(n)}\)</span>，因此有<span class="math inline">\(\sum_{n=0}^{\infty} p_{jj}^{(n)} =\infty\)</span>，因此状态 <span class="math inline">\(j\)</span>是常返的。</p><p>（2，3）略。</p>]]></content>
    
    
    <categories>
      
      <category>随机过程2</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Markov过程</tag>
      
      <tag>常返</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【随机过程2】布朗运动2 | 推广</title>
    <link href="/2022/01/24/stochastic-process-2/ch5-s2-brown-extension/"/>
    <url>/2022/01/24/stochastic-process-2/ch5-s2-brown-extension/</url>
    
    <content type="html"><![CDATA[<h2 id="最大值与首中时的分布特性">5.4 最大值与首中时的分布特性</h2><p>设 <span class="math inline">\(\{B(t),t\ge0\}\)</span>是标准布朗运动，不妨设 <span class="math inline">\(B(0)=0\)</span>。</p><p><strong>定义</strong>：首次击中 <spanclass="math inline">\(a\)</span> 的时间 <spanclass="math inline">\(\tau_a=\inf\{t:t\ge0,B(t)=a\}\)</span></p><span id="more"></span><p><strong>定义</strong>：对 <span class="math inline">\(\forall t &gt;0, M(t)=\max_{0\le u\le t}B(u)\)</span> 表示 <spanclass="math inline">\([0,t]\)</span> 上的最大值。</p><p>当 <span class="math inline">\(a &gt; 0\)</span> 时，显然存在等价关系<span class="math inline">\(\{\tau_a \le t\} = \{M(t) \gea\}\)</span>，因此有 <span class="math inline">\(P(\tau_a \le t) =P(M(t) \ge a)\)</span>。</p><p><strong>Remark</strong>：事实上，这与泊松过程中定义的 <spanclass="math inline">\(\{S_n\le t\} = \{N(t)\ge n\}\)</span>类似。主要差别在于泊松过程中讨论离散点情况，这里讨论连续情况。</p><p><strong>定理 5.6</strong>：对任意 <spanclass="math inline">\(a&gt;0\)</span>，<spanclass="math inline">\(M(t)\)</span> 和 <spanclass="math inline">\(\tau_a\)</span> 的分布密度函数分别为 <spanclass="math display">\[\begin{aligned}f_{M(t)}(a) &amp;= \sqrt{\frac{2}{\pi t} } e^{-a^2/ 2t}I_{[0,\infty)}(a) \\f_{\tau_a}(t) &amp;= \frac{a}{\sqrt{2\pi} } e^{-a^2/2t} t^{-3/2}, \quadt &gt; 0\end{aligned}\]</span> <span class="math inline">\(\tau_a\)</span> 的 Laplace 变换为<span class="math inline">\({\mathbb E}[\exp(-s\tau_a)] =e^{-\sqrt{2s}a}, ~ s&gt;0\)</span>。</p><p>证明：<span class="math inline">\(P(B(t)\ge a) = P(B(t\ge a | \tau_a\le t))P(\tau_a \le t)\)</span>，由于 <spanclass="math inline">\(P(B(t)\ge a) | \tau_a\le t) = P(B(t)&lt; a) |\tau_a\le t)=1/2\)</span>，因此可以得到 <spanclass="math inline">\(P(M(t)\ge a) = P(\tau_a \le t) = 2P(B(t)\gea)=\frac{2}{\sqrt{2\pi t} }\int_a^{\infty} e^{-x^2 /2t}dx\)</span>。于是 <spanclass="math inline">\(f_{M(t)}(a)={d(1-P(M(t)\ge a))} /{da}\)</span>，<span class="math inline">\(f_{\tau_a}(t) = d(P(\tau_a\le t)) / da\)</span>，证毕。</p><p>利用上述定理可以到如下结果：</p><ol type="1"><li><span class="math inline">\(\tau_a\)</span> 几乎处处有限，即 <spanclass="math inline">\(P(\tau_a &lt; \infty)=1\)</span>；</li><li><span class="math inline">\({\mathbb E}\tau_a =\infty\)</span>。</li></ol><p>证明：1）<span class="math inline">\(P(\tau_a&lt;\infty) =\lim_{t\to\infty}=P(\tau_a \le t) = \lim_{t\to\infty}\frac{2}{\sqrt{2\pi} }\int_{a/\sqrt{t} }^{\infty} e^{-u^2/2}du =1\)</span>；2）<span class="math inline">\({\mathbbE}[\exp(-s\tau_a)]=e^{-\sqrt{2s}a}\)</span>，两边对 <spanclass="math inline">\(s\)</span> 求导得到 <spanclass="math inline">\({\mathbb E}[\tau_a \exp(-s\tau_a)] =\frac{\sqrt{2} }{2} a s^{-1/2} e^{-\sqrt{2s}a}\)</span>，令 <spanclass="math inline">\(s\to 0\)</span> 即可得到 <spanclass="math inline">\({\mathbb E}\tau_a = \infty\)</span>，证毕。</p><p><em>栗子 5.1</em>：</p><p><strong>定理 5.7</strong>：设 <spanclass="math inline">\(\{B(t)\}\)</span> 为标准布朗运动，<spanclass="math inline">\(\forall a &gt; 0, y\ge0\)</span> 有 <spanclass="math inline">\(P(B(t)\le a-y, M(t)\ge a) = P(B(t) \gea+y)\)</span></p><p>证明：根据反射性定义 <span class="math inline">\(B^{\ast}(t) =2a-B(t)\)</span>，则有 <span class="math inline">\(\tau_a =\tau^{\ast}_a = \inf\{B^{\ast}(t)=a\}\)</span>，又由于 <spanclass="math inline">\(\{M(t)\ge a\} = \{\tau_a \le t\}\)</span>，于是有<span class="math display">\[\begin{aligned}P(B(t)\le a-y, M(t)\ge a) &amp;= P(B(t)\le a-y, \tau_a\le t) \\&amp;= P(B^{\ast}(t) \le a-y, \tau_a \le t) \\&amp;= P(B(t) \ge a+y, \tau_a\le t) \\&amp;= P(B(t)\ge a+y)\end{aligned}\]</span> <strong>推论 5.7.1</strong>：设 <spanclass="math inline">\(\{B(t)\}\)</span> 为标准布朗运动，<spanclass="math inline">\(\forall a &gt; 0\)</span> 有 <spanclass="math inline">\(P(M(t)\ge a) = 2P(B(t)\ge a) = P(|B(t)|\gea)\)</span>.</p><p><strong>推论 5.7.2</strong>：<span class="math inline">\(\forall \xi&gt; 0, x\le\xi\)</span>，<span class="math inline">\(M(t)\)</span> 和<span class="math inline">\(B(t)\)</span> 的联合分布密度函数为 <spanclass="math inline">\(f_{M,B}(\xi,x) = \sqrt{\frac{2}{\pi}}(\frac{2\xi-x}{t^{3/2} }) \exp(-(2\xi-x)^2/2t)I_{[0,\infty)}(\xi)I_{(-\infty,\xi]}(x)\)</span>.</p><h2 id="过零点的反正弦定理">5.5 过零点的反正弦定理</h2><p><span class="math inline">\(\forall t_1 &lt; t_2\)</span>，记事件<span class="math inline">\(o(t_1,t_2)=\{\exists t\in(t_1,t_2),B(t)=0\}\)</span>，利用全概率公式有 <span class="math display">\[P(o(t_1,t_2)) = \int_{-\infty}^{\infty} P(o(t_1,t_2) | B(t_1)=x)\frac{1}{\sqrt{2\pi t_1} }e^{-x^2/2t_1} dx\]</span> 利用布朗运动的连续性和对称性有 <span class="math display">\[P(o(t_1,t_2)|B(t_1)=x) = P(\tau_x\le t_2-t_1) =\frac{2}{\sqrt{2\pi(t_2-t_1)} }\int_x^{\infty} e^{-u^2/2(t_2-t_1)} du\]</span> 于是有 <span class="math display">\[P(o(t_1,t_2)) = \frac{1}{\pi\sqrt{t_1(t_2-t_1)}}\int_0^{\infty}\int_x^{\infty} e^{-\frac{y^2}{2(t_2-t_1)} }dy \cdote^{-\frac{x^2}{2t_1} }dx\]</span>这个积分的直接求解非常困难，为求此积分，采用另外的方法，也即反正弦定理。</p><p><strong>定理 5.8（反正弦定理）</strong>：设 <spanclass="math inline">\(B(t)\)</span> 是标准布朗运动，记 <spanclass="math inline">\(\bar{o}(t_1,t_2)=\{B(t)\ne 0,\forallt\in(t_1,t_2)\}\)</span>，则 <spanclass="math inline">\(P(\bar{o}(t_1,t_2))=\frac{2}{\pi}\arcsin\sqrt{\frac{t_1}{t_2} }\)</span>，且当 <spanclass="math inline">\(t_1=xt, t_2=t, 0 &lt; x &lt; 1\)</span> 时，有<span class="math inline">\(P(\bar{o}(xt,t))=\frac{2}{\pi} \arcsin\sqrt{x}\)</span>.</p><p><strong>Remark</strong>：这说明布朗运动处处连续但处处不可导。</p><h2 id="布朗运动的推广">5.6 布朗运动的推广</h2><h3 id="带吸收点的布朗运动">5.6.1 带吸收点的布朗运动</h3><p>设 <span class="math inline">\(Z(t)=\begin{cases}B(t), &amp; t &lt;\tau_x \\ x, &amp; t\ge \tau_x \end{cases}\)</span>，为求 <spanclass="math inline">\(Z(t)\)</span> 的分布，不妨设 <spanclass="math inline">\(x &gt; 0\)</span></p><p>（1）当 <span class="math inline">\(y &gt; x\)</span> 时，<spanclass="math inline">\(P(Z(t) \le y)=1\)</span>；</p><p>（2）当 <span class="math inline">\(y=x\)</span> 时，<spanclass="math inline">\(P(Z(t)=x) = P(\tau_x\le t) = \frac{2}{\sqrt{2\pit} }\int_x^\infty e^{-u^2/2t} du\)</span>；</p><p>（3）当 <span class="math inline">\(y &lt; x\)</span> 时，</p><h3 id="原点反射的布朗运动">5.6.2 原点反射的布朗运动</h3><h3 id="几何布朗运动">5.6.3 几何布朗运动</h3><p>令 <spanclass="math inline">\(W(t)=e^{B(t)}\)</span>，称它为几何布朗运动，取<span class="math inline">\(B(t)\)</span> 的矩母函数 <spanclass="math inline">\(\phi(s)={\mathbb E}[e^{sB(t)}]\)</span>，则 <spanclass="math inline">\(\phi(s)=e^{ts^2/2}\)</span>，因此 <spanclass="math inline">\({\mathbb E}[W(t)]=\phi(1)=e^{t/2}\)</span>，<spanclass="math inline">\(D[W(t)] = {\mathbb E}[W^2(t)]-({\mathbbE}[W(t)])^2=\phi(2)-e^t = e^{2t}-e^t\)</span>.</p><p><em>栗子 5.2</em>：考虑股票市场收益率，<spanclass="math inline">\(S_0,S_n\)</span> 分别表示最初价位和最终价位，<spanclass="math inline">\(S_n=S_0 e^{B(t_1)-B(t_0)}\cdotse^{B(t_n)-B(t_{n-1})}\)</span>.</p><h3 id="布朗运动的积分">5.6.4 布朗运动的积分</h3><p>令 <span class="math inline">\(S(t)=\int_0^tB(u)du\)</span>，根据正态分布的性质知道他是正态过程，<spanclass="math inline">\({\mathbb E}S(t)=0\)</span>，<spanclass="math inline">\(\forall 0\le \delta \le t\)</span>，有 <spanclass="math display">\[\operatorname{cov}[S(\delta),S(t)] = {\mathbb E}[\int_0^\delta\int_0^tB(u)B(v)dudv] = \int_0^\delta\int_0^t(u\wedgev)dudv=\frac{\delta^2}{2}(t-\frac{\delta}{3})\]</span></p><h3 id="布朗运动的形式导数">5.6.5 布朗运动的形式导数</h3><p>考虑增量比，固定 <span class="math inline">\(\Delta t &gt;0\)</span>，令 <span class="math inline">\(\frac{B(t+\Deltat)-B(t)}{\Delta t} = \frac{\Delta B(t)}{\Delta t}\)</span>，</p><h2 id="布朗桥与经验分布">5.7 布朗桥与经验分布</h2><h3 id="布朗桥的基本概念与性质">5.7.1 布朗桥的基本概念与性质</h3><p><strong>定义</strong>：<spanclass="math inline">\(\{B(t),t\ge0\}\)</span> 为标准布朗运动，不妨设<span class="math inline">\(B(0)=0\)</span>，令 <spanclass="math inline">\(B_{00}(t)=B(t)-tB(1)\)</span>，则称 <spanclass="math inline">\(\{B_{00}(t), 0\le t\le 1\}\)</span>为<strong>布朗桥</strong>。</p><p>根据其定义，可以得到基本性质如下：</p><ol type="1"><li><spanclass="math inline">\(B_{00}(0)=B_{00}(1)=0\)</span>；（？？）</li><li><span class="math inline">\({\mathbb E}[B_{00}(t)]={\mathbbE}[B(t)-tB(1)]=0\)</span>；</li><li><span class="math inline">\(D[B_{00}(t)]={\mathbbE}[B_{00}^2(t)]=t(1-t)\)</span>；</li><li>设 <span class="math inline">\(s\le t\)</span>，<spanclass="math inline">\(\operatorname{cov}[B_{00}(s),B_{00}(t)]=s(1-t)\)</span>；</li><li><span class="math inline">\(\{B_{00}(t),0\le t\le1 \}\)</span>的分布与 <span class="math inline">\(\{B(t), t\ge0 \}\)</span> 在 <spanclass="math inline">\(B(1)=0\)</span> 下的条件分布相同。</li></ol><h3 id="经验分布与布朗桥的关系">5.7.2 经验分布与布朗桥的关系</h3><p>工程统计中，经常独立抽取多个样本 <spanclass="math inline">\(X_1,...,X_n\)</span>来统计某参量的统计特性，定义经验分布 <spanclass="math inline">\(\hat{F}_n(x) = \frac{1}{n}\sum_{i=1}^n I_{\{X_i\lex\} }\)</span>。假设 <span class="math inline">\(X_1,...,X_n\)</span>独立同分布，且 <span class="math inline">\(X_n\simF(x)\)</span>，则有：</p><ol type="1"><li><span class="math inline">\({\mathbb E}[\hat{F}_n(x)] =F(x)\)</span></li><li><spanclass="math inline">\(\operatorname{Var}[\hat{F}_n(x)]=\frac{1}{n}F(x)(1-F(x))\)</span></li><li>任意给定 <span class="math inline">\(x\)</span>，利用强大数定理得到任意给定 <span class="math inline">\(x\)</span>，利用强大数定理得到<spanclass="math inline">\(P(\lim_{n\to\infty}\hat{F}_n(x)=F(x))=1\)</span></li><li>任意给定 <spanclass="math inline">\(x\)</span>，利用中心极限定理得到 <spanclass="math inline">\(n\to\infty\)</span> 时有（依分布收敛）</li></ol><p><span class="math display">\[\frac{\sum_{i=1}^n (I_{\{X_i\le x\} }-F(x)) }{\sqrt{nF(x)(1-F(x))} }\overset{d}{=} {\mathcal N}(0,1)\]</span></p><p>证明：（2）<spanclass="math inline">\(\operatorname{Var}[\hat{F}_n(x)]={\mathbbE}[\hat{F}_n(x)^2] - F(x)^2 = \frac{1}{n^2}{\mathbb E}[\sum_{i=1}^nI_{\{X_i\le x\} } \sum_{j=1}^n I_{\{X_j\le x\} }]\)</span>，展开化简就可以得到性质 2.</p><p>（4）记 <spanclass="math inline">\(G_n(x)=\sqrt{n}(\hat{F}_n(x)-F(x))\)</span>，容易证明<span class="math inline">\({\mathbbE}G_n(x)=0,\operatorname{Var}G_n(x)=F(x)(1-F(x))\)</span>，特别的，根据中心极限定理，当<span class="math inline">\(n\to\infty\)</span> 时有 <spanclass="math inline">\(G_n(x)\overset{d}{=}G(x)\)</span>，其中 <spanclass="math inline">\(G(x)\sim {\mathcalN}(0,F(x)(1-F(x)))\)</span>。</p><p><strong>引理 5.1</strong>：如果 <span class="math inline">\(x_1 &lt;x_2\)</span>，则 <span class="math inline">\({\mathbbE}[G_n(x_1)G_n(x_2)] = F(x_1)(1-F(x_2))\)</span>。</p><p>证明：代入展开化简即可得到。</p><blockquote><p><strong>Remark</strong>：根据上述引理和 <spanclass="math inline">\(G_n(x)\)</span> 的性质可知，当 <spanclass="math inline">\(F_n(x)=x\)</span> 时，即 <spanclass="math inline">\(X_1,...,X_n\)</span> 服从 <spanclass="math inline">\([0,1]\)</span> 上的均匀分布时，<spanclass="math inline">\(G_n(x)\)</span> 的极限分别 <spanclass="math inline">\(G(x)\)</span> 是布朗桥。</p><p>事实上，对于一般的连续分布函数 <spanclass="math inline">\(F(x)\)</span>，<spanclass="math inline">\(G_n(x)\)</span> 的极限分布 <spanclass="math inline">\(G(x)\)</span>也可以用布朗桥表示。为此，首先给出如下引理。</p></blockquote><p><strong>引理 5.2</strong>：随机变量 <spanclass="math inline">\(X\)</span> 的分布函数 <spanclass="math inline">\(F(x)\)</span> 连续，则 <spanclass="math inline">\(Y=F(X)\)</span> 是一个 <spanclass="math inline">\([0,1]\)</span> 均匀分布的随机变量。</p><p>证明：<span class="math inline">\(\forall y\in[0,1]\)</span>，定义<span class="math inline">\(x=\inf\{u:F(u)\ge y\}\)</span>，因此有 <spanclass="math inline">\(P(F(X)\ge y)) = P(Y\gey)=1-F(x)=1-y\)</span>，从而有 <span class="math inline">\(P(Y &lt; y) =y\)</span>，证毕。</p><p>基于引理 5.2，可以定义 <span class="math inline">\(G^{ \#}(x)=B_{00}(F(x))\)</span>，利用布朗桥性质有 <spanclass="math inline">\(G^{ \# }(x)\)</span> 与 <spanclass="math inline">\(G(x)\)</span> 有相同的分布特性，从而可以推得 <spanclass="math inline">\(G_n(x)\)</span> 的极限分布为以 <spanclass="math inline">\(F(x)\)</span> 为参变量的布朗桥。</p><h3 id="经验分布的误差估计">5.7.3 经验分布的误差估计</h3><p>略。</p><h2 id="带漂移的布朗运动">5.8 带漂移的布朗运动</h2><p><strong>定义</strong>：设 <spanclass="math inline">\(\{B(t),t\ge0\}\)</span> 为标准布朗运动，记 <spanclass="math inline">\(X(t)=B(t)+\eta t\)</span>，其中 <spanclass="math inline">\(\eta\)</span> 为常数，称 <spanclass="math inline">\(\{X(t),t\ge0\}\)</span> 为带漂移的布朗运动。</p><h3 id="移出区间的概率计算">5.8.1 移出区间的概率计算</h3><p><strong>定理 5.9</strong>：对任意 <span class="math inline">\(A &gt;0, B &gt; 0\)</span>，定义停时 <spanclass="math inline">\(\tau=\inf\{t:X(t)=A ~ or ~ X(t)=-B \}\)</span>，则<span class="math inline">\(P_{A}=P(X(\tau)=A) = \frac{e^{2\etaB}-1}{e^{2\eta B}-e^{2\eta a} }\)</span>.</p><h3 id="首中时问题">5.8.2 首中时问题</h3><h2 id="布朗运动的轨道性质">5.9 布朗运动的轨道性质</h2><p><strong>轨道处处连续，几乎处处不可导</strong>。</p><p><strong>定理</strong>：标准布朗运动 <spanclass="math inline">\(B(t)\)</span>，对任意的 <spanclass="math inline">\(t\ge0\)</span>，有 <span class="math display">\[P(\lim_{h\to 0}\sup\left|\frac{B(t+h)-B(t)}{h}\right|=+\infty) = 1\]</span> 证明：略。</p>]]></content>
    
    
    <categories>
      
      <category>随机过程2</category>
      
    </categories>
    
    
    <tags>
      
      <tag>首中时</tag>
      
      <tag>布朗运动</tag>
      
      <tag>反正弦定理</tag>
      
      <tag>布朗桥</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Hello World</title>
    <link href="/2022/01/23/hello-world/"/>
    <url>/2022/01/23/hello-world/</url>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your veryfirst post. Check <a href="https://hexo.io/docs/">documentation</a> formore info. If you get any problems when using Hexo, you can find theanswer in <ahref="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> oryou can ask me on <ahref="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="quick-start">Quick Start</h2><h3 id="create-a-new-post">Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo new <span class="hljs-string">&quot;My New Post&quot;</span><br></code></pre></td></tr></table></figure><p>More info: <ahref="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="run-server">Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo server<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="generate-static-files">Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo generate<br></code></pre></td></tr></table></figure><p>More info: <ahref="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="deploy-to-remote-sites">Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo deploy<br></code></pre></td></tr></table></figure><p>More info: <ahref="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>【高等数值分析】常微分方程数值解</title>
    <link href="/2022/01/14/advanced-numerical-analysis/ada-nsode/"/>
    <url>/2022/01/14/advanced-numerical-analysis/ada-nsode/</url>
    
    <content type="html"><![CDATA[<h2 id="预备理论">1. 预备理论</h2><p>求解常微分方程初值问题数值解 <span class="math display">\[\begin{align}&amp;\frac{dy}{dx} = f(x,y), \quad a &lt; x &lt; b, |y| &lt; \infty \\&amp;y(a) = y_0\end{align}\]</span> 存在唯一性定理：若 <span class="math inline">\(f(x,y)\)</span>连续，对 <span class="math inline">\(y\)</span> 满足 Lipschitz条件，那么初值问题有唯一解。</p><span id="more"></span><p>对上面的常微分方程积分就有 <span class="math inline">\(y(t_{n+k}) -y(t_{n-j}) = \int_{t_{n-j}}^{t_{n+k}} f(t,y(t))dt\)</span>，所以实际上可以转化为数值积分的问题，所以这一节的方法和数值积分很类似。但是这里的问题在于被积函数值是不知道的。</p><h2 id="线性多步法">2. 线性多步法</h2><p>在数值积分里面 <span class="math inline">\(f(t_k,y(t_k))\)</span>是已知的，主要是在设计求积节点对应的系数。在这里还需要首先估计每个节点的函数值。对前面的式子采样求积就得到<span class="math inline">\(y(t_{n+k}) - y(t_{n-j}) = h\sum_i \beta_if_{n-i}\)</span>，就引出了下面要介绍的线性多步法。</p><h3 id="线性多步法-1">2.1 线性多步法</h3><p>记 <span class="math inline">\(f_n=f(t_n,y_n),y_n=y(t_n)\)</span>，线性多步法（线性 <spanclass="math inline">\(k\)</span> 步法）的一般表达式为 <spanclass="math display">\[\sum_{i=0}^k \alpha_i y_{n+i} = h\sum_{i=0}^{k} \beta_i f_{n+i}\]</span> 其中 <span class="math inline">\(\alpha_k=1,\alpha_0^2+\beta_0^2\ne0\)</span>。给一些特例：</p><ul><li><span class="math inline">\(\alpha_0=-1,\beta_0=1,\beta_1=0\)</span>时为显式Euler法 <span class="math inline">\(y_{n+1}=y_n +hf_n\)</span>；</li><li><span class="math inline">\(\alpha_0=-1,\beta_0=0,\beta_1=1\)</span>时为隐式Euler法 <span class="math inline">\(y_{n+1}=y_n +hf_{n+1}\)</span>；</li><li><span class="math inline">\(\alpha_0=-1,\beta_0=\beta_1=1/2\)</span>时为梯形法 <span class="math inline">\(y_{n+1} = y_n +h/2(f_n+f_{n+1})\)</span>。</li></ul><p>可以定义<strong>“特征多项式”</strong>，在后面分析稳定性和收敛性的时候会很有用<span class="math display">\[\rho(\xi) = \sum_{i=0}^k \alpha_i \xi^i, \quad \sigma(\xi)=\sum_{i=0}^k\beta_i\xi^i\]</span>如何衡量数值求解方法的精度呢？定义<strong>局部截断误差</strong>为 <spanclass="math display">\[T_{n+k} = \sum_{i=0}^k [\alpha_i y(t_{n+i}) - h\beta_i y&#39;(t_{n+i})]\]</span> 对上面的式子做Taylor展开，可以得到形如 <spanclass="math inline">\(T_{n+1} = -1/90 h^5y^{(5)}(x_n)+O(h^6)\)</span>（这是Simpson公式的局部截断误差），这个式子表明Simpson公式是4阶的。</p><p>对于线性 <span class="math inline">\(k\)</span>步法，要想设计一种迭代方法使得数值精度是 <spanclass="math inline">\(p\)</span>阶的，可以采用待定系数法，保证局部截断误差中 <spanclass="math inline">\(y^{(1)}(x),...,y^{(q)}(x)\)</span>前面的系数都是0。</p><h3 id="稳定性与收敛性">2.2 稳定性与收敛性</h3><h4 id="相容性">2.2.1 相容性</h4><p>首先引入相容性的概念。若某个多步法的截断误差满足 <spanclass="math inline">\(T(t,y(t),h)=o(h)\)</span>那么称其为<strong>相容的</strong>。若 <spanclass="math inline">\(T(t,y(t),h)=O(h^{q+1})\)</span>，则称其为 <spanclass="math inline">\(q\)</span> 阶的。</p><p>实际上，相容性就是说该方法至少是1阶的，也就是当 <spanclass="math inline">\(y\)</span>为一次线性函数时，该方法要能够得到准确解。</p><p><strong>定理</strong>：相容的多步法充要条件是 <spanclass="math inline">\(\rho(1)=0,\rho&#39;(1)=\sigma(1)\)</span>。</p><h4 id="零稳定性">2.2.2 零稳定性</h4><p><strong>根条件</strong>：若多项式 <spanclass="math inline">\(\rho(\xi)\)</span> 的 <spanclass="math inline">\(k\)</span> 个根的模长都<strong>不大于1</strong>，并且模值等于 1 的根都是单根，则称其满足根条件。</p><p><strong>Note</strong>：根条件考虑的是齐次差分方程的解。当 <spanclass="math inline">\(f\equiv 0\)</span>的时候，齐次差分方程的解具有指数形式 <spanclass="math inline">\(y(n)=\sum_i P(n) \xi_i^n\)</span>，其中 <spanclass="math inline">\(P(n)\)</span> 是一个多项式， <spanclass="math inline">\(\xi_i\)</span> 就是 <spanclass="math inline">\(\rho(\xi)\)</span>的根（这里没考虑重根的情况，不过是类似的），如果 <spanclass="math inline">\(|\xi_i|&lt;1\)</span> 就意味着 <spanclass="math inline">\(\lim_{n\to\infty}y(n) =0\)</span>，那么这跟稳定性有什么关系呢？</p><p><strong>定理</strong>：线性多步法关于初值稳定的充要条件是 <spanclass="math inline">\(\rho(\xi)\)</span> 满足根条件。</p><p><strong>Note</strong>：这个定理说明了根条件和（零）稳定性二者的等价关系。为什么呢？假设真实的初值为<span class="math inline">\(y_0=y(t_0)\)</span>，真实的解为 <spanclass="math inline">\(y(n)=y_0\xi_0^{(n-t_0)}\)</span>。而我们计算的时候由于各种原因拿到的初值是有误差的，也就是<span class="math inline">\(\hat{y}_0\)</span>，那么最后求得的误差就是<spanclass="math inline">\(\hat{y}(n)-y(n)=(\hat{y}_0-y_0)\xi_0^{(n-t_0)}\)</span>，如果不满足根条件，当<span class="math inline">\(n\to\infty\)</span> 的时候，<spanclass="math inline">\(\hat{y}(n)-y(n) \to\infty\)</span>，解就是不稳定的。</p><h4 id="收敛性">2.2.3 收敛性</h4><p><strong>定义</strong>：假设在区间 <spanclass="math inline">\([a,b]\)</span> 上等距划分 <spanclass="math inline">\(N\)</span> 个区间，<span class="math inline">\(x_n= a+nh,n=0,1,...,N\)</span>，求解初值问题得到的解为 <spanclass="math inline">\(y_n,n=0,1,...,N\)</span>，最大整体误差为 <spanclass="math inline">\(E(h) = \max_{n} |y(x_n) - y_n|\)</span>，如果满足<span class="math inline">\(\lim_{h\to0}E(h)=0\)</span>，则称方法是<strong>收敛</strong>的。如果 <spanclass="math inline">\(E(h) \le Ch^p\)</span>，则称方法是 <spanclass="math inline">\(p\)</span> 阶收敛的。</p><p><strong>定理</strong>：相容性 + 零稳定性 <spanclass="math inline">\(\iff\)</span> 收敛性。</p><h4 id="绝对稳定性">2.2.4 绝对稳定性</h4><p>前面的零稳定性是跟所选择的方法有关的。而这里的绝对稳定性研究的是微分方程本身的属性。如果方程本身性质很不好，那么可能无论选择什么方法都是不稳定的。</p><p>取 <span class="math inline">\(f(x,y)=\lambday\)</span>，再研究方法的稳定性。以试验方程为例 <spanclass="math display">\[\begin{cases}y&#39; = \lambda y, t\in[a,b] \\y(a) = \tilde{y}_0\end{cases}\]</span> 用Euler法得到 <span class="math inline">\(y_n =(1+h\lambda)y_{n-1}\)</span>，于是两个解的误差满足 <spanclass="math inline">\(y_n-z_n = (1+h\lambda)^n (y_0-z_0)\)</span>，若<spanclass="math inline">\(|1+h\lambda|&gt;1\)</span>，则误差总会放大，这是我们不希望的。</p><p>要保证稳定性，既与方程本身的性质（也即 <spanclass="math inline">\(\lambda\)</span>） 有关，也与所选择的步长 <spanclass="math inline">\(h\)</span>有关。从另一个角度而言，方程本身的性质（<spanclass="math inline">\(\lambda\)</span>）会影响可选择的 <spanclass="math inline">\(h\)</span> 的范围。由此引出绝对稳定性的概念。</p><p>对前面提到的线性多步法，把 <span class="math inline">\(f(x,y)=\lambday\)</span> 代回去就有 <span class="math display">\[\sum_{i=0}^k (\alpha_i - h\lambda \beta_i) y_{n+i} = 0\]</span> 称 <span class="math inline">\(\Pi(\xi;z) = \rho(\xi) -z\sigma(\xi)\)</span> 为<strong>稳定多项式</strong>。</p><p><strong>定理</strong>：对给定的 <spanclass="math inline">\(z\)</span>，若 <spanclass="math inline">\(\Pi(\xi;z)\)</span> 的 <spanclass="math inline">\(k\)</span> 个根的模都<strong>小于1</strong>，则其是绝对稳定的。（满足这样条件的 <spanclass="math inline">\(z\)</span>的集合构成<strong>绝对稳定区域</strong>。）</p><h2 id="runge-kutta方法">3. Runge-Kutta方法</h2><p>Runge-Kutta方法和线性多步法的主要区别在于，其在 <spanclass="math inline">\(x_n,x_{n+1}\)</span>中间又进行了采样、插值。这种方法大概可以表示为 <spanclass="math display">\[\begin{align}&amp; y_{n+1} = y_n + h\sum_{i=1}^{s} b_i k_i \\&amp; k_i = y_n + f(t_n + c_i h, y_n + \sum_{i=1}^s a_{ij} k_j)\end{align}\]</span> 其中 <span class="math inline">\(0\le c_i\le1\)</span>。实际上<span class="math inline">\(k_i \approx y(t_n+c_i h)\)</span>，就是在<span class="math inline">\([y_n,y_{n+1}]\)</span>中间又进行了采样插值。</p><p>这样提高了精度，同时也会增加计算复杂度。</p><p>除此之外，提高精度的方法还有 Richardson 外推方法。</p><h2 id="刚性问题">4. 刚性问题</h2><p>刚性问题也是方程本身的属性，主要是指某些情况下两个特解的尺度相差很大，比如两个指数衰减的过程混合在一起，但是其中一个衰减特别快（<spanclass="math inline">\(\exp(-\lambda t)\)</span> 的 <spanclass="math inline">\(\lambda\)</span>特别大），另一个则衰减特别慢，那么数值求解的时候很可能只能看到衰减慢的那个过程，另一个则被忽略。这在化学反应中是经常遇到的。</p>]]></content>
    
    
    <categories>
      
      <category>高等数值分析</category>
      
    </categories>
    
    
    <tags>
      
      <tag>常微分方程</tag>
      
      <tag>刚性问题</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【高等数值分析】数值积分和数值微分</title>
    <link href="/2022/01/09/advanced-numerical-analysis/ada-integration/"/>
    <url>/2022/01/09/advanced-numerical-analysis/ada-integration/</url>
    
    <content type="html"><![CDATA[<h2 id="预备理论">1. 预备理论</h2><p>根据Newton-Leibniz公式有 <span class="math inline">\(\int_a^x f(t)dt=F(x)-F(a)\)</span>，但是绝大部分情况很难解析求解，需要数值积分。例如<strong>中点公式</strong><span class="math display">\[\int_a^b f(x)dx \approx f(\frac{a+b}{2})(b-a)\]</span> 若 <span class="math inline">\(f(x)\inC^2[a,b]\)</span>，则中点公式<strong>截断误差</strong>为 <spanclass="math display">\[\int_a^b f(x)dx - f(\frac{a+b}{2})(b-a) = \frac{(b-a)^2}{24}f&#39;&#39;(\xi), \quad \xi\in(a,b)\]</span> <span id="more"></span></p><h2 id="插值型求积公式">2. 插值型求积公式</h2><p>顾名思义，就是先插值再求积分。方法为给定求积节点 <spanclass="math inline">\(x_k,k=0,1,...,n\)</span> 和求积系数 <spanclass="math inline">\(A_k,k=0,1,...,n\)</span>，插值型求积公式表示为<span class="math display">\[\int_a^b f(x)dx \approx \sum_{k=0}^n A_k f(x_k)\]</span> 根据多项式插值中的理论，余项可表示为 <spanclass="math display">\[E_n(f) = \frac{1}{(n+1)!}\int_a^b f^{(n+1)}(\xi(x)) w_{n+1}(x) dx\]</span> 当 <span class="math inline">\(f(x)\in{\mathcal P}_n\)</span>时都有 <spanclass="math inline">\(E_n(f)=0\)</span>。由此可以定义代数精度，如果对所有<span class="math inline">\(p\in{\mathcal P}_m\)</span> 有 <spanclass="math inline">\(E_n(p)=0\)</span>，而对某个 <spanclass="math inline">\(q\in{\mathcal P}_{m+1}\)</span> 有 <spanclass="math inline">\(E_n(q)\ne 0\)</span>，称求积公式具有 <spanclass="math inline">\(m\)</span> 次<strong>代数精度</strong>。</p><p>插值型求积公式主要分为两类：Newton-Cotes求积公式和Gauss型求积公式。前者等距选取插值节点，后者则未必。</p><h3 id="newton-cotes求积公式">2.1 Newton-Cotes求积公式</h3><p>方法是将区间 <span class="math inline">\([a,b]\)</span> <spanclass="math inline">\(n\)</span> 等分，得到 <spanclass="math inline">\(h =\frac{b-a}{n},x_k=a+kh,k=0,...,n\)</span>，再利用Lagrange插值公式 <spanclass="math inline">\(l_k(x)\)</span>，得到 <spanclass="math display">\[\int_a^b f(x)dx = (b-a)\sum_{k} \frac{f(x_k)}{b-a}\int_a^b l_k(x)dx =(b-a)\sum_k C_k^{(n)} f(x_k)\]</span> 其中 <spanclass="math inline">\(C_k^{(n)}=\frac{1}{b-a}\int_a^b \prod_{j\nek}\frac{x-x_j}{x_k-x_j}dx = \frac{1}{n}\int_a^b \prod_{j\nek}\frac{t-j}{k-j}dx\)</span> 称为 Cotes求积系数，不仅<strong>与被积函数无关</strong>，<strong>与求积区间也无关</strong>。</p><p>该方法有如下性质：</p><ul><li><span class="math inline">\(\sum_{k=0}^n C_k^{(n)} = 1\)</span>（取<span class="math inline">\(f\equiv1\)</span> 即可得证）；</li><li><span class="math inline">\(E_n(f) = \frac{1}{(n+1)!}\int_a^bf^{(n+1)}(\xi(x)) w_{n+1}(x) dx\)</span>；</li><li>当 <span class="math inline">\(n\)</span> 为偶数时，代数精度为 <spanclass="math inline">\(n+1\)</span>；当 <spanclass="math inline">\(n\)</span> 为奇数时，代数精度为 <spanclass="math inline">\(n\)</span>。（直观理解是因为奇次多项式的奇对称性积分后恰好为0）</li></ul><p>下面是 <span class="math inline">\(n\)</span> 取不同数值的特例。</p><p><span class="math inline">\(n=1\)</span> 时为梯形公式，代数精度为<span class="math inline">\(1\)</span>： <span class="math display">\[\begin{align}&amp;\int_a^b f(x)dx \approx \frac{b-a}{2}[f(a)+f(b)] \\&amp;E_1(f) = -\frac{(b-a)^3}{12} f&#39;&#39;(\xi), \xi\in[a,b]\end{align}\]</span> <span class="math inline">\(n = 2\)</span> 时为 Simpson公式，代数精度为 <span class="math inline">\(3\)</span>： <spanclass="math display">\[\begin{align}&amp;\int_a^b f(x)dx \approx \frac{b-a}{6}[f(a)+4f(\frac{a+b}{2})+f(b)]\\&amp;E_1(f) = -\frac{(b-a)^5}{2880} f^{(4)}(\xi), \xi\in[a,b]\end{align}\]</span></p><h3 id="gauss型求积公式">2.2 Gauss型求积公式</h3><p>求积公式也表示为 <span class="math display">\[\int_a^b f(x)dx \approx \sum_{k=0}^n A_k f(x_k)\]</span>但与Newton-Cotes方法不同的是求积节点并非等距选取，而是将参数待定，解出使代数精度最高的参数<span class="math inline">\(A_k\)</span> 和 <spanclass="math inline">\(x_k\)</span>。共有 <spanclass="math inline">\(2n+2\)</span> 个参数待定，分别取 <spanclass="math inline">\(f(x)=1,x,x^2,...,x^{2n+1}\)</span>列方程组，因此代数精度最高可以达到 <spanclass="math inline">\(2n+1\)</span>。</p><p>从理论上也可以证明代数精度至多为 <spanclass="math inline">\(2n+1\)</span>。</p><p>证明：取 <spanclass="math inline">\(f(x)=\prod_{k=0}^n(x-x_k)^2\)</span>，那么上面等式左边一定有<span class="math inline">\(\int_a^b f(x)dx &gt;0\)</span>，但是等式右边有 <span class="math inline">\(\sum_{k} A_kf(x_k)=0\)</span>，显然不相等。证毕。</p><p>除此之外，Gauss型求积公式还可以拓展到带权积分的情况，也即 <spanclass="math display">\[\int_a^b \rho(x)f(x)dx = \sum_{k=0}^n A_k f(x_k) +\frac{1}{(n+1)!}\int_a^b f^{(n+1)}(\xi(x)) w_{n+1}(x) dx\]</span> 关键问题是如何求解 <spanclass="math inline">\(A_k,x_k\)</span> 呢？</p><p>由于代数精度为 <span class="math inline">\(2n+1\)</span>，对 <spanclass="math inline">\(\forall f\in{\mathcalP}_{2n+1}\)</span>，截断误差应满足 <spanclass="math inline">\(\frac{1}{(n+1)!}\int_a^b f^{(n+1)}(\xi(x))w_{n+1}(x) dx=0\)</span>。又由于 <spanclass="math inline">\(f^{(n+1)}\in{\mathcal P}_n\)</span>，那么只需要取<span class="math inline">\(w_{n+1}(x)\)</span> 为 <spanclass="math inline">\(n+1\)</span> 阶正交多项式（权函数为 <spanclass="math inline">\(\rho\)</span>）即可满足该条件。因此Gauss型求积公式的求解方法为：</p><ol type="1"><li>权函数为 <span class="math inline">\(\rho\)</span>，求 <spanclass="math inline">\(n+1\)</span> 阶正交多项式；</li><li>求 <span class="math inline">\(n+1\)</span> 个根 <spanclass="math inline">\(x_k\)</span>（在逼近一章中已经证明了一定存在 <spanclass="math inline">\(n+1\)</span> 个不同的根）；</li><li>取 <span class="math inline">\(f(x)=1,x,...,x^n\)</span>列线性方程组求 <span class="math inline">\(A_k\)</span>。</li></ol><p>Gauss型求积公式有如下性质：</p><ul><li><span class="math inline">\(A_k &gt; 0,k=0,1,...,n\)</span>（取<span class="math inline">\(f(x)=l_i(x)\)</span> 即可证明）；</li><li><span class="math inline">\(\sum_{k=0}^n A_k = \int_a^b\rho(x)dx\)</span>（取 <span class="math inline">\(f\equiv\)</span>即可证明）；</li><li>余项 <span class="math inline">\(E_n(f) =\frac{1}{(2n+2)!}f^{(2n+2)}(\eta)\int_a^b \rho(x) [w_{n+1}(x)]^2dx\)</span>。</li></ul><h2 id="数值微分">3. 数值微分</h2><p>数值微分和数值积分类似，也有插值型微分公式，即先进性多项式插值，再求导数值。</p><p>还可以利用Richardson外推公式提高精度。</p>]]></content>
    
    
    <categories>
      
      <category>高等数值分析</category>
      
    </categories>
    
    
    <tags>
      
      <tag>数值积分</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【高等数值分析】函数逼近</title>
    <link href="/2022/01/07/advanced-numerical-analysis/ada-approximation/"/>
    <url>/2022/01/07/advanced-numerical-analysis/ada-approximation/</url>
    
    <content type="html"><![CDATA[<h2 id="预备理论">1. 预备理论</h2><p>函数插值当中我们只有几个离散的的插值节点及其函数值，在函数逼近里我们考虑的是有一个<span class="math inline">\(f(x),x\in[a,b]\)</span>已知，但是希望用一组简单的基函数 <spanclass="math inline">\(\{\phi_0,...,\phi_n\}\)</span> 逼近 <spanclass="math inline">\(f(x)\)</span>。</p><span id="more"></span><p>首先定义加权内积为 <span class="math inline">\(\langlef,g\rangle_\rho = \int_a^b \rho(x)f(x)g(x)dx\)</span>，其中 <spanclass="math inline">\(\rho(x)\ge0\)</span>为权函数。相应的可以导出范数定义为 <span class="math inline">\(\Vertf\Vert_\rho = \sqrt{\langlef,f\rangle_\rho}\)</span>。后面为了符号简洁都默认省略下标 <spanclass="math inline">\(\rho\)</span>。</p><p>一般考虑最佳平方逼近问题，即 <spanclass="math inline">\(\min_{s\in\Phi} \Vert f-s\Vert\)</span>，其中<span class="math inline">\(\Phi\)</span>为某个函数空间，一般为代数多项式、三角多项式或有理多项式组。</p><h2 id="多项式逼近">2. 多项式逼近</h2><h3 id="总体框架">2.1 总体框架</h3><p>若 <spanclass="math inline">\(\Phi=\operatorname{span}\{\phi_0,...,\phi_n\}\)</span>，<spanclass="math inline">\(\{\phi_j,j=0,...,n\}\)</span>为一组线性无关的的基函数，那么 <span class="math inline">\(\foralls\in\Phi\)</span> 可以表示为 <span class="math inline">\(s(x) =\sum_{j=0}^n a_j\phi_j(x)\)</span>，最佳平方逼近问题变为 <spanclass="math display">\[\min_{s\in\Phi} F(a_0,...,a_n) \triangleq \Vert f-\sum a_j\phi_j \Vert^2\]</span> 令 <span class="math inline">\(\partial F/\partiala_k=0\)</span> 即可得到下面的法方程，再求解线性方程组即可得到 <spanclass="math inline">\(a_k\)</span> <span class="math display">\[\sum_{i=0}^n \langle \phi_i, \phi_k\rangle a_i = \langlef,\phi_k\rangle, \quad k=0,1,...,n\]</span>除了前面的求导得到法方程，还可以利用<strong>Galerkin条件</strong>（实际上与法方程等价）<span class="math display">\[\langle f-s^{\ast}, s\rangle = 0, \quad s\in\Phi\]</span> 根据前面的结论，要想求得 <spanclass="math inline">\(a_k\)</span> 需要解法方程 <spanclass="math inline">\({\Psi}\boldsymbol{a}=\boldsymbol{b}\)</span>，为了进一步简化该问题，可以选择基函数<span class="math inline">\(\phi_j\)</span> 相互正交，那么 <spanclass="math inline">\(\Psi\)</span> 就会退化为对角阵，并且此时有 <spanclass="math display">\[s^{\ast} = \sum_{k=0}^n \frac{\langle f,\phi_k\rangle}{\Vert\phi_k\Vert^2} \phi_k\]</span> 后面的关键就是如何获得相互正交的一组基函数？</p><h3 id="正交多项式">2.2 正交多项式</h3><p>答案就是Gram-Schmidt正交化。对于多项式基函数 <spanclass="math inline">\(\phi_k\in{\mathcal P}_k\)</span>，只需要对 <spanclass="math inline">\(\{1,x,x^2,...\}\)</span>逐次进行Gram-Schmidt正交化即可。 <span class="math display">\[\phi_k = x^k - \sum_{j=0}^{k-1} \frac{\langle x^k,\phi_j\rangle}{\langle\phi_j,\phi_j\rangle} \phi_j\]</span> 后面将介绍几种不同的正交多项式，他们的区别就在于支撑区间 <spanclass="math inline">\([a,b]\)</span> 和权函数 <spanclass="math inline">\(\rho(x)\)</span> 的不同。</p><h4 id="lengdre多项式">2.2.1 Lengdre多项式</h4><p><spanclass="math inline">\(\rho(x)=1,x\in[-1,1],\phi_0(x)=1\)</span>，有如下性质：</p><ul><li>递推关系：<span class="math inline">\((n+1)P_{n+1}(x) =(2n+1)xP_n(x) - n P_{n-1}(x)\)</span></li><li>奇偶性：<span class="math inline">\(P_n(-x) = (-1)^nP_n(x)\)</span></li><li><span class="math inline">\([-1,1]\)</span> 上Lengdre多项式与 <spanclass="math inline">\(f\equiv0\)</span> 的平方误差最小</li></ul><h4 id="chebyshev多项式">2.2.2 Chebyshev多项式</h4><p><spanclass="math inline">\(\rho(x)=1/\sqrt{1-x^2},x\in[-1,1],\phi_0=1\)</span>，有如下性质：</p><ul><li>递推关系：<span class="math inline">\(T_{n+1}(x) =2xT_n(x)-T_{n-1}(x)\)</span></li><li>奇偶性：<span class="math inline">\(P_n(-x) = (-1)^nP_n(x)\)</span></li><li><span class="math inline">\(T_n(x)\)</span> 在 <spanclass="math inline">\((-1,1)\)</span> 上有 <spanclass="math inline">\(n\)</span> 个不同的零点 <spanclass="math inline">\(x_k=\cos\frac{(2k-1)\pi}{2n},k=1,2,..,n\)</span></li></ul><h4 id="lagurre多项式">2.2.3 Lagurre多项式</h4><p><spanclass="math inline">\(\rho(x)=e^{-x},x\in(0,+\infty),\phi_0=1\)</span></p><h4 id="hermite多项式">2.2.4 Hermite多项式</h4><p><spanclass="math inline">\(\rho(x)=\exp(-x^2),x\in(-\infty,\infty),\phi_0=1\)</span></p><h2 id="pade逼近">3. Pade逼近</h2><p>Pade逼近是用有理多项式 <span class="math inline">\(R_{n,m}(x) =\frac{R_n(x)}{Q_m(x)}\)</span> 逼近 <spanclass="math inline">\(f(x)\)</span>，其中 <spanclass="math inline">\(P_n\in{\mathcal P}_n,Q_m\in{\mathcalP}_m\)</span>。如果对 <span class="math inline">\(f(x)\)</span> 做Taylor 展开的话，能得到 <span class="math display">\[f(x)Q_m(x) - P_n(x) = \sum_{i=0}^\infty c_ix^i\]</span> 理论上有 <span class="math inline">\(n+m+1\)</span>个待定系数，因此可以列出方程 <spanclass="math inline">\(c_0=c_1=\cdots=c_{n+m}=0\)</span>，即可得到 <spanclass="math inline">\(R_{n,m}\)</span>。</p><h2 id="最小二乘">4. 最小二乘</h2><p>如果给定了很多个节点函数值 <spanclass="math inline">\(f(x_i)\)</span>，但是不要求满足插值条件 <spanclass="math inline">\(f(x_i)=\phi(x_i)\)</span>，而只要求最小化平方误差<span class="math inline">\(\sum_i(f(x_i)-\phi(x_i))^2\)</span>，那么就是最小二乘问题 <spanclass="math display">\[\min \Vert b-Ax\Vert \Rightarrow x^{\ast} = (A^TA)^{-1}A^Tb\]</span> 也可以对 <span class="math inline">\(A\)</span>做QR分解，那么就有 <spanclass="math inline">\(Rx^{\ast}=Q^Tb\)</span>。</p>]]></content>
    
    
    <categories>
      
      <category>高等数值分析</category>
      
    </categories>
    
    
    <tags>
      
      <tag>多项式逼近</tag>
      
      <tag>Pade逼近</tag>
      
      <tag>Lengdre多项式</tag>
      
      <tag>Chebyshev多项式</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【高等数值分析】多项式插值</title>
    <link href="/2022/01/07/advanced-numerical-analysis/ada-interpolation/"/>
    <url>/2022/01/07/advanced-numerical-analysis/ada-interpolation/</url>
    
    <content type="html"><![CDATA[<h2 id="预备理论">1. 预备理论</h2><p>假设有离散的 <span class="math inline">\(\{x_0,x_1,...,x_n\}\)</span>插值节点，以及对应的函数值 <spanclass="math inline">\(\{f(x_0),....,f(x_n)\}\)</span>，希望用函数 <spanclass="math inline">\(\phi(x)\)</span> 来近似 <spanclass="math inline">\(f(x)\)</span>，使其满足插值条件 <spanclass="math inline">\(\phi(x_i)=f(x_i),i=0,...,n\)</span>。一般选择多项式插值函数<span class="math inline">\(p(x)=a_0+a_1x+\cdots+a_n x^n \in {\mathcalP}_n\)</span>。</p><span id="more"></span><p>根据插值条件 <span class="math inline">\(f(x_i)=\phi(x_i)\)</span>列出来 <span class="math inline">\(n+1\)</span> 个等式，再由 Hilbert阵的非奇异性质，可以证明插值函数 <spanclass="math inline">\(p(x)\)</span> 存在且唯一。但同时也由于 Hilbert的病态性，使得这种直接暴力求解的方式不好使。后面给出几种更好用的方法。</p><h2 id="lagrange插值">2. Lagrange插值</h2><p>采用了类似“正交基”的想法，如果有 <spanclass="math inline">\(n+1\)</span> 个插值节点，就先给出 <spanclass="math inline">\(n+1\)</span>个“正交基函数”，然后再用线性组合即可得到插值函数。</p><p>选择基底函数为 <span class="math display">\[l_i(x) = \prod_{k=0,k\ne i}^n \frac{x-x_k}{x_i-x_k}= \begin{cases}1, &amp; x=x_i \\0, &amp; x=x_k,k\ne i\end{cases}\]</span> 对应构造的插值函数为 <spanclass="math inline">\(L_n(x)=\sum_{i=0}^nf(x_i)l_i(x)\)</span>，插值余项 <span class="math display">\[R_n(x)\triangleq f(x)-L_n(x) = \frac{f^{(n+1)}(\xi)}{(n+1)!}w_{n+1}(x)\]</span> 其中 <spanclass="math inline">\(\xi(x)\in[a,b]\)</span>，<spanclass="math inline">\(w_{n+1}(x)=\prod_{k=0}^n(x-x_k)\)</span>。</p><p><strong>插值余项的证明</strong>：<span class="math inline">\(\forallx\in[a,b]\)</span>，将其看作新增插值节点，那么我们构造一个新的Lagrange插值函数<span class="math display">\[l_{n+1}(t) = R_n(x)\frac{w_{n+1}(t)}{w_{n+1}(x)}=\begin{cases}R_n(x), &amp; t=x \\0, &amp; t=x_0,...,x_n\end{cases}\]</span> 那么我们取 <span class="math inline">\(L_{n+1}(t) = L_n(t) +l_{n+1}(t)\)</span>，可以验证其满足 <spanclass="math inline">\(L_{n+1}(x_i)=f(x_i), t\in\{x,x_0,...,x_n\}\)</span>，也就是说他是新的插值函数，插值节点为 <spanclass="math inline">\(\{x,x_0,...,x_n\}\)</span>。此时插值余项为 <spanclass="math inline">\(R_{n+1}(t)=f(t)-L_{n+1}(t)=R_n(t)-l_{n+1}(t)\)</span>，其满足<span class="math inline">\(R_{n+1}(t)=0,t\in\{x,x_0,...,x_n\}\)</span>，反复应用 Rolle 定理，即可得到存在 <spanclass="math inline">\(\xi\in[a,b]\)</span> 使得 <spanclass="math inline">\(R_{n+1}^{(n+1)}(\xi)=f^{(n+1)}(\xi)-\frac{(n+1)!}{w_{n+1}(x)}R_n(x)\)</span>，证毕。</p><h2 id="newton插值">3. Newton插值</h2><h3 id="newton插值及其余项">3.1 Newton插值及其余项</h3><p>前面Lagrange插值方法存在的一个问题在于，如果新增一个插值节点，所有的基底函数<span class="math inline">\(l_i(x)\)</span>都要重新计算。Newton插值就是要克服这个问题，其思路在前面“插值余项的证明”过程中已经显现了，也就是每次新增一个插值节点，多项式的阶数会+1，那么我们就增加一个 <span class="math inline">\(n+1\)</span>次多项式来弥补。具体方法如下。 <span class="math display">\[N_n(x) = N_{n-1}(x) + a_n w_n(x)\]</span> 其中 <span class="math inline">\(N_{n-1}(x)\)</span> 为 <spanclass="math inline">\(\{x_0,...,x_{n-1}\}\)</span>的Newton插值函数，现在新增节点 <spanclass="math inline">\(x_n\)</span>，其插值函数 <spanclass="math inline">\(N_n(x)\)</span> 只需要添加一个 <spanclass="math inline">\(n\)</span> 阶多项式 <spanclass="math inline">\(a_n w_n(x)\)</span>，由 <spanclass="math inline">\(N_n(x_n)=f(x_n)\)</span> 可以推出 <spanclass="math inline">\(a_n =\frac{f(x_n)-N_{n-1}(x_n)}{w_n(x_n)}\)</span>，记为<strong>均差</strong><span class="math inline">\(a_n=f[x_0,...,x_n]\)</span>（实际上就是<span class="math inline">\(x^{n+1}\)</span>的系数，因此与节点的排列次序无关）。</p><p>由此得到Newton插值方法 <span class="math display">\[N_n(x) = \sum_{k=0}^n f[x_0,...,x_k] w_k(x)\]</span> 实际计算过程中均差可以递归计算 <span class="math display">\[f[x_0,...,x_n] = \frac{f[x_1,...,x_n] - f[x_0,...,x_{n-1}]}{x_n-x_0}\]</span> 证明：取 <span class="math inline">\(P_{n-1}(x)\in{\mathcalP}_{n-1}\)</span> 满足 <spanclass="math inline">\(P_{n-1}(x_i)=f(x_i),i=0,1,...,n-1\)</span>， <spanclass="math inline">\(Q_{n-1}(x)\in{\mathcal P}_{n-1}\)</span> 满足<spanclass="math inline">\(Q_{n-1}(x_i)=f(x_i),i=1,2,...,n\)</span>。构造<span class="math inline">\(P_n(x)=\frac{x-x_0}{x_n-x_0}Q_{n-1}(x) +\frac{x_n-x}{x_n-x_0}P_{n-1}(x) \quad(\bigstar)\)</span>，可以验证满足<span class="math inline">\(P_n(x_i)=f(x_i),i=0,...,n\)</span>。考虑<span class="math inline">\((\bigstar)\)</span> 式等号两侧 <spanclass="math inline">\(x^n\)</span> 的系数，即可得证。</p><p>插值余项为 <span class="math display">\[R_n(x) = f[x_0,...,x_n,x]\prod_{i=0}^n (x-x_i)\]</span> 证明：类似Lagrange中的方法，同样是将 <spanclass="math inline">\(x\)</span> 看作一个新的插值节点即可。证毕。</p><h3 id="高阶项">3.2 高阶项</h3><p>插值条件中除了直接给出函数值 <spanclass="math inline">\(f(x_i)\)</span>，有时候也会给出 <spanclass="math inline">\(f&#39;(x_i)\)</span>或者更高阶的导数值，那么此时的均差该如何计算呢？对于高阶项，如果有 <spanclass="math inline">\(x_0\le x_1\le \cdots \lex_n\)</span>，那么均差的计算方法为 <span class="math display">\[f[x_0,...,x_n] = \begin{cases}\frac{f[x_1,...,x_n] - f[x_0,...,x_{n-1}]}{x_n-x_0}, &amp; x_n\ne x_0 \\\frac{f^{(n)}(x_0)}{n!}, &amp; x_n=x_0\end{cases}\]</span>在解题过程中，主要还是用列表法，可以参考数值分析相关的教材。</p><h2 id="hermite插值">4. Hermite插值</h2><p>Hermite插值方法就是在Lagrange方法的基础上，再利用上插值节点的（高阶）导数值，用更少的插值节点获得更高阶的插值多项式。例如构造基函数<span class="math inline">\(\alpha_i,\beta_i\in {\mathcalP}_{2n+1},i=0,1,...,n\)</span> 满足 <span class="math display">\[\begin{cases}\alpha_i(x_j) = \delta_{ij}, &amp; \alpha&#39;_i(x_j)=0 \\\beta_i(x_j)=0, &amp; \beta&#39;_i(x_j) = \delta_{ij}\end{cases}\]</span> 构造的多项式即为 <span class="math display">\[H_{2n+1}(x) = \sum_{i=0}^n [f_i\alpha_i(x) + f&#39;(x_i)\beta_i(x)]\]</span> 具体细节略。</p><h2 id="样条插值">5. 样条插值</h2><p>前面的方法都会出现 Runge现象，也就是由于多项式本身的性质，插值函数阶数越高，边缘处振荡越严重，误差较大。样条插值的思路就是分段插值，并且只利用低阶多项式（如一阶、二阶、三阶）。其中一阶就是分段线性插值，用的比较多的还是三次样条插值。</p><p>三次样条插值的总体思路就是利用插值节点的函数值、一阶导、二阶导列出方程组来求解系数。不过为了使方程适定，需要再添加两个约束条件（增加两个方程），一般可选的有</p><ul><li>固支边界条件：<spanclass="math inline">\(S&#39;_3(x_0)=f&#39;(x_0),S&#39;_3(x_n)=f&#39;(x_n)\)</span>；</li><li>自然边界条件：<spanclass="math inline">\(S&#39;&#39;_3(x_0)=S&#39;&#39;_3(x_n)=0\)</span>；</li><li>周期边界条件：<span class="math inline">\(S_3(x_0)=S_3(x_n)=f_0,S&#39;_3(x_0)=S&#39;_3(x_n),S&#39;&#39;_3(x_0)=S&#39;&#39;_3(x_n)\)</span>。</li></ul><p>具体细节略。</p>]]></content>
    
    
    <categories>
      
      <category>高等数值分析</category>
      
    </categories>
    
    
    <tags>
      
      <tag>插值</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【随机过程2】布朗运动1 | 定义与基本性质</title>
    <link href="/2021/11/25/stochastic-process-2/ch5-s1-brown-concepts/"/>
    <url>/2021/11/25/stochastic-process-2/ch5-s1-brown-concepts/</url>
    
    <content type="html"><![CDATA[<h2 id="布朗运动概念">5.1 布朗运动概念</h2><p><strong>定义</strong>：若一个随机过程 <spanclass="math inline">\(\{X(t),t\ge0\}\)</span> 满足</p><ol type="1"><li><span class="math inline">\(X(t)\)</span> 是独立增量过程；</li><li><span class="math inline">\(\forall s,t\ge0, X(t+s)-X(s)\sim{\mathcal N}(0,c^2t)\)</span>；</li><li><span class="math inline">\(X(t)\)</span> 关于 <spanclass="math inline">\(t\)</span> 是连续函数；</li></ol><p>则称 <span class="math inline">\(X(t)\)</span>是布朗运动或维纳过程。</p><p>可以验证 <span class="math inline">\(R(t_1,t_2) = {\mathbbE}[X(t_1)X(t_2)]=c^2(t_1\wedget_2)\)</span>，所以布朗运动是<strong>非平稳过程</strong>。</p><span id="more"></span><h2 id="正态分布相关理论">5.2 正态分布相关理论</h2><h3 id="柯西分布与高斯随机变量">5.2.1 柯西分布与高斯随机变量</h3><p>问题 1：求 <span class="math inline">\(Z=X/Y\)</span>的概率分布与分布密度函数。</p><p><strong>定理 5.1</strong>：设 <spanclass="math inline">\(X_1,X_2\)</span> 是独立的均值为 <spanclass="math inline">\(0\)</span>，方差为 <spanclass="math inline">\(1\)</span> 的正态分布随机变量，则 <spanclass="math inline">\(X_1/|X_2|\)</span> 服从 Cauchy分布，分布密度函数为：<span class="math inline">\(f(x)=1/\pi(1+x^2),-\infty &lt; x &lt; \infty\)</span>，相应的概率分布函数为 <spanclass="math inline">\(F(x)=1/2 + \pi^{-1}\arctan x, -\infty &lt; x &lt;\infty\)</span>。</p><h3 id="区域分布与互相关系数的关系">5.2.2区域分布与互相关系数的关系</h3><p>定义 <span class="math inline">\(\sin \alpha = \frac{ {\mathbbE}[XY]}{\sqrt{ {\mathbb E}[X^2]{\mathbb E}[Y^2]} }=r\)</span>，那么<span class="math inline">\(P(X &gt; 0,Y &gt; 0) = P(X &lt; 0, Y &lt;0)=1/4 + \alpha / 2\pi\)</span>，<span class="math inline">\(P(X &lt;0,Y &gt; 0) = P(X &gt; 0, Y &lt; 0)=1/4 - \alpha / 2\pi\)</span>。</p><p>证明：略。</p><h3 id="贝叶斯定理与条件分布密度表示理论">5.2.3贝叶斯定理与条件分布密度表示理论</h3><p><strong>贝叶斯定理</strong>：<spanclass="math inline">\(f_Y(y|X=x)=\frac{f_X(x|Y=y)f_Y(y)}{f_X(x)}\)</span>。</p><p>该定理在讨论条件概率问题时，把需要利用分布函数讨论的问题转化为利用分布密度函数来讨论，简化了问题的讨论。</p><h3 id="联合正态分布的边缘分布密度与条件分布密度">5.2.4联合正态分布的边缘分布密度与条件分布密度</h3><p>略。</p><h3 id="几个基本关系式">5.2.5 几个基本关系式</h3><p>假设 <span class="math inline">\(X,Y\)</span> 服从均值为 0的联合正态分布，则 <span class="math inline">\({\mathbb E}[XY] =r\sigma_1\sigma_2\)</span>，<span class="math inline">\({\mathbbE}[X^2Y^2]={\mathbb E}[X^2]{\mathbb E}[Y^2] + 2{\mathbbE}^2[XY]\)</span>，<span class="math inline">\({\mathbb E}[|XY|] =\frac{2\sigma_1\sigma_2}{\pi}(\cos\alpha+\sin\alpha)\)</span>，其中<span class="math inline">\(r=\sin\alpha, -\pi/2 &lt; \alpha \le\pi/2\)</span>。</p><p>证明：略。</p><h3 id="反正弦率">5.2.6 反正弦率</h3><p>设 <span class="math inline">\(X(t)\)</span> 为平稳过程，且 <spanclass="math inline">\(X(t+\tau),X(t)\)</span> 的联合分布服从正态分布，对<span class="math inline">\(X(t)\)</span> 进行非线性运算 <spanclass="math display">\[Y(t) = \begin{cases} 1, &amp; X(t)\ge0 \\ -1, &amp; X(t) &lt; 0\end{cases}\]</span> 那么有 <span class="math inline">\({\mathbbE}[Y(t+\tau)Y(t)]=2\alpha / \pi\)</span>。随机变量 <spanclass="math inline">\(X(t+\tau),X(t)\)</span> 联合正态，那么 <spanclass="math inline">\(r=R(\tau)/R(0)=\sin\alpha\)</span>，于是有 <spanclass="math inline">\(R_Y(\tau)= \frac{2}{\pi}\arcsin{\frac{R(\tau)}{R(0)}}\)</span>。</p><h3 id="零交叉问题">5.2.7 零交叉问题</h3><p>略。</p><h3 id="正态分布拖尾概率估计">5.2.8 正态分布拖尾概率估计</h3><p><strong>定理 5.2（Mill比值）</strong>：对任意的 <spanclass="math inline">\(x &gt; 0\)</span> 有 <spanclass="math inline">\(\frac{x}{1+x^2} e^{-x^2/2} &lt; \int_x^\inftye^{-u^2/2}du &lt; \frac{1}{x} e^{-x^2/2}\)</span>。特别的，当 <spanclass="math inline">\(x\to\infty\)</span> 时有 <spanclass="math inline">\(\int_x^\infty e^{-u^2/2}du \approx \frac{1}{x}e^{-x^2/2}\)</span>。</p><h2 id="布朗运动">5.3 布朗运动</h2><h3 id="有限维联合概率密度">5.3.1 有限维联合概率密度</h3><p><strong>定理 5.3</strong>：设 <spanclass="math inline">\(\{B(t),t\ge0\}\)</span> 为标准的布朗运动，令 <spanclass="math inline">\(x_0=0,t_0=0\)</span>，则当 <spanclass="math inline">\(B(0)=0\)</span> 时，对 <spanclass="math inline">\(\forall 0 &lt; t_1 &lt; t_2 &lt; \cdots &lt;t_n\)</span>，<spanclass="math inline">\((B(t_1),B(t_2),...,B(t_n))\)</span>的联合概率密度函数为 <span class="math inline">\(g(x_1,x_2,...,x_n;t_1,t_2,...,t_n) = \Pi_{i=1}^n p(x_i-x_{i-1};t_i-t_{i-1})\)</span>，其中 <spanclass="math inline">\(p(x;t)=\frac{1}{\sqrt{2\pit}}\exp(-x^2/2t)\)</span>。</p><h3 id="布朗运动的性质">5.3.2 布朗运动的性质</h3><p>下面考虑标准布朗运动（即取 <spanclass="math inline">\(c=1\)</span>）的性质。</p><p><strong>平移特性</strong>：对任意的 <span class="math inline">\(s&gt; 0\)</span>，<spanclass="math inline">\(B_s(t)=B(t+s)-B(s),t\ge0\)</span>是标准布朗运动；</p><p><strong>伸缩性</strong>：对任意的 <span class="math inline">\(c &gt;0\)</span>，<span class="math inline">\(\{\sqrt{c} B(t/c),t\ge0\}\)</span> 是标准布朗运动；</p><p><strong>对称性</strong>：<spanclass="math inline">\(\{-B(t),t\ge0\}\)</span> 是标准布朗运动；</p><p><strong>鞅性</strong>：略。</p><p>其余还有正态过程性质、马尔可夫性质、反射性质、时间可逆性等在后面详细解释。</p><h3 id="正态过程">5.3.3 正态过程</h3><p><strong>定义</strong>：若随机过程 <spanclass="math inline">\(\{X(t),t\in T\}\)</span>，对任意 <spanclass="math inline">\(t_i\in T,i=1,2,...,n\)</span> 有 <spanclass="math inline">\(X(t_1),...,X(t_n)\)</span> 的联合分布为 <spanclass="math inline">\(n\)</span> 维正态分布，则称 <spanclass="math inline">\(\{X(t),t\in T\}\)</span> 为正态过程。</p><p><strong>定理 5.4</strong>：设 <span class="math inline">\(\{B(t),t\ge0\}\)</span> 是正态过程，轨道连续，<spanclass="math inline">\(B(0)=0,\forall s,t&gt;0\)</span>，有 <spanclass="math inline">\({\mathbb E}B(t)=0, {\mathbb E}[B(s)B(t)]=s\wedget\)</span>，则 <span class="math inline">\(\{B(t),t\ge0\}\)</span>是布朗运动，反之亦然。</p><p>证明：充分性易证。必要性证明，验证布朗运动有关条件：1）<spanclass="math inline">\(\forall t, s \ge0\)</span>，可以验证增量 <spanclass="math inline">\(B(t)-B(s) \sim {\mathcal N}(0,|t-s|)\)</span>是零均值正态随机变量；2）再验证独立增量过程，而验证两个高斯分布的独立性只需要证明他们的互相关为0，细节略。</p><h3 id="马尔可夫性">5.3.4 马尔可夫性</h3><p><strong>正向马尔可夫性</strong>：<span class="math inline">\(\forallt_1 &lt; t_2 &lt; \cdots &lt; t_n\)</span>，在给定 <spanclass="math inline">\(B(t_1),..,B(t_{n-1})\)</span> 下，<spanclass="math inline">\(B(t_n)\)</span> 的条件概率密度函数与只给定 <spanclass="math inline">\(B(t_{n-1})\)</span> 下 <spanclass="math inline">\(B(t_n)\)</span> 的条件概率密度相同。</p><p><strong>反向马尔可夫性</strong>：同理。</p><p><strong>中间关于两侧的马尔可夫性</strong>：<spanclass="math inline">\(\forall t_1 &lt; t_2 &lt; \cdots &lt;t_n\)</span>，在给定 <spanclass="math inline">\(...,B(t_{i-1}),B(t_{i+1}),...\)</span> 下，<spanclass="math inline">\(B(t_i)\)</span> 的条件概率密度函数与只给定 <spanclass="math inline">\(B(t_{i-1}), B(t_{i+1})\)</span> 下 <spanclass="math inline">\(B(t_i)\)</span> 的条件概率密度相同。</p><p>下面讨论 <span class="math inline">\(B(t_2)\)</span> 关于给定 <spanclass="math inline">\(B(t_1),B(t_3)\)</span> 的条件概率密度。</p><p><strong>定理5.5</strong>：对 <span class="math inline">\(0\le t_1&lt; t &lt;t_2\)</span>，给定 <span class="math inline">\(B(t_1)=a,B(t_2)=b, B(0)=0\)</span>，则 <span class="math inline">\(B(t)\)</span>的条件概率密度是一个正态密度，其均值为 <span class="math inline">\(a +(b-a)(t-t_1)/(t_2-t_1)\)</span>，方差为 <spanclass="math inline">\((t_2-t)(t-t_1) / (t_2-t_1)\)</span></p><p>证明：由于 <span class="math inline">\(B(t)\)</span>为正态过程，<spanclass="math inline">\(\boldsymbol{b}=B(t_1),B(t),B(t_2)\)</span>服从联合高斯分布，其均值为 <span class="math inline">\({\boldsymbol\mu}=[0,0,0]^{\mathrm T}\)</span>，协方差矩阵 <spanclass="math display">\[\Sigma = {\mathbb E}[{\boldsymbol b}{\boldsymbol b}^{\mathrm T}] =\begin{bmatrix} t_1 &amp; t_1 &amp; t_1 \\ t_1 &amp; t &amp; t \\ t_1&amp; t &amp; t_2 \end{bmatrix}\]</span> 直接根据高斯分布向量的条件分布即可得到。</p><p><strong>Remark</strong>：实际上 <span class="math inline">\({\mathbbE}[B(t) | B(t_1),B(t_2)]\)</span> 是关于 <spanclass="math inline">\(t\)</span> 的线性函数。</p><p><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2021/brown_conditional.png" /></p><h3 id="反射性">5.3.5 反射性</h3><p><strong>反射性</strong>：对 <span class="math inline">\(a &gt;0\)</span>，定义 <span class="math inline">\(\tau_a=\inf\{t:B(t)=a\}\)</span> 表示首次击中时间，定义 <spanclass="math inline">\(B^{\ast}(t)=\begin{cases} B(t), &amp; t \le \tau_a\\ 2a-B(t), &amp; t &gt; \tau_a \end{cases}\)</span>，则 <spanclass="math inline">\(\{B^\ast(t),t\ge0\}\)</span> 是标准布朗运动；</p><p>证明：略。</p><h3 id="时间可逆性">5.3.6 时间可逆性</h3><p><strong>时间可逆性</strong>：定义 <spanclass="math inline">\(B&#39;(t)=\begin{cases} tB(1/t), &amp; t &gt; 0 \\0, &amp; t=0 \end{cases}\)</span>，则 <spanclass="math inline">\(\{B&#39;(t),t\ge0\}\)</span> 是标准布朗运动；</p><p>证明：<span class="math inline">\(B(t)\)</span>是正态过程，根据前面正态过程的定义，可以得到 <spanclass="math inline">\(tB(1/t)\)</span> 也是正态过程。再根据定理 5.4可以验证条件 <span class="math inline">\({\mathbbE}[B&#39;(t)B&#39;(s)]=s\wedge t\)</span>，关于在 <spanclass="math inline">\(t=0\)</span> 点的连续性稍复杂，省略。由此可以证明<span class="math inline">\(B&#39;(t)\)</span> 是布朗运动。</p>]]></content>
    
    
    <categories>
      
      <category>随机过程2</category>
      
    </categories>
    
    
    <tags>
      
      <tag>布朗运动</tag>
      
      <tag>高斯过程</tag>
      
      <tag>维纳过程</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>洋葱</title>
    <link href="/2021/11/17/music/Onion/"/>
    <url>/2021/11/17/music/Onion/</url>
    
    <content type="html"><![CDATA[<center><h2>洋葱🧅</h1></center><span id="more"></span><iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width="330" height="86" src="//music.163.com/outchain/player?type=2&amp;id=176053&amp;auto=1&amp;height=66"></iframe><blockquote><p>如果你眼神能够为我 片刻的降临 如果你能听到 心碎的声音 沉默的守护着你沉默的等奇迹 沉默的让自己 像是空气</p><p>大家都吃着聊着笑着 今晚多开心 最角落里的我 笑得多合群 盘底的洋葱像我永远是调味品 偷偷的看着你 偷偷的隐藏着自己</p><p>如果你愿意一层一层 一层地剥开我的心 你会发现 你会讶异 你是我 最压抑最深处的秘密 如果你愿意一层一层 一层地剥开我的心 你会鼻酸 你会流泪只要你能 听到我 看到我的全心全意</p><p>听你说你和你的他们 暧昧的空气 我和我的绝望 装得很风趣 我就像一颗洋葱永远是配角戏 多希望能与你 有一秒专属的剧情</p><p>如果你愿意一层一层 一层地剥开我的心 你会发现 你会讶异 你是我 最压抑最深处的秘密 如果你愿意一层一层 一层地剥开我的心 你会鼻酸 你会流泪只要你能 听到我 看到我的全心全意</p><p>如果你愿意一层一层 一层地剥开我的心 你会发现 你会讶异 你是我 最压抑最深处的秘密 如果你愿意一层一层 一层地剥开我的心 你会鼻酸 你会流泪只要你能 听到我 看到我的全心全意 你会鼻酸 你会流泪 只要你能 听到我看到我的全心全意</p></blockquote>]]></content>
    
    
    <categories>
      
      <category>Music</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>【随机过程2】泊松过程2 | 泊松过程扩展</title>
    <link href="/2021/11/09/stochastic-process-2/ch4-s2-possion-extend/"/>
    <url>/2021/11/09/stochastic-process-2/ch4-s2-possion-extend/</url>
    
    <content type="html"><![CDATA[<h2 id="非时齐次泊松过程">4.5 非时齐次泊松过程</h2><p><strong>定义</strong>：一个计数过程若满足：</p><ol type="1"><li><span class="math inline">\(N(0)=0\)</span>；</li><li>它是独立增量过程；</li><li>对充分小的 <span class="math inline">\(\Delta t&gt;0\)</span>，有<span class="math inline">\(P(N(t+\Delta t)-N(t)=1) = \lambda(t) \Deltat + o(\Delta t)\)</span>，<span class="math inline">\(P(N(t+\Deltat)-N(t)\ge 2)=o(\Delta t)\)</span>；</li></ol><p>则称它为具有强度函数 <spanclass="math inline">\(\{\lambda(t),t\ge0\}\)</span>的非时齐次泊松过程。</p><p><strong>定理 4.7</strong>：若 <spanclass="math inline">\(N(t),t\ge0\)</span> 是非时齐次泊松过程，令 <spanclass="math inline">\(m(t)=\int_0^t \lambda (s)ds\)</span>，则对 <spanclass="math inline">\(\forall s,t\ge0\)</span>，有 <spanclass="math display">\[P(N(t+s)-N(s)=n) = \frac{(m(s+t)-m(s))^n}{n!}\exp(-(m(s+t)-m(s))), ~n\ge0\]</span> 上述定理最主要特点在于 <span class="math inline">\({\mathbbE}[N(t+s)-N(s)] = m(s+t)-m(s) = \int_s^{s+t} \lambda(s)ds\)</span>，相应的方差为 <spanclass="math inline">\(D_{[N(s+t)-N(s)]}=m(s+t)-m(s)\)</span>。</p><h2 id="复合泊松过程">4.6 复合泊松过程</h2><h3 id="定义">4.6.1 定义</h3><p><strong>定义</strong>：设 <spanclass="math inline">\(\{Y_i,i\ge1\}\)</span>是独立同分布的随机变量序列，<spanclass="math inline">\(\{N(t),t\ge0\}\)</span> 为泊松过程，且与 <spanclass="math inline">\(\{Y_i,i\ge1\}\)</span> 独立，记 <spanclass="math inline">\(X(t)=\sum_{i=1}^{N(t)} Y_i\)</span>称为复合泊松过程。</p><p>为求 <span class="math inline">\(X(t)\)</span> 的矩，先求它的矩母函数<span class="math display">\[\begin{aligned}\phi_t(u) &amp;= {\mathbb E}[\exp(u X(t))] \\&amp;= \sum_{n=0}^\infty P(N(t)=n){\mathbb E}[\exp(uX(t)) | N(t)=n] \\&amp;= \exp(\lambda t(\phi_Y(u)-1))\end{aligned}\]</span> 其中 <span class="math inline">\(\phi_Y(u)={\mathbbE}[\exp(uY)]\)</span> 为 <span class="math inline">\(Y\)</span>的矩母函数。上式在 <span class="math inline">\(u=0\)</span> 处求导得到<span class="math inline">\({\mathbb E}[X(t)] = \phi_t&#39;(0) = \lambdat {\mathbb E}Y\)</span>，<span class="math inline">\({D}[X(t)] =\phi_t&#39;&#39;(0)-(\phi_t&#39;(0))^2 = \lambda t{\mathbbE}Y^2\)</span>。若 <span class="math inline">\(Y_i\)</span>取正整数的随机变量，则称 <spanclass="math inline">\(\{X(t),t\ge0\}\)</span> 为平稳无后效流。</p><h3 id="复合泊松恒等式">4.6.2 复合泊松恒等式</h3><p><strong>定理 4.8</strong>：设 <spanclass="math inline">\(Y=\sum_{i=1}^N X_i\)</span>是复合泊松随机变量，其中随机变量 <span class="math inline">\(N\)</span>服从均值为 <span class="math inline">\(\lambda\)</span>的泊松分布，随机变量序列 <spanclass="math inline">\(\{X_k,k=1,2,...\}\)</span> 是独立同分布的，且与<span class="math inline">\(N\)</span> 统计独立。设 <spanclass="math inline">\(X_k,(k=1,2,...)\)</span> 的分布函数为 <spanclass="math inline">\(F(x)\)</span>，则对任意的有界函数 <spanclass="math inline">\(h(x)\)</span> 有 <spanclass="math inline">\({\mathbb E}[Y h(Y)] = \lambda {\mathbb E}[Xh(Y+X)]\)</span>，其中随机变量 <span class="math inline">\(X\)</span> 与<span class="math inline">\(N\)</span> 统计独立，它的分布函数也为 <spanclass="math inline">\(F(x)\)</span>。</p><p>证明：略。</p><p><strong>推论 4.8.1</strong>：对任何正整数 <spanclass="math inline">\(n\)</span> 有 <span class="math inline">\({\mathbbE}[Y^n] = \lambda \sum_{k=0}^{n-1} \tbinom{n-1}{k} {\mathbbE}[Y^k]{\mathbb E}[X^{n-k}]\)</span>。</p><p>证明：令 <span class="math inline">\(h(x)=x^{n-1}\)</span>即可得证。</p><p>利用此推论可以得到： <span class="math display">\[\begin{aligned}{\mathbb E}Y &amp;= \lambda{\mathbb E}X \\{\mathbb E}Y^2 &amp;= \lambda{\mathbb E}X^2 + \lambda^2({\mathbb E}X)^2\\{\mathbb E}[Y-{\mathbb E}Y]^2 &amp;= \lambda{\mathbb E}X^2 \\{\mathbb E}[Y-{\mathbb E}Y]^3 &amp;= \lambda{\mathbb E}X^3\end{aligned}\]</span></p><h2 id="条件泊松过程">4.7 条件泊松过程</h2><p><strong>定义</strong>：设 <spanclass="math inline">\(\Lambda\)</span> 是一个正的随机变量，分布函数为<span class="math inline">\(G(x),x\ge0\)</span>，设 <spanclass="math inline">\(\{N(t),t\ge0\}\)</span> 是一个计数过程，且给定<span class="math inline">\(\Lambda=\lambda\)</span> 的条件下，<spanclass="math inline">\(\{N(t),t\ge0\}\)</span> 是一个泊松过程，即 <spanclass="math inline">\(\forall s,t\ge0,n\in\mathbb{N},\lambda\ge0\)</span>，有 <span class="math display">\[P(N(s+t)-N(s)=n | \Lambda=\lambda) = \frac{(\lambda t)^n}{n!}e^{-\lambda t}\]</span> 则 <span class="math inline">\(\{N(t),t\ge0\}\)</span>是条件泊松过程。</p><p><strong>Remark</strong>：这里 <spanclass="math inline">\(\{N(t),t\ge0\}\)</span>本身并不是独立增量过程，由全概率公式得到 <span class="math display">\[P(N(s+t)-N(s)=n) = \int_0^{\infty} \frac{(\lambda t)^n}{n!} e^{-\lambdat} dG(\lambda)\]</span> <strong>定理 4.9</strong>：设 <spanclass="math inline">\(\{N(t),t\ge0\}\)</span> 是上述条件泊松过程，则</p><ol type="1"><li><span class="math inline">\({\mathbb E}[N(s+t)-N(t)] = s{\mathbbE}\Lambda\)</span></li><li><span class="math inline">\(D[N(s+t)-N(t)] = s{\mathbb E}\Lambda +s^2 D\Lambda\)</span></li></ol><p>证明：略。</p><h2 id="更新过程">4.8 更新过程</h2><h3 id="更新过程的定义">4.8.1 更新过程的定义</h3><p><strong>定义</strong>：设 <spanclass="math inline">\(\{X_k,k\ge1\}\)</span>独立同分布的非负随机变量，分布函数为 <spanclass="math inline">\(F(x)\)</span>，且 <spanclass="math inline">\(F(0)&lt;1\)</span>。令 <spanclass="math inline">\(S_0=0, S_n=\sum_{k=1}^n X_k\)</span>，对 <spanclass="math inline">\(\forall t\ge0\)</span>，记 <spanclass="math inline">\(N(t)=\sup\{n:S_n\le t\}\)</span> 或者 <spanclass="math inline">\(N(t)=\sum_{n=1}^\infty I_{\{S_n\let\}}\)</span>，称 <span class="math inline">\(\{N(t),t\ge0\}\)</span>为更新过程。</p><p>记 <span class="math inline">\(F_n(x)\)</span> 为 <spanclass="math inline">\(S_n\)</span> 的分布函数，易知 <spanclass="math inline">\(F_1(x)=F(x)\)</span>，<spanclass="math inline">\(F_n(x)=\int_0^xF_{n-1}(x-u)dF(u),(n\ge2)\)</span>，即 <spanclass="math inline">\(F_n(x)\)</span> 是 <spanclass="math inline">\(F(x)\)</span> 的 <spanclass="math inline">\(n\)</span> 重卷积。记 <spanclass="math inline">\(m(t)={\mathbb E}[N(t)]\)</span>，称 <spanclass="math inline">\(m(t)\)</span> 为更新函数。</p><p>类似的，分布密度函数同样是卷积的形式 <spanclass="math inline">\(f_n(x) = \int_0^xf_{n-1}(x-u)f(u)du\)</span>。</p><p><strong>定理 4.10</strong>：<span class="math inline">\(\forallt\ge0\)</span> 有 <span class="math inline">\(m(t)=\sum_{n=1}^\inftyF_n(t)\)</span>。</p><p>证明：<span class="math inline">\(m(t)=\sum_n nP(N(t)=n) = \sum_nP(N(t)\ge n) = \sum_n P(S_n\le t) = \sum_n F_n(t)\)</span>.</p><p><em>栗子 4.3</em>：<span class="math inline">\(F(x)\)</span>是指数分布函数，相应的概率密度函数为 <spanclass="math inline">\(f(x)=\lambda e^{-\lambda x},x\ge0,\lambda &gt;0\)</span>，那么由此可以计算 <spanclass="math inline">\(f_n(x)=\frac{\lambda (\lambda x)^{n-1}}{(n-1)!}e^{-\lambda x}\)</span>，然后计算得到 <span class="math inline">\(m(t) =\lambda t\)</span>，这与之前泊松过程的结论是一致的。</p><p><em>栗子 4.4</em>：设 <span class="math inline">\(F(x)\)</span> 是Gamma 分布函数，相应的额概率密度函数为 <spanclass="math inline">\(f(x)=xe^{-x}\)</span>，其 <strong>Laplace变换</strong>为 <span class="math inline">\(\hat{f}(s) =1/(1+s)^2\)</span>，利用 Laplace 变换的性质知道 <spanclass="math inline">\(\hat{f_n}(s)=1/(1+s)^{2n}\)</span>，反变换即可得到<span class="math inline">\(f_n(x)\)</span>，然后再根据定理 4.10计算得到<span class="math inline">\(m(t)=-\frac{1}{4} + \frac{t}{2} +\frac{e^{-2t}}{4}\)</span>。</p><h3 id="更新过程的剩余寿命与年龄">4.8.2 更新过程的剩余寿命与年龄</h3><p>设 <span class="math inline">\(N(t)\)</span> 表示 <spanclass="math inline">\([0,t]\)</span> 上事件发生的个数，<spanclass="math inline">\(S_n\)</span> 表示第 <spanclass="math inline">\(n\)</span> 个事件发生的时刻，那么 <spanclass="math inline">\(S_{N(t)}\)</span> 表示在 <spanclass="math inline">\(t\)</span> 之前最后一个事件发生的时刻，<spanclass="math inline">\(S_{N(t)+1}\)</span> 表示 <spanclass="math inline">\(t\)</span> 时刻后首次事件发生的时刻。令 <spanclass="math inline">\(W(t)=S_{N(t)+1}-t, V(t)=t-S_{N(t)}\)</span>，则<span class="math inline">\(W(t)\)</span> 表示 <spanclass="math inline">\(t\)</span> 时刻后直到首次事件发生的剩余时间。</p><p><strong>定理 4.11</strong>：若非负随机变量 <spanclass="math inline">\(\{X_n,n\ge1\}\)</span> 独立同分布，分布函数为<span class="math inline">\(F(x)\)</span>，则对 <spanclass="math inline">\(\forall x,t\ge0\)</span>，有</p><ol type="1"><li><span class="math inline">\(P(W(t) &gt; x)=1 - F(x+t) + \int_0^tP(W(t-u) &gt; x) dF(u)\)</span></li><li><span class="math inline">\(P(V(t) \le x) = (1-F(t)) I_{[0,x]}(t) +\int_0^t P(V(t-y) \le x) dF(y)\)</span></li></ol><p>证明：略。</p><p><strong>定理 4.12</strong>：设 <spanclass="math inline">\(\{N(t),t\ge0\}\)</span> 是参数为 <spanclass="math inline">\(\lambda\)</span> 的泊松过程，则</p><ol type="1"><li><span class="math inline">\(W(t)\)</span> 与 <spanclass="math inline">\(\{X_n,n\ge1\}\)</span> 同分布，即 <spanclass="math inline">\(P(W(t)\le x)=1-\exp(-\lambdax),x\ge0\)</span></li><li><span class="math inline">\(V(t)\)</span> 是截尾的指数分布，即 <spanclass="math inline">\(P(V(t)\le x)=\begin{cases} 1-\exp(-\lambda x)&amp; 0\le x &lt; t \\ 1 &amp; x\ge t \end{cases}\)</span></li></ol><p>证明：略。</p><h2 id="瓦尔德等式">4.10 瓦尔德等式</h2><p><strong>定义</strong>：设 <spanclass="math inline">\(\{X_n,n\ge1\}\)</span> 为随机序列，<spanclass="math inline">\(T\)</span> 为非负整数随机变量，若对任一 <spanclass="math inline">\(n\in{\mathbb N}\)</span> 事件 <spanclass="math inline">\(\{T=n\}\)</span> 仅依赖于 <spanclass="math inline">\(\{X_1,...,X_n\}\)</span>，而与 <spanclass="math inline">\(X_{n+1},X_{n+2},...\)</span> 独立，则称 <spanclass="math inline">\(T\)</span> 关于 <spanclass="math inline">\(\{X_n,n\ge1\}\)</span>是<strong>停时</strong>，或称马尔可夫时。</p><p><strong>定理 4.13（Wald）</strong>：设 <spanclass="math inline">\(\{X_n,n\ge1\}\)</span> 独立同分布，<spanclass="math inline">\(\mu={\mathbb E}X_n &lt; \infty\)</span>，<spanclass="math inline">\(X_n\)</span> 与 <spanclass="math inline">\(X\)</span> 同分布，<spanclass="math inline">\(\tau\)</span> 关于 <spanclass="math inline">\(\{X_n,n\ge1\}\)</span> 是停时，且 <spanclass="math inline">\({\mathbb E}\tau &lt; \infty\)</span>，则 <spanclass="math inline">\({\mathbb E}[\sum_{n=1}^\tau X_n] = {\mathbb E}X{\mathbb E}\tau\)</span></p><p>证明：略。</p><h2 id="泊松过程与鞅">4.11 泊松过程与鞅</h2><p>线性方法构造的鞅，<span class="math inline">\(Y(t)=N(t)-\lambda t,U(t)=Y^2(t)-\lambda t\)</span></p><p>基于特征函数构造的鞅 <span class="math inline">\(V(t)=\exp(-\thetaN(t) + \lambda t(1-e^{-\theta}))\)</span></p>]]></content>
    
    
    <categories>
      
      <category>随机过程2</category>
      
    </categories>
    
    
    <tags>
      
      <tag>泊松过程</tag>
      
      <tag>更新过程</tag>
      
      <tag>Wald等式</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【随机过程2】泊松过程1 | 定义与基本性质</title>
    <link href="/2021/11/02/stochastic-process-2/ch4-s1-possion-concepts/"/>
    <url>/2021/11/02/stochastic-process-2/ch4-s1-possion-concepts/</url>
    
    <content type="html"><![CDATA[<h2 id="泊松过程的定义与基本性质">4.1 泊松过程的定义与基本性质</h2><p><strong>定义 4.1</strong>：随机过程 <spanclass="math inline">\(\{N(t),t\ge0\}\)</span>称为时齐泊松过程，若满足下列条件：</p><ol type="1"><li>他是一个计数过程，且 <spanclass="math inline">\(N(0)=0\)</span>；</li><li>（独立增量）任取 <span class="math inline">\(0 &lt; t_1 &lt; t_2&lt; \cdots &lt; t_n\)</span>，<spanclass="math inline">\(N(t_1),N(t_2)-N(t_1),...,N(t_n)-N(t_{n-1})\)</span>相互独立；</li><li>（平稳增量）<span class="math inline">\(\foralls,t\ge0,n\ge0\)</span>，<span class="math inline">\(P(N(s+t)-N(s)=n) =P(N(t)=n)\)</span>；</li><li>对任意 <span class="math inline">\(t&gt;0\)</span> 和充分小的 <spanclass="math inline">\(\Delta t&gt;0\)</span>，有 <spanclass="math inline">\(P(N(t+\Delta t)-N(t)=1) = \lambda \Delta t +o(\Delta t)\)</span>，<span class="math inline">\(P(N(t+\Deltat)-N(t)\ge 2)=o(\Delta t)\)</span>；</li></ol><p>其中 <span class="math inline">\(\lambda&gt;0\)</span>称为强度常数，<span class="math inline">\(o(\Delta t)\)</span>为高阶无穷小。</p><span id="more"></span><p><strong>定义 4.2</strong>：计数过程 <spanclass="math inline">\(\{N(t),t\ge0\}\)</span>，被称为参数为 <spanclass="math inline">\(\lambda\)</span>的时齐泊松过程，若满足如下条件：</p><ol type="1"><li><span class="math inline">\(N(0)=0\)</span>；</li><li>它是独立增量过程；</li><li><span class="math inline">\(\forall s,t\ge0,N(s+t)-N(s)\)</span>是参数为 <span class="math inline">\(\lambda t\)</span> 的泊松分布，即<span class="math inline">\(P(N(t+s)-N(s)=k) = \frac{(\lambda t)^k}{k!}e^{-\lambda t}\)</span>。</li></ol><blockquote><p>两种定义是等价的。</p></blockquote><p>基本性质：</p><ol type="1"><li>均值 <span class="math inline">\({\mathbb E}[N(t)] = \lambdat\)</span>；</li><li>方差 <span class="math inline">\(\text{var}(N(t)) = {\mathbbE}[(N(t)-\lambda t)^2] = \lambda t\)</span>；</li><li>特征函数 <span class="math inline">\(\phi_{N(t)}(x) = {\mathbbE}[\exp(-j N(t)x)] = \exp(-\lambda t e^{jx})\)</span>；</li><li><span class="math inline">\({\mathbb E}[N(t)^2] = (\lambda t)^2 +\lambda t\)</span>；</li><li>自相关函数 <span class="math inline">\(R(t+\tau,t) = {\mathbbE}[N(t+\tau)N(t)] = (\lambda t)^2 + \lambda t + \lambda^2t\tau,(\tau&gt;0)\)</span>（非平稳过程）</li></ol><p><em>栗子 4.1</em>：<span class="math inline">\(\{N(t),t\ge0\}\)</span> 是参数为 <span class="math inline">\(\lambda\)</span>的时齐泊松过程，<span class="math inline">\(S_0=0,S_n\)</span> 为第<span class="math inline">\(n\)</span> 个事件发生的时刻，则 <spanclass="math inline">\(N(t)\)</span> 关于 <spanclass="math inline">\(\{S_n,n\ge0\}\)</span> 不是停时，但是 <spanclass="math inline">\(N(t)+1\)</span> 关于 <spanclass="math inline">\(\{S_n,n\ge0\}\)</span> 是停时。</p><p>证明：<span class="math inline">\(\{N(t)=n\} \iff \{S_n\le t &lt;S_{n+1} \}=\{S_n\le t \} - \{S_{n+1}\le t \}\)</span>，因此 <spanclass="math inline">\(\{N(t)=n\}\)</span> 可以由 <spanclass="math inline">\(\{S_0,...,S_{n+1} \}\)</span> 构成的事件表示，因此<span class="math inline">\(N(t)+1\)</span> 关于 <spanclass="math inline">\(\{S_n,n\ge0\}\)</span> 是停时。</p><h2 id="泊松过程与指数分布的关系">4.2 泊松过程与指数分布的关系</h2><p><span class="math inline">\(N(t),t\ge0\)</span> 是计数过程，令 <spanclass="math inline">\(S_0=0,S_n\)</span> 表示第 <spanclass="math inline">\(n\)</span> 个事件发生的时刻，<spanclass="math inline">\(X_n=S_n-S_{n-1}\)</span> 表示第 <spanclass="math inline">\(n\)</span> 个与第 <spanclass="math inline">\(n-1\)</span> 个事件之间的间隔，于是有 <spanclass="math inline">\(S_n=\inf\{t:N(t)=n \},n\ge1\)</span>。相应的 <spanclass="math inline">\(N(t)\)</span> 可以表示为 <spanclass="math inline">\(N(t)=\sum_{n=1}^{\infty}I_{[0,t]}(S_n)\)</span>。</p><p><span class="math inline">\(P(S_n \le t) = P(N(t)\ge n) =1-e^{-\lambda t} \sum_{k=0}^{n-1} \frac{(\lambdat)^k}{k!}\)</span>，特别当 <span class="math inline">\(n=1\)</span>时，有 <span class="math inline">\(P(S_1\le t) = P(X_1\le t) =1-e^{-\lambda t}\)</span>，即 <span class="math inline">\(X_1\simE(\lambda)\)</span> 是参数为 <spanclass="math inline">\(\lambda\)</span> 的指数分布。同样的可以得到 <spanclass="math inline">\(X_n(n\ge2)\)</span> 也服从指数分布，均值为 <spanclass="math inline">\(1/\lambda\)</span>，方差为 <spanclass="math inline">\(1/\lambda^2\)</span>。</p><p><strong>定理4.1</strong>：计数过程是泊松过程的<strong>充要条件</strong>是 <spanclass="math inline">\(\{X_n,n\ge1\}\)</span>是独立的同<strong>指数分布</strong>。</p><p>证明：略。</p><h2 id="到达时间的条件分布">4.3 到达时间的条件分布</h2><h3 id="到达时间的条件分布-1">4.3.1 到达时间的条件分布</h3><p><strong>定理 4.2</strong>：设 <spanclass="math inline">\(N(t),t\ge0\)</span> 是泊松过程，则对 <spanclass="math inline">\(\forall 0&lt; s &lt; t\)</span> 有 <spanclass="math inline">\(P(X_1\le s | N(t)=1) = s/t\)</span>。</p><p>证明：<span class="math inline">\(P(X_1\le s | N(t)=1) = P(X_1\le s,N(t)=1) / P(N(t)=1) = P(N(s)=1, N(t)-N(s)=0) / P(N(t)=1)\)</span>。</p><p><strong>定理 4.3</strong>：设 <spanclass="math inline">\(N(t),t\ge0\)</span> 是泊松过程，则对 <spanclass="math inline">\(\forall 0&lt; s &lt; t,k\le n\)</span> 有 <spanclass="math inline">\(P(S_k \le s | N(t)=n) = \sum_{l=k}^n\frac{n!}{l!(n-l)!}(\frac{s}{t})^l(1-\frac{s}{t})^{n-l}\)</span>。特别当 <spanclass="math inline">\(k=n\)</span> 时，有 <spanclass="math inline">\(P(S_n\le s | N(t)=n) =(\frac{s}{t})^n\)</span>。</p><p>证明：略。</p><h3 id="顺序统计量">4.3.2 顺序统计量</h3><p><span class="math inline">\(Y_1,...,Y_n\)</span> 是 <spanclass="math inline">\(n\)</span> 个随机变量，如果 <spanclass="math inline">\(Y_{(k)}\)</span> 是 <spanclass="math inline">\(Y_1,...,Y_n\)</span> 中第 <spanclass="math inline">\(k\)</span> 个最小的随机变量，我们称 <spanclass="math inline">\(Y_{(1)},...,Y_{(n)}\)</span> 是关于 <spanclass="math inline">\(Y_1,...,Y_n\)</span> 的顺序统计量。如果 <spanclass="math inline">\(Y_1,...,Y_n\)</span>是独立同分布的连续随机变量，其概率密度分布为 <spanclass="math inline">\(f(y)\)</span>，则 <spanclass="math inline">\(Y_{(1)},...,Y_{(n)}\)</span>的联合分布概率密度函数为 <span class="math display">\[f(y_1,...,y_n) = n! \Pi_{k=1}^n f(y_k), ~ y_1 &lt; y_2 &lt; \cdots &lt;y_n\]</span> 特别的，当 <span class="math inline">\(Y_1,...,Y_n\)</span> 为<span class="math inline">\((0,t)\)</span>上独立的均匀分布随机变量时，相应的顺序统计量 <spanclass="math inline">\(Y_{(1)},...,Y_{(n)}\)</span>的联合分布概率密度函数为 <span class="math display">\[f(y_1,...,y_n) = n! / t^n, ~ 0&lt; y_1 &lt; y_2 &lt; \cdots &lt; y_n&lt; t\]</span> <strong>定理 4.4</strong>：设 <spanclass="math inline">\(N(t),t\ge0\)</span> 为泊松过程，则在已给 <spanclass="math inline">\(N(t)=n\)</span> 时事件相继发生的时间 <spanclass="math inline">\(S_1,...,S_n\)</span> 的条件概率密度为 <spanclass="math display">\[f(t_1,t_2,...,t_n) = \begin{cases}n!/t^n, &amp; 0&lt; t_1 &lt; t_2 &lt;\cdots &lt; t_n \\ 0, &amp; others \end{cases}\]</span> 证明：对任取的 <span class="math inline">\(0=t_0 &lt; t_1 &lt;t_2 &lt; \cdots &lt; t_n &lt; t_{n+1}=t\)</span>，取 <spanclass="math inline">\(h_0=h_{n+1}=0\)</span> 及充分小的 <spanclass="math inline">\(h_i\)</span>，则 <span class="math display">\[\begin{aligned}&amp;P(t_i &lt; S_i \le t_i+h_i, 1\le i\le n | N(t)=n) \\=&amp; \frac{P(N(t_i+h_i)-N(t_i)=1,1\le i\le n, ~N(t_{j+1})-N(t_j+h_j)=0, 1\le j\le n)}{P(N(t)=n)} \\=&amp; \frac{n!}{t^n} h_1 h_2 \cdots h_n\end{aligned}\]</span> 取极限即可得证。</p><blockquote><p><strong>Remark</strong>：上述定理表明，若非负函数 <spanclass="math inline">\(g(x_1,...,x_n)\)</span> 是关于 <spanclass="math inline">\(x_i, i=1,...,n\)</span>的对称函数，即对任意一种排列模式 <spanclass="math inline">\(\phi\)</span>，有 <spanclass="math inline">\(g(x_1,...,x_n) = g(x_{\phi(1)}, x_{\phi(2)},...,x_{\phi(n)})\)</span>（也就是函数值与各分量的顺序无关），则在概率分布的意义上下列等式成立<span class="math display">\[g(S_1,...,S_n|N(t)=n) \overset{d}{=} g(Y_{(1)},...,Y_{(n)}) =g(Y_1,...,Y_n)\]</span> 其中 <span class="math inline">\(Y_1,...,Y_n\)</span> 为 <spanclass="math inline">\((0,t)\)</span> 上独立的均匀分布随机变量。</p></blockquote><p><em>栗子 4.2</em>：设某工地有一工程任务，工人到达工地遵照参数为 <spanclass="math inline">\(\lambda\)</span> 的泊松流，求在时刻 <spanclass="math inline">\(t\)</span> 工人完成的总的工程量的期望值。</p><p>解：设第 <span class="math inline">\(i\)</span>个工人到达工地的时刻为 <span class="math inline">\(S_i\)</span>，在<span class="math inline">\([0,t]\)</span> 内工人完成的总工程量为 <spanclass="math inline">\(S(t)=\sum_{i=1}^{N(t)}(t-S_i)\)</span>。有 <spanclass="math inline">\({\mathbb E}[S(t) | N(t)=n] = nt - {\mathbbE}[\sum_{i=1}^n S_i | N(t)=n]=nt - {\mathbb E}[\sum_{j=1}^n Y_j |N(t)=n]=nt/2\)</span>，于是 <span class="math inline">\({\mathbbE}[S(t)] = {\mathbb E}[{\mathbb E}[S(t) | N(t)=n]] = \lambdat^2/2\)</span>.</p><p><strong>定理 4.5</strong>：设 <spanclass="math inline">\(N(t),t\ge0\)</span> 是参数为 <spanclass="math inline">\(\lambda\)</span> 的泊松过程，<spanclass="math inline">\(S_k,k\ge1\)</span> 为到达时刻，则对任意的 <spanclass="math inline">\([0,+\infty)\)</span> 上可积函数 <spanclass="math inline">\(f\)</span> 有 <span class="math inline">\({\mathbbE}[\sum_{n=1}^{\infty} f(S_n)] = \lambda\int_0^\inftyf(s)ds\)</span>.</p><p>证明：当 <span class="math inline">\(t\ge0\)</span> 时，有 <spanclass="math inline">\(\{S_n\le t\}=\{N(t)\ge n\}\)</span>，因此有 <spanclass="math inline">\(P(S_n\le t)=P(N(t)\ge n) = \sum_{j=n}^\infty\frac{(\lambda t)^j}{j!} e^{-\lambda t}\)</span>，求导得到 <spanclass="math inline">\(S_n\)</span> 的概率密度为 <spanclass="math inline">\(f_{S_n}(t)=\lambda \frac{(\lambdat)^{n-1}}{(n-1)!} e^{-\lambda t}I_{\{t\ge0\}}\)</span>，因此 <spanclass="math inline">\({\mathbb E}[f(S_n)] = \lambda \int_0^\inftyf(s)\frac{(\lambda s)^{n-1}}{(n-1)!} e^{-\lambda s} ds\)</span>，再对<span class="math inline">\(n\)</span> 求和即可得证。</p><p><em>栗子 4.3</em>：题干同上面的栗子 4.2.</p><p>解：定义 <spanclass="math inline">\(f(s)=I_{[0,t]}(s)(t-s)\)</span>，则 <spanclass="math inline">\(S(t)=\sum_{i=1}^{\infty} f(s_i)\)</span>，利用定理4.5 结论即可得到 <span class="math inline">\({\mathbb E}[S(t)] = \lambdat^2 /2\)</span>。</p><h2 id="泊松过程的分流">4.4 泊松过程的分流</h2><p><strong>定理 4.6</strong>：设 <spanclass="math inline">\(N(t),t\ge0\)</span> 是参数为 <spanclass="math inline">\(\lambda\)</span>的泊松过程，到达事件的类型取决于它到达的时间。如果某到达时间是 <spanclass="math inline">\(s&gt;0\)</span>，则它属于类型 1 的概率为 <spanclass="math inline">\(P(s)\)</span>，输于类型 2 的概率为 <spanclass="math inline">\(1-P(s)\)</span>。假设 <spanclass="math inline">\(N_m(t),(m=1,2)\)</span> 表示 <spanclass="math inline">\((0,t]\)</span> 内到达的类型 <spanclass="math inline">\(m\)</span> 的事件数，则 <spanclass="math inline">\(N_1(t)\)</span> 和 <spanclass="math inline">\(N_2(t)\)</span>是两个独立的泊松变量，相应的均值分别为 <spanclass="math inline">\(\lambda pt\)</span> 和 <spanclass="math inline">\(\lambda(1-p)t\)</span>，其中 <spanclass="math inline">\(p=\frac{1}{t}\int_0^t P(s) ds\)</span>。</p><p>证明：<span class="math inline">\(P(N_1(t)=k, N_2(t)=l) = P(N_1(t)=k,N_2(t)=l | N(t)=k+l) P(N(t)=k+l)\)</span>，考虑发生在 <spanclass="math inline">\((0,t]\)</span> 的事件，如果事件在时刻 <spanclass="math inline">\(s\)</span> 发生，由于其在 <spanclass="math inline">\((0,t]\)</span> 服从均匀分布，那么该事件是类型 1的概率为 <span class="math inline">\(p=\frac{1}{t}\int_0^tP(s)ds\)</span>。</p><p>另外由于这些事件相互独立，因此 <spanclass="math inline">\(P(N_1(t)=k, N_2(t)=l |N(t)=k+l)=\tbinom{k+l}{k}p^k(1-p)^l\)</span>。证毕。</p><blockquote><p><strong>Remark</strong>：如果 <spanclass="math inline">\(P(s)\)</span> 与 <spanclass="math inline">\(s\)</span>无关，那么分流之后将得到两个新的泊松流，否则不是泊松流。</p></blockquote>]]></content>
    
    
    <categories>
      
      <category>随机过程2</category>
      
    </categories>
    
    
    <tags>
      
      <tag>泊松过程</tag>
      
      <tag>指数分布</tag>
      
      <tag>顺序统计量</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Happy 1024 day!</title>
    <link href="/2021/10/24/essay/2021-1024/"/>
    <url>/2021/10/24/essay/2021-1024/</url>
    
    <content type="html"><![CDATA[<p>:fireworks:</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>【随机过程2】离散鞅论3 | 鞅论应用</title>
    <link href="/2021/10/16/stochastic-process-2/ch3-s3-martingale-application/"/>
    <url>/2021/10/16/stochastic-process-2/ch3-s3-martingale-application/</url>
    
    <content type="html"><![CDATA[<h2 id="鞅论的应用">3.11 鞅论的应用</h2><p><em>栗子1</em>：三人赌博，每一轮从中随机依次选出两个人，第一个被选中的人给第二个一枚硬币。如果其中一个人没有硬币，其余两人继续赌博，直到其中一个人赢得所有硬币。假设三个人被选中概率完全相等，且每次选择相互独立。如果最初三人拥有的硬币数分别为<span class="math inline">\(a,b,c\)</span>，求此游戏结束的平均时间。</p><span id="more"></span><p><strong>解</strong>：设三个人在第 <spanclass="math inline">\(n\)</span> 次赌博之后拥有的硬币分别为 <spanclass="math inline">\(X_n,Y_n,Z_n\)</span>，记 <spanclass="math inline">\(S_n=X_n Y_n+Y_n Z_n+X_n Z_n\)</span>。定义 <spanclass="math inline">\(M_n=\sum_{k=1}^n (S_k - {\mathbb E}[S_k |X_0,Y_0,Z_0,...,X_{k-1},Y_{k-1},Z_{k-1}])\)</span>，则可以证明 <spanclass="math inline">\(\{M_n\}\)</span> 是鞅。下面想要计算 <spanclass="math inline">\(M_n\)</span> 的具体表达式，需要分情况讨论：</p><ul><li>case1：<spanclass="math inline">\(X_{k-1}Y_{k-1}Z_{k-1}&gt;0\)</span>，可以验证<span class="math inline">\({\mathbb E}[X_k Y_k | X_{k-1}=x,Y_{k-1}=y] =xy-1/3\)</span>，因此有 <span class="math inline">\({\mathbb E}[S_k |X_{k-1},Y_{k-1},Z_{k-1}] = S_{k-1}-1\)</span>；</li><li>case2：<span class="math inline">\(X_{k-1}=0\)</span>，此时有 <spanclass="math inline">\(X_k=0\)</span>，<spanclass="math inline">\({\mathbb E}[S_k | X_{k-1},Y_{k-1},Z_{k-1}] =S_{k-1}-1\)</span>；</li></ul><p>因此有 <span class="math inline">\(M_{n} =S_n-S_0+n\)</span>，可以验证<strong>鞅的停时定理 3</strong>条件成立，从而有 <span class="math inline">\({\mathbb E}[M_{\tau}] ={\mathbb E}[M_0]=0\)</span>，又有 <span class="math inline">\({\mathbbE}[M_\tau] = {\mathbb E}S_\tau - {\mathbb E}S_0 + {\mathbb E}\tau ={\mathbb E}\tau - {\mathbb E}S_0 = 0\)</span>，因此 <spanclass="math inline">\({\mathbb E}\tau={\mathbbE}S_0=ab+bc+ac\)</span>。</p><blockquote><p><strong>Note</strong>：如何想到这样定义一个鞅？首先考虑一阶统计量<span class="math inline">\(S_n=X_n+Y_n+Z_n\)</span>恒等于常数，因此考虑二阶统计量。</p></blockquote><p><em>栗子 2</em>（随机徘徊）：一维随机徘徊，<spanclass="math inline">\(Y_n\)</span>表示第 <spanclass="math inline">\(n\)</span> 个时刻质点移动的距离，<spanclass="math inline">\(P(Y_n=1)=P(Y_n=-1)=1/2\)</span>，在 <spanclass="math inline">\(n\)</span> 时刻质点离开原点的距离为 <spanclass="math inline">\(X_n=\sum_{i=1}^n Y_i\)</span>，其中 <spanclass="math inline">\(X_0=0\)</span>，容易验证 <spanclass="math inline">\(\{X_n\}\)</span> 关于 <spanclass="math inline">\(\{Y_n\}\)</span> 是鞅。下面需要讨论：</p><ol type="1"><li>从原点到达 1 的平均时间；</li><li>设 <span class="math inline">\(a&lt;0&lt;b\)</span>为两个整数，质点先到达 <span class="math inline">\(a\)</span> 的概率<span class="math inline">\(P_a\)</span>？</li><li>设 <span class="math inline">\(a&lt;0&lt;b\)</span>为两个整数，质点到达 <span class="math inline">\(a\)</span> 或 <spanclass="math inline">\(b\)</span> 的平均时间？</li></ol><p><em>解</em>：(1) 定义停时 <span class="math inline">\(\tau_1=\min\{n: X_0=0,X_n=1 \}\)</span>，那么需要求 <spanclass="math inline">\({\mathbbE}\tau\)</span>，可以考虑用<strong>鞅的停时定理3</strong>，首<strong>先假设条件 <span class="math inline">\({\mathbbE}\tau&lt;\infty\)</span> 成立</strong>，<spanclass="math inline">\({\mathbb E}[|X_{n+1}-X_n| | Y_0,...,Y_n]={\mathbbE}[|Y_{n+1}|]=1\)</span>，于是停时定理 3 条件满足，那么就有 <spanclass="math inline">\({\mathbb E}X_{\tau} = {\mathbbE}X_0=0\)</span>，但是根据停时的定义有 <spanclass="math inline">\({\mathbb E}X_\tau=1\)</span>，矛盾，这说明假设<span class="math inline">\({\mathbb E}\tau&lt;\infty\)</span>不成立，所以 <span class="math inline">\({\mathbbE}\tau=\infty\)</span>。</p><ol start="2" type="1"><li><p>设 <span class="math inline">\({\tau}\)</span> 表示从 <spanclass="math inline">\(0\)</span> 出发达到 <spanclass="math inline">\(a\)</span> 或 <spanclass="math inline">\(b\)</span> 的时间，<spanclass="math inline">\(\tau\)</span> 关于 <spanclass="math inline">\(\{Y_n\}\)</span> 是停时，容易验证 <spanclass="math inline">\(P(\tau&lt;\infty | X_0=0)=1\)</span>，而且 <spanclass="math inline">\(|X_{\tau \wedge n}| \le \max{-a,b}\)</span>，因此<span class="math inline">\({\mathbb E}[\sup_{n} |X_{\tau\wedgen}|]&lt;\infty\)</span>，<strong>鞅的停时定理 2</strong>条件满足，因此有 <span class="math inline">\({\mathbb E}X_\tau = aP_a +bP_b ={\mathbb E}X_0=0\)</span>，另外有 <spanclass="math inline">\(P_a+P_b=1\)</span>，于是可以得到 <spanclass="math inline">\(P_a=b/(b-a)\)</span>。</p></li><li><p>设 <span class="math inline">\(\tau\)</span> 为从 <spanclass="math inline">\(0\)</span> 出发达到 <spanclass="math inline">\(a\)</span> 或 <spanclass="math inline">\(b\)</span> 的时间，<spanclass="math inline">\(\tau\)</span> 关于 <spanclass="math inline">\(\{Y_n\}\)</span>是停时，接下来的关键就是构造一个新的鞅，使其与时间 <spanclass="math inline">\(n\)</span>产生直接的关系，这样利用停时定理的时候就能求得 <spanclass="math inline">\({\mathbb E}\tau\)</span>。那么可以取 <spanclass="math inline">\({Z_n} = \sum_{k=1}^n (X_k^2 - {\mathbb E}[X_k^2 |Y_0,...,Y_{k-1}])\)</span>，关于 <span class="math inline">\(\{Y_n\}\)</span> 是鞅，并且可以验证 <span class="math inline">\({\mathbbE}[X_k^2 | Y_0,...,Y_{k-1}]={\mathbb E}[(X_{k-1}+Y_k)^2 |Y_0,...,Y_{k-1}] = X_{k-1}^2+1\)</span>，因此有 <spanclass="math inline">\({Z_n}=X_n^2-n\)</span>。验证停时定理 3 的条件<span class="math inline">\({\mathbb E}[|Z_{n+1}-Z_n| | Y_0,...,Y_n] \le2|X_n|{\mathbb E}|Y_{n+1}| + 1+1 \le2\max(-a,b)+2\)</span>，根据停时定理 3 有 <spanclass="math inline">\({\mathbb E}Z_\tau = P_a(a^2-{\mathbb E}\tau) +P_b(b^2 - {\mathbb E}\tau) = {\mathbb E}Z_0=0\)</span>，故 <spanclass="math inline">\({\mathbb E}\tau=-ab\)</span>。</p></li></ol><p><strong>Note</strong>：利用停时定理时，条件 <spanclass="math inline">\({\mathbb E}\tau&lt;\infty\)</span>可以先假设成立，然后用求解的结果来验证。</p><h2 id="连续鞅论">3.12 连续鞅论</h2><p><strong>定义（鞅）</strong>：<span class="math inline">\(\{X(t),t\ge0\}\)</span> 为一个随机过程，如果 <spanclass="math inline">\(\{X(t),t\ge0\}\)</span> 满足下列条件：</p><ol type="1"><li>（存在性）对任意的 <span class="math inline">\(t\ge0\)</span>，有<span class="math inline">\({\mathbb E}|X(t)|&lt;\infty\)</span>；</li><li>（鞅性）对任意的 <span class="math inline">\(0\let_0&lt;t_1&lt;\cdots&lt;t_n&lt;t_{n+1}\)</span>，有 <spanclass="math inline">\({\mathbb E}[X(t_{n+1}) | X(t_1),...,X(t_n)] =X(t_{n})\)</span>；</li></ol><p>则称 <span class="math inline">\(\{X(t),t\ge0\}\)</span>是<strong>鞅</strong>。</p><p><strong>定义（上鞅）</strong>：<span class="math inline">\(\{X(t),t\ge0\}\)</span> 为一个随机过程，如果 <spanclass="math inline">\(\{X(t),t\ge0\}\)</span> 满足下列条件：</p><ol type="1"><li>（存在性）对任意的 <span class="math inline">\(t\ge0\)</span>，有<span class="math inline">\({\mathbb E}X(t)^-&lt;\infty\)</span>；</li><li>（鞅性）对任意的 <span class="math inline">\(0\let_0&lt;t_1&lt;\cdots&lt;t_n&lt;t_{n+1}\)</span>，有 <spanclass="math inline">\({\mathbb E}[X(t_{n+1}) | X(t_1),...,X(t_n)] \leX(t_{n})\)</span>；</li></ol><p>则称 <span class="math inline">\(\{X(t),t\ge0\}\)</span>是<strong>上鞅</strong>。下鞅定义类似。</p><p><strong>定理 3.12（停时定理）</strong>：设 <spanclass="math inline">\(\{X(t),t\ge0\}\)</span> 是鞅，<spanclass="math inline">\(\tau\)</span> 是关于 <spanclass="math inline">\(\{X(t),t\ge0\}\)</span> 的停时，若 <spanclass="math inline">\(P(\tau&lt;\infty)=1\)</span>，且 <spanclass="math inline">\({\mathbb E}[\sup_{t\ge0} |X_{\tau \wedge t}|] &lt;\infty\)</span>，则 <span class="math inline">\({\mathbb E}X_\tau ={\mathbb E}[X(0)]\)</span>。</p>]]></content>
    
    
    <categories>
      
      <category>随机过程2</category>
      
    </categories>
    
    
    <tags>
      
      <tag>鞅</tag>
      
      <tag>停时定理</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【随机过程2】离散鞅论2 | 停时与停时定理</title>
    <link href="/2021/10/16/stochastic-process-2/ch3-s2-martingale-stopping%20time/"/>
    <url>/2021/10/16/stochastic-process-2/ch3-s2-martingale-stopping%20time/</url>
    
    <content type="html"><![CDATA[<h2 id="停时与停时定理">3.7 停时与停时定理</h2><p>为了更好表述，下面给出一个不严谨的 <spanclass="math inline">\(\sigma\)</span> 域和停时的定义。</p><p>用 <span class="math inline">\(F_n = \sigma(Y_k,0\le k \len)\)</span> 表示 <span class="math inline">\(Y_0,...,Y_n\)</span>可提供的全部信息，称为他们生成的 <spanclass="math inline">\(\sigma\)</span> 域。</p><p>假设有非负随机变量 <span class="math inline">\(\tau\)</span>和随机序列 <span class="math inline">\(\{Y_n,n\ge0\}\)</span>，若 <spanclass="math inline">\(\forall n\ge0\)</span>，<spanclass="math inline">\(\{\tau=n\}\in F_n\)</span>，则称 <spanclass="math inline">\(\tau\)</span> 是 <spanclass="math inline">\(\{Y_n,n\ge0\}\)</span>的<strong>停时</strong>。</p><span id="more"></span><p>注：若 <span class="math inline">\(\tau\)</span> 是一个停时 <spanclass="math inline">\(\forall n\ge0\)</span>，<spanclass="math inline">\(\{\tau=n\}\in F_n\)</span>，那么可以导出事件 <spanclass="math inline">\(\{\tau\le n\},\{\tau&gt;n\},\{\tau\gen\},\{\tau&lt;n\}\)</span> 均只由 <spanclass="math inline">\(Y_0,...,Y_n\)</span> 确定，这意味着截至到 <spanclass="math inline">\(n\)</span>时刻，根据已有的信息可以完全确定停时所对应的事件是否已经发生。</p><p>停时的基本性质：设 <span class="math inline">\(\tau,\sigma\)</span>是关于 <span class="math inline">\(\{Y_n,n\ge0\}\)</span> 的停时，则<span class="math inline">\(\tau+\sigma,\tau\wedge\sigma,\tau\vee\sigma\)</span> 均是停时。</p><p><strong>定理 3.3（停时定理1）</strong>：设 <spanclass="math inline">\(\{X_n\}\)</span> 是鞅，<spanclass="math inline">\(\tau\)</span> 是停时，若</p><ol type="1"><li><span class="math inline">\(P(\tau&lt;\infty)=1\)</span></li><li><span class="math inline">\({\mathbb E}|X_\tau| &lt;\infty\)</span></li><li><span class="math inline">\(\lim_{n\to\infty} {\mathbb E}|X_nI_{\{\tau&gt;n\}}| = 0\)</span></li></ol><p>则 <span class="math inline">\({\mathbb E}X_\tau = {\mathbbE}X_0\)</span>。</p><p><strong>定理 3.4（停时定理2）</strong>：设 <spanclass="math inline">\(\{X_n\}\)</span> 是鞅，<spanclass="math inline">\(\tau\)</span> 是停时，若</p><ol type="1"><li><spanclass="math inline">\(P(\tau&lt;\infty)=1\)</span>（也可以用其增强型条件<span class="math inline">\({\mathbb E}\tau&lt;\infty\)</span>）</li><li><span class="math inline">\({\mathbb E}[\sup_{n\ge0} |X_{\tau \wedgen}|] &lt; \infty\)</span>（这是定理 3.3 中后两个条件的增强型条件）</li></ol><p>则 <span class="math inline">\({\mathbb E}X_\tau = {\mathbb E}X_{\tau\wedge n} = {\mathbb E}X_0\)</span>。</p><p><strong>推论 3.1（停时定理 3）</strong>：设 <spanclass="math inline">\(\{X_n\}\)</span> 关于 <spanclass="math inline">\(\{Y_n\}\)</span> 是鞅，<spanclass="math inline">\(\tau\)</span> 是停时，且 <spanclass="math inline">\({\mathbb E}\tau&lt;\infty\)</span>。若存在一个常数<span class="math inline">\(b&lt;\infty\)</span>，满足对 <spanclass="math inline">\(\forall n&lt;\infty\)</span> 有 <spanclass="math inline">\({\mathbb E}[|X_{n+1}-X_{n}| | Y_0,...,Y_n]\leb\)</span>，则 <span class="math inline">\({\mathbb E}X_\tau = {\mathbbE}X_0\)</span>。</p><p><strong>推论 3.2（停时定理 4）</strong>：设 <spanclass="math inline">\(\{X_n\}\)</span> 是鞅，<spanclass="math inline">\(\tau\)</span> 是停时，若</p><ol type="1"><li><span class="math inline">\(P(\tau&lt;\infty)=1\)</span></li><li><span class="math inline">\(\forall n, {\mathbb E}[X_{\tau \wedgen}^2]\)</span> 一致有界。</li></ol><p>则 <span class="math inline">\({\mathbb E}X_\tau = {\mathbbE}X_0\)</span>。</p><p>在证明停时定理之前，需要先介绍两个引理。</p><p><strong>引理 3.1</strong>：若 <spanclass="math inline">\(\{X_n\}\)</span> 是关于 <spanclass="math inline">\(\{Y_n\}\)</span> 的鞅，<spanclass="math inline">\(\tau\)</span> 是关于 <spanclass="math inline">\(\{Y_n\}\)</span> 的停时，则 <spanclass="math inline">\(\forall n\ge1\)</span> 有 <spanclass="math inline">\({\mathbb E}X_0 = {\mathbb E}X_{\tau\wedge n} ={\mathbb E}X_n\)</span>。</p><p>证明：<span class="math inline">\({\mathbb E}X_{\tau\wedge n} ={\mathbb E}[X_\tau I_{\{\tau&lt; n\}}] + {\mathbb E}[X_n I_{\{\tau \gen\}}] = \sum_{k&lt;n} {\mathbb E}[X_k I_{\{\tau=k\}}] + {\mathbb E}[X_nI_{\{\tau \ge n\}}]\)</span>，其中 <span class="math display">\[{\mathbb E}[X_n I_{\{\tau = k\}}] = {\mathbb E}[{\mathbb E}[X_nI_{\{\tau=k\}} | Y_0,...,Y_k]] = {\mathbb E}[I_{\{\tau=k\}}{\mathbbE}[X_n | Y_0,...,Y_k]] = {\mathbb E}[X_k I_{\{\tau = k\}}]\]</span> 于是 <span class="math inline">\({\mathbb E}X_{\tau\wedge n} ={\mathbb E}X_n\)</span>。证毕。</p><p><strong>引理 3.2</strong>：设 <span class="math inline">\(X\)</span>是一个随机变量，满足 <span class="math inline">\({\mathbbE}|X|&lt;\infty\)</span>，<span class="math inline">\(\tau\)</span>是一个关于 <span class="math inline">\(\{Y_n\}\)</span> 的停时，且 <spanclass="math inline">\(P(\tau&lt;\infty)=1\)</span>，则 <spanclass="math inline">\(\lim_{n\to\infty} {\mathbb E}[XI_{\{\tau&gt;n\}}]=0,\lim_{n\to\infty} {\mathbb E}[X I_{\{\tau\len\}}]={\mathbb E}X\)</span>。</p><p>证明：由于 <span class="math inline">\(\lim_{n\to\infty} I_{\{\tau\len\}}=1\)</span>，<span class="math inline">\(\lim_{n\to\infty}{\mathbbE}[|X| I_{\{\tau\le n\}}] = {\mathbb E}|X|\)</span>，因此 <spanclass="math inline">\(\lim_{n\to\infty} {\mathbb E}[|X| I_{\{\tau&gt;n\}}]=0\)</span>，于是有 <span class="math inline">\(\lim_{n\to\infty}{\mathbb E}[X I_{\{\tau&gt; n\}}]=0\)</span>。证毕。</p><p><strong>证明（停时定理 1）</strong>：暂略。</p><h2 id="上穿不等式">3.8 上穿不等式</h2><p>对于给定区间 <spanclass="math inline">\((a,b),b&gt;a\)</span>，如果一个随机序列先到达<span class="math inline">\(a\)</span> 下面，再到达 <spanclass="math inline">\(b\)</span> 上面，即为上穿 <spanclass="math inline">\((a,b)\)</span>一次，上穿不等式就要研究序列上穿次数的问题。</p><p>对随机序列 <span class="math inline">\(\{X_n\}\)</span>，令 <spanclass="math inline">\(V^{(n)}(a,b)\)</span> 是 <spanclass="math inline">\(X_0,...,X_n\)</span> 上穿 <spanclass="math inline">\((a,b)\)</span> 的次数，令 <spanclass="math inline">\(\alpha_0=0\)</span>，记 <spanclass="math inline">\(\alpha_1\)</span> 为首次到达 <spanclass="math inline">\((-\infty,a]\)</span> 的时间，<spanclass="math inline">\(\alpha_2\)</span> 为 <spanclass="math inline">\(\alpha_1\)</span> 之后首次到达 <spanclass="math inline">\(b\)</span> 的时间，即 <spanclass="math inline">\(\alpha_1 = \min\{n:n\ge0,X_n\lea\}\)</span>，<spanclass="math inline">\(\alpha_2=\min\{n:n&gt;\alpha_1,X_n\geb\}\)</span>；依此类推 <spanclass="math inline">\(\alpha_{2k-1}=\min\{n:n&gt;\alpha_{2k-2},X_n\lea\}\)</span>，<spanclass="math inline">\(\alpha_{2k}=\min\{n:n&gt;\alpha_{2k-1},X_n\geb\}\)</span>。于是可以定义上穿次数 <spanclass="math inline">\(V^{(n)}(a,b)=\max\{k:k\ge0,\alpha_{2k}\len\}\)</span>。</p><p><strong>定理 3.5（上穿不等式）</strong>：设 <spanclass="math inline">\(\{X_n\}\)</span> 关于 <spanclass="math inline">\(\{Y_n\}\)</span> 是<strong>下鞅</strong>， <spanclass="math inline">\(V^{(n)}(a,b)\)</span> 是 <spanclass="math inline">\(X_0,...,X_n\)</span> 上穿 <spanclass="math inline">\((a,b)\)</span> 的次数，则 <spanclass="math display">\[{\mathbb E}[V^{(n)}(a,b)] \le \frac{ {\mathbb E}[(X_n-a)^{+}] - {\mathbbE}[(X_0-a)^{+}]}{ b-a } \le \frac{ {\mathbb E}X_n^+ +|a|}{b-a}\]</span> 其中 <span class="math inline">\(a^+=\max(a,0)\)</span>。</p><p><strong>证明</strong>：因为 <spanclass="math inline">\(\{X_n\}\)</span> 关于 <spanclass="math inline">\(\{Y_n\}\)</span> 是下鞅，所以 <spanclass="math inline">\(\{(X_n-a)^+\}\)</span> 关于 <spanclass="math inline">\(\{Y_n\}\)</span> 也是下鞅。<spanclass="math inline">\(\tilde{X}_n=(X_n-a)^+\)</span> 上穿过 <spanclass="math inline">\((0,b-a)\)</span> 的次数也是 <spanclass="math inline">\(V^{(n)}(a,b)\)</span>，因此只需要证明 <spanclass="math inline">\((b-a){\mathbb E}[V^{(n)}(a,b)]\le {\mathbbE}\tilde{X}_n - {\mathbb E}\tilde{X}_0\)</span>。 <spanclass="math display">\[\begin{aligned}{\mathbb E}\tilde{X}_n - {\mathbb E}\tilde{X}_0 &amp;= {\mathbbE}\left[(\tilde{X}_{n}-\tilde{X}_{2V^{(n)}}) +\sum_{k=1}^{V^{(n)}}(\tilde{X}_{\alpha_{2k}} -\tilde{X}_{\alpha_{2k-1}}) +\sum_{k=1}^{V^{(n)}}(\tilde{X}_{\alpha_{2k-1}} -\tilde{X}_{\alpha_{2k-2}}) \right] \\&amp;= {\mathbb E}\left[(\tilde{X}_{n}-\tilde{X}_{2V^{(n)}})\right] +{\mathbb E}\left[\sum_{k=1}^{V^{(n)}}(\tilde{X}_{\alpha_{2k}} -\tilde{X}_{\alpha_{2k-1}})\right] + {\mathbbE}\left[\sum_{k=1}^{V^{(n)}}({\mathbb E}\tilde{X}_{\alpha_{2k}} -{\mathbb E}\tilde{X}_{\alpha_{2k-1}}) \right] \\&amp;= \text{I + II + III}\end{aligned}\]</span> 根据下鞅的定义有 <spanclass="math inline">\(\text{I,III}\ge0\)</span>，因此 <spanclass="math inline">\(\text{II}\ge {\mathbbE}[(b-a)V^{(n)}(a,b)]\)</span>。证毕。</p><blockquote><p><strong>Remark</strong>：为什么会有 <spanclass="math inline">\(\text{III}&gt;0\)</span>？上面的第二个等式成立吗？</p></blockquote><p><strong>推论 3.5.1</strong>：上鞅下穿不等式，略。</p><p><strong>定理 3.6（鞅收敛定理）</strong>：设 <spanclass="math inline">\(\{X_n\}\)</span> 关于 <spanclass="math inline">\(\{Y_n\}\)</span> 是<strong>下鞅</strong>，<spanclass="math inline">\(\sup_{n}{\mathbbE}|X_n|&lt;\infty\)</span>，则存在一个随机变量 <spanclass="math inline">\(X_{\infty}\)</span> 使 <spanclass="math inline">\(\{X_n,n\ge0\}\)</span> 以概率 1 收敛于 <spanclass="math inline">\(X_\infty\)</span>，即 <spanclass="math inline">\(P(\lim_{n\to\infty} X_n=X_\infty)=1\)</span>，且<span class="math inline">\({\mathbbE}|X_\infty|&lt;\infty\)</span>。</p><p>证明：首先由于 <span class="math inline">\({\mathbb E}X_n^+ \le{\mathbb E}|X_n| \le 2{\mathbb E}X_n^+-{\mathbb E}X_n\)</span>，因此<span class="math inline">\(\sup_n {\mathbb E}|X_n|&lt;\infty \iff\sup_n{\mathbb E} X_n^+&lt;\infty\)</span>（存疑？）</p><h2 id="极大值不等式与-doob-定理">3.9 极大值不等式与 Doob 定理</h2><p>随机变量序列 <span class="math inline">\(\{Y_n\}\)</span>独立同分布，且 <span class="math inline">\({\mathbb E}Y_n=0,{\mathbbE}Y_n^2=\sigma^2\)</span>，取 <spanclass="math inline">\(X_0=0,X_n=\sum_{k\le n} Y_k\)</span>，对任意 <spanclass="math inline">\(\varepsilon&gt;0\)</span>，有</p><ul><li><strong>切比雪夫不等式</strong>：<spanclass="math inline">\(\varepsilon^2 P(|X_n|&gt;\varepsilon)\len\sigma^2\)</span>；</li><li><strong>Kolmogorov不等式</strong>：<spanclass="math inline">\(\varepsilon^2 P(\max_{0\le k\le n}|X_k|&gt;\varepsilon) \le n\sigma^2\)</span>。</li></ul><p><strong>Markov不等式</strong>：非负随机变量 <spanclass="math inline">\(X\)</span>，对任意 <spanclass="math inline">\(a&gt;0\)</span> 有 <spanclass="math inline">\(aP(X\ge a)\le {\mathbb E}X\)</span>。</p><p><strong>Chernoff界</strong>：随机变量 <spanclass="math inline">\(X\)</span>，<spanclass="math inline">\(\phi(t)={\mathbb E}[e^{tX}]\)</span>，对任意实数<span class="math inline">\(a&gt;0\)</span> 有</p><ol type="1"><li><span class="math inline">\(t&gt;0\)</span> 时，有 <spanclass="math inline">\(P(X\ge a)\le e^{-at}\phi(t)\)</span>；</li><li><span class="math inline">\(t&lt;0\)</span> 时，有 <spanclass="math inline">\(P(X\le a)\le e^{-at}\phi(t)\)</span>。</li></ol><p>注：<span class="math inline">\({\mathbb E}[e^{tX}]=1+t{\mathbb E}X +\frac{t^2}{2!}{\mathbb E}X^2+\cdots\)</span>，当 <spanclass="math inline">\(X\)</span>的各阶矩都知道的时候，特征函数也就知道了。</p><p><strong>引理 3.3</strong>：<spanclass="math inline">\(\{X_n\}\)</span> 是下鞅，<spanclass="math inline">\(\forall n\ge0,X_n\ge0\)</span>，则对任何 <spanclass="math inline">\(\lambda&gt;0\)</span>，有 <spanclass="math inline">\(\lambda P(\max_{0\le k \le n} X_k&gt;\lambda) \le{\mathbb E}X_n\)</span>。</p><p><strong>推论 3.3</strong>：<spanclass="math inline">\(\{X_n\}\)</span> 是鞅，则对任意 <spanclass="math inline">\(\lambda&gt;0\)</span> 有</p><ul><li><span class="math inline">\(\lambda P(\max_{0\le k \le n}|X_k|&gt;\lambda) \le {\mathbb E}|X_n|\)</span></li><li><span class="math inline">\(\lambda P(\max_{0\le k \le n}|X_k|^2&gt;\lambda) \le {\mathbb E}|X_n|^2\)</span></li></ul><p><strong>定理 3.7（Doob）</strong>：<spanclass="math inline">\(\{X_k\}\)</span> 是鞅，如果 <spanclass="math inline">\(X_k\in L^p(P),1\le p&lt;\infty\)</span>，则 <spanclass="math display">\[{\mathbb E}\left[\max_{1\le k\le n} |X_k|^p\right] \le \begin{cases}q^p {\mathbb E}(|X_n|^p), &amp; p&gt;1,q=p/(p-1) \\\frac{e}{e-1}\left(1+{\mathbb E}[|X_n|\log^+|X_n|] \right), &amp; p=1\end{cases}\]</span> 证明从略。</p><h2 id="azuma不等式">3.10 Azuma不等式</h2><h3 id="azuma不等式-1">3.10.1 Azuma不等式</h3><p><strong>引理 3.4</strong>：若随机变量 <spanclass="math inline">\(X\)</span> 满足 <spanclass="math inline">\({\mathbb E}X=0\)</span>，<spanclass="math inline">\(P(-\alpha \le X\le\beta)=1,\alpha&gt;0,\beta&gt;0\)</span>，则对任意的凸函数 <spanclass="math inline">\(f(x)\)</span> 有 <spanclass="math inline">\({\mathbb E}[f(X)]\le\frac{\beta}{\alpha+\beta}f(-\alpha)+\frac{\alpha}{\alpha+\beta}f(\beta)\)</span>。</p><p><strong>引理 3.5</strong>：对任意参数 <spanclass="math inline">\(k\in[0,1]\)</span>，有 <spanclass="math inline">\(ke^{(1-k)x}+(1-k)e^{-kx}\lee^{x^2/8}\)</span>。</p><p>证明：略。</p><p><strong>定理 3.8（Azuma不等式）</strong>：<spanclass="math inline">\(\{Z_n,n\ge1\}\)</span> 是鞅，<spanclass="math inline">\(\mu={\mathbb E}Z_n\)</span>，令 <spanclass="math inline">\(Z_0=\mu\)</span>，并假设存在非负常数 <spanclass="math inline">\(\alpha_i,\beta_i,i\ge1\)</span>，满足条件 <spanclass="math inline">\(-\alpha_i\le Z_i - Z_{i-1} \le\beta_i\)</span>，则对任意的 <spanclass="math inline">\(n\ge1,a&gt;0\)</span> 有</p><ol type="1"><li><span class="math inline">\(P(Z_n-\mu \ge a) \le \exp(-2a^2 /\sum_{i=1}^n (\alpha_i+\beta_i)^2)\)</span></li><li><span class="math inline">\(P(Z_n-\mu \le -a) \le \exp(-2a^2 /\sum_{i=1}^n (\alpha_i+\beta_i)^2)\)</span></li></ol><p>证明：先假设 <span class="math inline">\(\mu=0\)</span>，对任意的<span class="math inline">\(c&gt;0\)</span>，则有 <spanclass="math inline">\(P(\exp(cZ_n)\ge \exp(ca))\le {\mathbbE}[\exp(cZ_n)]\exp(-ca)\)</span>。令 <spanclass="math inline">\(W_n=\exp(cZ_n)\)</span>，那么 <spanclass="math display">\[\begin{aligned}{\mathbb E}[W_n | Z_{n-1}] &amp;= \exp(cZ_{n-1}) {\mathbbE}[\exp(c(Z_n-Z_{n-1})) | Z_{n-1}] \\&amp;\le W_{n-1} \left[ \frac{\beta_n}{\alpha_n+\beta_n}\exp(-c\alpha_n)+ \frac{\alpha_n}{\alpha_n+\beta_n}\exp(c\beta_n) \right]\end{aligned}\]</span> 于是有 <span class="math inline">\({\mathbb E}W_n \le {\mathbbE}W_{n-1} (\beta_n\exp(-c\alpha_n) + \alpha_n\exp(c\beta_n)) /(\alpha_n+\beta_n)\)</span>，再利用引理 3.5 迭代即可证明 <spanclass="math inline">\({\mathbb E}W_n \le \exp(c^2\sum_{i=1}^n(\alpha_i+\beta_i)^2/8)\)</span>。取 <spanclass="math inline">\(c=4a/\sum_{i=1}^n(\alpha_i+\beta_i)^2\)</span>即可得证。第二个不等式可以用零均值的鞅 <spanclass="math inline">\(\{Z_n-\mu\}\)</span> 和 <spanclass="math inline">\(\{\mu-Z_n\}\)</span> 得到。</p><p><strong>推论 3.8.1</strong>：如果向量 <spanclass="math inline">\(X=(x_1,x_2,...,x_n)\)</span> 和 <spanclass="math inline">\(Y=(y_1,y_2,...,y_n)\)</span>最多只有一个坐标点不同，也就是说存在一个 <spanclass="math inline">\(k\)</span> 使得 <spanclass="math inline">\(x_i=y_i,\forall i\ne k\)</span>。假设存在一个函数<span class="math inline">\(h(X)\)</span> 满足条件 <spanclass="math inline">\(|h(X)-h(Y)|\le 1\)</span>，假设 <spanclass="math inline">\(X_1,...,X_n\)</span> 为独立的随机变量，于是有<span class="math inline">\(P(h(X)-{\mathbb E}[h(X)] \ge a) \le\exp(-a^2/2n)\)</span>，<span class="math inline">\(P(h(X)-{\mathbbE}[h(X)] \le -a) \le \exp(-a^2/2n)\)</span>。</p><p>证明：考虑（Doob）鞅 <span class="math inline">\(Z_i = {\mathbbE}[h(X) | X_1,...,X_i], i=1,2,...,n\)</span>，那么有 <spanclass="math display">\[\big|{\mathbb E}[h(X) | X_1=x_1,...,X_i=x_i] - {\mathbb E}[h(X) |X_1=x_1,...,X_{i-1}=x_{i-1}]\big| = \big|{\mathbbE}[h(x_1,...,x_i,X_{i+1},...,X_n)] - {\mathbbE}[h(x_1,...,x_{i-1},X_{i},...,X_n)]\big| \le 1\]</span> 因此 <span class="math inline">\({|Z_i-Z_{i-1}|} \le1\)</span>，再取 <spanclass="math inline">\(\alpha_i=-1,\beta_i=1\)</span> 利用 Azuma不等式即可。</p><h3 id="azuma不等式的推广">3.10.2 Azuma不等式的推广</h3><p><strong>引理 3.6</strong>：假设 <spanclass="math inline">\(Z_n\)</span> 是一个零均值的鞅，<spanclass="math inline">\(Z_0=0,-\alpha\leZ_i-Z_{i-1}\le\beta\)</span>，对所有的 <spanclass="math inline">\(i&gt;0\)</span> 成立，于是有 <spanclass="math inline">\(P(Z_n\ge a+bn) \le \exp(-8ab /(\alpha+\beta)^2)\)</span>，其中 <spanclass="math inline">\(a,b&gt;0\)</span>。</p><p><strong>证明</strong>：类似前面 Azuma 不等式的证明，取 <spanclass="math inline">\(W_n = \exp(c(Z_n-a-bn))\)</span>，那么可以验证<span class="math inline">\({\mathbb E}[W_n | W_1,...,W_{n-1}]\leW_{n-1} \exp(-cb) \exp(c^2(\alpha+\beta)^2/8)\)</span>，取 <spanclass="math inline">\(c=8b/(\alpha+\beta)^2\)</span> 就可以得到 <spanclass="math inline">\(\{W_n\}\)</span>为<strong>上鞅</strong>。对于一个固定的正整数 <spanclass="math inline">\(k\)</span>，定义有界停时 <spanclass="math inline">\(\tau=\min\{n:Z_n\ge a+bn, \text{ or }n=k\}\)</span>，于是有 <span class="math inline">\(P(Z_{\tau} \gea+b\tau) = P(W_\tau \ge 1) \le {\mathbb E}W_\tau \le {\mathbbE}W_0\)</span>，因此有 <span class="math inline">\(P(Z_n\ge a+bn,n\le k)\le \exp(-8ab / (\alpha+\beta)^2)\)</span>。令 <spanclass="math inline">\(k\to\infty\)</span> 就得到所需结论，证毕。</p><p><strong>定理 3.9</strong>：假设 <spanclass="math inline">\(Z_n\)</span> 是一个零均值的鞅，<spanclass="math inline">\(Z_0=0,-\alpha\leZ_i-Z_{i-1}\le\beta\)</span>，对所有的 <spanclass="math inline">\(i&gt;0\)</span> 成立，对任意的正常数 <spanclass="math inline">\(c\)</span> 和正整数 <spanclass="math inline">\(m\)</span> 有 <span class="math display">\[\begin{aligned}P(Z_n\ge cn,n\ge m) &amp;\le \exp(-2mc^2/(\alpha+\beta)^2) \\P(Z_n\le -cn,n\ge m) &amp;\le \exp(-2mc^2/(\alpha+\beta)^2)\end{aligned}\]</span> 证明：如果存在一个 <span class="math inline">\(n\)</span>满足条件 <span class="math inline">\(n\ge m,Z_n\ge nc\)</span>，对这个<span class="math inline">\(n\)</span> 有 <spanclass="math inline">\(Z_n\ge nc\ge mc/2 + nc/2\)</span>，直接利用引理3.6 即可得证。</p><blockquote><p><strong>Remark</strong>：面对概率放缩问题，首先考虑 Markov不等式，然后考虑 Chernoff 不等式，然后考虑 Azuma 不等式。</p></blockquote><p><em>栗子</em>：掷硬币，出现正面的概率为 <spanclass="math inline">\(p\)</span>，抛掷 <spanclass="math inline">\(m\)</span> 次后出现正面的比率与 <spanclass="math inline">\(p\)</span> 相差大于 <spanclass="math inline">\(\varepsilon\)</span> 的概率是多少？</p><p>解：令 <span class="math inline">\(S_n\)</span> 为前 <spanclass="math inline">\(n\)</span>次抛掷硬币中出现正面的次数，因此需要求解 <spanclass="math inline">\(P(|S_n/n - p| &gt; \varepsilon,n\gem)\)</span>。取 <spanclass="math inline">\(Z_n=S_n-np\)</span>，可以验证 <spanclass="math inline">\(\{Z_n\}\)</span> 为零均值的鞅，并且满足 <spanclass="math inline">\(-p\le Z_n - Z_{n-1}\le 1-p\)</span>，利用推广的Azuma 不等式就可以得到 <span class="math inline">\(P(Z_n\ge \varepsilonn,n\ge m)\le \exp(-2m\varepsilon^2)\)</span>。</p>]]></content>
    
    
    <categories>
      
      <category>随机过程2</category>
      
    </categories>
    
    
    <tags>
      
      <tag>停时</tag>
      
      <tag>鞅</tag>
      
      <tag>停时定理</tag>
      
      <tag>上穿不等式</tag>
      
      <tag>鞅收敛定理</tag>
      
      <tag>极大值不等式</tag>
      
      <tag>Markov不等式</tag>
      
      <tag>Azuma不等式</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【随机过程2】离散鞅论1 | 基本概念</title>
    <link href="/2021/10/03/stochastic-process-2/ch3-s1-martingale-concepts/"/>
    <url>/2021/10/03/stochastic-process-2/ch3-s1-martingale-concepts/</url>
    
    <content type="html"><![CDATA[<h2 id="条件概率">3.1 条件概率</h2><p>在初等概率论中，条件期望的概念比较好理解，有 <spanclass="math inline">\({\mathbb E}[X | Y = y_j] = \sum_i x_i P(X=x_i | Y= y_j)\)</span>，得到的条件期望实际上是一个关于 <spanclass="math inline">\(Y=y_j\)</span>的函数。但是在现代概率论中，这一概念进行了推广，也变得更加抽象，严谨的数学定义需要高等概率的知识，本教程基本只需要建立直观理解就够了。</p><span id="more"></span><p>（不严谨地）简单来说，条件期望 <span class="math inline">\({\mathbbE}[X | Y]\)</span> 是一个新的随机变量，也可以看作是随机变量 <spanclass="math inline">\(Y\)</span> 的函数。也就是可以理解为 <spanclass="math inline">\(g(Y)\)</span>，这个函数由 <spanclass="math inline">\(X,Y\)</span> 的性质所决定。</p><p>性质（可以用直觉来理解这些性质，培养一下数学直观）：</p><ul><li><span class="math inline">\({\mathbb E}[{\mathbb E}[X|Y]] = {\mathbbE}[X]\)</span></li><li><span class="math inline">\({\mathbb E}[\sum_i a_i X_i | Y] = \sum_ia_i {\mathbb E}[X_i |Y]\)</span></li><li><span class="math inline">\({\mathbb E}[g(X)h(Y) | Y] = h(Y){\mathbb E}[g(X) | Y]\)</span>，<spanclass="math inline">\(g(X),h(Y)\)</span> 为有界函数</li><li><span class="math inline">\({\mathbb E}[X | X] = X\)</span></li><li>若 <span class="math inline">\(X,Y\)</span> 独立，则 <spanclass="math inline">\({\mathbb E}[X|Y] = {\mathbb E}[X]\)</span></li><li><span class="math inline">\({\mathbb E}[{\mathbb E}[X|Y,Z] ~|~ Y\in{\mathcal D}_j, Z\in{\mathcal D}_k] = {\mathbb E}[X | Y\in {\mathcalD}_j, Z\in{\mathcal D}_k]\)</span></li><li><span class="math inline">\({\mathbb E}[{\mathbb E}[X|Y,Z] ~|~ Y]={\mathbb E}[X|Y] = {\mathbb E}[{\mathbb E}[X|Y] ~|~ Y,Z]\)</span></li></ul><h2 id="鞅的定义与基本性质">3.2 鞅的定义与基本性质</h2><p><strong>定义</strong>：<span class="math inline">\(\foralln\ge0\)</span>，若 (1) <span class="math inline">\({\mathbb E} |X_n|&lt; \infty\)</span>；(2) <span class="math inline">\({\mathbbE}[X_{n+1} | X_0,...,X_n]=X_n\)</span>，则过程 <spanclass="math inline">\(\{X_n,n\ge0\}\)</span> 称为鞅。</p><p>注：鞅过程和平稳过程没有相互包含关系，也不同于Markov过程。</p><p>有的时候 <span class="math inline">\(X_n\)</span>不能直接观察，只能观察另一个过程 <spanclass="math inline">\(\{Y_n,n\ge0\}\)</span>，因此将鞅的定义进行推广。</p><p><strong>定义（推广）</strong>：设两个随即过程 <spanclass="math inline">\(\{X_n,n\ge0\},\{Y_n,n\ge0\}\)</span>，若满足 (1)<span class="math inline">\({\mathbb E}|X_n|&lt;\infty\)</span>；(2)<span class="math inline">\({\mathbb E}[X_{n+1} | Y_0,...,Y_n] =X_n\)</span>，则称 <span class="math inline">\(\{X_n,n\ge0\}\)</span>关于 <span class="math inline">\(\{Y_n,n\ge0\}\)</span> 是鞅。</p><p>性质：</p><ul><li><span class="math inline">\({\mathbb E}[X_n | Y_0,...,Y_n] =X_n\)</span>，再推广可以有 <span class="math inline">\({\mathbbE}[X_{n-k} | Y_0,...,Y_n] = X_{n-k}, k\ge0\)</span></li><li><span class="math inline">\({\mathbb E}[X_{n+k} | Y_0,...,Y_n] =X_{n+k}, k\ge0\)</span></li><li><span class="math inline">\({\mathbb E}X_{n+1} = {\mathbb E}X_n ={\mathbb E}X_0\)</span></li><li>若 <span class="math inline">\(g(Y_0,...,Y_n)\)</span> 有界，则<span class="math inline">\({\mathbb E}[g(Y_0,...,Y_n)X_{n+k} |Y_0,...,Y_n] = g(Y_0,...,Y_n){\mathbb E}[X_{n+k} |Y_0,...,Y_n]\)</span></li><li>若 <span class="math inline">\(\{X_n,n\ge0\},\{Z_n,n\ge0\}\)</span>关于 <span class="math inline">\(\{Y_n,n\ge0\}\)</span> 是鞅，则 <spanclass="math inline">\(\{X_n\pm Z_n\}\)</span> 关于 <spanclass="math inline">\(\{Y_n,n\ge0\}\)</span> 是鞅</li><li>若 <span class="math inline">\(\{X_n,n\ge0\},\{Z_n,n\ge0\}\)</span>关于 <span class="math inline">\(\{Y_n,n\ge0\}\)</span> 是鞅，且 <spanclass="math inline">\(X_n,Z_n\)</span> 独立，则 <spanclass="math inline">\(\{X_n Z_n\}\)</span> 关于 <spanclass="math inline">\(\{Y_n,n\ge0\}\)</span> 是鞅</li></ul><p>注：<span class="math inline">\({\mathbb E}[X_{n+1}X_n] = {\mathbbE}[{\mathbb E}[X_{n+1}X_n | Y_0,...,Y_n]] = {\mathbb E}[X_n {\mathbbE}[X_{n+1}|Y_0,...,Y_n]] = {\mathbbE}[X_n^2]\)</span>，说明鞅不是平稳过程。</p><h2 id="鞅的举例与构造方法">3.3 鞅的举例与构造方法</h2><p><em>栗子 3.1</em>：<spanclass="math inline">\(Y_0=0,\{Y_n,n\ge1\}\)</span> 独立同分布，<spanclass="math inline">\({\mathbb E}|Y_n|&lt;\infty\)</span>，<spanclass="math inline">\({\mathbb E}Y_n=0\)</span>，取 <spanclass="math inline">\(X_0=0,X_n=\sum_{i=1}^nY_i\)</span>，则 <spanclass="math inline">\(\{X_n,n\ge0\}\)</span> 关于 <spanclass="math inline">\(\{Y_n,n\ge0\}\)</span> 是鞅。</p><p><em>栗子 3.2</em>：<spanclass="math inline">\(Y_0=0,\{Y_n,n\ge1\}\)</span> 独立同分布，<spanclass="math inline">\({\mathbb E}Y_n=0, {\mathbbE}Y_n^2=\sigma^2\)</span>，取 <span class="math inline">\(X_0=0,X_n =\sum_{i=1}^n Y_i^2-n\sigma^2\)</span>，则 <spanclass="math inline">\(\{X_n\}\)</span> 关于 <spanclass="math inline">\(\{Y_n\}\)</span> 是鞅。</p><p><em>栗子 3.3</em>（一般线性求和）：<span class="math inline">\(X_n =\sum_{k=0}^n a_k(Y_0,...,Y_{k-1}) \cdot \{f(Z_k) - {\mathbbE}[f(Z_k)|Y_0,...,Y_{k-1}]\}\)</span>，要求 <spanclass="math inline">\({\mathbb E}|f(Z_k)|&lt;\infty\)</span>，<spanclass="math inline">\(|a_k(y_0,...,y_{k-1})|&lt;A_k,\forally_0,...,y_{k-1}\)</span>。（一般情况下取 <span class="math inline">\(a_k= 1\)</span>）</p><p><em>栗子 3.4</em>（Doob 鞅过程）：<spanclass="math inline">\(X_n={\mathbb E}[X | Y_0,...,Y_n]\)</span>，<spanclass="math inline">\(\{X_n\}\)</span> 关于 <spanclass="math inline">\(\{Y_n\}\)</span> 是鞅。</p><p><em>栗子 3.5</em>（似然比构成的鞅）：设 <spanclass="math inline">\(\{Y_n\}\)</span> 独立同分布，<spanclass="math inline">\(f_0,f_1\)</span> 是概率密度函数（PDF），<spanclass="math inline">\(\forall y,f_0(y)&gt;0\)</span>，令 <spanclass="math inline">\(X_n=\frac{f_1(Y_0)\cdots f_1(Y_n)}{f_0(Y_0)\cdotsf_0(Y_n)}\)</span>，当 <span class="math inline">\(Y_n\)</span> 的PDF为<span class="math inline">\(f_0\)</span> 时，<spanclass="math inline">\(\{X_n\}\)</span> 关于 <spanclass="math inline">\(\{Y_n\}\)</span> 是鞅。</p><p><em>栗子 3.6</em>：<span class="math inline">\(\{Y_n\}\)</span> 为Markov 链，状态空间为 <span class="math inline">\({\mathcalS}\)</span>，转移矩阵为 <span class="math inline">\(P\)</span>，定义<span class="math inline">\(F=(f(0),...,f(i),...)\)</span>为右特征向量，<span class="math inline">\({\mathbbE}|f(Y_n)|&lt;\infty\)</span>。令 <span class="math inline">\(X_n =\lambda^{-n} f(Y_n)\)</span>，则 <spanclass="math inline">\(\{X_n\}\)</span> 关于 <spanclass="math inline">\(\{Y_n\}\)</span> 是鞅。</p><p>证明：<span class="math inline">\({\mathbb E}|X_n| = \lambda^{-n}{\mathbb E}|f(Y_n)|&lt;\infty\)</span>， <span class="math display">\[{\mathbb E}[X_{n+1} | Y_0,...,Y_n] = {\mathbb E}[\lambda^{-n-1}f(Y_{n+1}) | Y_n] = \lambda^{-n-1} \sum_{j\in{\mathcal S}}f(y_j)P(Y_{n+1}=y_j|Y_n)=\lambda^{-n} f(Y_n)\]</span> <em>栗子 3.7</em>（分支过程构造）：设 <spanclass="math inline">\(Z^{(n)}(j)\)</span> 表示第 <spanclass="math inline">\(n\)</span> 代第 <spanclass="math inline">\(j\)</span> 个个体产生的个体数目，<spanclass="math inline">\(Z^{(n)}(i)(i=1,2,...)\)</span> 独立同分布，<spanclass="math inline">\({\mathbb E}[Z^{(n)}(i)]=m\)</span>，<spanclass="math inline">\(Y_{n+1} = Z^{(n)}(1) + \cdots +Z^{(n)}(Y_n)\)</span>，则 <spanclass="math inline">\(X_n=m^{-n}Y_n\)</span> 关于 <spanclass="math inline">\(\{Y_n\}\)</span> 是鞅。<spanclass="math inline">\({\mathbb E}[Y_{n+1} | Y_n] = Y_n {\mathbbE}[Z^{(n)}(1)] = mY_n\)</span>。</p><p><em>栗子 3.8</em>（Wald鞅）：<spanclass="math inline">\(Y_0=0,\{Y_n\}\)</span> 独立同分布，<spanclass="math inline">\(\phi(\lambda)={\mathbb E}[\exp(\lambdaY_n)]\)</span>，<spanclass="math inline">\(X_0=1,X_n=\phi^{-n}(\lambda)\exp[\lambda(Y_1+\cdots+Y_n)]\)</span>，<span class="math inline">\(\{X_n\}\)</span>关于 <span class="math inline">\(\{Y_n\}\)</span> 是鞅。</p><p>证明：定义 <span class="math inline">\(S_n=\sum_{k=1}^nY_k\)</span>，结合栗子 3.6 可知 <spanclass="math inline">\(\{X_n\}\)</span> 关于 <spanclass="math inline">\(\{S_n\}\)</span> 是鞅，由于 <spanclass="math inline">\(S_1,...,S_n\)</span> 与 <spanclass="math inline">\(Y_1,...,Y_n\)</span> 可以相互表示，因此 <spanclass="math inline">\(\{X_n\}\)</span> 关于 <spanclass="math inline">\(\{Y_n\}\)</span> 也是鞅。</p><p><em>栗子 3.9</em>（R-N导数构成的鞅）：设 <spanclass="math inline">\(Z\sim U[0,1]\)</span>，<spanclass="math inline">\(f\)</span> 是 <spanclass="math inline">\([0,1]\)</span> 上的有界函数，令 <spanclass="math inline">\(X_n=2^n [f(Y_n+2^{-n}) - f(Y_n)]\)</span>，而<span class="math inline">\(Y_n=\sum_{k=0}^{2^n-1} \frac{k}{2^n}{\mathbf 1}_{\{k/2^n \le Z &lt; (k+1)/2^n\}}\)</span>，则 <spanclass="math inline">\(\{X_n\}\)</span> 关于 <spanclass="math inline">\(\{Y_n\}\)</span> 是鞅。</p><p>证明：在 <span class="math inline">\(Y_0,...,Y_n\)</span>条件下，<span class="math inline">\(Z\)</span> 服从 <spanclass="math inline">\([Y_n,Y_n+2^{-n})\)</span> 的均匀分布，并且 <spanclass="math inline">\(Y_{n+1}\)</span> 以相同的概率等于 <spanclass="math inline">\(Y_n\)</span> 或者 <spanclass="math inline">\(Y_n+2^{-n-1}\)</span>，于是有 <spanclass="math display">\[\begin{aligned}{\mathbb E}[X_{n+1} | Y_0,...,Y_n] &amp;= 2^{n+1} {\mathbbE}[f(Y_{n+1}+2^{-n-1})-f(Y_{n+1}) | Y_0,...,Y_n] \\&amp;= 2^{n+1}\left\{ \frac{1}{2} [f(Y_n+2^{-n-1})-f(Y_n)] +\frac{1}{2}[f(Y_n+2^{-n}) - f(Y_n+2^{-n-1})] \right\} \\&amp;= X_n\end{aligned}\]</span></p><blockquote><p>小结（鞅的构造方法）：</p><ol type="1"><li>满足 Markov 性的序列，若满足 <span class="math inline">\({\mathbbE}[X_{n+1} | X_n] = \lambda X_n\)</span>，则 <spanclass="math inline">\(Z_n = \lambda^{-n} X_n\)</span> 构成一个鞅；</li><li>满足 Markov 性的序列，若满足 <span class="math inline">\({\mathbbE}[g(X_{n+1}) | X_n] = f(\lambda) g(X_n)\)</span>，<spanclass="math inline">\(g(x)\)</span> 为有界函数，<spanclass="math inline">\(f(\lambda)\ne0\)</span>，则 <spanclass="math inline">\(Z_n = f(\lambda)^{-n} g(X_n)\)</span>构成一个鞅；</li><li>一般线性求和。</li></ol></blockquote><h2 id="上鞅下鞅的定义及基本性质">3.4 上鞅、下鞅的定义及基本性质</h2><p><strong>定义</strong>：随机过程 <spanclass="math inline">\(\{X_n,n\ge0\},\{Y_n,n\ge0\}\)</span>满足下列条件：</p><ol type="1"><li><span class="math inline">\({\mathbb E}[X^-]&gt;\infty,x^-:=\min(x,0)\)</span>；</li><li><span class="math inline">\({\mathbb E}[X_{n+1} | Y_0,...,Y_n] \leX_n\)</span>；</li><li><span class="math inline">\(X_n\)</span> 是 <spanclass="math inline">\(Y_0,...,Y_n\)</span> 的函数；</li></ol><p>则称 <span class="math inline">\(\{X_n\}\)</span> 关于 <spanclass="math inline">\(\{Y_n\}\)</span> 是上鞅。同理可定义下鞅。</p><p><strong>性质</strong>：</p><ul><li>上鞅 <span class="math inline">\(\{X_n\}\)</span>，则 <spanclass="math inline">\({\mathbb E}[X_{n+k} | Y_0,...,Y_n]\le X_n,\forallk\ge0\)</span></li><li>上鞅 <span class="math inline">\(\{X_n\}\)</span>，则 <spanclass="math inline">\({\mathbb E}[X_n] \le {\mathbb E}X_k \le {\mathbbE}X_0,0\le k\le n\)</span></li><li>上鞅 <span class="math inline">\(\{X_n\}\)</span>，<spanclass="math inline">\(g(Y_0,...,Y_n)\)</span> 是非负函数，则 <spanclass="math inline">\({\mathbb E}[g(Y_0,...,Y_n)X_{n+k} | Y_0,...,Y_n] =g(Y_0,...,Y_n) {\mathbb E}[X_{n+k} | Y_0,...,Y_n]\)</span></li><li><span class="math inline">\(\{X_n\},\{Z_n\}\)</span> 关于 <spanclass="math inline">\(\{Y_n\}\)</span> 是上（下）鞅，则 <spanclass="math inline">\(\{X_n+Z_n\}\)</span> 关于 <spanclass="math inline">\(\{Y_n\}\)</span> 是上（下）鞅</li><li><span class="math inline">\(\{X_n\},\{Z_n\}\)</span> 关于 <spanclass="math inline">\(\{Y_n\}\)</span> 是上鞅，且 <spanclass="math inline">\(X_n,Z_n\)</span> 相互独立，则 <spanclass="math inline">\(\{X_nZ_n\}\)</span> 关于 <spanclass="math inline">\(\{Y_n\}\)</span> 是上鞅（应该要求 <spanclass="math inline">\(X_n,Z_n\ge0\)</span>？？？）</li></ul><h2 id="jensen不等式与下鞅的构造">3.5 Jensen不等式与下鞅的构造</h2><p><strong>定理 3.1</strong>：若 <spanclass="math inline">\(\{X_n\}\)</span> 关于 <spanclass="math inline">\(\{Y_n\}\)</span> 是鞅，<spanclass="math inline">\(\varphi(x)\)</span> 为一个凸函数，且对 <spanclass="math inline">\(\forall n\)</span>，<spanclass="math inline">\({\mathbb E}[\varphi(X_n)^+]&lt;\infty\)</span>，则<span class="math inline">\(\{\varphi(X_n)\}\)</span> 关于 <spanclass="math inline">\(\{Y_n\}\)</span> 是下鞅。</p><p><strong>推论 3.1.1</strong>：若 <spanclass="math inline">\(\{X_n\}\)</span> 关于 <spanclass="math inline">\(\{Y_n\}\)</span> 是鞅，对 <spanclass="math inline">\(\forall n\)</span>，<spanclass="math inline">\({\mathbb E}[X_n^2]&lt;\infty\)</span>，则 <spanclass="math inline">\(\{|X_n|\},\{X_n^2\}\)</span> 关于 <spanclass="math inline">\(\{Y_n\}\)</span> 是下鞅。</p><p><strong>推论 3.1.2</strong>：若 <spanclass="math inline">\(\{X_n\}\)</span> 关于 <spanclass="math inline">\(\{Y_n\}\)</span> 是鞅，对 <spanclass="math inline">\(\forall n,p\ge1\)</span>，<spanclass="math inline">\({\mathbb E}[|X_n^p|]&lt;\infty\)</span>，则 <spanclass="math inline">\(\{|X_n|^p\}\)</span> 关于 <spanclass="math inline">\(\{Y_n\}\)</span> 是下鞅。</p><h2 id="分解定理">3.6 分解定理</h2><p><strong>定理 3.2（分解定理）</strong>：对任意一个 <spanclass="math inline">\(\{X_n\}\)</span> 关于 <spanclass="math inline">\(\{Y_n\}\)</span> 的下鞅，必存在过程 <spanclass="math inline">\(\{M_n\},\{Z_n\}\)</span> 使得</p><ol type="1"><li><span class="math inline">\(\{M_n\}\)</span> 关于 <spanclass="math inline">\(\{Y_n\}\)</span> 是鞅</li><li><span class="math inline">\(Z_n\)</span> 是 <spanclass="math inline">\(Y_0,...,Y_n\)</span> 的函数，且满足 <spanclass="math inline">\(Z_1=0,Z_n\le Z_{n+1},{\mathbbE}Z_n&lt;\infty\)</span></li><li><span class="math inline">\(X_n=M_n+Z_n\)</span></li></ol><p>且上述分解是<strong>唯一</strong>的。</p><p><strong>证明</strong>：证明的思路是首先构造出来这样一对 <spanclass="math inline">\(M_n,Z_n\)</span>，然后证明他们确实满足条件，最后再证明唯一性。</p><p>构造 <span class="math inline">\(Z_n = \sum_{k=1}^n{\mathbb E}[X_k-X_{k-1}| Y_0,...,Y_n]\)</span>，<spanclass="math inline">\(M_n=X_n-Z_n\)</span>，可以验证 <spanclass="math inline">\(\{M_n\}\)</span> 是鞅并且 <spanclass="math inline">\(Z_n\)</span> 是 <spanclass="math inline">\(Y_0,...,Y_n\)</span>的非负单调非降函数。唯一性证明用反证法。证毕。</p><p><strong>推论 3.2.1</strong>：对任意一个 <spanclass="math inline">\(\{X_n\}\)</span> 关于 <spanclass="math inline">\(\{Y_n\}\)</span> 的上鞅，必存在过程 <spanclass="math inline">\(\{M_n\},\{Z_n\}\)</span> 使得</p><ol type="1"><li><span class="math inline">\(\{M_n\}\)</span> 关于 <spanclass="math inline">\(\{Y_n\}\)</span> 是鞅</li><li><span class="math inline">\(Z_n\)</span> 是 <spanclass="math inline">\(Y_0,...,Y_n\)</span> 的函数，且满足 <spanclass="math inline">\(Z_1=0,Z_n\le Z_{n+1},{\mathbbE}Z_n&lt;\infty\)</span></li><li><span class="math inline">\(X_n=M_n-Z_n\)</span></li></ol><p>且上述分解是<strong>唯一</strong>的。</p>]]></content>
    
    
    <categories>
      
      <category>随机过程2</category>
      
    </categories>
    
    
    <tags>
      
      <tag>条件期望</tag>
      
      <tag>鞅</tag>
      
      <tag>Jensen不等式</tag>
      
      <tag>鞅分解定理</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【随机过程2】平稳过程与二阶矩过程</title>
    <link href="/2021/10/02/stochastic-process-2/ch2-stationary/"/>
    <url>/2021/10/02/stochastic-process-2/ch2-stationary/</url>
    
    <content type="html"><![CDATA[<p>若无特殊说明，本章均考虑平稳过程。</p><p>严平稳过程 + 一阶矩、二阶矩均存在 <spanclass="math inline">\(\Longrightarrow\)</span> 宽平稳</p><span id="more"></span><h2 id="相关函数">1. 相关函数</h2><ul><li><strong>互相关</strong>：<spanclass="math inline">\(R_{xy}(\tau)={\mathbbE}[X(t)Y^{\star}(t-\tau)]\)</span></li><li><strong>自相关</strong>：<spanclass="math inline">\(R_x(\tau)={\mathbbE}[X(t)X^{\star}(t-\tau)]\)</span><ul><li>共轭对称性 <spanclass="math inline">\(R(-\tau)=R^{\star}(\tau)\)</span></li><li><span class="math inline">\(R_x(0) \ge |R_x(\tau)|, \tau\in {\mathbbR}\)</span></li><li>若 <span class="math inline">\(R(\tau)\)</span> 在 <spanclass="math inline">\(0\)</span> 处连续，则 <spanclass="math inline">\(R(\tau)\)</span> 连续</li><li>若 <span class="math inline">\(R(\tau)\)</span> 在 <spanclass="math inline">\(0\)</span> 处可导，则有 <spanclass="math inline">\(R&#39;(0)=0\)</span></li><li>若存在 <span class="math inline">\(\tau_0\ne0\)</span> 使得 <spanclass="math inline">\(R(\tau_0)=R(0)\)</span>，则 <spanclass="math inline">\(R(\tau)\)</span> 是周期的</li><li><span class="math inline">\(R_{xy}^2(\tau) \le {R_{xx}(0)R_{yy}(0)}\)</span></li><li><span class="math inline">\(2|R_{xy}(\tau)| \le R_{xx}(0) +R_{yy}(0)\)</span></li><li>若 <span class="math inline">\(X,Y\)</span> 独立，<spanclass="math inline">\(W(t)=X(t)Y(t)\)</span>，则 <spanclass="math inline">\(R_{ww}(\tau)=R_{xx}(\tau)R_{yy}(\tau)\)</span></li></ul></li></ul><p><strong><em>栗子 2.1</em></strong>：<spanclass="math inline">\(X(t)=a\cos(wt) + b\sin(wt), a,b\sim {\mathcalN}(0,\sigma^2)\)</span>，那么可以验证其为宽平稳过程，<spanclass="math inline">\(R(t_1,t_2)=\sigma^2\cos w(t_1-t_2)\)</span></p><p><strong><em>栗子 2.2</em></strong>：AR(1) 模型渐进平稳，MA(<spanclass="math inline">\(q\)</span>) 模型平稳。</p><p><strong>性质</strong>：对于实过程的自相关函数，有 <spanclass="math inline">\(R(0)-R(\tau) \ge\frac{1}{4^n}(R(0)-R(2^n\tau))\)</span>。</p><p>证明：只需要证明 <span class="math inline">\(R(0)-R(\tau) \ge 1/4(R(0)-R(2\tau))\)</span>，这只需要验证 <spanclass="math inline">\({\mathbbE}[(X(t+2\tau)-2X(t+\tau)+X(t))^2]\ge0\)</span> 即可。证毕。</p><h2 id="功率谱">2. 功率谱</h2><h3 id="定义">2.1 定义</h3><p>平稳随机过程的功率谱定义为其自相关函数的傅里叶变换，即 <spanclass="math display">\[\begin{aligned}S(w) &amp;= \int R(\tau) e^{-jw\tau} d\tau \\R(\tau) &amp;= \frac{1}{2\pi}\int S(w)e^{jw\tau} dw\end{aligned}\]</span> 特别的，若 <span class="math inline">\(X(t)\)</span>是实过程，那么 <span class="math inline">\(R(\tau)\)</span>也是实的偶函数，<span class="math inline">\(S(w)\)</span>也是实的偶函数，有 <span class="math display">\[\begin{aligned}S(w) &amp;= \int R(\tau) \cos(w\tau) d\tau \\R(\tau) &amp;= \frac{1}{2\pi}\int \cos(w\tau) dw\end{aligned}\]</span> 定义两个过程 <span class="math inline">\(X(t),Y(t)\)</span>的<strong>交叉功率谱</strong>为互相关的傅里叶变换，即 <spanclass="math display">\[\begin{aligned}S_{xy}(w) &amp;= \int R_{xy}(\tau) e^{-jw\tau} d\tau \\R_{xy}(\tau) &amp;= \frac{1}{2\pi}\int S_{xy}(w)e^{jw\tau} dw\end{aligned}\]</span></p><p>性质：</p><ul><li>首先由于 <span class="math inline">\(R(\tau)\)</span>总是共轭对称的，因此可以验证 <span class="math inline">\(S(w)\)</span>总是实的；</li><li>功率谱密度总是正的，也就是说 <spanclass="math inline">\(S(w)\ge0\)</span>（注意交叉功率谱没有这个性质）；</li></ul><p>上面的第二个性质很符合直观，功率总不能是负的吧；对于确定性信号也很好理解，因为对于确定性信号有<spanclass="math inline">\(S(w)=|X(w)|^2\)</span>，自然满足。但是对于随机信号不能这做，因为随机信号的一次实现做傅里叶变换是没有意义的，甚至可能不收敛导致本身就无法做傅里叶变换，上面的式子也无从谈起了。</p><p>如果从信号处理的角度解释这个问题，不妨假设存在某个点使得 <spanclass="math inline">\(S(w_0)&lt;0\)</span>，由于 <spanclass="math inline">\(S(w)\)</span>连续，那么就一定存在一个小的邻域，是的这个区间上都有 <spanclass="math inline">\(S(w)&lt;0\)</span>，对于这样一个信号，如果我们通过一个带通滤波器，得到了输出信号，那么输出信号的功率谱就全是负的，在傅里叶反变换回去就会发现<span class="math inline">\(R(0)&lt;0\)</span>，这显然是不对的。因此总有<span class="math inline">\(S(w)\ge0\)</span>。</p><h3 id="功率谱与时域平均">2.2 功率谱与时域平均</h3><p>上面将功率谱定义为相关函数的傅里叶变换，那么这种定义是否合理呢？</p><p>其实功率谱的定义还有下面这一种，这种定义方式能够自然导出 <spanclass="math inline">\(S(w)\ge0\)</span>的性质，也能更好的理解功率谱的概念。</p><p>首先定义 <span class="math inline">\((-T,T)\)</span>时间段内的<strong>平均随机功率</strong>： <span class="math display">\[S_T(w) = \frac{1}{2T} \bigg| \int_{-T}^T X(t)e^{-jwt} dt \bigg|\]</span> <strong>定理 2.1</strong>：若 <spanclass="math inline">\(\int_{-\infty}^\infty |\tau R(\tau)|d\tau &lt;\infty\)</span>，则 <span class="math display">\[\lim_{T\to \infty} {\mathbb E}[S_T(w)] = S(w)\]</span> 证明：略。</p><h2 id="线性系统">3. 线性系统</h2><p>考虑一个线性系统，脉冲响应记为 <spanclass="math inline">\(h(t)\)</span>，频域响应为 <spanclass="math inline">\(H(w)\)</span></p><pre><code class=" mermaid">graph LR  input(&quot; &quot;) ==&quot;X(t)&quot;==&gt; system(&quot;线性系统 h(t)&quot;)  system ==&quot;Y(t)&quot;==&gt; output(&quot; &quot;)  style input fill: #ffffff, stroke: #ffffff  style output fill: #ffffff, stroke: #ffffff</code></pre><p>那么我们有 <span class="math inline">\(Y(t)=\int_{-\infty}^{\infty}X(t-a)h(a) da\)</span>，对于可实现系统（因果系统），应有 <spanclass="math display">\[Y(t)=\int_{0}^{\infty} X(t-a)h(a) da = \int_{-\infty}^t X(a) h(t-a) da\]</span> 对于输出信号的统计特性</p><ul><li><span class="math inline">\(R_{yx}(\tau)=R_{xx}(\tau) *h(\tau)\)</span>（卷积）</li><li><span class="math inline">\(R_{yy}(\tau) = R_{xx}(\tau) { \ast }h(\tau) { \ast} h(-\tau)\)</span>（卷积）<spanclass="math inline">\(\Longrightarrow S_{yy}(w) =S_{xx}(w)|H(w)|^2\)</span></li></ul><p>根据上面的第一个性质，如果输入信号为白噪声，即 <spanclass="math inline">\(R_{xx}(\tau) =\sigma^2\delta(\tau)\)</span>，那么就有输入信号和输出信号的互相关函数满足<span class="math inline">\(R_{xy}(\tau)=h(-\tau)\approx\frac{1}{T}\int_0^T X(t+\tau)Y(t)dt\)</span>。只考虑因果系统的时候，对于<span class="math inline">\(\tau&gt;0\)</span> 有 <spanclass="math inline">\(R_{xy}(\tau)=0\)</span>，也就是 <spanclass="math inline">\(X(t+\tau)\)</span> 与 <spanclass="math inline">\(Y(t)\)</span> 是正交的，符合直观；对于 <spanclass="math inline">\(\tau&lt;0\)</span>，如果取得 <spanclass="math inline">\(T\)</span>足够大，那么我们可以用这个方法来估计系统冲激响应 <spanclass="math inline">\(h(t)\)</span>。</p><h2 id="随机连续性与随机微积分">4. 随机连续性与随机微积分</h2><p>确定性函数的连续性定义不能直接应用到随机过程中，并且如果从确定性函数的角度来看，随机过程的任意一个实现很可能就是不连续的，比如泊松过程的轨迹是一个阶梯状的函数。为了将分析的工具应用到随机过程的讨论当中，需要给一个定义，比如绝对值连续、以概率1连续、平均值连续等，但这些定义同样存在一些问题。</p><h3 id="随机连续性">4.1 随机连续性</h3><p>我们用的比较多的是<strong>均方连续</strong>，定义为 <spanclass="math display">\[{\mathbb E}[(X(t+h)-X(t))^2] \to 0 \quad (h\to0)\]</span> <strong>推论 2.1</strong>：均方连续 <spanclass="math inline">\(\Longrightarrow\)</span> 平均值连续。</p><p><strong>定理 2.2</strong>：平稳过程连续 <spanclass="math inline">\(\iff\)</span> 自相关函数 <spanclass="math inline">\(R(\tau)\)</span> 在 <spanclass="math inline">\(\tau=0\)</span> 处连续。</p><h3 id="随机微分均方意义">4.2 随机微分（均方意义）</h3><p><strong>定义</strong>：过程 <span class="math inline">\(X(t)\)</span>对 <span class="math inline">\(t\)</span> 有均方导数，如果能找到一个过程<span class="math inline">\(X&#39;(t)\)</span> 满足 <spanclass="math display">\[\lim_{h\to 0} {\mathbb E}\left[ \frac{X(t+h) - X(t)}{h} - X&#39;(t)\right]^2 = 0\]</span> <strong>柯西准则</strong>（实际并不常用）： <spanclass="math display">\[\lim_{h_1\to 0,h_2\to0} {\mathbb E}\left[ \frac{X(t+h_1) - X(t)}{h_1} -\frac{X(t+h_2) - X(t)}{h_2} \right]^2 = 0\]</span> <strong>定理 2.3</strong>： 平稳过程 <spanclass="math inline">\(X(t)\)</span>，若自相关函数 <spanclass="math inline">\(R(\tau)\)</span> 具有二阶导数且在 <spanclass="math inline">\(\tau=0\)</span>处连续，则在均方意义下可微，反之亦然。</p><p>微分运算的一些性质：</p><ol type="1"><li><span class="math inline">\({\mathbb E}[X&#39;(t)] = {d {\mathbbE}[X(t)]}/{dt}\)</span>；</li><li><span class="math inline">\(R_{x&#39;x&#39;}(t_1,t_2) = {\mathbbE}[X&#39;(t_1)X&#39;(t_2)] = \partial^2 R_{xx}(t_1,t_2) / \partial t_1\partial t_2\)</span>；对平稳过程有 <spanclass="math inline">\(R_{x&#39;x&#39;}(\tau) = -d^2R_{xx}(\tau) /d\tau^2\)</span>；</li><li><span class="math inline">\({\mathbb E}[X^{(n)}(t)] = {d^n {\mathbbE}[X(t)]}/{dt^n}\)</span>；</li><li><span class="math inline">\(R_{x^{(n)}y^{(m)}}(t_1,t_2) = {\mathbbE}[X^{(n)}(t_1)Y^{(m)}(t_2)] = \partial^{n+m} R_{xy}(t_1,t_2) / \partialt_1^n \partial t_2^m\)</span>；对平稳过程有 <spanclass="math inline">\(R_{x^{(n)}y^{(m)}}(\tau) = (-1)^md^{m+n}R_{xy}(\tau) / d\tau^{m+n}\)</span>。</li></ol><h3 id="taylor-级数">4.3 Taylor 级数</h3><p><strong>定理 2.4</strong>：平稳过程 <spanclass="math inline">\(X(t)\)</span>，若 <spanclass="math inline">\(R(\tau)\)</span>是解析的，即存在无穷阶导数，且满足 <span class="math inline">\(R(\tau) =\sum_{n=0}^{\infty} R^{(n)}(0) \tau^n/n!\)</span>，则 <spanclass="math inline">\(X(t)\)</span> 可以展开成 Taylor 级数 <spanclass="math display">\[X(t+h) = \sum_{n=0}^{\infty} X^{(n)}(t) \frac{h^n}{n!}\]</span> <strong>注</strong>：这个式子很难应用，因为导数 <spanclass="math inline">\(X^{(n)}(t)\)</span>不好计算；不过根据这个式子，可以理解为把 <spanclass="math inline">\(X(t+h)\)</span> 投影到多项式基底上。</p><h3 id="随机微分方程">4.4 随机微分方程</h3><p>对于随机微分方程 <span class="math inline">\(a_n Y^{(n)}(t) + a_{n-1}Y^{(n-1)}(t) + \cdots + a_0 Y(t) =0\)</span>，先求均值/自相关，然后按确定性函数求解。</p><h3 id="随机积分">4.5 随机积分</h3><p>略。</p><h2 id="遍历性">5. 遍历性</h2><p>我们将随机过程看作每一个时刻都是一个随机变量 <spanclass="math inline">\(X(t)\)</span>，但是问题是时间是不停流逝的，对于某个时刻的随机变量我们可能只能获得一个采样，那么怎么去获得其统计特性呢？这个时候就需要引入遍历性这一概念。</p><p>如果一个随机过程的<strong>某个统计量</strong>的时间平均等于总体平均，那么称这个统计量具有<strong>遍历性</strong>。</p><h3 id="均值的遍历性">5.1 均值的遍历性</h3><p><strong>定理 2.5</strong>：给定平稳过程 <spanclass="math inline">\(X(t)\)</span>，其时间平均 <spanclass="math inline">\(\lim_{T\to\infty} \frac{1}{2T}\int_{-T}^{T}X(t) dt= {\mathbb E}[X(t)]=\eta\)</span> 的<strong>充要条件</strong>是 <spanclass="math display">\[\begin{aligned}\lim_{T\to\infty}\int_0^{2T} (1-\frac{\tau}{2T})[R(\tau)-\eta^2] d\tau =0 \\\iff \lim_{T\to\infty} \frac{1}{2T}\int_{-T}^T R(\tau) d\tau = \eta^2\end{aligned}\]</span> 注：上面两个判断条件数学上完全等价，第一个相当于加了三角窗，实际当中王王只存在有限个样本，因此采用加窗的方法更好。</p><p><strong>推论 2.5.1</strong>：给定实平稳过程 <spanclass="math inline">\(X(t)\)</span>，记 <spanclass="math inline">\(C(\tau)=R(\tau)-\eta^2\)</span></p><ol type="1"><li>若 <span class="math inline">\(\int_0^\infty C(\tau d\tau) &lt;\infty\)</span>，则 <span class="math inline">\(X(t)\)</span>为均值遍历的；</li><li>若 <span class="math inline">\(\lim_{\tau\to\infty}C(\tau)=0\)</span>，则 <span class="math inline">\(X(t)\)</span>为均值遍历的。</li></ol><p>证明：只需要得到 <span class="math inline">\(R(\tau)\to \eta^2 ~(\tau\to\infty)\)</span>，略。</p><h3 id="自相关的遍历性">5.2 自相关的遍历性</h3><p>首先回顾自相关的定义 <span class="math inline">\(R(\tau) = {\mathbbE}[X(t+\tau)X^{\star}(t)]\)</span>，那么实际上中我们只有每个时刻的采样值，用这些采样值相乘得到的所谓的“自相关”其实也是一个随机变量，可以定义为<span class="math inline">\(Z_{\tau}(t) =X(t+\tau)X^{\star}(t)\)</span>，那么 <spanclass="math inline">\(Z_\tau(t)\)</span>的时间平均是否等于其期望值呢？其时间平均可以定义为 <spanclass="math inline">\(R_T(\tau) = \frac{1}{2T}\int_{-T}^{T} Z(t) dt =\frac{1}{2T}\int_{-T}^{T} X(t+\tau)X^{\star}(t)dt\)</span>，显然有其均值为 <span class="math inline">\({\mathbbE}[R_T(\tau)] = R(\tau)\)</span>，自相关为 <span class="math display">\[R_{zz}(\lambda) = {\mathbb E}[ X(t+\tau+\lambda)X^{\star}(t+\lambda)X^{\star}(t+\tau)X(t) ]\]</span> <strong>定理 2.6</strong>：对于给定的 <spanclass="math inline">\(\tau\)</span>，时间平均等于期望，即 <spanclass="math inline">\(\lim_{T\to\infty} \int_{-T}^TX(t+\tau)X^{\star}(t)dt = {\mathbb E}[X(t+\tau)X^{\star}(t)] =R(\tau)\)</span>，的<strong>充要条件</strong>是 <spanclass="math display">\[\lim_{T\to\infty} \frac{1}{T} _0^{2T}(1-\frac{\tau}{2T})[R_{zz}(\lambda)- R^{2}(\tau)] = 0\]</span></p><h3 id="分布函数的遍历性">5.3 分布函数的遍历性</h3><p>随机变量的一阶分布函数定义为 <span class="math inline">\(F(x) =P(X(t)\lex)\)</span>，（不严谨的说）分布函数和随机变量是一一对应的，也就是两者可以认为是同一件事物的两种等价定义。那么如何研究分布函数的遍历性呢？就把它也转换成一个随机变量，定义一个新的过程。</p><p>假定 <span class="math inline">\(x\)</span> 为固定常数，定义 <spanclass="math display">\[Y(t) = \begin{cases}1,&amp; X(t)\le x \\0,&amp; X(t) &gt; x\end{cases}\]</span> 其平均值为 <span class="math inline">\({\mathbb E}[Y(t)] =P(X(t)\le x)\)</span>，自相关为 <span class="math inline">\({\mathbbE}[Y(t+\tau)Y^{\star}(t)] = P(X(t+\tau)\le x), X(t\le x) = F(x,x ;\tau)\)</span>，这里 <spanclass="math inline">\(F(x_1,x_2;\tau)\)</span> 是 <spanclass="math inline">\(X(t)\)</span>的二阶分布。类似前面两小节，其时间平均等于总体平均的充要条件是什么呢？</p><p><strong>定理 2.7</strong>：对于给定的 <spanclass="math inline">\(x\)</span>，<spanclass="math inline">\(\lim_{T\to\infty}\frac{1}{2T}\int_{-T}^{T} Y(t) dt= F(x)\)</span> 成立的<strong>充要条件</strong>是 <spanclass="math display">\[\lim_{T\to\infty}\frac{1}{2T}\int_{0}^{2T} (1-\frac{\tau}{2T})[F(x,x;\tau) - F^2(x)] dt = 0\]</span></p><blockquote><p><strong>注</strong>：从遍历性讨论得知，假如 <spanclass="math inline">\(X(t)\)</span> 具有遍历性，如果 <spanclass="math inline">\(\lim_{\tau\to\infty} R(\tau)\)</span> 存在，那么有<span class="math inline">\(\lim_{\tau\to\infty} R(\tau) =\eta^2\)</span>，这表明随着 <span class="math inline">\(\tau\)</span>的增加，<span class="math inline">\(X(t+\tau)\)</span> 与 <spanclass="math inline">\(X(t)\)</span> 的相关性减弱，特别的，在 <spanclass="math inline">\(\tau\to\infty\)</span> 时，随机变量 <spanclass="math inline">\(X(t+\tau)\)</span> 与 <spanclass="math inline">\(X(t)\)</span> 不相关。</p><p>对于分布函数的遍历性而言，有 <spanclass="math inline">\(\lim_{\tau\to\infty} F(x,x;\tau) =F^2(x)\)</span>，也就是 <spanclass="math inline">\(\tau\to\infty\)</span> 时 <spanclass="math inline">\(X(t+\tau)\)</span> 与 <spanclass="math inline">\(X(t)\)</span> 相互独立。</p></blockquote><h2 id="抽样定理与随机预测">6. 抽样定理与随机预测</h2><h3 id="随机过程抽样定理">6.1 随机过程抽样定理</h3><p>抽样定理描述了连续随机过程和离散随机过程自相关函数之间的关系。首先定义一个过程<span class="math inline">\(X(t)\)</span> 为低通的，若其功率谱 <spanclass="math inline">\(S(w)\)</span> 满足 <spanclass="math inline">\(S(w=0),\forall |w|&gt;w_c\)</span>。</p><p><strong>定理 2.8</strong>：对于带限过程 <spanclass="math inline">\(X(t)\)</span>，有（<spanclass="math inline">\(T=\pi/w_c\)</span>） <span class="math display">\[R(\tau) = \sum_{n=-\infty}^{\infty} R(nT) \frac{\sin(w_ct - n\pi)}{w_ct- n\pi}\]</span> 注：这从信号与系统的角度很好理解，<spanclass="math inline">\(X(nT)\)</span> 是对 <spanclass="math inline">\(X(\tau)\)</span>做了周期采样，因此其频谱是后者的周期延拓，由于连续信号的频谱是低通带限的，因此要想用<span class="math inline">\(X(nT)\)</span> 恢复出 <spanclass="math inline">\(X(\tau)\)</span>，就要加一个低通矩形窗，这在时域就表现为与Sa 脉冲做卷积。</p><p><strong>定理 2.9（抽样定理）</strong>：对于带限过程 <spanclass="math inline">\(X(t)\)</span>，有（<spanclass="math inline">\(T=\pi/w_c\)</span>） <span class="math display">\[X(t) = \sum_{n=-\infty}^{\infty} X(nT) \frac{\sin(w_ct - n\pi)}{w_c t-n\pi}\]</span> 证明：略。</p><p>注：这个定理跟上一个有略微的不同，上一个是自相关函数，实际上已经没有随机性，可以直接用以前的信号与系统的观点来看。但是这里的<span class="math inline">\(X(t),X(nT)\)</span>都是随机变量，实际上这里可以理解为 <spanclass="math inline">\(X(t)\)</span> 可以表示为 <spanclass="math inline">\(X(nT)\)</span>的线性组合，所以我们可以用采样值重构原始过程。信号处理方面，我们则可以使用截断的抽样定理公式来重构信号。</p><h3 id="随机预测">6.2 随机预测</h3><p>这部分举个栗子。考虑对 <span class="math inline">\(X(t)\)</span>构造过程 <span class="math display">\[\hat{X}_n(t) = \tbinom{n}{1}X(t-T_1) - \tbinom{n}{2}X(t-2T_1) + \cdots +(-1)^{n-1}X(t-nT_1)\]</span> 那么 <span class="math inline">\(Y(t) =X(t)-\hat{X}_n(t)\)</span> 的功率谱为 <spanclass="math inline">\(S_{yy}(w) = S_{xx}(w)(2\sin\frac{wT}{2})^{2n}\)</span>，于是有 <span class="math inline">\({\mathbbE}[(X(t)-\hat{X}_n(t))^2]\to 0 ~ (n\to\infty)\)</span>。</p>]]></content>
    
    
    <categories>
      
      <category>随机过程2</category>
      
    </categories>
    
    
    <tags>
      
      <tag>宽平稳</tag>
      
      <tag>相关函数</tag>
      
      <tag>随机连续性</tag>
      
      <tag>功率谱</tag>
      
      <tag>遍历性</tag>
      
      <tag>抽样定理</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【随机过程2】绪论</title>
    <link href="/2021/10/02/stochastic-process-2/ch1-intro/"/>
    <url>/2021/10/02/stochastic-process-2/ch1-intro/</url>
    
    <content type="html"><![CDATA[<p>这个随机过程是工科院系开设的，所以理论性不那么强，更注重于实际问题的应用。</p><p>参考教材为樊平毅老师撰写的《随机过程理论与应用》，清华大学出版社。</p>]]></content>
    
    
    <categories>
      
      <category>随机过程2</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>科目二点位</title>
    <link href="/2021/09/12/essay/driving-subject-2/"/>
    <url>/2021/09/12/essay/driving-subject-2/</url>
    
    <content type="html"><![CDATA[<blockquote><p>科目二考过了，在这里记录一下几个动作的点位。这东西显然不会有人看，仅仅是自己留下记录做个纪念:happy:</p></blockquote><span id="more"></span><h2 id="准备工作">准备工作</h2><p>其他：穿运动鞋，带水 操作：0.调整座位：双手搭在仪表盘上，感觉不拥挤即可1.调整后视镜：左侧后视镜需要能刚好看见后轮与地面接触点（下图的视角并不太对，因为没有露出后轮与地面的接触点），但是不能看到后轮前方的地面，右侧后视镜需要刚好露出后门把手一点，并使其位于后视镜中间位置<imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2021/driving-2.jpg"alt="右侧后视镜" /> <imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2021/driving-1.jpg"alt="左侧后视镜" /> 2.点火：看仪表盘转速是不是0，是0表示没发动起来3.启动：踩离合，点火，挂档（要看着），松刹车（按下按钮上拉一下然后按到底），慢慢松离合4.停车：踩离合，慢踩刹车，松档，拉手刹5.打方向盘：双手180°，三圈半，速度要最快6.挂档：正常是正档，按下是倒挡，<strong>挂档时一定要把离合踩到底，否则容易失败！！！</strong></p><h2 id="右倒车入库中间不能停车">右倒车入库（中间不能停车）</h2><p>1.溜直线，看左侧倒车镜底座 <imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2021/driving-3.jpg" />2.停车线基本与肩部平行时停车（以保证前轮在车库外），踩刹车 <imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2021/driving-4.jpg" />3.挂倒档，看左侧，距离横线3指，向右打方向盘到底 <imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2021/driving-5.jpg" />4.看右侧后视镜，看到角距离车身2指，方向盘回正 <imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2021/driving-6.jpg" />5.继续倒，角到后视镜底部，然后立即方向盘向右打 <imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2021/driving-7.jpg" />6.看左侧倒车镜，看到后面的角之后方向盘摆正 <imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2021/driving-8.jpg" />7.方向盘向右打90°，等车身与两侧线平行后回正8.看左侧倒车镜，找停车线，1指距离后停车 <imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2021/driving-9.jpg" /></p><h2 id="左倒车入库中间不能停车">左倒车入库（中间不能停车）</h2><p>1.此时在车库中，挂前进挡，看左侧后视镜，看到角后立马向左打方向盘到底（不要急着打！也不要磨蹭）（练习场里会有俩线，看到第一条线不要急着打，到第二条线再打。看到第一条线时可以预警，做好心理准备，因为快到第二条线了）<imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2021/driving-11.jpg" />2.目视前方，车头摆正，回方向盘，看左侧倒车线，在方向盘和肩膀中间的时候停车3.挂倒档，松离合开始倒车，看左侧倒车镜底座，跟倒车线2指立马向左打方向盘到底4.看左侧倒车镜，角距离车身2指的时候，方向盘立即回正 <imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2021/driving-12.jpg" />5.继续倒车，后轮角跟车轮后侧平齐时，方向盘向左打到底 <imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2021/driving-13.jpg" />6.继续倒车，直到车身与两侧线平行，方向盘回正7.观察左侧倒车镜底座，距离倒车线1指时停车注1：如果前一个点位还没到的时候就到下一个点位了，可以不用回正方向盘，一次到底注2：从停车位外边挂倒档往后倒的时候，2指多一些就开始向左打方向盘8.（出车库）挂正档，前进到车窗底部跟前面的线平齐，向右打转向到底 <imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2021/driving-10.jpg" />9.目视前方，车身回正后方向盘回正，整个车都出车库以后才算完成倒车入库</p><h2 id="半坡停车与起步30s启动">半坡停车与起步（30s启动）</h2><p>1.右侧进入，转头看中间的线，跟方向盘平齐时向左打死方向盘2.转过去以后对齐两个车轮印，正前方对齐第二个虚线左半部分（中间偏了就慢慢调节，即使在上坡也可以微调，但是注意尽量在上坡前调整的差不多，上坡后微调的时候就调整完立刻回正方向盘）（根据经验左转后车头还没回正时车轮就对上了轮胎印，此时就可以回正方向盘，然后向右前方行驶一小段距离后再向左打方向盘慢慢调整，调整时主要观察车头正前方是否对齐第二个虚线左侧，其次是有没有踩在车轮印上，然后上坡时也可以观察右侧后视镜中车身与右侧线的距离）3.前方看不到虚线之后转头看左侧，跟车身平行的中线那里（下图中看不到），左侧后视镜超过横着的实线2指后停车（下面图片中距离有点远了，2指即可）<imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2021/driving-20.jpg" />4.按住手刹按钮，抬一下之后迅速压到底5.压紧刹车，慢慢松离合，等到方向盘振动以后快速松刹车6.车子慢慢启动，可以轻微向左打方向盘然后立即回正（有可能一开始车不动，等1s之后车子才慢慢启动，这个时候一定不要松离合，一松就会熄火）7.上坡之后，踩离合减速，下坡轻踩刹车</p><h2 id="侧方停车90s完成">侧方停车（90s完成）</h2><p>1.从外部距离右边考试区平行驶向入口，需要能在右边看到路沿的底部2.观察右侧入口右侧路沿，看到以后接近于跟肩膀平行就向右打方向盘（练习时感觉，应该接近于跟方向盘平齐时打方向盘）<imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2021/driving-14.jpg" />3.目视前方，等车头摆正，回正方向盘4.往前走溜直线，可以看右侧雨刷器，也可以看左侧倒车镜，距离右侧大约30公分5.等到方向盘超过车库之后，看右侧后视镜，一开始会看到虚线，直到看到车库角（地面白线）停车，踩刹车，挂倒档<imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2021/driving-15.jpg" />6.松刹车，松离合慢慢往后退，后视镜盖住第一块虚线段1/3的时候向右打方向盘，立即看左侧倒车镜，踩离合减速<imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2021/driving-16.jpg" />7.看左侧倒车镜，踩离合，慢慢倒，看到后面的直角尖以后回正方向盘（这个地方坐直不太容易看到，可以稍微伸一下头去看）<imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2021/driving-17.jpg" />8.继续倒车，车轮后侧碰到虚线内侧以后，立即向左打方向盘到底，继续倒车（这个地方一定不能犹豫，碰到虚线内侧以后要立即向左打，否则很容易压到车库里面的线）<imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2021/driving-18.jpg" />9.车身与停车线平行之后，踩离合，踩刹车 10.打左转向灯，挂正档11.保持方向盘向左打到底，松刹车，慢慢松离合12.观察正前方车窗底部碰到石桩底部边沿线以后（注意不是地上的白线），立即向右回正方向盘，并多回一圈（打方向盘要快）（这里不能太早回正方向盘，否则右侧车轮会压车库角）13.目视前方，等车头摆正，回正方向盘</p><h2id="s弯速度要慢全程看车正前方引擎盖">S弯（速度要慢，全程看车正前方，引擎盖）</h2><p>1.从中间进入（凭感觉）2.看到正前方引擎盖压到石桩底部线（注意不是地上的白线）后，向左打方向盘一圈<imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2021/driving-21.jpg" />3.保持方向盘不动向前行驶，等到正前方引擎盖超过石桩底部一半的时候再向左打45°（不要打多，稍微多点比如60°可能就比较危险）4.向前行驶看到正前方引擎盖碰到地上白线以后，立刻回正 <imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2021/driving-22.jpg" />5.继续向前行驶，看到正前方引擎盖碰到石桩上沿以后，向右打方向盘一圈 <imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2021/driving-23.jpg" />6.看到正前方引擎盖超过石桩上方边线以后，再向右打45°（总之就是尽量使正前方引擎盖跟石桩上沿平齐，超过了就向右打方向盘修一下）7.转眼过去进入直角弯，等车头摆正回正方向盘8.观察前方石桩，找到从右向左第4和第5块石头正中间，自己的正前方对齐这两块正中间（根据经验差不多要对齐第5块石头右侧，如果对齐4,5块中间的话会离右侧边缘线太近）9.对齐以后，左手放在车窗上，之后一直压着左转向灯，然后目视前方，观察是否走直，单手调节方向盘直行10.快到转弯处时，观察左侧石桩跟手臂（根据经验差不多是胳膊肘和大臂的位置）对齐之后，双手立刻向左打死方向盘11.目视正前方，车头回正以后回正方向盘</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>正交(IQ)调制解调与希尔伯特变换</title>
    <link href="/2021/08/29/communication/IQ-modulation/"/>
    <url>/2021/08/29/communication/IQ-modulation/</url>
    
    <content type="html"><![CDATA[<h2 id="复信号">1. 复信号</h2><p>首先我们为什么需要复信号？</p><p>第一是因为复信号便于<strong>数学处理</strong>，例如获得信号的包络、相位等等；</p><p>除此之外，从频域来看，实信号频谱总是共轭对称的，也就是双边带信号，这就导致有一半的频带是无用的，浪费频谱资源，因此实际通信系统中我们更希望传输单边带的复信号。</p><p>但是在实际系统中我们只能获得实信号。</p><span id="more"></span><h2 id="正交调制解调">2. 正交调制解调</h2><p>假设我们现在要发送一个复基带信号 <spanclass="math inline">\(x(t)=a(t)+jb(t)\)</span>，调制以后变成 <spanclass="math inline">\(x(t)\exp(j2\pi f_ct)\)</span>，但是发送的时候只能发送实信号，因此我们要取实部，因此实际发送的信号为<span class="math display">\[z(t) = \text{Re}\left\{ x(t)\exp(j2\pi f_c t) \right\} = a(t)\cos(2\pif_c t) - b(t)\sin(2\pi f_c t)\]</span> 那么在接收端，我们希望恢复原始单边带基带信号 <spanclass="math inline">\(x(t)\)</span>，注意这个时候不能直接乘以 <spanclass="math inline">\(\cos(2\pi f_c t)\)</span>进行频谱搬移，因为会丢失虚部，我们想要得到的是复信号，因此就需要输出两路信号，分别为实部和虚部。那么怎么做呢？那就是<span class="math display">\[z(t)\cos(2\pi f_c t) \xrightarrow{\text{low pass}} a(t) \\z(t)\sin(2\pi f_c t) \xrightarrow{\text{low pass}} b(t)\]</span> 参考下面这个OFDM系统框图就能很容易理解了。</p><figure><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2021/OFDM.jpg"alt="OFDM" /><figcaption aria-hidden="true">OFDM</figcaption></figure><h2 id="希尔伯特变换">3. 希尔伯特变换</h2><p>那么上面的这个系统跟希尔伯特变换又有什么关系呢？</p><p>首先我们来从时域和频域分别看一下希尔伯特变换： <spanclass="math display">\[\begin{aligned}h(t) &amp;= \frac{1}{\pi t} \\H(f) &amp;= -j \operatorname{sgn}(f)\end{aligned}\]</span> 希尔伯特变换实际上是一个使相位滞后pi/2的全通移相网络，比如信号<span class="math inline">\(\cos(\omega t)\)</span>经过希尔伯特滤波器后就变成 <span class="math inline">\(\sin(\omegat)\)</span>。另外希尔伯特变换还有一个性质就是 <spanclass="math inline">\(H^2(f) =-1\)</span>，即经过两次变换之后就是原信号的反相。</p><p>那么再回到通信系统里边。基于傅里叶变换我们知道，一个复信号可以表示成<span class="math inline">\(x(t) = \int X(f)\exp(j2\pi f t)df\)</span>，即时域和频域是对应的，可以相互转化，我们记成 <spanclass="math display">\[x(t) \longleftrightarrow X(f)\]</span> 假设 <span class="math inline">\(x(t)\)</span>用其实部和虚部表示 <span class="math inline">\(x(t) = a(t) +jb(t)\)</span>，那么有 <span class="math display">\[\begin{aligned}a(t) &amp;\longleftrightarrow \frac{X(f) + X^{*}(-f)}{2} \\b(t) &amp;\longleftrightarrow \frac{X(f) - X^{*}(-f)}{2j}\end{aligned}\]</span> 对于一个单边带信号 <spanclass="math inline">\(x(t)\)</span>，<spanclass="math inline">\(X(f)\)</span> 只在正(或负)频率非零，那么 <spanclass="math inline">\(X(f)\)</span> 和 <spanclass="math inline">\(X^{*}(-f)\)</span>是没有频谱重叠的，所以我们可以看到 <spanclass="math inline">\(b(t)\)</span> 实际上就是 <spanclass="math inline">\(a(t)\)</span> 的希尔伯特变换，也即： <spanclass="math display">\[\begin{aligned}b(t) &amp;= \mathcal{H}(a(t)) \\a(t) &amp;= -\mathcal{H}(b(t))\end{aligned}\]</span> 所以只需要信号 <span class="math inline">\(x(t)\)</span>的实部 <span class="math inline">\(a(t)\)</span>（或只需要虚部 <spanclass="math inline">\(b(t)\)</span>）我们就能恢复出完整的复信号 <spanclass="math inline">\(x(t)\)</span>。</p><p>联想第 2 节的系统，想要在收发端传输的是单边带复信号 <spanclass="math inline">\(x(t)\exp(j2\pi f_ct)\)</span>，实际上只发射了它的实部 <span class="math inline">\(z(t) =\text{Re}\left\{ x(t)\exp(j2\pi f_c t)\right\}\)</span>，尽管如此我们在接收端还是可以只根据其实部就恢复出完整的信号，这就可以用希尔伯特变换来解释。</p><p>但是需要注意的是，这只适用于单边带信号！双边带信号的实部和虚部并没有这种关系，因此不能仅通过实部或虚部恢复完整复信号！</p>]]></content>
    
    
    <categories>
      
      <category>Communication and Networks</category>
      
    </categories>
    
    
    <tags>
      
      <tag>IQ调制</tag>
      
      <tag>Hilbert变换</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>今夕何夕</title>
    <link href="/2021/08/14/music/Later/"/>
    <url>/2021/08/14/music/Later/</url>
    
    <content type="html"><![CDATA[<center><h2>有些人一旦错过就不再</h2></center><span id="more"></span><iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width="330" height="86" src="//music.163.com/outchain/player?type=2&amp;id=254574&amp;auto=1&amp;height=66"></iframe><blockquote><p>后来 我总算学会了如何去爱 可惜你 早已远去 消失在人海 后来终于在眼泪中明白 有些人 一旦错过就不在</p><p>栀子花 白花瓣 落在我蓝色百褶裙上 爱你 你轻声说 我低下头 闻见一阵芬芳那个永恒的夜晚 十七岁仲夏 你吻我的那个夜晚 让我往后的时光 每当有感叹总想起当天的星光</p><p>那时候的爱情 为什么就能那样简单 而又是为什么 人年少时一定要让深爱的人受伤 在这相似的深夜里 你是否一样 也在静静追悔感伤如果当时我们能 不那么倔强 现在也 不那么遗憾</p><p>你都如何回忆我 带着笑或是很沉默 这些年来 有没有人能让你不寂寞 后来我总算学会了如何去爱 可惜你 早已远去 消失在人海 后来 终于在眼泪中明白有些人 一旦错过就不在</p><p>你都如何回忆我 带着笑或是很沉默 这些年来 有没有人能让你不寂寞 后来我总算学会了如何去爱 可惜你 早已远去 消失在人海 后来 终于在眼泪中明白有些人 一旦错过就不在</p><p>后来 我总算学会了如何去爱 可惜你 早已远去 消失在人海 后来终于在眼泪中明白 有些人 一旦错过就不在 永远不会再重来有一个男孩爱着那个女孩</p></blockquote>]]></content>
    
    
    <categories>
      
      <category>Music</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>转载 | Woodbury 恒等式</title>
    <link href="/2021/07/09/linear-algebra/woodbury/"/>
    <url>/2021/07/09/linear-algebra/woodbury/</url>
    
    <content type="html"><![CDATA[<blockquote><p>版权声明：本文为CSDN博主「Anusat」的原创文章，遵循CC 4.0BY-SA版权协议，转载请附上原文出处链接及本声明。原文链接：https://blog.csdn.net/Louis___Zhang/article/details/103483743</p></blockquote><p>在数学（特别是线性代数）中，Woodbury矩阵恒等式是以MaxA.Woodbury命名的，它可以通过对原矩阵的逆进行秩k校正来计算某个矩阵的秩k校正的逆。这个公式的另一个名字是矩阵逆引理，谢尔曼-莫里森-伍德伯里（Sherman–Morrison–Woodburyformula）公式或只是伍德伯里公式。然而，在伍德伯里发现之前，这一等式出现在其他文献中。</p><h2 id="伍德伯里矩阵恒等式">1. 伍德伯里矩阵恒等式</h2><p><span class="math display">\[\left(A+UCV\right)^{-1}=A^{-1}-A^{-1}U\left(C^{-1}+VA^{-1}U\right)^{-1}VA^{-1}\]</span></p><p>其中<span class="math inline">\(A\)</span>、<spanclass="math inline">\(U\)</span>、 <spanclass="math inline">\(C\)</span> 和 <spanclass="math inline">\(V\)</span> 都表示适形尺寸的矩阵。具体来说， <spanclass="math inline">\(A\)</span> 的大小为 <span class="math inline">\(n\times n\)</span>， <span class="math inline">\(U\)</span> 为 <spanclass="math inline">\(n \times k\)</span>， <spanclass="math inline">\(C\)</span> 为 <span class="math inline">\(k \timesk\)</span> <span class="math inline">\(V\)</span> 为 <spanclass="math inline">\(k \times n\)</span>。</p><h2 id="扩展">2. 扩展</h2><p>不失一般性，可用单位矩阵替换矩阵 <spanclass="math inline">\(A\)</span> 和 <spanclass="math inline">\(C\)</span>：</p><p><span class="math display">\[\left(I+UV\right)^{-1}=I-U\left(I+VU\right)^{-1}V\]</span> 这里 <span class="math inline">\(U=A^{-1}X, V = CY\)</span>。</p><p>这个等式本身可以看作是两个简单等式的组合，即等式 <spanclass="math display">\[(I+P)^{-1}=I-(I+P)^{-1}P=I-P(I+P)^{-1}\]</span> 和所谓的 push-through 等式 <span class="math display">\[(I+UV)^{-1}U=U(I+VU)^{-1}\]</span></p><p>的结合。</p><h2 id="特殊情况">3. 特殊情况</h2><p>当 <span class="math inline">\(V, U\)</span>是向量时，伍德伯里恒等式退化为谢尔曼-莫里森公式，在标量情况下，它（简化版）只是：<span class="math display">\[{\frac {1}{1+uv}}=1-{\frac {uv}{1+uv}}\]</span> 如果 <span class="math inline">\(p = q\)</span> 和 <spanclass="math inline">\(U=V=I_p\)</span> 是单位矩阵，那么 <spanclass="math display">\[\begin{aligned}\left({A}+{B}\right)^{-1} &amp;= A^{-1}-A^{-1}(B^{-1}+A^{-1})^{-1}A^{-1}\\&amp;= {A}^{-1}-{A}^{-1}\left({I}+{B}{A}^{-1}\right)^{-1}{B}{A}^{-1}.\end{aligned}\]</span> 继续合并上述方程最右边的项，就可以得到一下恒等式： <spanclass="math display">\[\left({A}+{B}\right)^{-1}={A}^{-1}-\left({A}+{A}{B}^{-1}{A}\right)^{-1}\]</span> 此等式的另一个有用的形式是： <span class="math display">\[\left({A}-{B}\right)^{-1}={A}^{-1}+{A}^{-1}{B}\left({A}-{B}\right)^{-1}\]</span> 它有一个递归结构： <span class="math display">\[\left({A}-{B}\right)^{-1}=\sum _{k=0}^{\infty}\left({A}^{-1}{B}\right)^{k}{A}^{-1}\]</span> 这种形式可用于微扰展开式，其中<spanclass="math inline">\(B\)</span> 是 <spanclass="math inline">\(A\)</span> 的微扰。</p><h2 id="推广">4. 推广</h2><p>二项式逆定理（Binomial Inverse Theorem） 如果 <spanclass="math inline">\(A,U,B,V\)</span> 分别是 <spanclass="math inline">\(p\times p,p\times q, q\times q, q\times p\)</span>的矩阵，那么: <span class="math display">\[\left(A+UBV\right)^{-1}=A^{-1}-A^{-1}UB\left(B+BVA^{-1}UB\right)^{-1}BVA^{-1}\]</span> 前提是 <span class="math inline">\(A\)</span> 和 <spanclass="math inline">\(B+BVA^{-1}UB\)</span>是非奇异的。后者的非奇异性要求 <spanclass="math inline">\(B^{-1}\)</span> 存在，因为它等于 <spanclass="math inline">\(B(I+VA＝1ub)\)</span> ，并且后者的秩不能超过 <spanclass="math inline">\(B\)</span> 的秩。由于 <spanclass="math inline">\(B\)</span>是可逆的，所以在右手边的附加量逆的两边的两个 <spanclass="math inline">\(B\)</span> 项可以被 <spanclass="math inline">\((B^{-1})^{-1}\)</span>替换，从而得到原始的Woodbury恒等式: <span class="math display">\[(A+UBV)^{-1}=A^{-1}-A^{-1}U(I+BVA^{-1}U)^{-1}BVA^{-1}\]</span> 在某些情况下，<span class="math inline">\(A\)</span>是有可能是奇异的。</p><h2 id="延伸">5. 延伸</h2><p>公式可以通过检查 <span class="math inline">\(A+UCV\)</span>乘以伍德伯里恒等式右侧的所谓逆得到恒等式矩阵来证明： <spanclass="math display">\[\begin{aligned}&amp;\left(A+UCV\right)\left[A^{-1}-A^{-1}U\left(C^{-1}+VA^{-1}U\right)^{-1}VA^{-1}\right]\\=&amp;\left\{I-U\left(C^{-1}+VA^{-1}U\right)^{-1}VA^{-1}\right\}+\left\{UCVA^{-1}-UCVA^{-1}U\left(C^{-1}+VA^{-1}U\right)^{-1}VA^{-1}\right\}\\=&amp;\left\{I+UCVA^{-1}\right\}-\left\{U\left(C^{-1}+VA^{-1}U\right)^{-1}VA^{-1}+UCVA^{-1}U\left(C^{-1}+VA^{-1}U\right)^{-1}VA^{-1}\right\}\\=&amp;UCVA^{-1}-\left(U+UCVA^{-1}U\right)\left(C^{-1}+VA^{-1}U\right)^{-1}VA^{-1}\\=&amp; UCVA^{-1}-UC \left( C^{-1} + VA^{-1}U \right)\left(C^{-1}+VA^{-1}U\right)^{-1} VA^{-1} + UCVA^{-1}-UCVA^{-1}\left({A}+{B}\right)^{-1} \\=&amp; A^{-1}-A^{-1}(B^{-1}+A^{-1})^{-1}A^{-1} \\=&amp; {A}^{-1}-{A}^{-1}\left({I}+{B}{A}^{-1}\right)^{-1}{B}{A}^{-1}.\end{aligned}\]</span></p><h2 id="参考文献">参考文献</h2><ol type="1"><li><ahref="https://en.wikipedia.org/wiki/Woodbury_matrix_identit">https://en.wikipedia.org/wiki/Woodbury_matrix_identity</a></li></ol>]]></content>
    
    
    <categories>
      
      <category>Linear Algebra</category>
      
    </categories>
    
    
    <tags>
      
      <tag>转载</tag>
      
      <tag>Woodbury 恒等式</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【随机过程（数学系）】基本概念</title>
    <link href="/2021/06/04/stochastic-process/ch1-stopping-time/"/>
    <url>/2021/06/04/stochastic-process/ch1-stopping-time/</url>
    
    <content type="html"><![CDATA[<p>第一章主要介绍随机过程中的基本概念。</p><h2 id="基本概念">1. 基本概念</h2><p><strong>什么是随机过程？</strong></p><p><strong>定义</strong>：设 <span class="math inline">\((\Omega,\mathcal{F},P)\)</span> 是一个概率空间，<spanclass="math inline">\((E,\mathcal{E})\)</span> 是一个可测空间，<spanclass="math inline">\(\mathcal{T}\)</span> 是一个指标集，<spanclass="math inline">\(X_{\mathcal{T} }=\{X_t,t\in{\mathcal T}\}\)</span>是一族定义在 <span class="math inline">\((\Omega,\mathcal{F},P)\)</span> 上，取值于 <spanclass="math inline">\((E,\mathcal{E})\)</span> 中的随机变量，称 <spanclass="math inline">\(X_T\)</span>为（E-值）<strong>随机过程</strong>。对每个 <spanclass="math inline">\(\omega\in\Omega\)</span>，<spanclass="math inline">\(X_T(\omega)=\{X_t(\omega),t\in T\}\)</span>称为随机过程的一个<strong>实现</strong>，或者<strong>样本轨道</strong>，或者<strong>样本函数</strong>。</p><blockquote><p><strong>注</strong>：随机过程实际上是一个二元函数 <spanclass="math inline">\(X(t,\omega)\)</span>，因此这里的 <spanclass="math inline">\(\omega\)</span> 所属的样本空间 <spanclass="math inline">\(\Omega\)</span> 包含了所有时刻 <spanclass="math inline">\({\mathcal T}\)</span>的所有可能事件，而不是只针对某个时刻随机变量 <spanclass="math inline">\(X_t\)</span> 的样本空间。</p></blockquote><span id="more"></span><p><strong>定义</strong>：设 <span class="math inline">\(X_T\)</span>是一个 <span class="math inline">\(E\)</span>-值随机过程，对任意 <spanclass="math inline">\(\Lambda=\{t_1,\cdots,t_n\}\subset T\)</span>，称<span class="math inline">\(\mu_\Lambda(B_\Lambda) =P((X_{t_1},\cdots,X_{t_n})\in B_\Lambda), B_\Lambda\in{\mathcalE}^\Lambda\)</span> 为 <span class="math inline">\(X_T\)</span>的一个<strong>有限维分布</strong>。称 <spanclass="math inline">\(\{\mu_\Lambda, \Lambda\Subset T\}\)</span> 为<span class="math inline">\(X_T\)</span>的<strong>有限维分布族</strong>。</p><blockquote><p><strong>注</strong>：这里相当于是取了 <spanclass="math inline">\(X_T\)</span>在一个下标集子集（一般取至多可数集）上的限制，这么做一半是为了从连续时间随机过程转到离散时间，可能便于处理。</p></blockquote><p><strong>命题 1.1.1</strong>：<spanclass="math inline">\(\{\mu_\Lambda,\Lambda\Subset T\}\)</span>是<strong>相容</strong>的，也就是说对于 <spanclass="math inline">\(\Lambda_1\subset\Lambda_2\Subset T\)</span>，有<span class="math inline">\(\mu_{\Lambda_2}(B_{\Lambda_1}\timesE^{\Lambda_2\backslash\Lambda_1})=\mu_{\Lambda_2}(B_{\Lambda_1}).\)</span></p><p>证明：略。</p><p><strong>定义</strong>：设 <spanclass="math inline">\(X_T,Y_T\)</span> 是两个 <spanclass="math inline">\(E\)</span> 值随机过程</p><ol type="1"><li>若 <span class="math inline">\(X_T,Y_T\)</span>有相同的有限维分布族，则称 <span class="math inline">\(Y_T\)</span> 是<span class="math inline">\(X_T\)</span>的一个<strong>版本</strong>；</li><li>若 <span class="math inline">\(P(X_t=Y_t)=1,\forall t\inT\)</span>，则称 <span class="math inline">\(Y_T\)</span> 是 <spanclass="math inline">\(X_T\)</span> 的一个<strong>修正</strong>；</li><li>若 <span class="math inline">\(P(X_t=Y_t,\forall t\inT)=1\)</span>，则称 <span class="math inline">\(Y_T\)</span> 是 <spanclass="math inline">\(X_T\)</span>的一个<strong>不可区别</strong>；</li></ol><blockquote><p><strong>注</strong>：<spanclass="math inline">\((3)\Rightarrow(2)\Rightarrow(1)\)</span>。</p></blockquote><h2 id="可测性">2. 可测性</h2><p><strong>定义</strong>：设 <span class="math inline">\(X_T\)</span>是定义在 <span class="math inline">\((\Omega, \mathcal{F},P)\)</span>上取值于 <span class="math inline">\((E,\mathcal{E})\)</span>中的随机过程，若 <spanclass="math inline">\(X(t,\omega):([0,+\infty)\times\Omega, {\mathcalB}_{[0,+\infty)}\times{\mathcal F}) \to (E,{\mathcal E})\)</span>是可测的，则称过程 <span class="math inline">\(X_T\)</span>是<strong>可测</strong>的。</p><p><strong>定义</strong>：设 <span class="math inline">\(\{ {\mathcalF}_t,t\in T\}(T\subset {\mathbb R}_+ \})\)</span> 是 <spanclass="math inline">\({\mathcal F}\)</span> 的一族单调上升子 <spanclass="math inline">\(\sigma\)</span> 代数（即 $st_s_t $，此时也称 <spanclass="math inline">\(\{ {\mathcal F}_t,t\in T\}\)</span> 为 <spanclass="math inline">\({\mathcal F}\)</span> 的一个子 <spanclass="math inline">\(\sigma\)</span> 域流），<spanclass="math inline">\(X_T\)</span> 是 <spanclass="math inline">\(E\)</span> 值随机过程，称 <spanclass="math inline">\(X_T\)</span> 是 <span class="math inline">\(\{{\mathcal F}_t,t\in T\}\)</span> <strong>适应</strong>的，若 <spanclass="math inline">\(\forall t\in T, X_t:(\Omega,{\mathcalF}_t)\to(E,{\mathcal E})\)</span> 可测（简单来说即 <spanclass="math inline">\(X_t\)</span> 是 <spanclass="math inline">\({\mathcal F}_t\)</span> 可测的）。若 <spanclass="math inline">\(\forall t\in T,X(s,\omega):([0,t)\times\Omega,{\mathcal B}_{[0,t)}\times{\mathcal F}_t) \to (E,{\mathcal E})\)</span>可测，则称 <span class="math inline">\(X_T\)</span><strong>循序可测</strong>。</p><p><strong>命题 1.2.1</strong>：设 <spanclass="math inline">\(X_T=\{X_t,t\ge0\}\)</span>是实值随机过程，关于域流 <span class="math inline">\(\{ {\mathcal F}_t,t\ge0\}\)</span> 适应，若 <span class="math inline">\(X_T\)</span>是右连续的，则它一定是循序可测的。</p><h2 id="可分性">3. 可分性</h2><p><strong>定义</strong>：设 <spanclass="math inline">\(X_T=\{X_t,t\ge0\}\)</span>是一个实值随机过程，<span class="math inline">\(Q\subset[0,+\infty)\)</span> 可数稠密，若 <span class="math inline">\(\forall\omega\)</span>，<span class="math inline">\(\{(t,X_t(\omega)),t\ge0\}\subset\{(r,X_r(\omega)), r\in Q \}^-\)</span>（<spanclass="math inline">\(A^-\)</span> 表示 <spanclass="math inline">\(A\)</span> 的闭包），则称 <spanclass="math inline">\(X_T\)</span> 关于 <spanclass="math inline">\(Q\)</span> 可分。<spanclass="math inline">\(Q\)</span> 称为一个可分集，若存在可数稠密 <spanclass="math inline">\(Q\subset [0,+\infty)\)</span> 使 <spanclass="math inline">\(X_T\)</span> 关于 <spanclass="math inline">\(Q\)</span> 可分，则称 <spanclass="math inline">\(X_T\)</span> 可分。</p><blockquote><p><strong>注</strong>：可分性用的比较多的大概是把原来的连续指标集 <spanclass="math inline">\(T\)</span> 转化成可数指标集 <spanclass="math inline">\(Q\)</span>，便于证明。</p></blockquote><p><strong>命题 1.3.1</strong>：若实值随机过程 <spanclass="math inline">\(X_T=\{X_t,t\ge0\}\)</span> 可分，则 <spanclass="math inline">\(\forall c\)</span>，<spanclass="math inline">\(\{X_t\ge c, t\ge0\}\in {\mathcal F}\)</span>。</p><p>证明：利用可分性，将其表示为可数个集合的交集。</p><p><strong>定理 1.3.2</strong>：任一实值随机过程必有可分修正。</p><h2 id="停时">4. 停时</h2><p><strong>定义</strong>：设 <span class="math inline">\((\Omega,\mathcal{F},P)\)</span> 是一个概率空间，<span class="math inline">\(\{{\mathcal F}_t,t\in T\}\)</span> 是 <spanclass="math inline">\({\mathcal F}\)</span> 的一个上升子 <spanclass="math inline">\(\sigma\)</span> 域流，<spanclass="math inline">\(T\subset {\mathbb R}_+\)</span>是一个时间参数集，<span class="math inline">\(\tau\)</span> 是从 <spanclass="math inline">\(\Omega\)</span> 到 <spanclass="math inline">\(T\)</span> 中的映射，若 <spanclass="math inline">\(\{\tau\le t\}\in{\mathcal F}_t,\forall t\inT\)</span>，则称 <span class="math inline">\(\tau\)</span> （关于 <spanclass="math inline">\(\{ {\mathcal F}_t,t\inT\}\)</span>）是一个<strong>停时</strong>。若 <spanclass="math inline">\(\{\tau&lt; t\}\in{\mathcal F}_t,\forall t\inT\)</span>，则称 <span class="math inline">\(\tau\)</span> （关于 <spanclass="math inline">\(\{ {\mathcal F}_t,t\inT\}\)</span>）是一个<strong>宽停时</strong>。</p><blockquote><p><strong>注</strong>：引用网上对于停时的直观解释：<spanclass="math inline">\(\{\tau\le t\}\in{\mathcal F}_t\)</span> 意味着到<span class="math inline">\(t\)</span> 时刻的信息足够判断是否在 <spanclass="math inline">\(t\)</span> 时刻或 <spanclass="math inline">\(t\)</span> 之前停下来。</p></blockquote><p><strong>性质 1.4.1</strong>：</p><ol type="1"><li>若 <span class="math inline">\(\tau,\sigma\)</span> 是两个停时，则<span class="math inline">\(\tau \vee\sigma,\tau\wedge\sigma,\tau+\sigma\)</span> 也是停时；</li><li>若 <span class="math inline">\(\{\tau_n,n\ge1\}\)</span>是一列宽停时，则 <span class="math inline">\(\sup_n \tau_n,\inf_n\tau_n, \liminf \tau_n,\limsup \tau_n\)</span> 也是宽停时；</li><li>若 <span class="math inline">\(\{\tau_n,n\ge1\}\)</span>是一列停时，则 <span class="math inline">\(\sup_n \tau_n\)</span>也是停时；</li><li><span class="math inline">\(\tau\)</span> 是 <spanclass="math inline">\(\{ {\mathcal F}_t,t\ge0\}\)</span> 停时 <spanclass="math inline">\(\iff\)</span> <spanclass="math inline">\(\tau\)</span> 关于域流 <spanclass="math inline">\({\mathcal F}_{t+}\triangleq \cap_{s&gt;t}{\mathcalF}_s,t\in T\)</span> 是停时；</li><li>若 <span class="math inline">\(\tau\)</span>是宽停时，则它是一列停时，<span class="math inline">\(\tau_n\)</span>的递减极限，即 <span class="math inline">\(\tau_n \downarrow\tau\)</span>；</li><li>若 <span class="math inline">\(T={\mathbb Z_+}\text{ or }{\mathbbN}\)</span>（可数），则 <span class="math inline">\(\tau\)</span> 是停时<span class="math inline">\(\iff\)</span> <spanclass="math inline">\(\{\tau=t\}\in {\mathcal F}_t,\forall t\inT\)</span>。</li></ol><p>证明：略</p><p><strong>定义</strong>：设 <span class="math inline">\(\tau\)</span>是 <span class="math inline">\({\mathcal F}_t\)</span> 停时，定义 <spanclass="math inline">\({\mathcal F}_\tau=\{A\in{\mathcal F}, A\cap\{\tau\le t\}\in {\mathcal F}_t,\forall t\in T \}\)</span>，则 <spanclass="math inline">\({\mathcal F}_\tau\)</span> 是停时。</p><p><strong>定理</strong>：设 <span class="math inline">\(\tau\)</span>是 <span class="math inline">\({\mathcal F}_t\)</span> 停时，<spanclass="math inline">\(X_t\)</span> 是 <spanclass="math inline">\({\mathcal F}_t\)</span> 适应的，则</p><ol type="1"><li><span class="math inline">\(\tau\)</span> 是 <spanclass="math inline">\({\mathcal F}_\tau\)</span> 可测的；</li><li>若 <span class="math inline">\(T={\mathbb Z}_+\text{ or }{\mathbbN}\)</span>，则 <span class="math inline">\(X_\tau\)</span> 是 <spanclass="math inline">\({\mathcal F}_\tau\)</span> 可测的；</li><li>若 <span class="math inline">\(T=[0,+\infty)\)</span> 且 <spanclass="math inline">\(\{X_t,t\ge0\}\)</span> 是关于 <spanclass="math inline">\(\{ {\mathcal F}_t,t\ge0\}\)</span> 循序可测，则<span class="math inline">\(X_\tau\)</span> 是 <spanclass="math inline">\({\mathcal F}_\tau\)</span> 可测的。</li></ol><p>证明：略。</p><p>接下来定义某个时间首次发生的时间作为首中时，实际上很多情况下首中时就是一种停时，他在很多问题中都会出现，比如赌博前决定赢1毛钱就收手，首次发生“赢1毛钱”这个事件的时刻就是一个停时。</p><p><strong>定义</strong>：<spanclass="math inline">\(\{X_t,t\ge0\},(E,{\mathcal E}),B\in{\mathcalE}\)</span>，定义<strong>首中时</strong> <spanclass="math inline">\(\tau_B=\inf\{t:X_t(\omega)\in B\}\)</span></p><p><strong>定理 1.4.2</strong>：</p><ol type="1"><li>若 <span class="math inline">\(T={\mathbb Z}_+\)</span>，则 <spanclass="math inline">\(\forall B\in{\mathcal E}\)</span>，<spanclass="math inline">\(\tau_B\)</span> 是停时；</li><li>若 <span class="math inline">\((E,{\mathcal E})\)</span>是距离可测空间，<span class="math inline">\(T={\mathbbR}_+\)</span>，<span class="math inline">\(X_t\)</span> 适应， <spanclass="math inline">\(B\)</span> 是<strong>开集</strong>，若 <spanclass="math inline">\(X_t\)</span> 是关于 <spanclass="math inline">\(t\)</span> <strong>右连续</strong>的，则 <spanclass="math inline">\(\tau_B\)</span> 是<strong>宽停时</strong>；</li><li>若 <span class="math inline">\((E,{\mathcal E})\)</span>是距离可测空间，<span class="math inline">\(T={\mathbbR}_+\)</span>，<span class="math inline">\(X_t\)</span> 适应， <spanclass="math inline">\(B\)</span> 是<strong>闭集</strong>，若 <spanclass="math inline">\(X_t\)</span> 是关于 <spanclass="math inline">\(t\)</span> <strong>连续</strong>的，则 <spanclass="math inline">\(\tau_B\)</span> 是<strong>停时</strong>。</li></ol><p>证明：略。</p><blockquote><p><strong>注1</strong>：若 <span class="math inline">\(\{ {\mathcalF}_t\}\)</span> 右连续（即 <span class="math inline">\({\mathcalF}_{t+}={\mathcal F}_t,t\ge0\)</span>）则<spanclass="math inline">\(B\)</span>无论开、闭，<spanclass="math inline">\(\tau_B\)</span> 都是停时。</p><p><strong>注2</strong>：这里为什么会有开集/闭集的区别？是怎么跟停时/宽停时的定义联系在一起的？以及为什么会对<span class="math inline">\(X_t\)</span> 的连续性有要求？</p></blockquote><blockquote><p><strong>注</strong>：实际上我们常用的域流是自然 <spanclass="math inline">\(\sigma\)</span> 域流，即 <spanclass="math inline">\({\mathcal F}^X_t=\sigma\{X_s:s\let\}\)</span>。</p></blockquote>]]></content>
    
    
    <categories>
      
      <category>随机过程2</category>
      
    </categories>
    
    
    <tags>
      
      <tag>样本轨道</tag>
      
      <tag>循序可测</tag>
      
      <tag>可分性</tag>
      
      <tag>停时</tag>
      
      <tag>首中时</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【随机过程（数学系）】绪论</title>
    <link href="/2021/06/04/stochastic-process/ch0-intro/"/>
    <url>/2021/06/04/stochastic-process/ch0-intro/</url>
    
    <content type="html"><![CDATA[<p>本系列为研究生随机过程的课程笔记，主要内容包括停时、鞅论、Markov过程等，以高等概率论为基础，因此会需要部分测度相关的知识（目前为止高等概率论的专栏还在咕咕...）</p><p>参考书为 Durret 的《Probability: Theory and Examples》</p>]]></content>
    
    
    <categories>
      
      <category>随机过程2</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>舒尔补</title>
    <link href="/2021/05/28/linear-algebra/SchurComplement/"/>
    <url>/2021/05/28/linear-algebra/SchurComplement/</url>
    
    <content type="html"><![CDATA[<p>舒尔补其实就是将一个矩阵变成块对角化的矩阵，便于求逆。</p><h2 id="定义">1. 定义</h2><p>n*n 的矩阵可以写成分块矩阵形式 <span class="math display">\[M = \left[\begin{array}{cc}{A} &amp; {B} \\{C} &amp; {D}\end{array}\right]_{n\times n}\]</span></p><ul><li>若 A 是非奇异的，则 A 在 M 中的舒尔补为：<spanclass="math inline">\(D-CA^{-1}B\)</span></li><li>若 D 是非奇异的，则 D 在 M 中的舒尔补为：<spanclass="math inline">\(A-BD^{-1}C\)</span></li><li>只要记住字母顺序 DCAB、ABDC 都是在 M中<strong>顺时针</strong>排列的</li></ul><h2 id="推导">2. 推导</h2><p>若 A 非奇异，有 <span class="math display">\[\left[\begin{array}{cc}{I} &amp; {0} \\{-C A^{-1}} &amp; {I}\end{array}\right]\left[\begin{array}{cc}{A} &amp; {B} \\{C} &amp; {D}\end{array}\right]\left[\begin{array}{cc}{I} &amp; {-A^{-1} B} \\{0} &amp; {I}\end{array}\right]=\left[\begin{array}{cc}{A} &amp; {0} \\{0} &amp; {D-C A^{-1} B}\end{array}\right]\]</span> 可得到 <span class="math display">\[\left|\begin{array}{cc}{A} &amp; {B} \\{C} &amp; {D}\end{array}\right|=\left|\begin{array}{cc}{A} &amp; {0} \\{0} &amp; {D-C A^{-1} B}\end{array}\right|=|A||D-CA^{-1}B|\]</span> 此时 <span class="math display">\[M 非奇异 \Leftrightarrow D-CA^{-1}B 非奇异\]</span></p><h2 id="性质">3. 性质</h2><p>记矩阵 <span class="math inline">\(A&lt;0\)</span> 表示 A负定，则对于矩阵 M 有以下性质 <span class="math display">\[M &lt; 0 \\\iff A&lt;0, D-C A^{-1} B&lt;0 \\\iff D&lt;0, A-BD^{-1}C&lt;0\]</span></p><p>逆矩阵 <span class="math display">\[\left[\begin{array}{cc}{A} &amp; {B} \\{C} &amp; {D}\end{array}\right]^{-1} =\left[\begin{array}{cc}{(A-BD^{-1}C)^{-1}} &amp; {X} \\{Y} &amp; {(D-CA^{-1}B)^{-1}}\end{array}\right]\]</span></p>]]></content>
    
    
    <categories>
      
      <category>Linear Algebra</category>
      
    </categories>
    
    
    <tags>
      
      <tag>舒尔补</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>转载|理解复数域上的向量空间</title>
    <link href="/2021/04/08/linear-algebra/complex_space/"/>
    <url>/2021/04/08/linear-algebra/complex_space/</url>
    
    <content type="html"><![CDATA[<blockquote><p>说明：本文转载自<ahref="https://math.tianpeng.org/2010/07/%e7%90%86%e8%a7%a3%e5%a4%8d%e6%95%b0%e5%9f%9f%e4%b8%8a%e7%9a%84%e5%90%91%e9%87%8f%e7%a9%ba%e9%97%b4%ef%bc%88%e7%ac%ac%e4%b8%80%e7%af%87%ef%bc%89/">博客：理解复数域上的向量空间（第一篇）</a>，由于没有找到原作者的联系方式，所以直接搬运过来了，如有侵权请联系我，我立即删除。</p></blockquote><p>线性代数进行到酉空间中的自伴算子、正规算子以及谱定理这部分内容时，会发现很多在复空间中成立的命题在实空间中却未必成立。这种情况多少让人感到有点奇怪，为什么会出现这种情况？复数域是包含实数域的，我们学习复数之后碰到最多的是相反的情况：原本在实数域上成立的性质在复数域中不一定成立了，比如，实数可以比较大小，但复数没有大小关系；又比如，实数的平方非负，等等。这样的命题见多了，容易使人产生思维定势，认为复数包含实数，因此在复数范围内成立的命题在实数范围内也必然成立，而实数范围成立的命题不一定都能推广到复数。可尤其是学习到复变函数之后，这种情况似乎反过来了，同样的一个概念，到了复数中反倒比原来实数情况下的相应概念有了更多的内涵。这又是为什么呢？</p><span id="more"></span><p>比如，在”Linear Algebra Done Right” 第七章有个命题 7.2，是说</p><p><strong>命题7.2：</strong> 如果 <spanclass="math inline">\(V\)</span>是复数域上的内积空间，并且 <spanclass="math inline">\(T\)</span>是 <spanclass="math inline">\(V\)</span>上的线性算子，且对任意向量 <spanclass="math inline">\(v\)</span>，都有 <spanclass="math inline">\(\langle Tv,v\rangle=0\)</span>，那么 <spanclass="math inline">\(T=0\)</span>。 <strong>证明：</strong> 使用恒等式<span class="math inline">\(\begin{aligned}\langleTu,w\rangle=&amp;\frac{\langle T(u+w),u+w\rangle-\langleT(u-w),u-w\rangle}{4}\\ &amp;+\frac{\langle T(u+iw),u+iw\rangle+\langleT(u-iw),u-iw\rangle}{4}i\end{aligned}\)</span> 即可得证。</p><p>但是，同样的假设，在实数空间中却得不出同样的结论来，比如，二维空间中把所有向量都逆时针旋转90度角。</p><p>可是，在实空间中可以存在旋转90度的映射，为什么在复空间中就没有这种映射？难道就不可以有一个线性变换像实空间中那样把每一个向量都旋转到垂直的位置上吗？</p><p>它的证明的确在那里，证法也的确没有错，但是我却从直观上难以接受这个命题。我不甘心，于是找来实空间中的那个旋转映射放在复空间上，定义复空间上的映射<span class="math inline">\(T\begin{pmatrix}a\\b\end{pmatrix}=\begin{pmatrix}b\\ -a\end{pmatrix}\)</span> 那么 <spanclass="math inline">\(\langle Tv,v\rangle=a\bar b-b\bara\)</span>，通常情况下，这是个纯虚数，不一定是零。所以这个反例失败了，在这个例子上，我不得不承认上面那个命题。但是，它给我带来更多的思考：</p><p>我们应该怎样直观地想象复向量空间？从前我们总是把向量想象成一条带有方向的线段，把一维子空间想象成一条直线，”线”总是伴随着我们对向量空间的影像理解，因为实数上面可以定义线序，而我们生存的三维空间就可以看成实三维空间，所以在理解一般的向量空间的时候，这种影像可以帮助我们建立起很多问题的直观。但是，当探究复向量空间内部的特殊结构的时候，这种形象的理解遇到了一些问题。比如，把一个复向量取共轭，跟原来的向量是什么位置关系？又比如，一个向量<span class="math inline">\(v\)</span>乘以 <spanclass="math inline">\(i\)</span>，变成了 <spanclass="math inline">\(iv\)</span>，是把这个向量怎么样了？旋转了九十度？可是毕竟二者是线性相关的，而在我们的直观理解中，线性相关的两个向量是共线的，数乘只是把向量拉长或缩短。但是如果把它们两个想象成共线的，又无法想象它们两个有相同的长度，一个一维子空间中相同长度的向量不是两个，而是无穷多个，无法想象。看来，与复平面类似，只有把一维复向量空间理解成我们所熟悉的平面才自然一些，而这个一维复空间中的一个复向量，可以看成是躺在个平面上的，它并不占据这个一维空间的一整段，在它周围可以有无数多条与它长度相等的向量。那么这么看来，一个 n 维的复空间，是否可以形象地把它想象成一个 2n维实空间？</p><p>把问题提得更明确一些，如果我们把一个 n维复空间看成一个实数域上的向量空间，即把数量乘法中用到的数限制在实数域中，那么，原来的基底<spanclass="math inline">\(e_1,e_2,\dots,e_n\)</span>就张不成整个空间了，可以证明，向量组 <spanclass="math inline">\(e_1,ie_1,e_2,ie_2,\dots,e_n,ie_n\)</span>是这个实向量空间的基底，一共2n 个元素，所以它是一个 2n维实向量空间。（注意，这个实数空间中的一个向量 v在原来复空间意义下可以乘以纯量 i 变成 iv，但在实空间中 iv将不再是这种乘法的结果，它只是与 v 有关的一个向量而已。我们仍然记为iv。）</p><p>如果只考虑空间本身，那么这样的理解是足够的，也足以提供复空间的一些直观信息。可是，我们需要理解的不止是这些，还有内积、线性变换等一些东西，在这个衍生出来的实空间中的这些东西到底跟原来的复空间中相应的对象有什么联系？</p><p>首先分析内积，如果原来的复空间中有内积 <spanclass="math inline">\(\langle \cdot,\cdot\rangle\)</span>，那么 <spanclass="math inline">\(\mathrm{Re}\,\langle\cdot,\cdot\rangle\)</span>就是衍生出的实空间中的内积，我们用方括号<span class="math inline">\([\cdot,\cdot]\)</span>表示这个实空间的内积，那么原来的内积就可以用这个实数空间内积表示为 <spanclass="math inline">\(\langle u,v\rangle=[u,v]+i[u,iv]\)</span>并且，这两个内积诱导的范数是相同的。 对任意向量 <spanclass="math inline">\(v\)</span>，向量 <spanclass="math inline">\(iv\)</span>在实数空间的内积意义下是垂直于 <spanclass="math inline">\(v\)</span>的： <spanclass="math inline">\([iv,v]=\mathrm{Re}\,i\langlev,v\rangle=0\)</span>。 如果 <spanclass="math inline">\(e_1,e_2,\dots,e_n\)</span>是复空间的标准正交基底，那么<spanclass="math inline">\(e_1,ie_1,e_2,ie_2,\dots,e_n,ie_n\)</span>是实空间的标准正交基底。</p><p>下面讨论一个向量乘以 i 是怎么回事。在复空间中，变换 <spanclass="math inline">\(S=iI\)</span>是个线性变换，那么在实空间中 <spanclass="math inline">\(v\)</span>到 <spanclass="math inline">\(iv\)</span>的变换是否也是线性变换？注意到原来复空间的任何线性变换在实空间下也是线性变换，所以<spanclass="math inline">\(S\)</span>也不例外。那么它在实空间意义下对应什么矩阵呢？取上面的标准正交基底 <spanclass="math inline">\(e_1,ie_1,e_2,ie_2,\dots,e_n,ie_n\)</span>，显然它在这组基底下的矩阵为<span class="math inline">\(\begin{pmatrix}0&amp;-1&amp;&amp;0&amp;0\\1&amp;0&amp;&amp;0&amp;0\\ &amp;&amp;\ddots&amp;&amp;\\0&amp;0&amp;&amp;0&amp;-1\\0&amp;0&amp;&amp;1&amp;0\end{pmatrix}\)</span> 即主对角线上是 2×2阶矩阵块 <span class="math inline">\(\begin{pmatrix}0&amp;-1\\1&amp;0\end{pmatrix}\)</span> 其余位置都为零。</p><p>接下来讨论一般的线性变换。在复空间中每个线性变换 <spanclass="math inline">\(T\)</span>都对应实空间的一个线性变换，那么反过来，是否一个实空间的线性变换在复空间中也是线性变换呢？<spanclass="math inline">\(T(u+v)=Tu+Tv\)</span>这一条是两种空间都共同满足的，但关键是<spanclass="math inline">\(T(kv)=kTv\)</span>这个性质，对于实空间，我们只要求<span class="math inline">\(k\)</span>为实数，但对于复空间，我们还要求<span class="math inline">\(k\)</span>可以取复数。那么就必须有 <spanclass="math inline">\(T(au+biu)=aTu+biTu\)</span>，换句话说，就是 <spanclass="math inline">\(T\)</span>与上面定义的 <spanclass="math inline">\(S\)</span>可交换：<spanclass="math inline">\(TSv=STv\)</span>，只有这样的 <spanclass="math inline">\(T\)</span>才有资格作为复空间的线性变换，并且这是个充要条件。分析一下 <span class="math inline">\(\mathcal L(V)\)</span>的维数，当<span class="math inline">\(V\)</span>是复空间时，<spanclass="math inline">\(\mathcal L(V)\)</span>的维数是 <spanclass="math inline">\(n^2\)</span>，把 <spanclass="math inline">\(\mathcalL(V)\)</span>看成相应的实数空间，维数也不过是 <spanclass="math inline">\(2n^2\)</span>，但如果把 <spanclass="math inline">\(V\)</span>看成相应的实空间，那么 <spanclass="math inline">\(\mathcal L(V)\)</span>的维数是 <spanclass="math inline">\(4n^2\)</span>，可见，复空间上的线性变换比相应的实空间的线性变换少了一半，原因就是复空间的特性对线性变换会有更多的限制。利用矩阵的分块乘法规则可以证明，实空间上的 <spanclass="math inline">\(2n\times 2n\)</span> 阶矩阵 <spanclass="math inline">\(A\)</span>，如果与 <spanclass="math inline">\(S\)</span> 对应的矩阵可交换，那么 <spanclass="math inline">\(A\)</span> 有以下形式： <spanclass="math inline">\(\begin{pmatrix}a&amp;-b&amp;&amp;c&amp;-d\\b&amp;a&amp;&amp;d&amp;c\\ &amp;&amp;\ddots&amp;&amp;\\e&amp;-f&amp;&amp;g&amp;-h\\f&amp;e&amp;&amp;h&amp;g\end{pmatrix}\)</span>显然，它对应复空间上的矩阵 <spanclass="math inline">\(\begin{pmatrix}a+bi&amp;\dots&amp;c+di\\\vdots&amp;\ddots&amp;\vdots\\e+fi&amp;\dots&amp;g+hi\end{pmatrix}\)</span>而且，分析这种矩阵的自由度，与上面分析的复空间变换的维数恰好吻合。</p><p>下面利用实空间的理论，在复空间衍生的实空间中证明命题7.2。首先证明一条引理：</p><p><strong>引理1：</strong> 如果 <span class="math inline">\(V\)</span>是实的内积空间，<span class="math inline">\(T\in\mathcalL(V)\)</span>，那么 <span class="math inline">\(T\)</span> 满足 <spanclass="math inline">\(\forall v\in V,\langle Tv,v\rangle=0\)</span>当且仅当 <span class="math inline">\(T\)</span> 是斜自伴的，即 <spanclass="math inline">\(T^\star=-T\)</span>。 <strong>证明：</strong> 如果<span class="math inline">\(T^\star=-T\)</span>，那么有 <spanclass="math inline">\(\langle Tv,v\rangle=\langle v,T^\starv\rangle=-\langle v,Tv\rangle=-\langle Tv,v\rangle\)</span>，因此 <spanclass="math inline">\(\langle Tv,v\rangle=0\)</span>。 反过来，如果<span class="math inline">\(\forall v\in V,\langleTv,v\rangle=0\)</span>，那么 <spanclass="math inline">\(\begin{aligned}\langleT(v+w),v+w\rangle=&amp;\langle Tv,v\rangle+\langle Tv,w\rangle+\langleTw,v\rangle+\langle Tw,w\rangle\\ =&amp;0\end{aligned}\)</span> 因此<span class="math inline">\(\begin{aligned}\langle Tv,w\rangle+\langleTw,v\rangle=&amp;\langle Tv,w\rangle+\langle w,T^{\star}v\rangle\\=&amp;\langle Tv,w\rangle+\langle T^{\star}v,w\rangle\\ =&amp;\langle(T+T^{\star})v,w\rangle\\ =&amp;0\end{aligned}\)</span> 取 <spanclass="math inline">\(w=(T+T^{\star})v\)</span>即可得证。</p><p>接下来把命题7.2 翻译成实空间中的命题并证明之。</p><p><strong>命题2</strong>：<spanclass="math inline">\(V\)</span>是实内积空间，<spanclass="math inline">\(T\)</span> 与 <spanclass="math inline">\(S\)</span> 都是 <spanclass="math inline">\(V\)</span>上的斜自伴算子，且 <spanclass="math inline">\(S\)</span> 可逆，<spanclass="math inline">\(T\)</span> 与 <spanclass="math inline">\(S\)</span> 可交换，并且任意向量 <spanclass="math inline">\(v\)</span>，<span class="math inline">\(\langleTv,Sv\rangle=0\)</span>，那么 <span class="math inline">\(T=0\)</span>。证明：由 <span class="math inline">\(\langle Tv,Sv\rangle=-\langleSTv,v\rangle=0\)</span>，可知 <span class="math inline">\(ST\)</span>也是斜自伴的。那么 <spanclass="math inline">\(-TS=(TS)^{\star}=S^{\star}T^{\star}=ST=TS\)</span>，因此<span class="math inline">\(TS=0\)</span>。又 <spanclass="math inline">\(S\)</span> 可逆，故 <spanclass="math inline">\(T=0\)</span>。证毕。 （P.S: 如果没有 <spanclass="math inline">\(S\)</span> 可逆的条件，那么 <spanclass="math inline">\(\mathrm{null}\,T\supset\mathrm{range}\,S\)</span>。）</p><p>原来一个复向量空间上的线性变换相当于暗中假定了这么多的条件！难怪复空间中的算子理论有那么好的性质。</p><hr /><p>2015/10/28 补充：</p><p>我们可以完善引理1，使得通过这个引理可以更直接地证明书上的命题7.2：</p><p><strong>引理1'：</strong> 设 <spanclass="math inline">\(V\)</span>是实数域或复数域上的内积空间，<spanclass="math inline">\(T\in\mathcal L(V)\)</span>。记<spanclass="math inline">\(i\mathbb R\)</span>为所有纯虚数和<spanclass="math inline">\(0\)</span>构成的集合，那么，<spanclass="math inline">\(T\)</span> 满足 <spanclass="math inline">\(\forall v\in V,\langle Tv,v\rangle\in i\mathbbR\)</span> 当且仅当 <span class="math inline">\(T\)</span>是斜自伴的，即<span class="math inline">\(T^{\star}=-T\)</span>。<strong>证明：</strong> 如果 <spanclass="math inline">\(T^{\star}=-T\)</span>，那么有 <spanclass="math inline">\(\langle Tv,v\rangle=\langlev,T^{\star}v\rangle=-\langle v,Tv\rangle=-\overline{\langleTv,v\rangle}\)</span>，因此 <span class="math inline">\(\langleTv,v\rangle\in i\mathbb R\)</span>。 反过来，如果 <spanclass="math inline">\(\forall v\in V,\langle Tv,v\rangle\in i\mathbbR\)</span>，那么 <span class="math inline">\(\begin{aligned}\langleT(v+w),v+w\rangle=&amp;\langle Tv,v\rangle+\langle Tv,w\rangle+\langleTw,v\rangle+\langle Tw,w\rangle\\ \in&amp; i\mathbbR\end{aligned}\)</span> 因此 <spanclass="math inline">\(\begin{aligned}\Re\langle Tv,w\rangle+\langleTw,v\rangle=&amp;\Re(\langle Tv,w\rangle+\langle w,T^{\star}v\rangle)\\=&amp;\Re(\langle Tv,w\rangle+\langle T^{\star}v,w\rangle)\\=&amp;\Re\langle (T+T^{\star})v,w\rangle\\ =&amp;0\end{aligned}\)</span>取 <span class="math inline">\(w=(T+T^\star)v\)</span> 即可得 <spanclass="math inline">\(\forall v, \|(T+T^\star)v\|^2=0\)</span>，因此<span class="math inline">\(T=-T^\star\)</span>。</p><p>这样，在复数域空间中，如果<spanclass="math inline">\(T\)</span>满足<span class="math inline">\(\forallv\in V,\langle Tv,v\rangle =0\)</span>，那么<spanclass="math inline">\(T\)</span>和<spanclass="math inline">\(iT\)</span>就同时满足引理1’的条件，所以同时有<spanclass="math inline">\(T=-T^\star\)</span>和<spanclass="math inline">\(iT=-(iT)^\star=iT^\star\)</span>，因此<spanclass="math inline">\(T=0\)</span>。</p>]]></content>
    
    
    <categories>
      
      <category>Linear Algebra</category>
      
    </categories>
    
    
    <tags>
      
      <tag>复数域空间</tag>
      
      <tag>矩阵分析</tag>
      
      <tag>转载</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>红豆</title>
    <link href="/2021/02/12/music/LovePea/"/>
    <url>/2021/02/12/music/LovePea/</url>
    
    <content type="html"><![CDATA[<center><h2>相思</h2></center><center><h4>红豆生南国，春来发几枝。<br> 愿君多采撷，此物最相思。</h4></center><span id="more"></span><iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width="330" height="86" src="//music.163.com/outchain/player?type=2&amp;id=1468957767&amp;auto=1&amp;height=66"></iframe><blockquote><p>还没好好地感受​ 雪花绽放的气候 我们一起颤抖 会更明白什么是温柔还没跟你牵着手 走过荒芜的沙丘 可能从此以后 学会珍惜天长和地久</p><p>有时候　有时候 我会相信一切有尽头 相聚离开都有时候 没有什么会永垂不朽可是我　有时候 宁愿选择留恋不放手 等到风景都看透也许你会陪我看细水长流</p><p>还没为你把红豆 熬成缠绵的伤口 然后一起分享 会更明白相思的哀愁还没好好地感受 醒着亲吻的温柔 可能在我左右 你才追求孤独的自由</p><p>有时候　有时候 我会相信一切有尽头 相聚离开都有时候 没有什么会永垂不朽可是我　有时候 宁愿选择留恋不放手 等到风景都看透也许你会陪我看细水长流</p><p>有时候　有时候 我会相信一切有尽头 相聚离开都有时候 没有什么会永垂不朽可是我　有时候 宁愿选择留恋不放手 等到风景都看透也许你会陪我看细水长流</p></blockquote>]]></content>
    
    
    <categories>
      
      <category>Music</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>泛函分析笔记8：开映射定理与闭图像定理</title>
    <link href="/2020/12/27/functional-analysis/ch4-5-open-closed/"/>
    <url>/2020/12/27/functional-analysis/ch4-5-open-closed/</url>
    
    <content type="html"><![CDATA[<p>接下来四大定理就剩下了两个：开映射定理与闭图像定理。剩下的内容相比于前面两个定理要少很多，也更简单，我们一口气讲完吧！</p><h2 id="开映射定理">1. 开映射定理</h2><p><span class="math inline">\((X_1,d_1),(X_2,d_2)\)</span>，称 <spanclass="math inline">\(T:X_1\to X_2\)</span>为<strong>开映射</strong>，若 <span class="math inline">\(\forallG\subset X\)</span> 为开集，都有 <spanclass="math inline">\(T(G)\)</span> 在 <spanclass="math inline">\(X_2\)</span> 中为开集。</p><p><strong>NOTE</strong>：我们讲到连续映射的时候证明了一个定理，即 <spanclass="math inline">\(T\)</span> 为<strong>连续映射</strong> <spanclass="math inline">\(\iff \forall G\subset X_2\)</span> 为开集，那么<span class="math inline">\(T^{-1}(G)=\{x\in X_1, Tx\in G\}\)</span> 是<span class="math inline">\(X_1\)</span>中的开集。注意这与开映射不同，开映射是正向的，连续映射是反向的。</p><span id="more"></span><p>在给出开映射定理之前我们需要先准备几条引理。</p><p><strong>引理</strong>：设 <span class="math inline">\(X\)</span>为赋范空间，<spanclass="math inline">\(\lambda\in\mathbb{K},\lambda\ne0\)</span></p><ul><li>若 <span class="math inline">\(x_0\in X,r&gt;0\)</span>，则 <spanclass="math inline">\(\lambda B(x_0,r) = B(\lambdax_0,|\lambda|r)\)</span>；</li><li>若 <span class="math inline">\(M\subset X\)</span>，则 <spanclass="math inline">\(\overline{\lambda M}=\lambda\overline{M}\)</span>；</li><li>若 <span class="math inline">\(M\subset X\)</span>，则 <spanclass="math inline">\((\lambda M)^\circ=\lambda M^\circ\)</span>。</li></ul><p>证明：只证第3条，若 <span class="math inline">\(x\in (\lambdaM)^\circ\)</span>，那么存在 <spanclass="math inline">\(r&gt;0，B(x,r)\in \lambda M\)</span>，也即 <spanclass="math inline">\(\frac{1}{\lambda} B(x,r)\inM\)</span>，根据第1条结论，也即 <spanclass="math inline">\(B(x/\lambda,r/|\lambda|)\in M\)</span>，因此 <spanclass="math inline">\(x/\lambda\in M^\circ\)</span>，所以有 <spanclass="math inline">\((\lambda M)^\circ\subset\lambdaM^\circ\)</span>。反过来若 <span class="math inline">\(x\in\lambdaM^\circ\)</span>，即 <span class="math inline">\(x/\lambda\inM^\circ\)</span>，类的的可以得到 <span class="math inline">\(\lambdaM^\circ\subset(\lambda M)^\circ.\)</span> 证毕。</p><p><strong>引理</strong>：<span class="math inline">\(X,Y\)</span> 为Banach 空间，<span class="math inline">\(T\in B(X,Y)\)</span> 为满射，则<span class="math inline">\(T(B_X(0,1))\)</span> 包含一个以 <spanclass="math inline">\(0\)</span> 为中心的开球，即存在 <spanclass="math inline">\(\delta&gt;0\)</span>，<spanclass="math inline">\(B_Y(0,\delta)\subset T(B_X(0,1)).\)</span></p><p><strong>证明</strong>：这个引理看起来简单，证明还挺复杂的。我们记<span class="math inline">\(B_n=B_X(0,1/2^n)\)</span>。</p><p>首先证明 <span class="math inline">\(\overline{T(B_1)}\)</span>包含某个开球。考虑到 <span class="math inline">\(\bigcup_{n=1}^\inftynT(B_1)=Y\)</span>，由于 <span class="math inline">\(Y\)</span> 为Banach 空间，也可以表示为 <spanclass="math inline">\(\bigcup_{n=1}^\inftyn\overline{T(B_1)}=Y\)</span>，根据 Baire 范畴定理，一定存在 <spanclass="math inline">\(n_0\ge1\)</span> 使得 <spanclass="math inline">\(n_0\overline{T(B_1)}\)</span> 有内点，即存在 <spanclass="math inline">\(y\in Y,\delta&gt;0\)</span> 使得 <spanclass="math inline">\(B(y,\delta)\subsetn_0\overline{T(B_1)}\)</span>，记 <spanclass="math inline">\(B(y_0,\delta_0)=B(y/n_0,\delta/n_0)\subset\overline{T(B_1)}\)</span>。</p><p>接下来证明 <span class="math inline">\(B(0,\delta_0)\subset\overline{T(B_0)}\)</span>。对任意 <span class="math inline">\(y\inB(0,\delta_0)\)</span>，有 <span class="math inline">\(y_0+y\inB(y_0,\delta_0)\)</span>，所以存在 <spanclass="math inline">\(u_n,v_n\in B_1\)</span> 分别有 <spanclass="math inline">\(Tu_n\to y_0,Tv_n\to y_0+y\)</span>，此时 <spanclass="math inline">\(v_n-u_n\in B_0\)</span>，并且 <spanclass="math inline">\(T(v_n-u_n)\to y\)</span>，因此 <spanclass="math inline">\(y\in \overline{T(B_0)}\)</span>。</p><p>最后证明 <span class="math inline">\(B(0,\delta_0/2)\subsetT(B_0)\)</span>。已有 <spanclass="math inline">\(B(0,\delta_0/2^n)\subset\overline{T(B_n)}\)</span>，任取 <span class="math inline">\(y\inB(0,\delta_0/2)\)</span>，由于 <spanclass="math inline">\(B(0,\delta_0/2)\subset\overline{T(B_1)}\)</span>，因此存在 <span class="math inline">\(x_1\inB_1\)</span> 使得 <span class="math inline">\(\Vert y-Tx_1\Vert &lt;\delta_0/2^2\)</span>。因此 <span class="math inline">\(y-Tx_1\inB(0,\delta_0/2^2)\)</span>，又由于 <spanclass="math inline">\(B(0,\delta_0/2^2)\subset\overline{T(B_2)}\)</span>，因此存在 <span class="math inline">\(x_2\inB_2\)</span> 使得 <span class="math inline">\(\Vert y-Tx_1-Tx_2\Vert&lt; \delta_0/2^3\)</span>。依此类推，对任意的 <spanclass="math inline">\(n\ge1\)</span>，可以找到 <spanclass="math inline">\(x_n\in B_n\)</span>，使得 <spanclass="math display">\[\Vert y-Tx_1-Tx_2-\cdots-Tx_n\Vert &lt; \frac{\delta_0}{2^{n+1}}\]</span> 若令 <spanclass="math inline">\(s_n=x_1+\cdots+x_n\)</span>，则有 <spanclass="math inline">\(s_n\)</span> 为柯西列，假设 <spanclass="math inline">\(s_n\to s\in X\)</span>，则可以验证 <spanclass="math inline">\(y=Ts\)</span>。因为 <spanclass="math inline">\(\Vert s\Vert\le \sum_{n=1}^\infty \Vertx_n\Vert&lt;1\)</span>，因此 <span class="math inline">\(s\inB_0\)</span>，所以 <span class="math inline">\(y\in T(B_0)\)</span>，故<span class="math inline">\(B(0,\delta_0/2)\subsetT(B_0)\)</span>。证毕。</p><blockquote><p><strong>开映射定理</strong>：<span class="math inline">\(X,Y\)</span>为 Banach 空间，<span class="math inline">\(T\in B(X,Y)\)</span>为满射，则 <span class="math inline">\(T\)</span> 一定是开映射。</p></blockquote><p>证明：由前面的引理很容易证明，略。</p><blockquote><p><strong>推论</strong>：<span class="math inline">\(X,Y\)</span> 为Banach 空间，<span class="math inline">\(T\in B(X,Y)\)</span>为满射，特别地，若 <span class="math inline">\(T\)</span>为一一映射，我们有 <span class="math inline">\(T^{-1}\inB(Y,X)\)</span>（即逆映射也是有界的）。</p></blockquote><p>证明：由于 <span class="math inline">\(T\)</span>为开映射且为一一映射，因此 <span class="math inline">\(T^{-1}\)</span>为连续的，因此 <span class="math inline">\(T^{-1}\inB(Y,X)\)</span>。</p><p><strong>推论</strong>：<spanclass="math inline">\((X,\Vert\cdot\Vert_1),(X,\Vert\cdot\Vert_2)\)</span> 均为 Bananch 空间，若存在常数 <spanclass="math inline">\(\alpha&gt;0\)</span> 使得 <spanclass="math inline">\(\Vert x\Vert_1\le \alpha\Vert x\Vert_2,\forallx\in X\)</span>，则存在 <span class="math inline">\(\beta&gt;0\)</span>使得 <span class="math inline">\(\Vert x\Vert_2\le \beta\Vertx\Vert_1,\forall x\in X\)</span>，即 <spanclass="math inline">\(\Vert\cdot\Vert_1\)</span> 与 <spanclass="math inline">\(\Vert\cdot\Vert_2\)</span> 为等价范数。</p><p>证明：考虑 <spanclass="math inline">\(T:(X,\Vert\cdot\Vert_2)\to(X,\Vert\cdot\Vert_1)\)</span>，有 <span class="math inline">\(T:x\mapstox\)</span>。根据条件可以知道 <span class="math inline">\(T\)</span>为有界线性算子，并且 <span class="math inline">\(T\)</span>为一一映射。因此 <span class="math inline">\(T^{-1}\)</span>也是有界线性算子，<span class="math inline">\(\Vert x\Vert_2=\VertT^{-1}x\Vert_2\le \Vert T^{-1}\Vert\Vert x\Vert_1,\forall x\inX\)</span>。证毕。</p><h2 id="闭图像定理">2. 闭图像定理</h2><p>设 <span class="math inline">\(X,Y\)</span> 为赋范空间，令 <spanclass="math inline">\(Z=X\times Y=\{(x,y): x\in X,y\in Y\}\)</span>，定义 <span class="math inline">\(\Vert(x,y)\Vert=\Vertx\Vert_X+\Vert y\Vert_Y\)</span>，可以验证 <spanclass="math inline">\(\Vert\cdot\Vert\)</span> 为 <spanclass="math inline">\(Z\)</span> 上的范数。若 <spanclass="math inline">\(X,Y\)</span> 为 Banach 空间，则 <spanclass="math inline">\(Z\)</span> 也为 Banach 空间。</p><p>设 <span class="math inline">\(X,Y\)</span> 为赋范空间，<spanclass="math inline">\(D(A)\)</span> 为 <spanclass="math inline">\(X\)</span> 中的线性子空间，<spanclass="math inline">\(A:D(A)\to Y\)</span> 为线性算子，称 <spanclass="math inline">\(A\)</span> 为<strong>闭算子</strong>，若 <spanclass="math inline">\(G_A = \{(x,Ax)\in X\times Y:x\in D(A) \}\)</span>为闭集。</p><p><strong>命题</strong>：有界线性算子 <spanclass="math inline">\(\Rightarrow\)</span> 闭算子。</p><p>证明：有界线性算子 <span class="math inline">\(A\)</span>，任意 <spanclass="math inline">\((x,Ax)\in G_A\)</span>，存在 <spanclass="math inline">\(x_n\to x\)</span>，假设 <spanclass="math inline">\((x_n,Ax_n)\to (x,y)\)</span>，由于 <spanclass="math inline">\(A\)</span> 连续，因此 <spanclass="math inline">\(Ax_n\to Ax\)</span>，因此 <spanclass="math inline">\(y=Ax\)</span>，即 <spanclass="math inline">\((x,y)\in G\)</span>，因此 <spanclass="math inline">\(G_A\)</span> 为闭集。证毕。</p><p><strong><em>例子 1</em></strong>(闭算子 <spanclass="math inline">\(\nRightarrow\)</span>有界线性算子)：考虑求导算子，<span class="math inline">\(X=Y=C[0,1],\Vert x\Vert_\infty=\max_{0\le t\le1}|x(t)|\)</span>。<spanclass="math inline">\(D(A)=C^1[0,1]\)</span>，<spanclass="math inline">\(A:x\mapsto x&#39;\)</span> 为线性算子，考虑 <spanclass="math inline">\(x_n(t)=t^n, \Vert x\Vert_\infty=1\)</span>，有<span class="math inline">\(\Vert Ax_n\Vert=n\)</span>，因此 <spanclass="math inline">\(A\)</span> 无界，但是 <spanclass="math inline">\(A\)</span> 为闭算子。</p><p>证明：假设 <span class="math inline">\((x_n,x_n&#39;)\to(x,y)\)</span>，即 <span class="math inline">\(x_n\rightrightarrowsx,x_n&#39;\rightrightarrows y\)</span>，现证明 <spanclass="math inline">\(y=x&#39;\)</span>。由于 <spanclass="math inline">\(x_n&#39; \rightrightarrows y\)</span>一致收敛，积分与极限可以换序，对于 <spanclass="math inline">\(t\in[0,1]\)</span> 有 <spanclass="math display">\[\begin{aligned}\int_0^t y(s)ds &amp;= \int_0^t \lim_{n\to\infty}x_n&#39;(s)ds=\lim_{n\to\infty}\int_0^t x_n&#39;(s)ds \\&amp;=\lim_{n\to\infty} x_n(t)-x_n(0) = x(t)-x(0)\end{aligned}\]</span> 由于 <span class="math inline">\(y\in C[0,1]\)</span>，因此<span class="math inline">\(\int_0^t y(s)ds\)</span>为连续可导函数，因此 <span class="math inline">\(x\inC^1[0,1]=D(A)\)</span>，并且有 <spanclass="math inline">\(x&#39;=y\)</span>，这说明 <spanclass="math inline">\((x,y)=(x,x&#39;)\in G_A\)</span>，从而 <spanclass="math inline">\(A\)</span> 为闭算子。</p><p><strong>NOTE</strong>：闭算子的定义域 <spanclass="math inline">\(D(A)\)</span>不一定是闭集，比如上面的求导算子。</p><p><strong><em>例子 2</em></strong>(有界、不闭算子)：<spanclass="math inline">\(X\)</span> 为赋范空间，<spanclass="math inline">\(X_0\subsetneq X\)</span> 为线性子空间，<spanclass="math inline">\(X_0\)</span> 不闭。算子 <spanclass="math inline">\(A:X_0\to X(x\mapsto x)\)</span>为线性有界算子。但是对于 <span class="math inline">\(y\in\bar{X}\backslash X_0\)</span>，存在 <span class="math inline">\(y_n\inX_0\)</span> 使得 <span class="math inline">\((y_n,Ay_n)\to (y,y)\notinG_A\)</span>，因此 <span class="math inline">\(A\)</span>不是闭算子。</p><blockquote><p><strong>闭图像定理</strong>：<span class="math inline">\(X,Y\)</span>为 <strong>Banach 空间</strong>，<spanclass="math inline">\(D(A)\)</span> 为 <spanclass="math inline">\(X\)</span> 的线性子空间，<spanclass="math inline">\(A:D(A)\to Y\)</span> 为<strong>闭算子</strong>。若<span class="math inline">\(D(A)\)</span> 为 <spanclass="math inline">\(X\)</span> 的<strong>闭线性子空间</strong>，则<span class="math inline">\(A\)</span> <strong>有界</strong>。</p></blockquote><p><strong>证明</strong>：证明算子有界性可以想到一致有界性原理，但是这里并没有说<span class="math inline">\(D(A)\)</span> 可分，也没有说 <spanclass="math inline">\(X\)</span>自反，因此一致有界性原理行不通。那么又可以联想到前面开映射定理，若有界算子<span class="math inline">\(T\)</span> 为开映射，同时又是一一映射，那么<span class="math inline">\(T^{-1}\)</span> 也是有界算子。因此我们构造<span class="math inline">\(P:G_A\to D(A)((x,Ax)\mapstox)\)</span>，其中 <span class="math inline">\(G_A\)</span> 为 Banach空间，并且 <span class="math inline">\(P\)</span>为有界线性算子，为满射、一一映射，因此 <spanclass="math inline">\(P^{-1}:D(A)\to G_A(x\mapsto (x,Ax))\)</span>也是有界算子，进而 <span class="math inline">\(A\)</span> 也有界。</p><blockquote><p><strong>推论</strong>：<span class="math inline">\(X,Y\)</span> 为<strong>Banach 空间</strong>，<spanclass="math inline">\(D(A)=X\)</span>，若 <spanclass="math inline">\(A:X\to Y\)</span> 为<strong>闭算子</strong>，则<span class="math inline">\(A\in B(X,Y).\)</span></p><p><strong>NOTE</strong>：如果想直接证明 <spanclass="math inline">\(A\in B(X,Y)\)</span> 需要什么条件？<spanclass="math inline">\(\forall x_n\in X\)</span>, 设 <spanclass="math inline">\(x_n\to x\)</span>，则 1）<spanclass="math inline">\(Ax_n\)</span> 收敛；2）收敛极限为 <spanclass="math inline">\(Ax\)</span>。但如果我们有 <spanclass="math inline">\(A\)</span> 为闭算子的条件，那么不需要证明 <spanclass="math inline">\(Ax_n\)</span> 收敛，可以直接假设 <spanclass="math inline">\(Ax_n\)</span> 收敛到某 <spanclass="math inline">\(y\)</span>，只需要证明 <spanclass="math inline">\(y=Ax\)</span> 即可。</p><p>这是因为我们已经假设了 <span class="math inline">\(X,Y\)</span> 均为Banach 空间，因此 <span class="math inline">\(X\times Y\)</span>也一定是 Banach 空间，所以一定有 <spanclass="math inline">\((x_n,Ax_n)\)</span> 收敛到某 <spanclass="math inline">\((x,y)\)</span>，因此 <spanclass="math inline">\(Ax_n\)</span> 也一定收敛。</p></blockquote><p><em>例子 3</em>：<span class="math inline">\(H\)</span> 为 Hilbert空间，<span class="math inline">\(A:H\to H, B:H\to H\)</span>均为线性算子，并且满足 <span class="math inline">\(\forall x,y\inH\)</span>，<span class="math inline">\(\langle Ax,y\rangle=\langlex,By\rangle\)</span>，则 <span class="math inline">\(A,B\)</span>均有界。</p><p>证明：<span class="math inline">\(\langle Ax_n,y\rangle=\langlex_n,By\rangle\to\langle x,By\rangle=\langle Ax,y\rangle\)</span>，由于<span class="math inline">\(y\)</span> 任取，因此 <spanclass="math inline">\(Ax_n\to Ax\)</span>，所以 <spanclass="math inline">\(A\)</span> 为闭算子，因此 <spanclass="math inline">\(A\)</span> 有界。证毕。</p>]]></content>
    
    
    <categories>
      
      <category>Functional Analysis</category>
      
    </categories>
    
    
    <tags>
      
      <tag>开映射定理</tag>
      
      <tag>闭图像定理</tag>
      
      <tag>开映射</tag>
      
      <tag>闭算子</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>泛函分析笔记7：弱收敛与弱星收敛</title>
    <link href="/2020/12/26/functional-analysis/ch4-4-convergence/"/>
    <url>/2020/12/26/functional-analysis/ch4-4-convergence/</url>
    
    <content type="html"><![CDATA[<p>一致有界性原理的一个应用就是序列和算子的收敛性分析。</p><h2 id="序列收敛性">1. 序列收敛性</h2><p><span class="math inline">\((X,\Vert\cdot\Vert)\)</span>，有 <spanclass="math inline">\(x_n,x\in X\)</span>，称 <spanclass="math inline">\(x_n\)</span> <strong>强收敛</strong>到 <spanclass="math inline">\(x\)</span>，若 <span class="math inline">\(\Vertx_n-x\Vert \to 0\)</span>；称 <span class="math inline">\(x_n\)</span><strong>弱收敛</strong>到 <span class="math inline">\(x\)</span> 若<span class="math inline">\(\forall f\in X&#39;\)</span> 都有 <spanclass="math inline">\(f(x_n)\to f(x)\)</span>，记为 <spanclass="math inline">\(x_n \stackrel{w}{\longrightarrow} x.\)</span></p><p>关于弱收敛有以下几条性质：</p><ul><li>若 <span class="math inline">\(x_n \stackrel{w}{\longrightarrow} x,x_n \stackrel{w}{\longrightarrow} y\)</span>，则 <spanclass="math inline">\(x=y\)</span>；</li><li>若 <span class="math inline">\(x_n \stackrel{w}{\longrightarrow}x\)</span>，则存在 <span class="math inline">\(c\ge0, \Vert x_n\Vert \lec.\)</span></li></ul><span id="more"></span><p>证明：仅证第二条。这个性质说明 <spanclass="math inline">\(x_n\)</span>有界，因此容易想到需要用一致有界性原理证明，但是该原理说明的是算子的一致有界，这里是元素<span class="math inline">\(x_n\)</span>有界，因此又可以想到上一篇讲到的典范映射 <spanclass="math inline">\(J:X\to X&#39;&#39;\)</span>从元素映射到算子。因此这里考虑 <spanclass="math inline">\(X&#39;\)</span> 上的线性泛函 <spanclass="math inline">\(g_n= J(x_n):X&#39;\to \mathbb{R}\)</span>，有<span class="math inline">\(g_n(f)=f(x_n),\forall f\in X&#39;.\)</span>于是有 <span class="math inline">\(f(x_n)\to f(x)\)</span>，因而固定任一<span class="math inline">\(f\)</span>，都有 <spanclass="math inline">\(\sup_n g_n(f) &lt; \infty\)</span>，同时由于 <spanclass="math inline">\(X&#39;\)</span> 总为 Banach空间，利用一致有界性原理有 <span class="math inline">\(\sup_n \Vertg_n\Vert =\sup_n \Vert x_n\Vert &lt; \infty\)</span>。证毕。</p><blockquote><p><strong>定理</strong>：<spanclass="math inline">\((X,\Vert\cdot\Vert)\)</span>，有 <spanclass="math inline">\(x_n,x\in X\)</span>，则 <spanclass="math inline">\(x_n \stackrel{w}{\longrightarrow} x\)</span><strong>当且仅当</strong>：</p><ol type="1"><li>存在 <span class="math inline">\(c\ge0,\Vert x_n\Vert\lec\)</span>；</li><li>并且存在 <span class="math inline">\(M\subsetX&#39;,\overline{\text{span}M}=X&#39;\)</span>，对 <spanclass="math inline">\(\forall f\in M, f(x_n)\to f(x).\)</span>（此时<span class="math inline">\(M\)</span>称为<strong>完全集</strong>）</li></ol><p><strong>NOTE</strong>：该定理简化了弱收敛的判断条件，只需要在 <spanclass="math inline">\(X&#39;\)</span>的一个子集上判断函数值是否收敛。</p></blockquote><p>证明：<spanclass="math inline">\(&quot;\Longrightarrow&quot;\)</span> 易证；</p><p><spanclass="math inline">\(&quot;\Longleftarrow&quot;\)</span>，首先考虑<span class="math inline">\(\forall f\in \text{span}M\)</span>，容易得到<span class="math inline">\(f(x_n)\to f(x)\)</span>。然后对 <spanclass="math inline">\(\forall g\in X&#39;\)</span>，那么存在 <spanclass="math inline">\(f_m\in\text{span}M\)</span> 使得 <spanclass="math inline">\(\Vert f_m-g\Vert \le 1/m\)</span>，因此 <spanclass="math display">\[\begin{align}|g(x_n)-g(x)|&amp;\le |g(x_n)-f_m(x_n)|+|f_m(x_n)-f_m(x)|+|f_m(x)-g(x)|\\&amp;\le \frac{1}{m}(\Vert x_n\Vert+\Vert x\Vert)+|f_m(x_n)-f_m(x)| \to0(m,n\to\infty)\end{align}\]</span> 证毕。</p><p><strong><em>例子 1</em></strong>：考虑 <spanclass="math inline">\(X=\ell^p(1&lt;p&lt;\infty)\)</span>，有 <spanclass="math inline">\((\ell^p)&#39;=\ell^q, 1/p+1/q=1.\)</span>考虑线性泛函 <span class="math inline">\(f_y(x)=\sum_i y_ix_i,y\in\ell^q\)</span>，有 <span class="math inline">\(\Vert f_y\Vert=\Verty\Vert_q\)</span>。我们考虑 <span class="math inline">\(X&#39;\)</span>的子空间 <span class="math inline">\(M=\{e_n,n\ge1\}\)</span>，其中<span class="math inline">\(e_n=(...,0,1,0,...)\)</span> 表示只有第<span class="math inline">\(n\)</span> 个分量为 1，其余为 0。那么 <spanclass="math inline">\(\overline{\text{span}M}=X&#39;\)</span>，因此要想验证<span class="math inline">\(x_n\)</span> 是否弱收敛到 <spanclass="math inline">\(x\)</span> 就只需要验证：1）其有界性；2）对每个<span class="math inline">\(f_{e_k},k\ge1\)</span> 是否有 <spanclass="math inline">\(f_{e_k}(x_n)\tof_{e_k}(x)(n\to\infty).\)</span></p><p>强收敛与弱收敛之间有如下关系：</p><ul><li><span class="math inline">\(x_n\to x \Longrightarrow x_n\stackrel{w}{\longrightarrow} x\)</span>(即强收敛可以导出弱收敛)；</li><li>若 <span class="math inline">\(\text{dim}X&lt;\infty\)</span>，则<span class="math inline">\(x_n \stackrel{w}{\longrightarrow}x\Longrightarrow x_n\tox\)</span>(<strong>有限维</strong>赋范空间中，强收敛与弱收敛等价)；</li></ul><p>证明：仅证第二条。设 <spanclass="math inline">\(\text{dim}X=n&lt;\infty\)</span>，有限维赋范空间中我们可以找到一组基，<spanclass="math inline">\(x_k=\lambda_{k,1}e_1+\cdots+\lambda_{k,n}e_n\)</span>，<spanclass="math inline">\(x=\lambda_1 e_1+\cdots+\lambda_ne_n\)</span>。那么 <span class="math display">\[\lambda_{k,1}f(e_1)+\cdots+\lambda_{k,n}f(e_n) \to\lambda_{1}f(e_1)+\cdots+\lambda_{n}f(e_n), \quad\forall f\in X&#39;\]</span> 由于 <span class="math inline">\(f\in X&#39;\)</span>任取，那么我们可以取 <spanclass="math inline">\(f_i(y)=\mu_i\)</span>，其中 <spanclass="math inline">\(y=\mu_1 e_1+\cdots+\mu_n e_n\)</span>，即 <spanclass="math inline">\(f_i\)</span> 取出来第 <spanclass="math inline">\(i\)</span> 个坐标系数。由此可以得到 <spanclass="math inline">\(\lambda_{k,i}\to\lambda_i(k\to\infty)\)</span>，然后就容易得到<span class="math inline">\(x_n\to x.\)</span> 证毕。</p><p><strong><em>例子 2</em></strong>：有些无穷维空间中也可以得到 <spanclass="math inline">\(x_n \stackrel{w}{\longrightarrow} x\iff x_n\tox\)</span>，例如 <span class="math inline">\(\ell^1.\)</span></p><p><strong><em>例子 3</em></strong>：无穷维 Hilbert 空间（<spanclass="math inline">\(\ell^2\)</span>，注意只有 <spanclass="math inline">\(2-\)</span>范数才能定义出对应的内积），考虑 <spanclass="math inline">\(\{e_1,e_2,\ldots\}\)</span> 为 <spanclass="math inline">\(H\)</span> 的标准正交集，那么有 <spanclass="math inline">\(e_n \stackrel{w}{\longrightarrow} 0\)</span> 但是<span class="math inline">\(e_n \nrightarrow 0\)</span>。考虑 <spanclass="math inline">\(\forall f\in H&#39;\)</span>，存在唯一的 <spanclass="math inline">\(z_0\in H, f(x)=\langlex,z_0\rangle\)</span>，由Bessel方程 <spanclass="math inline">\(\sum_n|\langle e_n,z_0\rangle|^2\le \Vertz_0\Vert^2\)</span>，因此 <span class="math inline">\(f(e_n)\to 0(n\to\infty),\forall f\in H&#39;\)</span>，但另一方面 <spanclass="math inline">\(\Vert e_n\Vert=1\nrightarrow0\)</span>。</p><h2 id="线性泛函收敛性">2. 线性泛函收敛性</h2><p>对于算子的收敛性，如线性泛函 <span class="math inline">\(f_n\inX&#39;\)</span> 或者有界线性算子 <span class="math inline">\(T\inB(X,Y)\)</span>，收敛性的定义跟上面序列的收敛性是相似的，但是又略有不同。下面就先给出线性泛函收敛性的分析。</p><p>同样考虑赋范空间 <span class="math inline">\(X\)</span>，<spanclass="math inline">\(f,f_n\in X&#39;\)</span>，称 <spanclass="math inline">\(f_n\)</span> <strong>弱星收敛</strong>到 <spanclass="math inline">\(f\)</span>，若任取 <spanclass="math inline">\(x\in X\)</span> 都有 <spanclass="math inline">\(f_n(x)\to f(x)\)</span>，记为 <spanclass="math inline">\(f_n \stackrel{w\star}{\longrightarrow}f.\)</span></p><p><strong>NOTE</strong>：实际上这里的弱星收敛跟序列的弱收敛是完全对称的，因此他们的性质也是类似的。</p><ul><li>弱星收敛极限 <span class="math inline">\(f\)</span> 唯一；</li><li><span class="math inline">\(\{f_n\}\)</span> 的任意子列均弱星收敛到<span class="math inline">\(f\)</span>；</li><li>若 <span class="math inline">\(X\)</span> 为 Banach 空间，则 <spanclass="math inline">\(\{f_n\}\)</span> 在 <spanclass="math inline">\(X&#39;\)</span> 中为<strong>有界集</strong>。</li></ul><p>证明：仅证第三条，对于任意 <span class="math inline">\(x\inX\)</span>，有 <span class="math inline">\(f_n(x)\to f(x)\)</span>，因此<span class="math inline">\(f_n(x)\)</span>有界，由一致有界性原理，<span class="math inline">\(\sup_n \Vertf_n\Vert&lt;\infty.\)</span> 证毕。</p><blockquote><p><strong>定理</strong>：<span class="math inline">\(X\)</span> 为<strong>Banach 空间</strong>，<span class="math inline">\(f_n,f\inX&#39;\)</span>，则 <span class="math inline">\(f_n\stackrel{w\star}{\longrightarrow} f\)</span><strong>当且仅当</strong>：</p><ol type="1"><li>存在 <span class="math inline">\(c\ge0,\Vert f_n\Vert\lec\)</span>；</li><li>并且存在 <span class="math inline">\(M\subsetX,\overline{\text{span}M}=X\)</span>，对 <spanclass="math inline">\(\forall x\in M, f_n(x)\to f(x).\)</span></li></ol><p><strong>NOTE</strong>：该性质与序列弱收敛的性质完全对称，证明省略。</p></blockquote><blockquote><p><strong>NOTE</strong>：对于 <spanclass="math inline">\(X&#39;\)</span> 中的线性算子 <spanclass="math inline">\(f\)</span>，也有范数的定义，因此我们也可以按照序列的收敛性来定义算子的收敛性。这个时候就用<span class="math inline">\(X&#39;\)</span> 代替上面的 <spanclass="math inline">\(X\)</span>，用 <spanclass="math inline">\(X&#39;&#39;\)</span> 代替上面的 <spanclass="math inline">\(X&#39;\)</span>。我们可以得到什么样的强收敛和弱收敛定义呢？（下面并不是标准的数学定义，只是我为了引出之后的内容做的解释）</p><p>对于 <span class="math inline">\(f,f_n\in X&#39;\)</span>，若满足<span class="math inline">\(\Vert f_n-f\Vert\to 0\)</span>，则称 <spanclass="math inline">\(f_n\)</span> <strong>一致收敛</strong>到 <spanclass="math inline">\(f\)</span>；若对 <spanclass="math inline">\(\forall g\in X&#39;&#39;\)</span>，都有 <spanclass="math inline">\(g(f_n)\to g(f)\)</span>，那么称 <spanclass="math inline">\(f_n\)</span> <strong>强收敛</strong>到 <spanclass="math inline">\(f\)</span>；弱收敛的定义暂且不管。</p><p>注意从这个定义的字面意思来看，这里的一致收敛对应于上面序列的强收敛；这里的强收敛对应上面序列的弱收敛，它实际上也就对应于弱星收敛。这里就有两个值得思考的问题：1）<strong>一致收敛和强收敛的区别是什么？</strong>2）这里的强收敛为什么对应上面的弱收敛？</p><p>先看第2个问题：讲 Hahn-Banach 定理应用的时候我们讲到了典范映射，如果<span class="math inline">\(X\)</span> 为自反的，那么任意一个 <spanclass="math inline">\(g_0\in X&#39;&#39;\)</span> 都唯一的对应于 <spanclass="math inline">\(X\)</span> 中的元素 <spanclass="math inline">\(x_0\)</span>，并且满足 <spanclass="math inline">\(g_0(f)=f(x_0),\forall f\in X&#39;\)</span>。假设<span class="math inline">\(X\)</span>是自反的，那么上面的强收敛定义就可以表述为 <spanclass="math inline">\(\forall x\in X\)</span>，都有 <spanclass="math inline">\(f_n(x)\tof(x)\)</span>，注意看！这是不是就是线性泛函弱星收敛的定义！也对应了序列的弱收敛。不过弱星收敛的定义里面并没有要求<span class="math inline">\(X\)</span> 是自反的。</p><p>那么再看第1个问题：一致收敛中要求 <span class="math inline">\(\Vertf_n-f\Vert\to0\)</span>，线性算子的范数是针对整个源空间考虑的；而强收敛中对每个<span class="math inline">\(x\in X\)</span>，关注 <spanclass="math inline">\(f_n(x)\tof(x)\)</span>，也就是说关注的是每一个局部点。因此一致收敛要强于强收敛。</p></blockquote><h2 id="一般有界线性算子收敛性">3. 一般有界线性算子收敛性</h2><p>实际上一致收敛、强收敛、弱收敛的概念可以扩展到任意的有界线性算子定义。</p><p>设 <span class="math inline">\(X,Y\)</span> 为赋范空间，<spanclass="math inline">\(T_n\in B(X,Y),T:X\to Y\)</span>为线性算子，有三种收敛性：</p><ul><li><span class="math inline">\(\{T_n\}\)</span><strong>一致收敛</strong>到 <span class="math inline">\(T\)</span>，若<span class="math inline">\(\Vert T_n-T\Vert \to 0\)</span>；</li><li><span class="math inline">\(\{T_n\}\)</span><strong>强收敛</strong>到 <span class="math inline">\(T\)</span>，若<span class="math inline">\(\forall x\in X,T_n x\to Tx\)</span>；</li><li><span class="math inline">\(\{T_n\}\)</span><strong>弱收敛</strong>到 <span class="math inline">\(T\)</span>，若任取<span class="math inline">\(x\in X, f\in Y&#39;\)</span>，<spanclass="math inline">\(f(T_nx)\to f(Tx)\)</span>。</li></ul><p>容易看出来一致收敛 <spanclass="math inline">\(\Longrightarrow\)</span> 强收敛 <spanclass="math inline">\(\Longrightarrow\)</span>弱收敛，但是反向则不成立，可以举出对应的反例。</p><p><strong><em>例子 4</em></strong>(强收敛 <spanclass="math inline">\(\nRightarrow\)</span> 一致收敛)：<spanclass="math inline">\(X=Y=\ell^2\)</span>，<spanclass="math inline">\(T_n:\ell^2\to\ell^2\)</span> 有 <spanclass="math display">\[T_n: (x_1,x_2,\cdots) \mapsto (0,\cdots,0,x_{n+1},x_{n+2},\cdots)\]</span> 容易验证 <span class="math inline">\(T_n\)</span>为有界线性算子，<span class="math inline">\(\VertT_n\Vert=1\)</span>。可以验证 <span class="math inline">\(T_n\)</span>强收敛到 <span class="math inline">\(0\)</span> 算子，即 <spanclass="math inline">\(T_0x\equiv 0\)</span>。但是 <spanclass="math inline">\(\Vert T_n-T_0\Vert=1\nrightarrow0\)</span>，即不满足一致收敛。</p><p><strong><em>例子 5</em></strong>(弱收敛 <spanclass="math inline">\(\nRightarrow\)</span> 强收敛)：<spanclass="math inline">\(X=Y=\ell^2\)</span>，<spanclass="math inline">\(T_n:\ell^2\to\ell^2\)</span> 有 <spanclass="math display">\[T_n:(x_1,x_2,\cdots)\mapsto(0_1,\cdots,0_n,x_1,x_2,\cdots)\]</span> 可以验证 <span class="math inline">\(T_n\)</span>为有界线性算子，并且 <span class="math inline">\(\VertT_n\Vert=1\)</span>。是否有 <span class="math inline">\(T_n\)</span>弱收敛到某个 <span class="math inline">\(T\)</span> 呢？考虑任意 <spanclass="math inline">\(f\in(\ell^2)&#39;\)</span>，都存在唯一的 <spanclass="math inline">\(z\in\ell^2\)</span>，<spanclass="math inline">\(f(x)=\langle x,z\rangle\)</span>，所以 <spanclass="math inline">\(f(T_nx)=x_1\overline{z_{n+1}}+x_2\overline{z_{n+2}}+\cdots\)</span>，因此<span class="math display">\[|f(T_nx)|\le\sum_{k=1}^\infty |x_k|\cdot|z_{n+k}| \le \Vertx\Vert\left(\sum_{k=n+1}^\infty |z_k|^2\right)^{1/2} \to 0\]</span> 所以有 <span class="math inline">\(f(T_nx) \to 0\)</span>对任意 <span class="math inline">\(f\in (\ell^2)&#39;\)</span>成立，因此 <span class="math inline">\(f(T_nx)\to f(T_0x)\equivf(0)=0\)</span>。所以 <span class="math inline">\(T_n\)</span> 弱收敛到<span class="math inline">\(T_0=0\)</span> 算子，但是总有 <spanclass="math inline">\(\Vert T_nx\Vert=\Vert x\Vert\nrightarrow0\)</span>，因此 <span class="math inline">\(T_nx\nrightarrowT_0x\)</span>，即不满足强收敛。</p><p><strong>命题</strong>：对于一般有界线性算子，若 <spanclass="math inline">\(T_n\)</span> <strong>一致收敛</strong>到 <spanclass="math inline">\(T\)</span>，则 <spanclass="math inline">\(T\)</span> 也是有界的，这是因为 <spanclass="math inline">\(\Vert T\Vert\le \Vert T-T_n\Vert+\Vert T_n\Vert\le \infty\)</span>；若只能得到 <span class="math inline">\(T_n\)</span><strong>强收敛</strong>到 <span class="math inline">\(T\)</span>，那么<span class="math inline">\(T\)</span><strong>不一定是有界</strong>的。</p><p><strong><em>例子 6</em></strong>(强收敛极限未必有界)：<spanclass="math inline">\(X=Y=\{(x_n),\exists N,\forall n\ge N, x_n=0\}\)</span>，考虑 <span class="math inline">\(T_n:X\to Y\)</span> 有<span class="math display">\[\begin{aligned}T_n:&amp; (x_1,x_2,\cdots)\mapsto(x_1,2x_2,\cdots,nx_n,x_{n+1},x_{n+2},\cdots) \\T:&amp; (x_1,x_2,\cdots)\mapsto (x_1,2x_2,\cdots)\end{aligned}\]</span> 那么 <span class="math inline">\(\VertT_n\Vert=n\)</span>，取可以验证对于 <span class="math inline">\(\forallx\in X\)</span>，<span class="math inline">\(T_nx\to Tx\)</span>，即<span class="math inline">\(T_n\)</span> 强收敛到 <spanclass="math inline">\(T\)</span>，但是 <spanclass="math inline">\(T\)</span> 不是有界算子。</p><p>那么什么情况下可以保证强/弱收敛极限也是有界算子呢？</p><blockquote><p><strong>定理</strong>：设 <span class="math inline">\(X\)</span> 为<strong>Banach 空间</strong>，<span class="math inline">\(Y\)</span>为赋范空间，<span class="math inline">\(T_n\in B(X,Y),T:X\to Y\)</span>为线性算子。设 <span class="math inline">\(T_n\)</span><strong>弱收敛</strong>到 <span class="math inline">\(T\)</span>，则<span class="math inline">\(\sup_{n\ge1}\Vert T_n\Vert &lt; \infty, T\inB(X,Y)\)</span> 并且 <span class="math inline">\(\Vert T\Vert \le\sup_{n\ge1}\Vert T_n\Vert &lt;\infty.\)</span></p></blockquote><p><strong>证明</strong>：由于 <span class="math inline">\(T_n\)</span>弱收敛到 <span class="math inline">\(T\)</span>，即 <spanclass="math inline">\(\forall x\in X,f\in Y&#39;\)</span> 都有 <spanclass="math inline">\(f(T_nx)\to f(Tx)\)</span>，因此有 <spanclass="math inline">\(T_nx \stackrel{w}{\longrightarrow}Tx\)</span>。那么根据序列弱收敛的性质，存在 <spanclass="math inline">\(c_x\)</span> 满足 <spanclass="math inline">\(\sup_n \Vert T_nx\Vert \lec_x\)</span>，再由一致有界性原理，有 <span class="math inline">\(\sup_n\Vert T_n\Vert &lt; \infty\)</span>。</p><p>然后考虑 <span class="math inline">\(T\)</span>，<spanclass="math inline">\(\forall x\in X\)</span>，由 Hahn-Banach定理的推论，都存在 <span class="math inline">\(f\in Y&#39;,\Vertf\Vert=1\)</span> 满足 <span class="math display">\[\Vert Tx\Vert=|f(Tx)| = \lim_{n\to\infty} |f(T_nx)| \le\lim_{n\to\infty}\Vert T_nx\Vert\]</span> 因此 <span class="math inline">\(\Vert T\Vert\le \sup_n\VertT_n\Vert.\)</span> 证毕。</p><blockquote><p><strong>定理</strong>：设 <span class="math inline">\(X\)</span> 为<strong>Banach 空间</strong>，<span class="math inline">\(Y\)</span>为赋范空间，<span class="math inline">\(T_n,T\in B(X,Y)\)</span>，则<span class="math inline">\(T_n\)</span> <strong>强收敛</strong>到 <spanclass="math inline">\(T\)</span> <strong>当且仅当</strong>：</p><ol type="1"><li><span class="math inline">\(\sup_n \Vert T_n\Vert &lt;\infty\)</span>；</li><li>存在 <span class="math inline">\(M\subsetX,\overline{\text{span}M}=X\)</span>，对 <spanclass="math inline">\(\forall x\in M, T_n(x)\to T(x).\)</span></li></ol><p><strong>NOTE</strong>：这跟线性泛函弱星收敛的等价条件是完全一样的，证明省略。</p></blockquote><h2 id="应用举例">4. 应用举例</h2><p><strong><em>例子 7</em></strong>(求积分的数值方法)：考虑实值函数<span class="math inline">\(x\in C[a,b]\)</span>，并赋予无穷范数，那么<span class="math inline">\((C[a,b],\Vert\cdot\Vert)\)</span> 为 Banach空间，求 <span class="math inline">\(\int_a^b x(t)dt.\)</span></p><p>既然是在本节举的这个例子，那就要用到算子收敛性。先定义有界线性算子<span class="math inline">\(f(x)=\int_a^b x(t)dt\)</span>，<spanclass="math inline">\(\Vertf\Vert=b-a\)</span>。我们现在的目标就是找一列有界线性泛函 <spanclass="math inline">\(f_n\)</span> 弱收敛到 <spanclass="math inline">\(f\)</span>。回忆我们在学微积分的时候，往往是用分段的矩形面积求和来逼近积分。在<span class="math inline">\([a,b]\)</span> 上取 <spanclass="math inline">\(n+1\)</span> 个结点 <spanclass="math inline">\(a=t_{n,0}&lt;t_{n,1}&lt;\cdots&lt;t_{n,n}=b\)</span>，再取<span class="math inline">\(n+1\)</span> 个实数 <spanclass="math inline">\(a_{n,0},\cdots,a_{n,n}\)</span>，令 <spanclass="math display">\[f_n(x) = \sum_{k=0}^n a_{n,k} x(t_{n,k})\]</span> <span class="math inline">\(f_n\)</span> 是 <spanclass="math inline">\(C[a,b]\)</span> 上的线性泛函，并且 <spanclass="math inline">\(\Vert f_n\Vert \le\sum_{k=0}^n|a_{n,k}|\)</span>，另外我们总能够造出一个 <spanclass="math inline">\(x\in C[a,b]\)</span> 满足 <spanclass="math inline">\(x(t_{n,k})=\text{sgn}(a_{n,k})\)</span> 并且 <spanclass="math inline">\(\Vert x\Vert_\infty=1\)</span>，此时就有 <spanclass="math inline">\(f(x)=\sum_{k=0}^n|a_{n,k}|\)</span>，于是可以得到<span class="math inline">\(\Vert f_n\Vert =\sum_{k=0}^n|a_{n,k}|\)</span>。现在的问题就是我们能否找到合适的系数<span class="math inline">\(a_{n,k}\)</span> 使得 <spanclass="math inline">\(f_n\stackrel{w}{\longrightarrow} f\)</span> ？</p><p>这里我们提出一个额外的要求，就是对于次数小于 <spanclass="math inline">\(n\)</span> 的多项式 <spanclass="math inline">\(p\)</span>，需要 <spanclass="math inline">\(f_n(p)\)</span> 能获得精确积分结果，即 <spanclass="math inline">\(f_n(p)=\int_a^b p(t)dt\)</span>。由于 <spanclass="math inline">\(\{1,t,\ldots,t^n\}\)</span> 构成次数小于 <spanclass="math inline">\(n\)</span> 的多项式空间的 Hamel基，所以只需要验证对每个基有 <span class="math inline">\(f_n(e_k)=f(e_k)\)</span> 即可。这就要求 <span class="math display">\[\begin{cases}\begin{matrix}a_{n,0} &amp; + &amp; a_{n,1} &amp; + &amp; \cdots &amp; + &amp; a_{n,n}&amp; = &amp; b-a \\a_{n,0}t_{n,0} &amp; + &amp; a_{n,1}t_{n,1} &amp; + &amp; \cdots &amp; +&amp; a_{n,n}t_{n,n} &amp; = &amp; \frac{b^2-a^2}{2} \\&amp; &amp; &amp; &amp; \ldots &amp; \\a_{n,0}t_{n,0}^n &amp; + &amp; a_{n,1}t_{n,1}^n &amp; + &amp; \cdots&amp; + &amp; a_{n,n}t_{n,n}^n &amp; = &amp; \frac{b^{n+1}-a^{n+1}}{n+1}\end{matrix}\end{cases}\]</span> 上式左侧可以用 Vandermonde 矩阵表示，因此存在唯一解 <spanclass="math inline">\(a_{n,k},k=1,...,n\)</span>。</p><p>接下来对于任意的 <span class="math inline">\(x\inC[a,b]\)</span>，能否找到 <span class="math inline">\(a_{n,k}\)</span>满足的条件使得 <span class="math inline">\(f_n(x)\to f(x)\)</span>呢？根据 Stone-Weierstrass 定理，多项式的集合在 <spanclass="math inline">\(C[a,b]\)</span>中是<strong>稠密的</strong>，因此对于任意次数 <spanclass="math inline">\(N\)</span> 的多项式 <spanclass="math inline">\(p\)</span> 总有 <spanclass="math inline">\(f_n(p)\tof(p)\)</span>。那么再应用前面的定理（即只需要判断完全集 <spanclass="math inline">\(M\subset X\)</span>中的元素是否满足条件即可），可以有如下结论</p><p><strong>定理(G.Polya)</strong>：设数值积分 <spanclass="math inline">\(f_n\)</span> 满足前面对于有限次多项式的要求（即<span class="math inline">\(a_{n,k}\)</span> 为 Vandermonde矩阵方程的解）则任取 <span class="math inline">\(x\in C[a,b],f_n(x)\tof(x)\)</span> 当且仅当存在常数 <spanclass="math inline">\(C\ge0\)</span>，使得任取 <spanclass="math inline">\(n\ge1\)</span>，有 <spanclass="math inline">\(\sum_{k=1}^na_{n,k}\le C.\)</span></p>]]></content>
    
    
    <categories>
      
      <category>Functional Analysis</category>
      
    </categories>
    
    
    <tags>
      
      <tag>强收敛</tag>
      
      <tag>弱收敛</tag>
      
      <tag>弱星收敛</tag>
      
      <tag>一致收敛</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>泛函分析笔记6：一致有界性原理</title>
    <link href="/2020/12/26/functional-analysis/ch4-3-banach-steinhauss/"/>
    <url>/2020/12/26/functional-analysis/ch4-3-banach-steinhauss/</url>
    
    <content type="html"><![CDATA[<p>Hahn-Banach定理主要是用于泛函的延拓，在较小的子空间上满足某个性质之后我们就可以将对应的泛函延拓至整个空间。而这一节要讲的一致有界性原理恰如其名，主要讨论一族有界线性算子一致有界的条件。他也是后续讨论序列弱收敛性以及泛函弱星收敛性的基础。</p><h2 id="baire范畴定理">1. Baire范畴定理</h2><p>一致有界性原理的证明需要用到Baire范畴定理（也叫Baire纲定理）。</p><p><span class="math inline">\((X,d)\)</span>，若 <spanclass="math inline">\(\bar{M}\subset X\)</span> 没有内点，则称 <spanclass="math inline">\(M\)</span> 是<strong>无处稠密</strong>的。若 <spanclass="math inline">\(N=\cup^\infty_n N_n\)</span>，<spanclass="math inline">\(N_n\)</span> 均为无处稠密的，则称 <spanclass="math inline">\(N\)</span>为<strong>第一范畴</strong>。不为第一范畴的子集称为<strong>第二范畴</strong>。</p><span id="more"></span><p><em>例子 1</em>：<spanclass="math inline">\(X=\mathbb{R},d(s,t)=|s-t|\)</span>，任意有限集均为无处稠密的，因此可数集均为第一范畴。</p><blockquote><p><strong>定理(范畴定理)</strong>：<spanclass="math inline">\((X,d)\)</span> 为<strong>非空完备</strong>的，则<span class="math inline">\(X\)</span>必为<strong>第二范畴</strong>的。</p></blockquote><p><strong>证明</strong>：第二范畴意味着 <spanclass="math inline">\(X\)</span>不能表示为可数个没有内点的集合的并集。假设 <spanclass="math inline">\(X\)</span> 属于第一范畴，即 <spanclass="math inline">\(X=\cup_n M_n\)</span>，并且不妨设 <spanclass="math inline">\(M_n\)</span> 均为闭集（否则可以取 <spanclass="math inline">\(X=\cup_n \bar{M}_n\)</span>），并且 <spanclass="math inline">\(M_n\)</span> 都没有内点。</p><p>首先考虑 <span class="math inline">\(Y_1=M_1^c\)</span>为开集，因此存在某个 <span class="math inline">\(x_1\inY_1,r_1\in(0,1/2)\)</span> 使得 <spanclass="math inline">\(B(x_1,r_1)\subset Y_1\)</span>。由于 <spanclass="math inline">\(M_2\)</span> 也没有内点并且为闭集，因此 <spanclass="math inline">\(Y_2=B(x_1,r_1) \cap M_2^c \ne \varnothing\)</span>也为开集，因此可以找到某个 <span class="math inline">\(x_2\inY_2,r_2\in(0,r_1/2)\)</span> 使得 <spanclass="math inline">\(B(x_2,r_2)\subset Y_2\)</span>。依此类推，可以找到<span class="math inline">\(B(x_1,r_1) \supset \cdots \supsetB(x_n,r_n)\supset \cdots\)</span>，并且有 <spanclass="math inline">\(r_n\in (0,1/2^n)\)</span>。容易验证 <spanclass="math inline">\(\{x_n\}\)</span> 为柯西列，因此存在收敛值 <spanclass="math inline">\(x_n\to x,x\in X\)</span>。对于 <spanclass="math inline">\(k\ge1\)</span> 考虑 <spanclass="math inline">\(x_{n+k},x\in \bar{B}(x_n,r_n/2)\subsetB(x_n,r_n)\)</span>，于是有 <span class="math inline">\(x\inB(x_n,r_n),\forall n\ge1\)</span>，因此就有 <spanclass="math inline">\(x\notin M_n,\forall n\ge1\)</span>，因此 <spanclass="math inline">\(x\notin X\)</span>，导出矛盾。证毕。</p><h2 id="一致有界性原理">2. 一致有界性原理</h2><blockquote><p><strong>一致有界性原理</strong>：假设 <spanclass="math inline">\(X\)</span> 为 <strong>Banach 空间</strong>，<spanclass="math inline">\(Y\)</span> 为赋范空间，<spanclass="math inline">\(T_i\in B(X,Y),\forall i\in\mathcal{I}\)</span>，并且对任取 <span class="math inline">\(x\inX\)</span> 有 <span class="math display">\[\sup_{i\in\mathcal{I}} \Vert T_ix\Vert &lt; \infty\]</span> 则 <span class="math inline">\(\sup_{i\in\mathcal{I}}\VertT_i\Vert&lt;\infty.\)</span></p><p><strong>NOTE</strong>：条件当中针对的是固定任意一个 <spanclass="math inline">\(x\in X\)</span>，<span class="math inline">\(T_ix\)</span> 有界，也即是说所有的 <spanclass="math inline">\(T_ix,i\in\mathcal{I}\)</span> 存在一个上界 <spanclass="math inline">\(c_x\)</span>，该上界与 <spanclass="math inline">\(x\)</span> 有关。对于线性泛函，我们只需要考虑<span class="math inline">\(\Vert x\Vert=1\)</span>的情况，但即便如此，一般而言由该条件并不能推导出对于所有的 <spanclass="math inline">\(\Vert x\Vert, c_x\)</span>存在一个共同的上界，因为随着 <span class="math inline">\(x\)</span>的变化 <span class="math inline">\(c_x\)</span>有可能趋于无穷。而一致有界性原理则说明当 <spanclass="math inline">\(X\)</span> 为 Banach空间的时候，一定存在这样一个上界，从而说明 <spanclass="math inline">\(\Vert T_i\Vert\)</span> 有上确界。</p></blockquote><p><strong>证明</strong>：根据上面的分析，我们在寻找 <spanclass="math inline">\(\sup_i\Vert T_i\Vert\)</span> 的时候不能局限在<span class="math inline">\(\Vert x\Vert=1\)</span>的情况，下面的证明方法很巧妙。</p><p>首先考虑 <span class="math inline">\(X\)</span> 完备，根据 Baire范畴定理，不能表示为可数个没有内点的集合的并集。那么假如我们将其表示为可数个集合的并集，则一定存在某个集合有内点。因此考虑<span class="math inline">\(M_n=\{x\in X, \sup_i\Vert T_ix\Vert \len\}\)</span>，因此就有 <span class="math inline">\(X=\cup_n^\inftyM_n\)</span>，一定存在某个 <span class="math inline">\(N\ge1\)</span>使得 <span class="math inline">\(M_N\)</span> 有内点，此时找到 <spanclass="math inline">\(x_0\in M_N,r&gt;0\)</span> 使得 <spanclass="math inline">\(\bar{B}(x_0,r)\subset M_N\)</span>，并且 <spanclass="math inline">\(\forall y\in X,\Vert y\Vert=1\)</span>，都有 <spanclass="math display">\[\Vert T_i(x_0)\Vert \le N,\ \Vert T_i(x_0+ry)\Vert \le N,\quad \foralli\in\mathcal{I},\Vert y\Vert=1 \\\Longrightarrow \Vert T_iy\Vert \le 2N/r, \quad \foralli\in\mathcal{I},\Vert y\Vert=1 \\\Longrightarrow \sup_{i\in\mathcal{I}}\Vert T_i\Vert \le 2N/r\]</span> 证毕。</p><blockquote><p><strong>共鸣定理</strong>：假设 <spanclass="math inline">\(X\)</span> 为 <strong>Banach 空间</strong>，<spanclass="math inline">\(Y\)</span> 为赋范空间，<spanclass="math inline">\(T_i\in B(X,Y),\forall i\in\mathcal{I}\)</span>，设 <span class="math inline">\(\sup_i\VertT_i\Vert = \infty\)</span>，则 <span class="math inline">\(\exists x\inX\)</span> 使得 <span class="math inline">\(\sup_{i} \Vert T_i x\Vert=\infty\)</span>，其中 <span class="math inline">\(x\)</span> 即为 <spanclass="math inline">\(T_i\)</span> 的共鸣点。</p><p><strong>NOTE</strong>：实际上共鸣定理就是一致有界性原理的逆反命题。</p></blockquote><h2 id="应用举例">3. 应用举例</h2><p>一致有界性原理的 Banach空间假设是必不可少的，下面的例子将进行解释。</p><p><strong><em>例子 2</em></strong>：<spanclass="math inline">\(X\)</span> 为所有的多项式，即 <spanclass="math inline">\(p\in X\)</span> 可以表示为 <spanclass="math inline">\(p(t)=a_0+a_1 t+\cdots a_N t^N\)</span>，定义 <spanclass="math inline">\(\Vert p\Vert =\max_{0\le i\leN}|a_i|\)</span>。取一列线性泛函 <spanclass="math inline">\(f_n(p)=a_0+a_1+\cdots a_n\)</span>，那么可以验证<span class="math inline">\(f_n\in X&#39;\)</span> 并且有 <spanclass="math inline">\(\Vert f_n\Vert=n+1\)</span>。</p><p>此时显然我们有对任意固定的 <span class="math inline">\(p=a_0+a_1t+\cdots a_N t^N\in X\)</span>，<span class="math inline">\(\Vertf_n(p)\Vert \le |a_0|+\cdots+|a_N|\)</span>，但是同时我们也有 <spanclass="math inline">\(\sup_n \Vertf_n\Vert=\infty\)</span>，这似乎与一致有界性原理矛盾？其实原因是 <spanclass="math inline">\(X\)</span> 并不是 Banach 空间。</p><p>考虑 <spanclass="math inline">\(p_n(t)=1+\frac{1}{2}t+\cdots+\frac{1}{n+1}t^n\)</span>，那么可以验证<span class="math inline">\(\{p_n\}\)</span>为柯西列，但是其收敛值却并不在 <span class="math inline">\(X\)</span>内部（<span class="math inline">\(X\)</span>中只包含有限项的多项式），因此 <span class="math inline">\(X\)</span>不完备。</p><p>一致有界性原理还可用于讨论 Fourier 级数的收敛问题。</p><p><strong><em>例子 3</em></strong>：考虑 <spanclass="math inline">\(t\in[0,2\pi]\)</span>，对于 <spanclass="math inline">\([0,2\pi]\)</span> 上的周期函数，很多时候我们用Fourier 级数来表示他们，即 <span class="math display">\[\begin{aligned}a_0(x) &amp;= \frac{1}{2\pi}\int_0^{2\pi} x(t)dt \\a_m(x) &amp;= \frac{1}{\pi}\int_a^{2\pi} x(t)\cos(mt)dt, m\ge1 \\b_m(x) &amp;= \frac{1}{\pi}\int_a^{2\pi} x(t)\sin(mt)dt, m\ge1\end{aligned}\]</span> <span class="math inline">\(x_n(t)=a_0+\sum_{m=1}^n\left(a_m\cos mt+b_m\sin mt\right)\)</span> 即为 Fourier 级数。但是一个问题就是Fourier 级数是否点点收敛到 <spanclass="math inline">\(x\)</span>？答案是否定的，可以用一致有界性原理证明。</p><p>证明：考虑 <spanclass="math inline">\(f_n(x)=x_n(0)=a_0(x)+\sum_{m=1}^na_m(x)\)</span>，显然 <span class="math inline">\(f_n(x)\)</span> 为<spanclass="math inline">\(C_{per}[0,2\pi]\)</span>（连续周期函数）上的线性泛函。并且有<span class="math display">\[\begin{aligned}f_n(x)&amp;=\frac{1}{2\pi}\int_0^{2\pi} \left(1+2\sum_{m=1}^n \cos(mt)\right)x(t)dt \\&amp;= \frac{1}{2\pi}\int_0^{2\pi} \frac{\sin(n+1/2)t}{\sin(t/2)}x(t)dt=\frac{1}{2\pi}\int_0^{2\pi} Q_n(t)x(t)dt \\\end{aligned}\]</span> 因此 <span class="math inline">\(\Vert f_n\Vert \le\int_0^{2\pi} |Q_n(t)|dt\)</span>。由于 <spanclass="math inline">\(Q_n(t)\)</span> 在 <spanclass="math inline">\([0,2\pi]\)</span>上只有有限个零点，因此可以构造合适的 <spanclass="math inline">\(x\)</span> 证明 <span class="math inline">\(\Vertf_n=\Vert \ge \frac{1}{2\pi}\int_0^{2\pi} |Q_n(t)|dt\)</span>。而 <spanclass="math display">\[\begin{aligned}\int_0^{2\pi} |Q_n(t)|dt &amp;\ge 2\int_0^{(2n+1)\pi} \frac{|\sint|}{t}dt \ge2\sum_{k=0}^{2n}\int_{k\pi}^{(k+1)\pi} \frac{|\sin t|}{t}dt\\&amp;\ge \sqrt{2} \sum_{k=0}^{2n}\int_{k\pi+\pi/4}^{k\pi+3\pi/4}\frac{1}{t}dt \\&amp;\ge \sum_{k=0}^{2n} \frac{4\sqrt{2}}{8k+3}\end{aligned}\]</span> 因此有 <span class="math inline">\(\sup_{n\ge1}\Vertf_n\Vert=\infty\)</span>，由一致有界性原理，存在 <spanclass="math inline">\(x_0\in C_{per}[0,2\pi]\)</span> 使得 <spanclass="math inline">\(\sup_{n\ge1} |f_n(x_0)|=\infty\)</span>，因此<span class="math inline">\(x_0\)</span> 的 Fourier 级数在 <spanclass="math inline">\(t=0\)</span> 处不收敛。证毕。</p>]]></content>
    
    
    <categories>
      
      <category>Functional Analysis</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Baire范畴定理</tag>
      
      <tag>无处稠密</tag>
      
      <tag>第一范畴、第二范畴</tag>
      
      <tag>一致有界性原理</tag>
      
      <tag>共鸣定理</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>泛函分析笔记5：Hahn-Banach定理的应用</title>
    <link href="/2020/12/26/functional-analysis/ch4-2-application/"/>
    <url>/2020/12/26/functional-analysis/ch4-2-application/</url>
    
    <content type="html"><![CDATA[<h2 id="共轭算子">1. 共轭算子</h2><p>赋范空间 <span class="math inline">\(X,Y\)</span>，<spanclass="math inline">\(T\in B(X,Y)\)</span>，对于任意的 <spanclass="math inline">\(f\in Y&#39;\)</span>，<spanclass="math inline">\(X\stackrel{T}{\longrightarrow}Y\stackrel{f}{\longrightarrow}\mathbb{K}\)</span>，可以得到<span class="math inline">\(f\circ T\inX&#39;\)</span>。因此我们可以定义映射 <span class="math display">\[\begin{aligned}T^{\times}:Y&#39; &amp;\to X&#39; \\f &amp;\mapsto f\circ T\end{aligned}\]</span>称其为<strong>共轭算子</strong>。他有如下性质（容易验证，不再证明）：</p><span id="more"></span><ul><li><span class="math inline">\(T^{\times}\inB(Y&#39;,X&#39;)\)</span></li><li><span class="math inline">\(\Vert T^{\times}\Vert=\VertT\Vert\)</span>（证明过程用到了 Hahn-Banach定理）</li><li><span class="math inline">\((S+T)^{\times}=S^\times + T^\times,\S,T\in B(X,Y)\)</span></li><li><span class="math inline">\((\lambda T)^\times=\lambdaT^\times\)</span></li><li><span class="math inline">\((AB)^\times=B^\times A^\times,\ A\inB(X,Y),B\in B(Y,Z)\)</span></li></ul><p><em>例子 1</em>：设 <span class="math inline">\(X=Y=\mathbb{C}^n,T\inB(\mathbb{C}^n,\mathbb{C}^n)\)</span>，则 <spanclass="math inline">\(\exists!A\)</span> 为 <spanclass="math inline">\(n\)</span> 阶方阵使得 <spanclass="math inline">\(Tx=Ax\)</span>，而 <spanclass="math inline">\(T^\times\inB((\mathbb{C}^n)&#39;,(\mathbb{C}^n)&#39;)\)</span>。实际上 <spanclass="math inline">\(f\in(\mathbb{C}^n)&#39;\)</span> 可以表示为 <spanclass="math inline">\(f(x)=\sum_i^n \alpha_i x_i=\alpha^Tx\)</span>，<span class="math inline">\(T^\times f(x)=\sum_i^n\beta_ix_i=\beta^T x\)</span>。容易验证 <spanclass="math inline">\(\beta=A^T\alpha.\)</span></p><p>在这里，我们可以联想到<strong>伴随算子</strong>，<spanclass="math inline">\(T\in B(H_1,H_2)\)</span>，其伴随算子 <spanclass="math inline">\(T^\star\in B(H_2,H_1)\)</span> 满足 <spanclass="math inline">\(\langle Tx,y\rangle=\langle x,T^\stary\rangle.\)</span> 而这里的共轭算子则是 <spanclass="math inline">\(T^\times\in B(H_2&#39;, H_1&#39;).\)</span></p><p>回忆第二章我们讲等距同构概念的时候，提到了 <spanclass="math inline">\((\mathbb{K}^n,\Vert\cdot\Vert_2)&#39; =(\mathbb{K}^n,\Vert\cdot\Vert_2)\)</span>，也就是说实际上我们可以找到某个映射<span class="math inline">\(A:H&#39;\toH\)</span>。如果能找到这样的一个双射，就可以认为 <spanclass="math inline">\(T^\star\)</span> 与 <spanclass="math inline">\(T^\times\)</span> 是等价的。</p><p>一般的空间未必有如此良好的性质，但对于 <strong>Hilbert空间</strong>来说，任意 <span class="math inline">\(f\in H&#39;\)</span>都可以唯一地表示为 <span class="math inline">\(f(x)=\langle x,z\rangle,z\in H\)</span>，那么我们就可以定义映射 <span class="math display">\[\begin{aligned}A:H&#39; &amp;\to H \\f &amp;\mapsto z\end{aligned}\]</span> 容易证明 <span class="math inline">\(A\)</span>时<strong>共轭线性</strong>的（并且是<strong>双射</strong>），即 <spanclass="math inline">\(A(\lambda f+\mug)=\bar{\lambda}Af+\bar{\mu}Ag\)</span>。</p><p>此时我们可以得到如下图所示的映射关系，可以看到实际上 <spanclass="math inline">\(T^\times = A_1^{-1}T^\star A_2\)</span></p><figure><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2020/ch4-1-conjugate-operator.png"alt="conjugate operator" /><figcaption aria-hidden="true">conjugate operator</figcaption></figure><p><em>例子 2</em>：考虑 Hilbert 空间 <spanclass="math inline">\(H_1,H_2\)</span>，<span class="math inline">\(g\inH_2&#39;\)</span> 可以表示为 <span class="math inline">\(g(y)=\langley,y_0\rangle\)</span>，因此实际上有 <spanclass="math inline">\(A_2g=y_0\in H_2\)</span>，令 <spanclass="math inline">\(f=T^\times g\in H_1&#39;\)</span>，因此可以表示为<span class="math inline">\(f(x)=\langlex,x_0\rangle\)</span>，这可以表示为 <spanclass="math inline">\(A_1f=x_0\in H_1\)</span>，因此有 <spanclass="math inline">\(A_1T^\times g=x_0\)</span>，结合 <spanclass="math inline">\(A_1T^\times = T^\star A_2\)</span> 就有 <spanclass="math inline">\(x_0=T^\star y_0.\)</span></p><h2 id="自反空间">2. 自反空间</h2><p>前面我们研究了 <span class="math inline">\(X\)</span> 与 <spanclass="math inline">\(X&#39;\)</span> 的关系，当 <spanclass="math inline">\(X\)</span> 为 Hilbert空间时二者等距同构。这一小节我们想再研究研究 <spanclass="math inline">\(X\)</span> 与 <spanclass="math inline">\(X&#39;&#39;\)</span>的关系。为什么要研究他们的关系呢？因为不论原始空间 <spanclass="math inline">\(X\)</span> 怎么样，<strong>对偶空间 <spanclass="math inline">\(X&#39;\)</span> 总是 Banach空间</strong>。友情提示，接下来这部分会比较绕。</p><h3 id="典范映射">2.1 典范映射</h3><p>如果想要研究 <span class="math inline">\(X\)</span> 与 <spanclass="math inline">\(X&#39;&#39;\)</span> 的关系，考虑映射 <spanclass="math inline">\(J:X\to X&#39;&#39;\)</span>，那么就需要考虑 <spanclass="math inline">\(J\)</span>是否是等距同构的，或者是否是单射、满射、双射？如何定义 <spanclass="math inline">\(J\)</span> 呢？考虑 <spanclass="math inline">\(J(x)\in X&#39;&#39;\)</span>，记 <spanclass="math inline">\(g_x=J(x): X&#39;\to\mathbb{K}\)</span>，即 <spanclass="math display">\[\begin{aligned}J:X&amp;\to X&#39;&#39; \\x&amp;\mapsto g_x\end{aligned}\]</span> 那么对于任意 <span class="math inline">\(f\inX&#39;\)</span>，定义 <spanclass="math inline">\(g_x(f)=f(x)\in\mathbb{K}\)</span>，因此 <spanclass="math inline">\((J(x))(f)=f(x)\)</span>。其中 <spanclass="math inline">\(x\)</span> 为 <spanclass="math inline">\(J\)</span> 的自变量，<spanclass="math inline">\(J(x)\)</span> 是一个泛函，<spanclass="math inline">\(f\)</span> 为 <spanclass="math inline">\(J(x)\)</span> 的自变量。</p><p>首先来看按照上面的方法给出的 <span class="math inline">\(J\)</span>的定义是否满足 <span class="math inline">\(J:X\to X&#39;&#39;.\)</span>首先来看 <span class="math inline">\(J(x)=g_x\)</span> 是否为 <spanclass="math inline">\(X&#39;\)</span> 上的线性泛函？<spanclass="math inline">\(g_x(\lambda f+\mu h)=\lambda f(x)+\mu h(x)=\lambdag_x(f)+\mu g_x(h)\)</span>，因此 <span class="math inline">\(g_x\in(X&#39;)^\star\)</span>，接下来还需要验证 <spanclass="math inline">\(\Vert g_x\Vert\)</span> 是否是有界的。 <spanclass="math display">\[\Vert g_x\Vert = \sup_{f\in X&#39;}\frac{\Vert g_x(f)\Vert}{\Vertf\Vert} = \sup_{f\in X&#39;}\frac{|f(x)|}{\Vert f\Vert} = \Vert x\Vert\]</span> 因此有 <span class="math inline">\(J(x)=g_x\inX&#39;&#39;,\forall x\in X\)</span>，说明我们定义的 <spanclass="math inline">\(J\)</span> 确实是 <span class="math inline">\(X\toX&#39;&#39;\)</span> 的映射，我们称之为<strong>典范映射</strong>。</p><p>那么这个映射有什么性质呢？<span class="math inline">\(J\)</span>是否为线性映射？<span class="math inline">\(g_{\lambda x+\muy}=J(\lambda x+\mu y)\in X&#39;&#39;\)</span>，对于 <spanclass="math inline">\(\forall f\in X&#39;\)</span>，都有 <spanclass="math display">\[g_{\lambda x+\mu y}(f)=f(\lambda x+\mu y)=\lambda f(x)+\mu g(y)=\lambdag_x(f)+\mu g_y(f) \\\Longrightarrow g_{\lambda x+\mu y} = \lambda g_x+\mu g_y\\\Longrightarrow J(\lambda x+\mu y) = \lambda J(x) + \mu J(y)\]</span> 这说明 <span class="math inline">\(J\)</span> 是线性映射，那么<span class="math inline">\(\Vert J\Vert\)</span>是多少？是否是有界线性映射？ <span class="math display">\[\Vert J\Vert = \sup_{x\in X} \frac{\Vert J(x)\Vert}{\Vert x\Vert},\quad\Vert J(x)\Vert=\Vert x\Vert\]</span> 因此 <span class="math inline">\(\Vert J\Vert =1.\)</span></p><p>由于任意 <span class="math inline">\(x\in X\)</span> 都可以得到 <spanclass="math inline">\(J(x)\in X&#39;&#39;\)</span>，因此 <spanclass="math inline">\(X\)</span> 可以视为 <spanclass="math inline">\(X&#39;&#39;\)</span> 的“赋范子空间”，也就是说<span class="math inline">\(X\)</span> 的势小于 <spanclass="math inline">\(X&#39;&#39;\)</span>。那么是否有 <spanclass="math inline">\(X&#39;&#39;\)</span> 的势就等于 <spanclass="math inline">\(X\)</span> 的势呢？如果二者势相等，由于 <spanclass="math inline">\(J\)</span> 是保范映射，就说明 <spanclass="math inline">\(X\)</span> 与 <spanclass="math inline">\(X&#39;&#39;\)</span>是等距同构的！但是遗憾的是并不是任意赋范空间 <spanclass="math inline">\(X\)</span> 都有这个结论，只有某些条件下，比如Hilbert 空间有这个性质。</p><p>若 <span class="math inline">\(J\)</span> 为满射，则称 <spanclass="math inline">\(X\)</span> 为<strong>自反空间</strong>（意味着<span class="math inline">\(X\)</span> 与 <spanclass="math inline">\(X&#39;&#39;\)</span><strong>等距同构</strong>），这有如下两种等价表示： <spanclass="math display">\[\begin{aligned}\iff&amp; \forall F\in X&#39;&#39;,\quad \exists! x\in X,\quad F=J(x) \\\iff&amp; \forall F\in X&#39;&#39;,\quad \exists! x\in X,\quadF(f)=f(x),\forall f\in X&#39;\end{aligned}\]</span></p><p>如果 <span class="math inline">\(X\)</span> 为自反的，由于 <spanclass="math inline">\(X&#39;&#39;\)</span> 为 Banach 空间，那么 <spanclass="math inline">\(X\)</span> 也是 Banach 空间。</p><p><strong>命题</strong>：Hilbert 空间均为自反的。</p><p><strong>证明</strong>：这个证明的思路非常巧妙！直接按照上面的定义来证明很难证出来。为此我们首先考虑<span class="math inline">\(H&#39;\)</span>，我们已经知道他是 Banach空间了，但它实际上是一个 Hilbert 空间，怎么证明呢？</p><p>对 <span class="math inline">\(\forall f,g\inH&#39;\)</span>，我们前面提到 <span class="math inline">\(f(x)=\langlex,Af\rangle, Af\in H\)</span>，因此定义 <span class="math display">\[\langle f,g\rangle_1 = \langle Ag, Af\rangle\]</span> 验证内积的定义可以证明 <strong><spanclass="math inline">\(\langle \cdot,\cdot\rangle_1\)</span> 就是 <spanclass="math inline">\(H&#39;\)</span> 上的内积</strong>，因此<strong><span class="math inline">\(H&#39;\)</span> 是 Hilbert空间</strong>。这样的话就太好了，因为 <spanclass="math inline">\(\forall F\in H&#39;&#39;\)</span>，都存在唯一的<span class="math inline">\(f_0\in H&#39;\)</span>，使得 <spanclass="math inline">\(F(f)=\langle f,f_0\rangle_1=\langle Af_0,Af\rangle=f(Af_0)\)</span>！因此 <span class="math inline">\(H\)</span>为自反空间。证毕。</p><p><em>例子 1</em>：若 <spanclass="math inline">\(1&lt;p&lt;\infty\)</span>，<spanclass="math inline">\(\ell^p\)</span> 是自反的。</p><p><strong>证明</strong>：我们首先知道 <spanclass="math inline">\((\ell^p)&#39;\)</span> 与 <spanclass="math inline">\(\ell^q\)</span> 是等距同构的，而 <spanclass="math inline">\((\ell^p)&#39;&#39;=(\ell^q)&#39;=\ell^p\)</span>，因此<span class="math inline">\(\ell^p\)</span> 是自反的（<spanclass="math inline">\(1/p+1/q=1\)</span>）。</p><p>不过这个证明不太严谨，也可以利用自反空间的等价定义（跟上面的表述是等价的）。任意的<span class="math inline">\(f\in (\ell^p)&#39;\)</span>，可以表示为<span class="math inline">\(f(x)=\langlex,y\rangle,x\in\ell^p,y\in\ell^q\)</span>，对任意的 <spanclass="math inline">\(F\in(\ell^p)&#39;&#39;\)</span>，现在问题来了，<spanclass="math inline">\(F(f)\)</span> 是个什么东西？我们怎么定义 <spanclass="math inline">\(F(f)\)</span>？<spanclass="math inline">\(f\)</span> 是一个函数，如何将其映射到 <spanclass="math inline">\(\mathbb{K}\)</span>上去呢？这是时候还是要应用等距同构的性质，<spanclass="math inline">\((\ell^p)&#39;\)</span> 与 <spanclass="math inline">\(\ell^q\)</span> 等距同构，因此我们可以用 <spanclass="math inline">\(y\in\ell^q\)</span> 来等价的代替 <spanclass="math inline">\(f\in(\ell^p)&#39;\)</span>，这样的话 <spanclass="math inline">\(F(f)\)</span> 就很容易定义了，<spanclass="math inline">\(F(f)\triangleqF_1(y)\in\mathbb{K}\)</span>，那么我们就能找到唯一的 <spanclass="math inline">\(x_0\in\ell^p\)</span>，使得 <spanclass="math inline">\(F_1(y)=\langle y,x_0\rangle=\langlex_0,y\rangle=f(x_0)\)</span>，这样的话任意 <spanclass="math inline">\(F\in(\ell^p)&#39;&#39;\)</span>，我们都能找到对应的唯一的 <spanclass="math inline">\(x_0\in \ell^p\)</span>，使得 <spanclass="math inline">\(F(f)=f(x_0)\)</span>。证毕。</p><p><strong><em>例子 2</em></strong>：有限维赋范空间自反。</p><p>证明：假设 <spanclass="math inline">\(\text{dim}X=n&lt;\infty\)</span>，那么应用 Hamel基的性质（参考教材例 2.5.3）<spanclass="math inline">\(\text{dim}X^\star=n\)</span>。再应用下面的引理（可参考第2章），可以知道有限维赋范空间的<span class="math inline">\(X&#39;=X^\star\)</span> 等距同构，因此 <spanclass="math inline">\(\text{dim}X&#39;=n\)</span>，因此也有 <spanclass="math inline">\(\text{dim}X&#39;&#39;=n\)</span>，因此 <spanclass="math inline">\(J:X\to X&#39;&#39;\)</span> 为满射，<spanclass="math inline">\(X\)</span> 为自反的。证毕。</p><blockquote><p><strong>引理</strong>：<span class="math inline">\(X,Y\)</span> 为<span class="math inline">\(\mathbb{K}\)</span> 上的赋范空间，假设 <spanclass="math inline">\(\text{dim}X=n&lt;\infty\)</span>，<spanclass="math inline">\(T:X\to Y\)</span> 是线性算子，那么 <spanclass="math inline">\(T\)</span> 一定是有界的。</p></blockquote><h3 id="可分性">2.2 可分性</h3><p>研究集合的可分性，可以通过验证典范映射 <spanclass="math inline">\(J\)</span>是否为双射，也有另一个思路，就是下面要讲的可分性。</p><blockquote><p><strong>定理(Hahn-Banach) 5</strong>：<spanclass="math inline">\((X,\Vert\cdot\Vert)\)</span>，<spanclass="math inline">\(Y\)</span> 为 <spanclass="math inline">\(X\)</span> 的线性子空间，<spanclass="math inline">\(Y\subsetneq X\)</span>，对 <spanclass="math inline">\(\forall x_0\in Y^c\)</span>，令 <spanclass="math display">\[\delta = \rho(x_0,Y)=\inf_{y\in Y}\Vert x_0-y\Vert\]</span> 则存在 <span class="math inline">\(f\in X&#39;\)</span>，使得<span class="math inline">\(\Vert f\Vert=1,f|_Y=0,f(x_0)=\delta.\)</span></p><p><strong>NOTE</strong>：这个定理在说什么事呢？前面在讲内积空间的时候，我们提到了Hilbert 空间上的有界线性泛函实际上可以表示为 <spanclass="math inline">\(f(x)=\langlex,z_0\rangle\)</span>，这实际上可以看成是以 <spanclass="math inline">\(z_0\)</span> 为法向量的超平面，因此 <spanclass="math inline">\(N(f)^{\perp}\)</span> 是一维的，也就是说 <spanclass="math inline">\(f\)</span> 在 <spanclass="math inline">\(z_0\)</span> 方向上是非零的，在正交于 <spanclass="math inline">\(z_0\)</span> 的平面内都是0。而这个定理当中，寻找这个 <span class="math inline">\(f\)</span>要做的就是找到一个合适的法向量，使得 <spanclass="math inline">\(z_0\perpY\)</span>，并且添加一个线性系数使得刚好有 <spanclass="math inline">\(f(x_0)=\delta\)</span>。不过这个定理更加强大的一个地方在于不要求<span class="math inline">\(X\)</span> 是 Hilbert空间，只要求赋范空间即可。</p></blockquote><p><strong>证明</strong>：考虑 <spanclass="math inline">\(M=\text{span}(Y\cup \{x_0\})\)</span> 是 <spanclass="math inline">\(X\)</span> 的线性子空间，则 <spanclass="math inline">\(\forall x\in M\)</span>，存在唯一的分解方式 <spanclass="math inline">\(x=y+\lambda x_0\)</span>，<spanclass="math inline">\(y\in Y,\lambda\in\mathbb{K}\)</span>，定义 <spanclass="math inline">\(f_0(x)=\lambda \delta.\)</span> 容易验证 <spanclass="math inline">\(f_0\in M&#39;, \Vertf_0\Vert\le1\)</span>，也可以验证 <span class="math inline">\(\Vertf_0\Vert \ge1\)</span>（需要思考一下）。因此存在 <spanclass="math inline">\(f\in X&#39;\)</span> 使得 <spanclass="math inline">\(\Vert f\Vert=\Vert f_0\Vert\)</span>，<spanclass="math inline">\(f|_Y=f_0|_Y=0\)</span>，并且 <spanclass="math inline">\(f(x_0)=f_0(x_0)=\delta.\)</span> 证毕。</p><blockquote><p><strong>推论</strong>：<spanclass="math inline">\((X,\Vert\cdot\Vert)\)</span>，若 <spanclass="math inline">\(X&#39;\)</span> 为可分空间，则 <spanclass="math inline">\(X\)</span> 为可分空间。</p><p><strong>NOTE</strong>：这个推论可用于证明某个空间不是自反空间：如果<span class="math inline">\(X\)</span> 可分，但是 <spanclass="math inline">\(X’\)</span> 不可分，那么 <spanclass="math inline">\(X\)</span> 一定不自反。否则的话 <spanclass="math inline">\(X&#39;&#39;=X\)</span> 是可分的，应该有 <spanclass="math inline">\(X&#39;\)</span> 也是可分的，矛盾。</p></blockquote><p>证明： 参考教材，略。</p><p><em>例子 3</em>：<span class="math inline">\(c_o,\ \ell^1,\\ell^\infty,\ C[a,b]\)</span> 都不是自反空间。</p><p><strong>证明</strong>：<spanclass="math inline">\(c_0&#39;=\ell^1,(\ell^1)&#39;=\ell^\infty,(\ell^\infty)&#39;=\ell^1\)</span>（参考课本 P68），但是由于<strong><span class="math inline">\(c_0,\ell^1\)</span> 是可分的，而<span class="math inline">\(\ell^\infty\)</span>不是可分的</strong>，因此 <span class="math inline">\(\ell^1\)</span>不自反。</p><p><span class="math inline">\(C[a,b]&#39;\)</span> 是不可分的，<spanclass="math inline">\(C[a,b]\)</span> 是可分的，细节参考课本，懒得写了......后面心情好了再补吧......</p><h2 id="riemann-stieltjes积分">3. Riemann-Stieltjes积分</h2><p>称函数 <span class="math inline">\(\omega:[a,b]\to\mathbb{K}\)</span>为<strong>有界变差函数</strong>，若存在常数 <spanclass="math inline">\(C\ge0\)</span>，使得任取 <spanclass="math inline">\([a,b]\)</span> 的分划 <spanclass="math display">\[a=t_0&lt;t_1&lt;\cdots&lt;t_n=b\]</span> 都有 <span class="math inline">\(\sum_{i=1}^n|\omega(t_i)-\omega(t_{i-1})|\le C\)</span>。记所有 <spanclass="math inline">\([a,b]\)</span> 上的有界变差函数构成的集合为 <spanclass="math inline">\(BV[a,b]\)</span>。并定义 <spanclass="math inline">\([a,s],a\le s\le b\)</span>上的<strong>全变差</strong>为 <span class="math display">\[\text{Var}_{[a,s]}(\omega)=\sup\sum_{i=1}^n|\omega(t_i)-\omega(t_{i-1})|\]</span> 其中上确界是对所有 <span class="math inline">\([a,s]\)</span>上的分划来取。</p><p><strong>命题</strong>：若 <spanclass="math inline">\(\omega:[a,b]\to\mathbb{R}\)</span> 单调，则 <spanclass="math inline">\(\omega\in BV[a,b]\)</span>，并且此时有 <spanclass="math inline">\(\text{Var}_{[a,b]}(\omega)=|\omega(b)-\omega(a)|.\)</span></p><p><strong>命题</strong>：若 <span class="math inline">\(\omega:[a,b]\to\mathbb{R}\)</span> 为有界变差的，则存在 <spanclass="math inline">\(\omega_1,\omega_2\)</span> 单调递增，使得 <spanclass="math inline">\(\omega=\omega_1-\omega_2.\)</span></p><p>证明：取 <spanclass="math inline">\(\omega_1(t)=\text{Var}_{[a,t]}(\omega)\)</span>，那么易证<span class="math inline">\(\omega_1\)</span> 是单调递增的。取 <spanclass="math inline">\(\omega_2=\omega-\omega_1\)</span>也是递增的，这是因为 <span class="math inline">\(\forallt&lt;s\)</span>，<span class="math inline">\(t,x\in[a,b]\)</span> 都有<span class="math display">\[\begin{aligned}\omega_2(s)-\omega_2(t)&amp;=\text{Var}_{[a,s]}(\omega)-\text{Var}_{[a,t]}(\omega)-\omega(s)+\omega(t)\\&amp;=\text{Var}_{[t,s]}(\omega)-(\omega(s)-\omega(t)) \ge 0\end{aligned}\]</span> 其中第二个等号用到了下面的引理。</p><p><strong>引理</strong>：<spanclass="math inline">\(\text{Var}_{[a,s]}(\omega)=\text{Var}_{[a,t]}(\omega)+\text{Var}_{[t,s]}(\omega).\)</span></p><p>证明：略。</p><p>在 <span class="math inline">\(BV[a,b]\)</span> 上定义范数 <spanclass="math inline">\(\Vert\omega\Vert_{bv}=\text{Var}_{[a,b]}(\omega)+|\omega(a)|\)</span>，则可以证明<span class="math inline">\(\Vert\cdot\Vert_{bv}\)</span> 为 <spanclass="math inline">\(BV[a,b]\)</span> 上的范数，并且 <spanclass="math inline">\(BV[a,b]\)</span> 为 Banach 空间。</p><p>对 <span class="math inline">\(\forall \omega\in BV[a,b], x\inC[a,b]\)</span>，若 <span class="math inline">\(\mathcal{P}\)</span> 为<span class="math inline">\([a,b]\)</span> 的分划 <spanclass="math inline">\(a=t_0&lt;t_1&lt;\cdots&lt;t_n=b\)</span>，令 <spanclass="math display">\[S(x,\omega,\mathcal{P})=\sum_{i=1}^nx(t_{i-1})(\omega(t_i)-\omega(t_{i-1}))\]</span> 是 <span class="math inline">\(x\)</span> 关于有界变差函数<span class="math inline">\(\omega\)</span> 和分划 <spanclass="math inline">\(\mathcal{P}\)</span> 的 Darboux 和。记 <spanclass="math inline">\(\eta(\mathcal{P})=\max_i (t_i-t_{i-1}) \to0\)</span>，若存在唯一的 <spanclass="math inline">\(A\in\mathbb{K}\)</span> 使得 <spanclass="math inline">\(S(x,\omega,\mathcal{P})\to A\)</span>，则称 <spanclass="math inline">\(A\)</span> 为 <spanclass="math inline">\(x\)</span> 关于 <spanclass="math inline">\(\omega\)</span> 的 Riemann-Stieltjes 积分，记为<span class="math display">\[A = \int_a^b x(t)d\omega(t).\]</span> 定义线性泛函 <spanclass="math inline">\(\phi_{\omega}:C[a,b]\to\mathbb{K}\)</span> 为<span class="math display">\[\phi_\omega(x)=\int_a^b x(t)d\omega(t)\]</span> 则 <span class="math inline">\(\phi_\omega\inC[a,b]&#39;\)</span>，并且有 <span class="math inline">\(\Vert\phi_\omega\Vert\le \text{Var}_{[a,b]}(\omega)\)</span>。</p><p><strong>定理</strong>：<span class="math inline">\(\forall \phi\inC[a,b]&#39;\)</span>，<span class="math inline">\(\exists! \omega\inBV[a,b]\)</span>，满足 <spanclass="math inline">\(\omega(a)=0\)</span>，<spanclass="math inline">\(\forall x\in C[a,b]\)</span>，<spanclass="math inline">\(\phi(x)=\int_a^b x(t)d\omega(t)\)</span>，此时有<span class="math inline">\(\Vert\phi\Vert=\Vert\omega\Vert_{bv}.\)</span></p><p>证明：略。</p>]]></content>
    
    
    <categories>
      
      <category>Functional Analysis</category>
      
    </categories>
    
    
    <tags>
      
      <tag>共轭算子</tag>
      
      <tag>典范映射</tag>
      
      <tag>自反空间</tag>
      
      <tag>Riemann-Stieltjes积分</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>泛函分析笔记4：Hahn-Banach定理</title>
    <link href="/2020/12/14/functional-analysis/ch4-1-hahn-banach/"/>
    <url>/2020/12/14/functional-analysis/ch4-1-hahn-banach/</url>
    
    <content type="html"><![CDATA[<p>前面三章讲了很多东西，但实际上都只是开胃小菜&gt;__&lt;，度量空间、赋范空间、内积空间等等都是为了我们接下来要讲的四大定理做铺垫。泛函中的四大定理，即Hahn-Banach定理、一致有界性原理、开映射定理和闭图像定理，是整个泛函分析的基石（前面三章的内容是基石的基石）。</p><span id="more"></span><h2 id="hahn-banach-定理">1. Hahn-Banach 定理</h2><p>首先介绍几个要用到的概念。对于定义了序关系 <spanclass="math inline">\(\preceq\)</span> 的集合 <spanclass="math inline">\(X\)</span>，<span class="math inline">\(N\subsetX\)</span>，称 <span class="math inline">\(x_0\in X\)</span> 为 <spanclass="math inline">\(N\)</span> 的<strong>上界</strong>，若 <spanclass="math inline">\(x\preceq x_0,\forall x\in N\)</span>；称 <spanclass="math inline">\(y_0\in N\)</span> 为<strong>极大元</strong>，若<span class="math inline">\(y_0\le y,\forall y\in N \Longrightarrowy=y_0.\)</span></p><p><strong>Zorn引理</strong>：非空半序集合 <spanclass="math inline">\((X,\preceq)\)</span>，若 <spanclass="math inline">\(X\)</span> 的任意非空全序子集均有上界，则 <spanclass="math inline">\(X\)</span> 必有极大元。</p><p>Hahn-Banach 定理有很多种不同的形式，在给出第一个 Hahn-Banach定理之前，我们先引入次线性泛函。对于线性空间 <spanclass="math inline">\(X\)</span>，称 <span class="math inline">\(p:X\to\mathbb{K}\)</span> 为<strong>次线性泛函</strong>，若：</p><ol type="1"><li><span class="math inline">\(\forall x,y\in X, p(x+y)\lep(x)+p(y)\)</span></li><li><span class="math inline">\(\forall x\in X,a\ge0,p(ax)=ap(x).\)</span></li></ol><blockquote><p><strong>定理(Hahn-Banach) 1</strong>：对于<strong>实线性空间</strong><span class="math inline">\(X\)</span>，<spanclass="math inline">\(X_0\)</span> 为 <spanclass="math inline">\(X\)</span> 的线性子空间，<spanclass="math inline">\(p\)</span> 为 <spanclass="math inline">\(X\)</span> 上的<strong>次线性泛函</strong>，<spanclass="math inline">\(f_0\in X_0^\star\)</span> 为线性泛函并且满足 <spanclass="math inline">\(f_0(x)\le p(x),\forall x\in X_0\)</span>，那么存在<span class="math inline">\(f\in X^\star\)</span> 使得 <spanclass="math inline">\(f|_{X_0}=f_0\)</span>，并且 <spanclass="math inline">\(f(x)\le p(x),\forall x\in X.\)</span></p></blockquote><p><strong>证明</strong>：要证明 <span class="math inline">\(f\)</span>的存在性我们就需要找到满足条件的 <spanclass="math inline">\(f\)</span>，但是给出的 <spanclass="math inline">\(f_0\)</span> 只在 <spanclass="math inline">\(X_0\)</span> 上有定义，怎么把它扩展到整个 <spanclass="math inline">\(X\)</span> 上得到我们想要的 <spanclass="math inline">\(f\)</span>呢？下面的构造方法非常的“山路十八弯”，我自己是想不到 orz。</p><p>首先定义 <span class="math inline">\(\mathcal{E}=\{(Y,g):Y为X的线性子空间,X_0\subset Y,\quad g\in Y^\star ,g|_{X_0}=f_0, g(x)\lep(x),\forall x\in Y\}\)</span>（这个集合的构造就不是一般人能想到的[狗头]）。由于 <spanclass="math inline">\((X_0,f_0)\in \mathcal{E}\)</span>，因此 <spanclass="math inline">\(\mathcal{E}\)</span> 非空，我们可以定义 <spanclass="math inline">\(\mathcal{E}\)</span> 上的序关系 <spanclass="math display">\[(Y_1,g_1)\preceq(Y_2,g_2) \iff Y_1\subset Y_2,\ g_2|_{Y_1}=g_1\]</span> 那么取 <span class="math inline">\(\mathcal{E}\)</span>的非空全序子集 <span class="math inline">\(\mathcal{E}_1\)</span>，令<span class="math inline">\(W=\cup_{(Y,g)\in\mathcal{E}_1}Y\)</span>，对应的 <span class="math inline">\(\forallx\in W\)</span>，我们可以找到 <span class="math inline">\((Y,g)\in\mathcal{E}_1, x\in Y\)</span>，此时定义 <spanclass="math inline">\(h(x)=g(x)\)</span>。容易验证 <spanclass="math inline">\(W\)</span> 为 <spanclass="math inline">\(X\)</span> 的线性子空间，另外由于 <spanclass="math inline">\(\mathcal{E}_1\)</span> 是全序的，也可以验证 <spanclass="math inline">\(h(x),\forall x\in W\)</span> 的定义是唯一的（与<span class="math inline">\((Y,g)\)</span> 的选取无关），并且 <spanclass="math inline">\(h(x)\)</span> 为 <spanclass="math inline">\(W\)</span> 上的线性泛函。因此我们有 <spanclass="math inline">\((W,h)\in\mathcal{E}.\)</span></p><p>由于任意 <spanclass="math inline">\((Y,g)\in\mathcal{E}_1\)</span>，都有 <spanclass="math inline">\((Y,g)\preceq(W,h)\)</span>，即 <spanclass="math inline">\((W,h)\)</span> 为 <spanclass="math inline">\(\mathcal{E}_1\)</span> 的上界，<spanclass="math inline">\(\mathcal{E}\)</span>中任意非空全序子集都有上界，根据 Zorn 引理，<spanclass="math inline">\(\mathcal{E}\)</span> 有极大元 <spanclass="math inline">\((Y_0,g_0).\)</span></p><p>到这里我们就把 <span class="math inline">\((X_0,f_0)\)</span>扩展到了一个更大的空间 <span class="math inline">\((Y_0,g_0)\)</span>上面，但是 <span class="math inline">\(Y_0\)</span> 是否就是 <spanclass="math inline">\(X\)</span> 呢？感觉应该是，但是需要证明一下。</p><p>假如 <span class="math inline">\(Y_0\subsetneq X\)</span>，可以取<span class="math inline">\(y\in Y_0^c\)</span>，考虑 <spanclass="math inline">\(V=\text{span}(Y_0\cup \{y\})\)</span>，那么 <spanclass="math inline">\(\forall x\in V\)</span> 都可以唯一的表示为 <spanclass="math inline">\(x=w+\lambda y,w\inY_0,\lambda\in\mathbb{R}\)</span>，此时定义 <spanclass="math display">\[h(x)=g_0(w)+\lambda a\]</span> 容易验证 <span class="math inline">\(h\)</span> 为 <spanclass="math inline">\(V\)</span> 上的线性泛函，并且有 <spanclass="math inline">\(h_{Y_0}=g_0\)</span>，因此我们就对 <spanclass="math inline">\(g_0\)</span> 又进行了扩展，只需要证明 <spanclass="math inline">\((V,h)\in\mathcal{E}\)</span>就能导出矛盾（因为已经证明 <spanclass="math inline">\((Y_0,g_0)\)</span> 为极大元）从而说明 <spanclass="math inline">\(Y_0=X\)</span>。这就需要满足 <spanclass="math inline">\(h(x)\le p(x),\forall x\in V\)</span>。考虑 <spanclass="math inline">\(\lambda&gt;0\)</span>，这等价于 <spanclass="math inline">\(h(x/\lambda)=g_0(w/\lambda)+a\lep(w/\lambda+y)\)</span>，也等价于 <span class="math inline">\(\forallw\in Y_0, g_0(w)+a\le p(w+y)\)</span>。类似得取 <spanclass="math inline">\(x=w-\lambda y,\lambda&gt;0\)</span> 就可以得到<span class="math inline">\(g_0(w)-a\le p(w-y)\)</span>。因此 <spanclass="math inline">\(a\)</span> 需要满足以下条件： <spanclass="math display">\[g_0(w)-p(w-y) \le a \le p(w+y) - g_0(w)\]</span> 因此就需要满足 <span class="math inline">\(2g_0(w) \lep(w-y)+p(w+y)\)</span>，由于 <span class="math inline">\(2g_0(w)\lep(2w) \le p(w+y+w-y)\lep(w+y)+p(w-y)\)</span>，因此上式一定可以满足，即能找到合适的 <spanclass="math inline">\(a\)</span> 使得 <spanclass="math inline">\((V,h)\in\mathcal{E}\)</span>，因为 <spanclass="math inline">\(Y_0\subsetneq V\)</span>，这就说明 <spanclass="math inline">\((Y_0,g_0)\)</span> 不是 <spanclass="math inline">\(\mathcal{E}\)</span> 的极大元，导出矛盾，因此有<span class="math inline">\(Y_0=X\)</span>。至此我们就找到了 <spanclass="math inline">\(g_0\)</span> 满足定理要求的全部条件。</p><p>证毕。</p><p>上面的定理只研究了实线性空间的情况，对于复线性空间有相似的结论，不过我们需要对条件稍加修改。</p><p>首先将上面 <span class="math inline">\(p\)</span>的次线性泛函假设改为更强的假设——半范。对于线性空间 <spanclass="math inline">\(X\)</span>，<spanclass="math inline">\(p:X\to\mathbb{R}\)</span> 称为 <spanclass="math inline">\(X\)</span> 上的<strong>半范</strong>，若满足：</p><ol type="1"><li><span class="math inline">\(p(x)\ge0, \forall x\in X\)</span></li><li><span class="math inline">\(p(x+y)\le p(x)+p(y),\forall x,y\inX\)</span></li><li><span class="math inline">\(p(ax)=|a|p(x),\forall x\inX,a\in\mathbb{K}\)</span></li></ol><p>半范与范数的概念相比，少了一个条件即 <spanclass="math inline">\(p(x)=0\iff x=0\)</span>，因此说明可能存在 <spanclass="math inline">\(x\ne0,p(x)=0\)</span>。另外半范可以导出次线性。</p><blockquote><p><strong>定理(Hahn-Banach) 2</strong>：<spanclass="math inline">\(X\)</span> 为 <spanclass="math inline">\(\mathbb{K}\)</span> 上的线性空间，<spanclass="math inline">\(X_0\)</span> 为 <spanclass="math inline">\(X\)</span> 的线性子空间，<spanclass="math inline">\(p:X\to \mathbb{R}\)</span> 为半范，<spanclass="math inline">\(f_0\in X_0^\star\)</span> 并且有 <spanclass="math inline">\(|f_0(x)|\le p(x),\forall x\inX_0\)</span>，那么存在 <span class="math inline">\(f\in X^\star\)</span>使得 <span class="math inline">\(f|_{X_0}=f_0\)</span>，并且 <spanclass="math inline">\(f(x)\le p(x),\forall x\in X.\)</span></p></blockquote><p><strong>证明</strong>：要想把原来的结论从实线性空间扩展到复线性空间，首先要考虑复线性空间有什么特殊的性质。如果用两个实线性泛函来表示<spanclass="math inline">\(f(x)=f_1(x)+if_2(x)\)</span>，我们可以想一下复线性空间可以粗略的看成两个实线性空间的组合，<spanclass="math inline">\(\foralla\in\mathbb{R},f(ax)=af_1(x)+iaf_2(x)\)</span>。但是实际上并没有这么简单，因为<span class="math inline">\(a\)</span> 还可以取自复空间，那么我们令<span class="math inline">\(a=i\)</span> 就可以得到 <spanclass="math display">\[\begin{aligned}if(x)&amp;=f(ix) \\if_1(x)-f_2(x)&amp;=f_1(ix)+if_2(x)\end{aligned}\]</span> 由于 <span class="math inline">\(x\in X\)</span>任取，实部虚部需要分别相等，因此 <spanclass="math inline">\(f_2(x)=-f_1(ix),\forall x\inX\)</span>，即<strong>复线性泛函 <span class="math inline">\(f\)</span>的实部和虚部是相互约束的</strong>！另一方面，实部和虚部只需要知道其中一个，另一个也就确定了。那么也就是说给定一个复线性泛函<span class="math inline">\(f\)</span> 我们可以唯一的用某个实线性泛函<span class="math inline">\(f_1\)</span> 来表示 <spanclass="math inline">\(f\)</span>。</p><blockquote><p><strong>NOTE</strong>：读者如果了解信号的相干解调的话，这里可以联想到Hilbert 变换。实际上。</p></blockquote><p>对于定理中的 <span class="math inline">\(f_0\)</span>我们可以将其表示为 <spanclass="math inline">\(f_0(x)=f_1(x)+if_2(x)\)</span>。容易验证 <spanclass="math inline">\(f_1(x)\le p(x)\)</span>，根据上一个 Hahn-Banach定理，就能找到一个实线性泛函 <spanclass="math inline">\(g_1\)</span>，使得 <spanclass="math inline">\(g_1|_{X_0}=f_1, g_1(x)\lep(x)\)</span>。那么我们再定义 <spanclass="math inline">\(g(x)=g_1(x)-ig_1(ix)\)</span>，容易验证 <spanclass="math inline">\(g\in X^\star,g|_{X_0}=f_0\)</span>，接下来验证<span class="math inline">\(|g(x)|\le p(x)\)</span> 的方法也有一点巧妙：<span class="math display">\[|g(x)|=g(x)e^{-i\theta} = g(e^{-i\theta}x)=g_1(e^{-i\theta}x)\lep(e^{-i\theta}x)=p(x)\]</span> 证毕。</p><p>接下来再把 <span class="math inline">\(X\)</span>限制在赋范空间上，就能得到有界线性泛函的保范延拓定理，这也是 Hahn-Banach定理最重要的应用。我们这里讲前面两个定理基本上也是为下面一个定理做铺垫。他们的基本含义都是将一个线性泛函从较小的线性子空间延拓到整个空间。</p><blockquote><p><strong>定理(Hahn-Banach/保范延拓定理) 3</strong>：<spanclass="math inline">\((X,\Vert\cdot\Vert)\)</span>，<spanclass="math inline">\(X_0\)</span> 为 <spanclass="math inline">\(X\)</span> 的线性子空间，<spanclass="math inline">\(\forall f_0\in X_0&#39;\)</span>，则 <spanclass="math inline">\(\exists f\in X&#39;\)</span>，<spanclass="math inline">\(f|_{X_0}=f_0\)</span> 且 <spanclass="math inline">\(\Vert f\Vert = \Vert f_0\Vert.\)</span></p></blockquote><p><strong>证明</strong>：我们还是要对 <spanclass="math inline">\(f_0\)</span>进行延拓，那么怎么样才能应用上面两个定理的结论呢？首先需要构造一个半范<span class="math inline">\(p\)</span>，可以定义 <spanclass="math inline">\(p(x)=\Vert f_0\Vert\cdot \Vertx\Vert\)</span>，容易验证其为半范（在这里能看出来半范的好处，由于不要求<span class="math inline">\(p(x+y)=p(x)+p(y)\)</span>，因此 <spanclass="math inline">\(p\)</span> 可以含有 <spanclass="math inline">\(\Vert x\Vert\)</span> 项）。那么就能找到 <spanclass="math inline">\(f\in X^\star,f|_{X_0}=f_0,|f(x)|\le \Vertf_0\Vert\cdot \Vert x\Vert\)</span>，之后容易验证 <spanclass="math inline">\(\Vert f\Vert=\Vert f_0\Vert.\)</span> 证毕。</p><p>对上一定义的假设条件进行增强，把 <spanclass="math inline">\(X\)</span> 限制为 Hilbert 空间，回忆上一章提到了<strong>Hilbert空间</strong>上的<strong>线性泛函</strong>都可以<strong>唯一的</strong>表示为<span class="math inline">\(f(x)=\langle x,z_0\rangle\)</span>的形式，那么我们可以把上面的保范延拓定理进一步加强，获得唯一性！</p><blockquote><p><strong>推论 1</strong>：若 <span class="math inline">\(X\)</span> 为HIlbert 空间，<span class="math inline">\(X_0\)</span> 为 <spanclass="math inline">\(X\)</span> 的闭线性子空间，<spanclass="math inline">\(f_0\inX_0&#39;\)</span>，则<strong>存在唯一的</strong> <spanclass="math inline">\(f\in X&#39;\)</span>，<spanclass="math inline">\(f|_{X_0}=f_0\)</span> 且 <spanclass="math inline">\(\Vert f\Vert = \Vert f_0\Vert.\)</span></p></blockquote><p><strong>证明</strong>：<span class="math inline">\(X_0\)</span> 也是Hilbert 空间，因此 <span class="math inline">\(\exists! z_0\inX_0\)</span>，使得 <span class="math inline">\(f_0(x)=\langlex,z_0\rangle\)</span>，因此很方便地可以取 <spanclass="math inline">\(f_0(x)=\langle x,z_0\rangle, \forall x\inX\)</span>，并且可以验证 <span class="math inline">\(f\)</span> 满足条件<span class="math inline">\(f|_{X_0}=f_0, \Vert f\Vert = \Vertf_0\Vert=\Vert z_0\Vert.\)</span></p><p>接下来就需要证明 <span class="math inline">\(f\)</span>的唯一性。假设还有 <span class="math inline">\(g\)</span> 满足条件，那么<span class="math inline">\(\exists! z_1\in X\)</span>，<spanclass="math inline">\(g(x)=\langle x,z_1\rangle\)</span> <spanclass="math display">\[\forall x\in X_0.f(x)-g(x)=\langle x,z_0-z_1\rangle=0 \Longrightarrowz_0-z_1\in X_0^{\perp} \\\Vert g_0\Vert=\Vert z_1\Vert^2 = \Vert z_1-z_0\Vert^2+\Vertz_0\Vert^2=\Vert f_0\Vert^2 \Longrightarrow z_1=z_0\]</span> 证毕。</p><blockquote><p><strong>定理(Hahn-Banach) 4</strong>：<spanclass="math inline">\((X,\Vert\cdot\Vert)\)</span>，<spanclass="math inline">\(x_0\in X, x_0\ne 0\)</span>，则 <spanclass="math inline">\(\exists f\in X&#39;, \Vert f\Vert=1\)</span>，使得<span class="math inline">\(f(x_0)=\Vert x_0\Vert.\)</span></p></blockquote><p><strong>证明</strong>：可以取 <spanclass="math inline">\(X_0=\mathbb{K}x_0=\{\lambdax_0,\lambda\in\mathbb{K}\}\)</span>，定义 <spanclass="math inline">\(f_0(\lambda x_0)=\lambda \Vert x_0\Vert \inX_0&#39;\)</span>，<span class="math inline">\(\Vertf_0\Vert=1\)</span>，再应用上一推论自然就出来了。证毕。</p><p><strong>NOTE</strong>：对于 <span class="math inline">\(\forallx,y\in X,x\ne y\)</span>，那么我们取 <spanclass="math inline">\(x_0=x-y\ne0\)</span>，根据上面的定理，一定存在<span class="math inline">\(f\in X&#39;\)</span> 使得 <spanclass="math inline">\(f(x_0)=f(x)-f(y)\ne0\)</span>。这说明只要 <spanclass="math inline">\(x\ne y\)</span>，就一定存在某个 <spanclass="math inline">\(f\in X&#39;,\Vert f\Vert=1\)</span> 使得 <spanclass="math inline">\(f(x)\ne f(y).\)</span> 可以表述为 <spanclass="math display">\[x=y \iff f(x)=f(y),\forall f\in X&#39;\]</span></p><blockquote><p><strong>推论 2</strong>：<spanclass="math inline">\(X\ne\{0\}\)</span> 为赋范空间，<spanclass="math inline">\(x_0\in X,x_0\ne 0\)</span>，则 <spanclass="math display">\[\Vert x_0\Vert = \max_{f\in X&#39;,\Vert f\Vert=1} |f(x_0)| = \max_{f\inX&#39;,\Vert f\Vert\le1} |f(x_0)| = \max_{f\ne0} \frac{|f(x_0)|}{\Vertf\Vert}\]</span> <strong>NOTE</strong>：回忆 <span class="math inline">\(\Vertf\Vert=\sup_{x\in X,\Vertx\Vert\le1}|f(x)|\)</span>，从这个结论来看，<spanclass="math inline">\(X\)</span> 与 <spanclass="math inline">\(X&#39;\)</span> 有某种的对称性。证明略。</p></blockquote>]]></content>
    
    
    <categories>
      
      <category>Functional Analysis</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Hilbert空间</tag>
      
      <tag>Hahn-Banach定理</tag>
      
      <tag>次线性泛函</tag>
      
      <tag>半范</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>泛函分析笔记3：内积空间</title>
    <link href="/2020/12/11/functional-analysis/ch3-hilbert-space/"/>
    <url>/2020/12/11/functional-analysis/ch3-hilbert-space/</url>
    
    <content type="html"><![CDATA[<p>我们前面讲了距离空间、赋范空间，距离空间赋予了两个点之间的距离度量，范数赋予了每个点自身的长度度量，而范数则可以导出距离。本章要讲的内积可以看成是更加统一的定义，因为从内积我们可以导出范数，进而导出距离。因此内积空间是一个“更小”的空间，在此基础上结合完备性我们引出了Hilbert 空间，后续我们的研究也大多集中在 Hilbert 空间上。</p><h2 id="内积空间">1. 内积空间</h2><p><strong>定义</strong>：<span class="math inline">\(X\)</span> 为<span class="math inline">\(\mathbb{K}\)</span> 上的线性空间，<spanclass="math inline">\(\langle \cdot,\cdot\rangle :X\times X\to\mathbb{K}\)</span>，若满足如下条件</p><ol type="1"><li><span class="math inline">\(\langle \lambda x+\mu y, z\rangle =\lambda\langle x,z\rangle +\mu\langle y,z\rangle\)</span></li><li><span class="math inline">\(\overline{\langle x,y\rangle }=\langley,z\rangle\)</span></li><li><span class="math inline">\(\forall x\in X, \langle x,x\rangle \ge0\)</span></li><li><span class="math inline">\(\langle x,x\rangle =0 \iffx=0\)</span></li></ol><p>则称 <span class="math inline">\((X,\langle \cdot,\cdot\rangle)\)</span> 为<strong>内积空间</strong>。可以用内积定义范数 <spanclass="math inline">\(\Vert x\Vert = \langle x,x\rangle^{1/2}\)</span>。若得到的 <spanclass="math inline">\((X,\Vert\cdot\Vert)\)</span> 为 Banach 空间，那么<span class="math inline">\((X,\langle \cdot,\cdot\rangle )\)</span> 为<strong>Hilbert 空间</strong>。</p><span id="more"></span><p><strong>定理</strong>：<span class="math inline">\((X,\langle\cdot,\cdot\rangle ),\forall x,y\in X\)</span> 有</p><ul><li><span class="math inline">\(|\langle x,y\rangle |\le \Vert x\Vert\cdot\Vert y\Vert\)</span>（Schwartz 不等式）等号成立 <spanclass="math inline">\(\iff x,y\)</span> 线性相关 <spanclass="math inline">\(\iff y=0\)</span> 或 <spanclass="math inline">\(x=cy\)</span></li><li><span class="math inline">\(\Vert x+y\Vert\le\Vert x\Vert+\Verty\Vert\)</span> 等号成立 <span class="math inline">\(\iff x,y\)</span>线性相关 <span class="math inline">\(\iff y=0\)</span> 或 <spanclass="math inline">\(x=cy\)</span></li></ul><p><strong>定理</strong>：<span class="math inline">\((X,\langle\cdot,\cdot\rangle )\)</span>，设 <span class="math inline">\(x_n\tox,y_n\to y\)</span>，则$x_n,y_nx,y$（此定理说明<strong>内积为连续映射</strong>）。</p><p>证明：略。</p><p><strong>命题</strong>：若 <spanclass="math inline">\(\Vert\cdot\Vert\)</span> 为 <spanclass="math inline">\(X\)</span> 上的范数，若 <spanclass="math inline">\(\forall x,y\in X\)</span> 都满足平行四边形等式<span class="math inline">\(\Vert x+y\Vert^2 + \Vert x-y\Vert^2=2(\Vertx\Vert^2 + \Vert y\Vert^2)\)</span>，则存在 <spanclass="math inline">\(X\)</span> 上的内积 $,$，使得 <spanclass="math inline">\(\Vert x\Vert=\langle \cdot,\cdot\rangle^{1/2}.\)</span></p><p>证明：较复杂，略。</p><p><em>例子 1</em>：<spanclass="math inline">\(X=\mathbb{K}^2,\Vert(x,y)\Vert_\infty\)</span>不是内积空间，反例比如 <spanclass="math inline">\(x=(1,1),y=(1,-1)\)</span>，验证平行四边形等式不成立即可。</p><p><em>例子 2</em>：<spanclass="math inline">\((\ell^\infty,\Vert\cdot\Vert_\infty)\)</span>不是内积空间，反例如 <spanclass="math inline">\(x=(1,0,0,...),y=(0,-1,0,...)\)</span>。</p><p>实际上对于空间 <spanclass="math inline">\(X=\mathbb{K}^n,n&gt;0\)</span>，<spanclass="math inline">\(\Vert x\Vert_p\)</span> <strong>只有在 <spanclass="math inline">\(p=2\)</span>的时候才是内积空间</strong>，其余情况均不是内积空间。</p><p>对于空间 <spanclass="math inline">\((\ell^p,\Vert\cdot\Vert_p)\)</span>也<strong>只有在 <span class="math inline">\(p=2\)</span>的时候才是内积空间</strong>。</p><p><em>例子 3</em>：<span class="math inline">\(C[0,1],\Vertx\Vert_\infty\)</span> 不是内积空间，反例比如 <spanclass="math inline">\(x(t)=1+t,y(t)=1-t\)</span>，验证平行四边形等式不成立即可(说明找不到合适的内积定义来导出无穷范数)。</p><p>类比上面的例子，我们也可以对连续函数定义 <spanclass="math inline">\(2\)</span> 范数(<spanclass="math inline">\(p\)</span> 范数)。首先定义内积 <spanclass="math display">\[\begin{aligned}\langle x,y\rangle =\int_a^b x(t)\overline{y(t)} dt\quad\Rightarrow\quad \Vert x\Vert=\langle x,x\rangle ^{1/2} \\\Vert x\Vert_p = \left(\int_a^b |x(t)|^p dt\right)^{1/p}\end{aligned}\]</span> 同样地，<strong>只有在 <spanclass="math inline">\(p=2\)</span> 的时候 <spanclass="math inline">\((C[a,b],\Vert x\Vert_p)\)</span>才是内积空间。</strong></p><p>到这里大家基本了解了内积空间的特点，他比一般的赋范空间更严格，度量空间就更不用说了。根据初中的知识，有了内积我们就能计算夹角了，不过这里我们不讲夹角，而是考虑<strong>正交</strong>和<strong>正交补</strong>的概念。</p><blockquote><p><strong>小结</strong>：这一部分讲了内积运算的定义，并且由内积可以导出范数的定义，但是内积比范数的要求更严格，因此对于某个范数，可以通过验证平行四边形等式来验证其是否可以由内积运算来导出。</p></blockquote><h2 id="正交补与正交投影">2. 正交补与正交投影</h2><p>内积空间 <span class="math inline">\((X,\langle \rangle )\)</span>中，称 <span class="math inline">\(x,y\)</span><strong>正交</strong>，若 <span class="math inline">\(\langle x,y\rangle=0\)</span>，记为 <span class="math inline">\(x\perp y\)</span>。<spanclass="math inline">\(M\subset X\)</span>非空，定义其<strong>正交补</strong> <spanclass="math inline">\(M^{\perp}=\{x\in X:x\perp y,\forall y\inM\}.\)</span></p><p><strong>命题</strong>：<span class="math inline">\(M^{\perp}\)</span>为 <span class="math inline">\(X\)</span>的<strong>闭集线性子空间</strong>。</p><p>证明：易证 <span class="math inline">\(M^{\perp}\)</span>为线性子空间，然后再用内积的是连续映射证明 <spanclass="math inline">\(M^{\perp}\)</span> 为闭集。</p><p>这里插入一个<strong>最佳逼近元</strong>的概念。定义 <spanclass="math inline">\(\xi(x_0,M)=\inf_{y\in M}d(x_0,y)\)</span>，若存在<span class="math inline">\(y_0\in M\)</span> 使得 <spanclass="math inline">\(d(x_0,y_0)=\xi(x_0,M)\)</span>，那么就称 <spanclass="math inline">\(y_0\)</span>为最佳逼近元。什么情况下最佳逼近元存在呢？</p><ol type="1"><li>当 <span class="math inline">\(M\)</span> 为非空紧集的时候，<spanclass="math inline">\(y_0\)</span> 存在（因为紧集一定是有界闭集）。</li><li>若 <span class="math inline">\(X\)</span> 为赋范空间，<spanclass="math inline">\(M\)</span> 为 <spanclass="math inline">\(X\)</span> 的有限维线性子空间，则 <spanclass="math inline">\(y_0\)</span> 存在（因为有限维赋范空间都完备，<spanclass="math inline">\(M\)</span> 为闭集）。</li></ol><p><strong>定理</strong>：<span class="math inline">\((X,\langle \rangle)\)</span>，<span class="math inline">\(M\)</span> 为 <spanclass="math inline">\(X\)</span> 非空凸子集，且 <spanclass="math inline">\(M\)</span> 完备，则 <spanclass="math inline">\(\forall x_0\in X\)</span>，<spanclass="math inline">\(\exists!y_0\in M\)</span> 为最佳逼近元，并且有<span class="math inline">\(x_0-y_0\in M^{\perp}\)</span>。</p><p>证明：先找到 <span class="math inline">\(y_n\inM,d(x_0,y_n)\le\xi(x_0,M)+\frac{1}{n}\)</span>，证明其为柯西列，由于<span class="math inline">\(M\)</span>完备，得到最佳逼近元的存在性。再由 <spanclass="math inline">\(M\)</span> 的凸性质证明唯一性。证毕。</p><p>对于线性空间 <span class="math inline">\(X\)</span>，<spanclass="math inline">\(M,N\)</span> 为 <spanclass="math inline">\(X\)</span> 的线性子空间，称 <spanclass="math inline">\(X\)</span> 为 <spanclass="math inline">\(M,N\)</span> 的<strong>直和</strong>，若 <spanclass="math inline">\(\forall x\in X,\exists! m\in M,n\inN,x=m+n\)</span>，记为 <span class="math inline">\(X=M\oplusN.\)</span></p><p>很容易验证 <span class="math inline">\(X=M\oplus N \iffX=\text{span}(M\cup N), M\cap N=\{0\}.\)</span></p><p><strong>定理</strong>：设 <span class="math inline">\(H\)</span> 为Hilbert 空间，<span class="math inline">\(M\)</span> 为 <spanclass="math inline">\(H\)</span> 的闭线性子空间，则 <spanclass="math inline">\(H=M\oplus M^{\perp}.\)</span></p><p>证明：<span class="math inline">\(M\)</span> 完备，对 <spanclass="math inline">\(\forall x\in H\)</span>，<spanclass="math inline">\(\exists!y\in M\)</span>，使得 <spanclass="math inline">\(\Vert x-y\Vert=\xi(x,M)\)</span>，并且 <spanclass="math inline">\(x-y\in M^{\perp}\)</span>。证毕。</p><p><strong>定理</strong>：设 <span class="math inline">\(H\)</span> 为Hilbert 空间，<span class="math inline">\(M\)</span> 为 <spanclass="math inline">\(H\)</span> 的闭线性子空间，则 <spanclass="math inline">\((M^{\perp})^{\perp}=M.\)</span></p><p>证明：略。</p><p>上面两条定理当中，只有 <span class="math inline">\(M\)</span> 是<span class="math inline">\(H\)</span>的闭线性子空间才有如此良好的性质！因为只有闭线性子空间才能认为 <spanclass="math inline">\(M\)</span> 是尽可能“丰满”的。举个例子，<spanclass="math inline">\(\mathbb{R}^3\)</span> 中，令 <spanclass="math inline">\(M=\{e_1=(1,0,0)\}\)</span>，那么 <spanclass="math inline">\(M^{\perp}\)</span> 为 <spanclass="math inline">\(y-z\)</span> 平面，<spanclass="math inline">\((M^{\perp})^{\perp}\)</span> 为 <spanclass="math inline">\(x\)</span> 轴，相比于原始的 <spanclass="math inline">\(M\)</span> 扩展到无穷远处了。</p><p><strong>推论</strong>：设 <span class="math inline">\(H\)</span> 为Hilbert 空间，<span class="math inline">\(M\subset H\)</span> 非空，则<span class="math inline">\(\overline{\text{span}M}=H \iffM^{\perp}=\{0\}.\)</span></p><p><strong>引理</strong>：<spanclass="math inline">\(M^{\perp}=(\bar{M})^\perp,\quad(\text{span}M)^{\perp}=M^{\perp}.\)</span></p><p>证明：略。</p><p><strong>NOTE</strong>：这个引理实际上说明了正交补空间在定义的时候已经是“最大化的”，即使原空间<span class="math inline">\(M\)</span>稍微扩张一点点，其正交补空间仍然保持不变。</p><p>设 <span class="math inline">\(H\)</span> 为 Hilbert 空间，<spanclass="math inline">\(M\)</span> 为 <spanclass="math inline">\(H\)</span> 的闭线性子空间，那么对于 <spanclass="math inline">\(\forall x\in H\)</span>，存在唯一的分解 <spanclass="math inline">\(x=y+z,y\in M,z\in M^\perp.\)</span> 记 <spanclass="math inline">\(P_Mx=y\)</span>，称 <spanclass="math inline">\(P_M\)</span> 为从 <spanclass="math inline">\(H\)</span> 到 <spanclass="math inline">\(M\)</span>上的<strong>正交投影</strong>，其有如下性质：</p><ol type="1"><li><span class="math inline">\(P_M\)</span> 为线性算子；</li><li><span class="math inline">\(P_M\)</span> 有界，并且 <spanclass="math inline">\(P_M=1, M\ne\{0\}\)</span>，<spanclass="math inline">\(P_M=0,M=\{0\}\)</span>；</li><li><span class="math inline">\(P_M^2=P_M\)</span>；</li><li><span class="math inline">\(R(P_M)=M,N(P_M)=M^{\perp}\)</span>。</li></ol><blockquote><p><strong>小结</strong>：本小节给出了正交补的定义</p><ol type="1"><li>不论原空间 <span class="math inline">\(M\)</span> 如何，正交补空间<span class="math inline">\(M^{\perp}\)</span>总是有一些良好的性质：1）闭线性子空间；2）“最大化的”；</li><li>如果原空间 <span class="math inline">\(M\)</span>同时有良好的性质（闭线性子空间），那么他们两个就是对整个空间 <spanclass="math inline">\(H\)</span> 的良好分割。</li></ol></blockquote><h2 id="标准正交基">3. 标准正交基</h2><p>内积空间 <span class="math inline">\((X,\langle \rangle )\)</span>中，<span class="math inline">\(M\subset X\)</span>为<strong>正交集</strong>，若 <span class="math inline">\(\forall x,y\inM,x\ne y,\Rightarrow x\perp y.\)</span> 进一步若 <spanclass="math inline">\(M\)</span> 中任意元素 <spanclass="math inline">\(\Vert x\Vert=1\)</span>，则称 <spanclass="math inline">\(M\)</span> 为<strong>标准正交集</strong>。</p><p>对于一个标准正交序列 <spanclass="math inline">\(M=\{e_n,n\ge1\}\)</span>，有 <strong>Bessel不等式</strong> <span class="math display">\[\sum_{i=1}^\infty |\langle x,e_i\rangle |^2 \le \Vert x\Vert^2.\]</span></p><p>有了标准正交集的概念，我们很容易联想到正交基。下面列出的正交集的性质都可以类比基，但是随便取一个标准正交集，其并不一定完备，因此二者又有细微的差别。</p><p><strong>定理</strong>：<span class="math inline">\(H\)</span> 为Hilbert 空间，<span class="math inline">\(\{e_1,e_2,...\}\)</span> 为<span class="math inline">\(H\)</span> 的标准正交集，那么有</p><ul><li><span class="math inline">\(\forall \lambda_n\in\mathbb{K},\sum^\infty_n \lambda_ne_n\)</span> 收敛 <spanclass="math inline">\(\iff \sum_n^\infty|\lambda_n|^2&lt;\infty\)</span></li><li>若 <span class="math inline">\(x=\sum^\infty_n \lambda_ne_n\)</span>，则 $_n=x,e_n$</li><li><span class="math inline">\(\forall x\in H, \sum^\infty_n\langlex,e_n\rangle e_n\)</span> 收敛</li></ul><p>证明：由于涉及到无穷级数，因此证明过程中需要首先考虑 <spanclass="math inline">\(S_N=\sum_{n=1}^N \lambda_n e_n\)</span>的情况，再证明 <span class="math inline">\(N\to\infty\)</span>的时候极限成立。细节略。</p><p>如果对于标准正交集 <span class="math inline">\(M\)</span> 我们有<span class="math inline">\(\overline{\text{span}M}=H\)</span>，那么称<span class="math inline">\(M\)</span> 在 <spanclass="math inline">\(H\)</span>中为<strong>完全的</strong>。实际上这里很容易联想到完备正交基，我们知道空间中任意一点都可以用基的线性组合来表示，如果<span class="math inline">\(M\)</span>是完全的，那么我们可以有相似的结论。</p><p><strong>命题</strong>：首先定义 <span class="math inline">\(\forallx\in X, M_x=\{e\in M, \langle x,e\rangle \ne0\}\)</span>，那么一定有<span class="math inline">\(M_x\)</span> 是至多可数的。</p><p>证明：定义 <span class="math inline">\(M_{x,n}=\{e\in M, |\langlex,e\rangle |\ge \frac{1}{n}\}\)</span>，<spanclass="math inline">\(M_x=\cup^\infty_{n=1} M_{x,n}\)</span>，只需证明<span class="math inline">\(\forall n\ge1, M_{x,n}\)</span>为至多可数集。</p><p>假设 <span class="math inline">\(M_{x,n}\)</span>中两两不等的元素可以表示为 <spanclass="math inline">\(e_1,...,e_N\)</span>，那么 <spanclass="math inline">\(\frac{N}{n^2}\le\sum_{n=1}^N|\langle x,e_i\rangle|^2\le\Vert x\Vert^2 \Rightarrow N\le n^2\Vert x\Vert^2\)</span>，说明<span class="math inline">\(M_{x,n}\)</span>中的元素个数是有限的。证毕。</p><p><strong>定理</strong>：<span class="math inline">\(H\)</span> 为Hilbert 空间，<span class="math inline">\(M\)</span> 为 <spanclass="math inline">\(H\)</span> 的标准正交集，则下述命题等价：</p><ol type="1"><li><span class="math inline">\(M\)</span> 为完全的；</li><li><span class="math inline">\(\forall x\in H,x=\sum_{e\in M}\langlex,e\rangle e\)</span>；</li><li><span class="math inline">\(\forall x\in H, \Vertx\Vert^2=\sum_{e\in M}|\langle x,e\rangle |^2.\)</span></li><li>$x,yH,x,y=_{eM}x,ee,y$</li></ol><p>证明：首先用反证法证明 <spanclass="math inline">\(2\Rightarrow1,3\Rightarrow1.\)</span> 然后考虑<span class="math inline">\(\forall x\in H,M_x=\{e_1,e_2,...\}\)</span>，令 <spanclass="math inline">\(y=\sum^\infty_{i=1} \langle x,e_i\ranglee_i\)</span>， <span class="math inline">\(z=y-x\)</span>，容易证明<span class="math inline">\(\langle z,e_i\rangle =0,\foralli\ge1\)</span>，那么就有 <span class="math inline">\(z\inM^{\perp}=\{0\}\)</span>，从而 <spanclass="math inline">\(x=y=\sum^\infty_{i=1} \langle x,e_i\ranglee_i\)</span>，<spanclass="math inline">\(1\Rightarrow2\)</span>。其余证明可以参考课本。此处省略。</p><p>对于内积空间 <span class="math inline">\(X\)</span>的一列线性无关元素 <spanclass="math inline">\(\{x_1,...,x_n\}\)</span>，那么存在一组标准正交序列<span class="math inline">\(e_1,...,e_n\)</span> 使得 <spanclass="math display">\[\text{span}\{x_1,...,x_n\} = \text{span}\{e_1,...,e_n\}\]</span> 其中一种获取方法为 <strong>Gram-Schmidt标准正交化方法</strong>，即</p><ol type="1"><li>首先取 <span class="math inline">\(e_1=\frac{x_1}{\Vertx_1\Vert}\)</span></li><li>然后 <span class="math inline">\(v_2=x_2-\langle x_2,e_1\rangle e_1,e_2 = \frac{v_1}{\Vert v_2\Vert}\)</span></li><li>上述过程重复进行。</li></ol><p><strong>定理</strong>：<span class="math inline">\(H\)</span> 为Hilbert 空间，<span class="math inline">\(M\)</span> 为 <spanclass="math inline">\(H\)</span> 的标准正交集，则存在 <spanclass="math inline">\(N\)</span> 为完全标准正交集，<spanclass="math inline">\(M\subset N.\)</span></p><p><strong>推论</strong>：任意 Hilbert 空间均有完全标准正交集。</p><p>证明：可以根据有限维空间、无限维可分空间进行讨论，应用 Gram-Schmidt标准正交化方法即可获得完全标准正交集。</p><p>实际上如果我们能构造出来 Hilbert空间的一组标准正交基，那么对于有限维空间 <spanclass="math inline">\(\text{dim}H=n\)</span>，其与 <spanclass="math inline">\(\mathbb{K}^n\)</span>等距同构；对于无穷维可分空间，其与 <spanclass="math inline">\(\ell^2\)</span> 等距同构。</p><blockquote><p><strong>小结</strong>：</p><ol type="1"><li>本小节讲到的标准正交集可以用于向量的线性分解表示。</li><li>当标准正交集是完全的，那么它实际上就是 Hilbert 空间 <spanclass="math inline">\(H\)</span>的一组标准正交基。这又可以看作是线性空间中 Hamel 基/Schauder基的更特殊的情况，因为完备的标准正交集要求相互正交，而 Hamel 基和Schauder 基只要求线性无关。</li><li>实际上根据 Gram-Schmidt标准正交化方法可以由两种基构造出标准正交基。</li></ol></blockquote><h2 id="hilbert-空间上有界线性泛函表示">4. Hilbert空间上有界线性泛函表示</h2><p>对于内积空间 <span class="math inline">\(X\)</span>，取 <spanclass="math inline">\(z_0\in X\)</span>，那么我们可以定义一个线性泛函<span class="math inline">\(f_{z_0}(x)=\langlex,z_0\rangle\)</span>，可以验证 <span class="math inline">\(f_{z_0}\inX^{\star}\)</span>，并且有 <span class="math inline">\(\Vertf_{z_0}\Vert = \Vert z_0\Vert\)</span>，因此 <spanclass="math inline">\(f_{z_0}\in X&#39;\)</span>。</p><p>那么如果反过来，任取 <span class="math inline">\(f\inX&#39;\)</span>，我们是否能够断言 <span class="math inline">\(f\)</span>都可以表示为 <span class="math inline">\(f(x)=\langlex,z_0\rangle\)</span>的形式呢？可以！这个表示形式如此简洁，以后你会发现这个性质非常有用！但并不是任意赋范空间都可以如此表示，只有Hilbert 空间有这个良好的性质。</p><blockquote><p><strong>定理(F.Riesz)</strong>：<spanclass="math inline">\(H\)</span> 为 Hilbert 空间，则 <spanclass="math inline">\(\forall f\in H&#39;,\exists! z_0\in H,f(x)=\langlex,z_0\rangle .\)</span></p><p><strong>证明</strong>：若 <spanclass="math inline">\(f=0\)</span>，取 <spanclass="math inline">\(z_0=0.\)</span></p><p>若<span class="math inline">\(f\ne0,f\in H&#39;\)</span>，那么 <spanclass="math inline">\(N(f)=\{x\in H,f(x)=0\}\)</span> 为 <spanclass="math inline">\(H\)</span> 的闭线性子空间，因此有 <spanclass="math inline">\(H=N(f)\oplus N(f)^{\perp}\)</span>，且 <spanclass="math inline">\(N(f)^{\perp}\ne\{0\}\)</span>。接下来的问题就是如何构造一个函数$x,z$ 让其等于 <span class="math inline">\(f(x)\)</span>？</p><p>首先固定 <span class="math inline">\(z_0\inN(f)^{\perp},z_0\ne0\)</span>。任给 <span class="math inline">\(x\inH\)</span>，考虑 <span class="math inline">\(v=f(x)z_0-f(z_0)x \inH\)</span>，显然有 <span class="math inline">\(f(v)=0\)</span>，故 <spanclass="math inline">\(v\in N(f)\)</span>，从而有 <spanclass="math display">\[\begin{aligned}\langle v,z_0\rangle  = f(x)\langle z_0,z_0\rangle -f(z_0)\langlex,z_0\rangle =0 \\\Longrightarrow f(x)=\langle x,\frac{\overline{f(z_0)}z_0}{\Vertz_0\Vert^2}\rangle =\langle x,y_0\rangle .\end{aligned}\]</span> 下面证明 <span class="math inline">\(y_0\)</span>的唯一性。略。</p><p>证毕。</p><p><strong>NOTE</strong>：实际上 <spanclass="math inline">\(N(f)^{\perp}\)</span> 是一维空间，也就是 <spanclass="math inline">\(\text{span}\{z_0\}\)</span>，因此我们随便从 <spanclass="math inline">\(N(f)^{\perp}\)</span> 中取一个向量 <spanclass="math inline">\(z_0\)</span> 乘以一个线性系数就能得到 <spanclass="math inline">\(f(x)\)</span>。</p><blockquote><p>显然 $g(x)=x,z_0$ 并不一定等于 <spanclass="math inline">\(f(x)\)</span>，那么我们怎么让他变化一下变成 <spanclass="math inline">\(f\)</span> 呢？看来需要对 <spanclass="math inline">\(g\)</span>做一些映射，最简单的做一个线性变换，考虑 <spanclass="math inline">\(g&#39;(x)=cg(x)\)</span>，要想让 <spanclass="math inline">\(g&#39;(x)=f(x)\)</span>，至少应该满足 <spanclass="math inline">\(g&#39;(z_0)=c\langle z_0,z_0\rangle=f(z_0)\Rightarrow g&#39;(x)=\langle x,\frac{\overline{f(z_0)}z_0}{\Vertz_0\Vert^2}\rangle =\langle x,y_0\rangle .\)</span>那么我们来验证一下是否任意的 <span class="math inline">\(x\in H\)</span>都有 <span class="math inline">\(g(x)=f(x)\)</span>？</p><p><span class="math inline">\(z_0\in N(f)^{\perp},\forall x\inN(f),g&#39;(x)=0\)</span> 没毛病，</p></blockquote></blockquote><p>假设 <span class="math inline">\(X,Y\)</span> 为 <spanclass="math inline">\(\mathbb{K}\)</span> 上的赋范空间，称 <spanclass="math inline">\(f:X\times Y\to \mathbb{K}\)</span>为<strong>共轭双线性泛函</strong>，若 <span class="math display">\[\begin{aligned}f(\lambda_1 x_1+\lambda_2 x_2,y)=\lambda_1 f(x_1,y)+\lambda_2 f(x_2,y)\\f(x,\lambda_1 y_1+\lambda_2 y_2)=\overline{\lambda_1}f(x,y_1)+\overline{\lambda_2} f(x,y_2)\end{aligned}\]</span> 称其为有界的，若 <span class="math inline">\(\existsC\ge0\)</span>，使 <span class="math display">\[|f(x,y)|\le C\Vert x\Vert \Vert y\Vert, \quad \forall x\in X, y\in Y\]</span> 定义其范数为 <span class="math display">\[\Vert f\Vert = \sup_{x\ne0,y\ne0} \frac{|f(x,y)|}{\Vert x\Vert \Verty\Vert}.\]</span> <strong>定理(F.Riesz)</strong>：<spanclass="math inline">\(H_1,H_2\)</span> 为 Hilbert 空间，<spanclass="math inline">\(f:H_1\times H_2\to \mathbb{K}\)</span>为有界共轭双线性泛函，则 <span class="math inline">\(\exists! S\inB(H_1,H_2), f(x,y)=\langle Sx,y\rangle ,x\in X,y\in Y.\)</span></p><p>证明：首先固定 <span class="math inline">\(x\in H_1\)</span>，只关注<span class="math inline">\(H_2 \to \mathbb{K}\)</span>，即 <spanclass="math inline">\(y\mapsto \overline{f(x,y)}\)</span>为有界线性泛函，因此可以 <span class="math inline">\(\exists!S_x\inH_1\)</span>，使得 <span class="math display">\[\overline{f(x,y)}=\langle y,S_x\rangle \Rightarrow f(x,y)=\langleS_x,y\rangle\]</span> 现在对 <span class="math inline">\(x\)</span> 任取，可以得到<span class="math inline">\(S:H_1\to H_2\)</span>，由于 <spanclass="math inline">\(f\)</span> 是有界共轭双线性的，容易验证 <spanclass="math inline">\(S\)</span> 为有界线性算子。证毕。</p><p>下面如果我们定义 <spanclass="math inline">\(g(x,y)=\overline{f(y,x)}=\langle x,Sy\rangle ,x\inH_2,y\in H_1\)</span>，那么 <span class="math inline">\(g\)</span>也是有界共轭双线性算子，并且根据上面的 Riesz 表示定理，<spanclass="math inline">\(\exists! T\in B(H_2，H_1)\)</span> 使得 <spanclass="math inline">\(g(x,y)=\langle Tx,y\rangle =\langle x,Sy\rangle.\)</span> 由此我们就导出了伴随算子的定义，我们称 <spanclass="math inline">\(S\)</span> 为 <spanclass="math inline">\(T\)</span> 的<strong>伴随算子</strong>，记为 <spanclass="math inline">\(S=T^{\star}\)</span>，并且根据上面的推导过程可以得到伴随算子是<strong>唯一的</strong>。</p><p>伴随算子有以下性质：</p><ul><li><span class="math inline">\(\Vert T^{\star}\Vert=\Vert T\Vert\)</span></li><li><span class="math inline">\((\lambda S+\muT)^{\star}=\bar{\lambda}S^\star + \bar\mu T^{\star}\)</span></li><li><span class="math inline">\((T^\star)^\star=T\)</span></li><li><span class="math inline">\(\Vert T^{\star}T\Vert=\VertTT^{\star}\Vert=\Vert T \Vert^2\)</span></li><li><span class="math inline">\(T^{\star}T=0 \iff T=0\)</span></li><li><span class="math inline">\((PS)^\star=S^\star P^\star\)</span></li></ul><p><em>例子 1</em>：伴随算子一个最简单的例子就是矩阵。<spanclass="math inline">\(H_1=H_2=\mathbb{K}^n,T\inB(H_1,H_2),\exists!A\)</span> 为 <span class="math inline">\(n\)</span>阶方针，使得 <span class="math inline">\(Tx=Ax\)</span>，容易验证 <spanclass="math inline">\(T^\star x=A^H x.\)</span></p><p><strong>定理</strong>：<span class="math inline">\(H_1,H_2\)</span>为 Hilbert 空间，<span class="math inline">\(T\in B(H_1,H_2)\)</span>为一一映射，则 <span class="math inline">\(T\)</span>为<strong>等距同构</strong>，当且仅当 <span class="math display">\[TT^\star=I_{H_2},\quad T^\star T=I_{H_1.}\]</span> 此时称 <span class="math inline">\(T\)</span> 为 <spanclass="math inline">\(H_1\)</span> 到 <spanclass="math inline">\(H_2\)</span> 的<strong>酉算子</strong>。</p><p>证明：要证明等距同构只需要验证 <span class="math inline">\(\langleTx,Ty\rangle _2=\langle x,y\rangle _1,\forall x,y\in H_1\)</span> 或者<span class="math inline">\(\langle T^\star x,T^\star y\rangle_1=\langle x,y\rangle _2,\forall x,y\in H_2\)</span>成立，做一下变换即可证明。证毕。</p><p><strong>NOTE</strong>：实际上这里可以联想到酉矩阵。</p><blockquote><p><strong>小结</strong>：这一小节最核心的内容就是 Riesz 表示定理，即<strong>Hilbert空间</strong>上任意<strong>有界线性泛函</strong>都可以<strong>唯一地</strong>表示为<span class="math display">\[f(x) = \langle x,z_0\rangle , \forall x\in H\]</span></p></blockquote>]]></content>
    
    
    <categories>
      
      <category>Functional Analysis</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Hilbert空间</tag>
      
      <tag>内积空间</tag>
      
      <tag>共轭双线性泛函</tag>
      
      <tag>伴随算子</tag>
      
      <tag>Riesz表示定理</tag>
      
      <tag>直和</tag>
      
      <tag>正交补</tag>
      
      <tag>标准正交基</tag>
      
      <tag>标准正交集</tag>
      
      <tag>Bessel不等式</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>泛函分析笔记2：赋范空间</title>
    <link href="/2020/11/10/functional-analysis/ch2-normed-space/"/>
    <url>/2020/11/10/functional-analysis/ch2-normed-space/</url>
    
    <content type="html"><![CDATA[<p>在度量空间中，我们重点关注的是两个元素之间的距离，而这一部分要引出来的赋范空间中，则对每个元素本身也赋予了“范数”，也就是“长度”。</p><h2 id="线性空间">1. 线性空间</h2><p>线性空间，可以简单理解为对线性运算封闭的集合。那么线性运算的形式是什么呢？常见的线性运算可以写为<span class="math inline">\(T(x;a)=\sum_ia_ix_i\)</span>，因此可以看出来包含了<strong>数乘</strong>和<strong>加法</strong>两种基本运算，因此线性空间必然需要对数乘和加法封闭，除此之外，为了保证运算体系的自洽性，我们还需要规定一些其他的运算规则。最后，给出来线性空间的定义：</p><span id="more"></span><p>考虑 <span class="math inline">\(\mathbb{K=C\ or\ R}, X\ne\varnothing,\forall x,y\in X,\forall\lambda\in\mathbb{K}\)</span>，可以定义 <spanclass="math inline">\(x+y\in X,\lambda x\in X\)</span>，如果满足</p><ol type="1"><li><span class="math inline">\(x+y=y+x\)</span></li><li><span class="math inline">\((x+y)+z=x+(y+z)\)</span></li><li><span class="math inline">\(\exists 0\in X,\forall x\in X,x+0=0+x=x\)</span></li><li><span class="math inline">\(\forall x,\exists! y\inX,x+y=0,y=-x\)</span></li><li><span class="math inline">\(\alpha(\betax)=(\alpha\beta)x\)</span></li><li><span class="math inline">\(1x=x\)</span></li><li><span class="math inline">\((\alpha+\beta)x=\alpha x+\betax\)</span></li><li><span class="math inline">\(\alpha(x+y)=\alpha x+\alphay\)</span></li></ol><p>则称 <span class="math inline">\(X\)</span> 为 <spanclass="math inline">\(\mathbb{K}\)</span>上的<strong>线性空间</strong>。</p><p><strong><em>例子 1</em></strong>：<spanclass="math inline">\(S=\{(x_n)_{n\ge1},x_n\in\mathbb{K}\}\)</span>，定义加法 <spanclass="math inline">\((x_n)_{n\ge1}+(y_n)_{n\ge1}=(x_n+y_n)_{n\ge1}\inS\)</span>，定义数乘 <spanclass="math inline">\(\lambda(x_n)_{n\ge1}=(\lambda x_n)_{n\ge1}\inS\)</span>，那么可以验证 <span class="math inline">\(S\)</span>为线性空间。</p><p><strong><em>例子 2</em></strong>：<spanclass="math inline">\(C[a,b]\)</span>，定义 <spanclass="math inline">\((f+g)(t)=f(t)+g(t), (\lambda f)(t)=\lambdaf(t)\)</span>，可以验证 <span class="math inline">\(C[a,b]\)</span>为线性空间。</p><p><strong>定义</strong>：<span class="math inline">\(X\)</span> 为<span class="math inline">\(\mathbb{K}\)</span> 上的线性空间，<spanclass="math inline">\(Y\subset X\)</span>，称 <spanclass="math inline">\(Y\)</span> 为 <spanclass="math inline">\(X\)</span> 的线性子空间，若 <spanclass="math inline">\(\forall x,y\in Y,\forall\lambda\in\mathbb{K}\)</span>，有 <span class="math inline">\(x+y\inY,\lambda x\in Y\)</span>，并且 <span class="math inline">\(Y\)</span>本身也是线性空间。</p><p><strong><em>例子 3</em></strong>：<spanclass="math inline">\(\ell^\infty \subset S\)</span> 是线性空间。</p><p><strong><em>例子 4</em></strong>：<span class="math inline">\(\ell^p\subset S,1\le p &lt; \infty\)</span> 是线性空间。</p><p><strong><em>例子 5</em></strong>：<span class="math inline">\(\ell^p\subset c_0(x_n\to0的序列\{(x_n)\}) \subset c(x_n收敛的序列) \subset\ell^\infty\subset S(无穷维序列)\)</span>，每一个都是线性空间。</p><p><strong><em>例子 6</em></strong>：<spanclass="math inline">\(P\)</span> 所有多项式的集合，<spanclass="math inline">\(P\subset C[a,b]\)</span> 也是线性空间。</p><p><strong>命题</strong>：若 <span class="math inline">\(X\)</span>为线性空间，<span class="math inline">\((Y_i)_{i\in I}\)</span> 为 <spanclass="math inline">\(X\)</span> 的一族线性子空间，则 <spanclass="math inline">\(Y=\bigcap_{i\in I}Y_i\)</span> 仍然是 <spanclass="math inline">\(X\)</span> 的线性子空间。</p><p><strong>定义</strong>：<span class="math inline">\(X\)</span>为线性空间，<span class="math inline">\(M\subset X\)</span> 非空，令<span class="math inline">\(\mathcal{E}\)</span> 为所有包含 <spanclass="math inline">\(M\)</span> 的线性子空间，那么一定有 <spanclass="math inline">\(X\in\mathcal{E}\)</span>，因此 <spanclass="math inline">\(\mathcal{E}\)</span> 一定非空。令 <spanclass="math inline">\(Z=\bigcap_{Y\in\mathcal{E}}Y\)</span> 也一定是<span class="math inline">\(X\)</span> 的线性子空间，记 <spanclass="math inline">\(Z=\text{span}(M)\)</span> 称为 <spanclass="math inline">\(M\)</span> <strong>生成的线性子空间</strong>。</p><p><strong>命题</strong>：若 <span class="math inline">\(M\subsetX\)</span> 非空，那么 <span class="math inline">\(Z=\text{span}(M) =\{\sum_i^n \lambda_i x_i,n\ge1,x_i\inM,\lambda_i\in\mathbb{K}\}\)</span> 为包含 <spanclass="math inline">\(M\)</span> 的 <spanclass="math inline">\(X\)</span> 的<strong>最小线性子空间</strong>。</p><p>证明：略。</p><p><strong><em>例子 1</em></strong>：<spanclass="math inline">\(X=S,e_n=(0,\cdots,0,1,0,\cdots)\in S,M=\{e_n,n\ge1\}\subset S\)</span>，则 <spanclass="math inline">\(\text{span}(M)=c_{00}\)</span>(只有有限个元素非零的无穷维序列)。</p><p><strong>定义</strong>：<span class="math inline">\(M\subsetX\)</span> 为<strong>线性无关</strong>的，若 <spanclass="math inline">\(\forall x_1,...,x_n\in M\)</span> 两两不等，都有<span class="math inline">\(x_1,...,x_n\)</span>都线性无关(也即任意有限个元素都线性无关)。</p><p><strong><em>例子 2</em></strong>：<spanclass="math inline">\(X=C[a,b],\alpha_1&lt;\alpha_2&lt;\cdots&lt;\alpha_n\le\cdots,f_n=e^{\alpha_n t}\in C[a,b]\)</span>，那么取 <spanclass="math inline">\(M=\{f_1,f_2,\cdots\}\)</span> 是线性无关的 <spanclass="math inline">\(\iff \forall n\ge1, f_1,...,f_n\)</span>线性无关。</p><p><em>证明</em>：利用线性相关的定义，重复求导、相减的过程，细节略。</p><p><strong>定义</strong>： <span class="math inline">\(X\)</span>为线性空间，若 <span class="math inline">\(X\)</span> 中存在 <spanclass="math inline">\(n\)</span> 个元素线性无关，但任意 <spanclass="math inline">\(n+1\)</span> 个元素都线性相关，则称 <spanclass="math inline">\(X\)</span> 为 <spanclass="math inline">\(n\)</span> <strong>维</strong>的，记为 <spanclass="math inline">\(\text{dim}X=n\)</span>。若 <spanclass="math inline">\(\forall n\ge1,\exists x_!,...,x_n\)</span>线性无关，则称 <span class="math inline">\(X\)</span>为<strong>无穷维</strong>的。</p><p><strong>命题</strong>：<spanclass="math inline">\(\text{dim}X=n,\forall x\in X\)</span>都存在唯一的系数 <span class="math inline">\(a_1,...,a_n\)</span> 使得<span class="math inline">\(x=a_1x_1+\cdots+a_nx_n\)</span>。</p><p>证明：略。</p><p>对于复空间 <span class="math inline">\(\mathbb{C}^n\)</span>，认为<span class="math inline">\(\text{dim}\mathbb{C}^n=2n\)</span>。</p><p><strong>定义</strong>：<span class="math inline">\(X\)</span>为线性空间，<span class="math inline">\(M\subset X\)</span> 线性无关，若<span class="math inline">\(\text{span}(M)=X\)</span>，则称 <spanclass="math inline">\(M\)</span> 为 <spanclass="math inline">\(X\)</span> 的 <strong>Hamel 基</strong>。</p><blockquote><p><strong>命题</strong>：<span class="math inline">\(\forall x\inX\)</span>，则 <span class="math inline">\(\exists x_1,...,x_n\inM\)</span> 两两不等，<span class="math inline">\(\exists\lambda_1,...,\lambda_n\in\mathbb{K}\)</span> 均不为 0，使得 <spanclass="math inline">\(x=\lambda_1 x_1+...+\lambda_nx_n\)</span>，并且上述<strong>表示唯一</strong>。</p><p>证明：略。</p></blockquote><p><strong><em>例子 1</em></strong>：<spanclass="math inline">\(\{e_1,e_1,...\}\)</span> 为 <spanclass="math inline">\(c_{00}\)</span> 的 Hamel 基。</p><p><strong>定理</strong>：<span class="math inline">\(X\)</span>为线性空间，<span class="math inline">\(M\subset X\)</span> 线性无关，则<span class="math inline">\(\exists N\)</span> 为 <spanclass="math inline">\(X\)</span> 的 Hamel 基，使得 <spanclass="math inline">\(M\subset N\)</span>。</p><blockquote><p><strong>小结</strong>：这一部分主要是讲解了线性空间的定义，最关键的概念就在于</p><ol type="1"><li>对于加法和数乘封闭；</li><li>可以找到一组基，任意向量都可以用基的线性组合来表示，并且表示方法唯一。</li></ol></blockquote><h2 id="赋范空间与banach空间">2. 赋范空间与Banach空间</h2><p>假设 <span class="math inline">\(X\)</span> 为 <spanclass="math inline">\(\mathbb{K}\)</span> 上的线性空间，定义范数运算<span class="math inline">\(\Vert\cdot\Vert:X\to\mathbb{R}\)</span>，满足如下条件：</p><ol type="1"><li><span class="math inline">\(\Vert x\Vert \ge 0\)</span></li><li><span class="math inline">\(\Vert x\Vert =0\iff x=0\)</span></li><li><span class="math inline">\(\Vert\lambda x\Vert=|\lambda|\cdot\Vertx\Vert\)</span></li><li><span class="math inline">\(\forall x,y\in X, \Vert x+y\Vert\le\Vert x\Vert + \Vert y\Vert\)</span></li></ol><p>则称 <span class="math inline">\(\Vert\cdot\Vert\)</span> 为 <spanclass="math inline">\(X\)</span> 上的范数，<spanclass="math inline">\((X,\Vert\cdot\Vert)\)</span>为<strong>赋范空间</strong>。</p><p><strong>定义</strong>：在赋范空间中，<spanclass="math inline">\(\forall x,y\in X\)</span>，若定义 <spanclass="math inline">\(d(x,y)=\Vert x-y\Vert\)</span>，那么该方法定义的<span class="math inline">\(d(x,y)\)</span> 也是度量，称为 <spanclass="math inline">\(\Vert\cdot\Vert\)</span><strong>诱导的度量</strong>。若此时 <spanclass="math inline">\((X,d)\)</span> 为<strong>完备空间</strong>，则称<span class="math inline">\((X,\Vert\cdot\Vert)\)</span> 为<strong>Banach 空间</strong>（即完备的赋范空间）。</p><p><strong>注</strong>：由于范数的定义中第 3 条存在，以及诱导度量只有<span class="math inline">\(x-y\)</span>决定，使得诱导度量相比于一般定义的度量还具有一些特别性质，例如：</p><ul><li>平移不变性 <spanclass="math inline">\(d(x+a,y+a)=d(x+y)\)</span></li><li>齐次性 <span class="math inline">\(d(\lambda x,\lambda y)=|\lambda|d(x,y)\)</span></li></ul><p><strong><em>例子 1</em></strong>：<spanclass="math inline">\((\mathbb{K}^n,\Vert\cdot\Vert_\infty),(\mathbb{K}^n,\Vert\cdot\Vert_p),(\ell^\infty,\Vert\cdot\Vert_\infty),(\ell^p,\Vert\cdot\Vert_p),(c_{0},\Vert\cdot\Vert_\infty),(c,\Vert\cdot\Vert_\infty)\)</span>均为 Banach 空间。</p><p><strong><em>例子 2</em></strong>：<spanclass="math inline">\(S=\{(x_n)_{n\ge1},x_n\in\mathbb{K}\},d(x,y)=\sum_n\frac{1}{2^n}\frac{|x_n-y_n|}{1+|x_n-y_n|}\)</span>，<strong>不存在</strong><span class="math inline">\(S\)</span> 上的范数 <spanclass="math inline">\(\Vert\cdot\Vert\)</span> 使 <spanclass="math inline">\(d\)</span> 被诱导出，因为 <spanclass="math inline">\(d\)</span> 不满足齐次性。</p><p><strong><em>例子 3</em></strong>：<spanclass="math inline">\((C[a,b],\Vert\cdot\Vert_\infty)\)</span> 为 Banach空间，<span class="math inline">\((C[a,b],\Vert\cdot\Vert_p)\)</span>不是 Banach 空间。</p><p><strong><em>例子4</em></strong>：离散度量不满足齐次性，因此不可能由范数诱导出。</p><p><strong>命题 1</strong>：<spanclass="math inline">\((X,\Vert\cdot\Vert_\infty)\)</span>为赋范空间，<span class="math inline">\(Y\)</span> 为 <spanclass="math inline">\(X\)</span> 的线性子空间。若 <spanclass="math inline">\(Y\)</span> 为 Banach 空间，则 <spanclass="math inline">\(Y\)</span> 在 <spanclass="math inline">\(X\)</span> 中必为闭集。</p><p><strong>命题 2</strong>：<spanclass="math inline">\((X,\Vert\cdot\Vert_\infty)\)</span> 为 Banach空间，<span class="math inline">\(Y\subset X\)</span>为闭集线性子空间，则 <span class="math inline">\(Y\)</span> 必为 Banach空间。</p><p>证明：赋范空间的线性子空间仍然是赋范空间，完备空间一定要是闭集。细节略。</p><blockquote><p>只需要掌握关键点，那么上面的命题都可以由下面的关键点轻松导出：</p><ol type="1"><li>完备空间一定是闭集；完备空间的子空间也完备 <spanclass="math inline">\(\iff\)</span> 该子空间为闭集；</li><li>赋范空间 + 完备性 = Banach 空间。</li></ol></blockquote><p><strong>命题</strong>：若 <spanclass="math inline">\((X,\Vert\cdot\Vert)\)</span> 为 Banach 空间，<spanclass="math inline">\(x_n\in X\)</span>，且 <spanclass="math inline">\(\sum_n^\infty \Vert x_n\Vert &lt;\infty\)</span>，则 <span class="math inline">\(\sum^\infty x_n\)</span>收敛。</p><p>证明：完备空间中，证明序列收敛可以证明序列是柯西列。</p><p><strong>定义</strong>：<spanclass="math inline">\((X,\Vert\cdot\Vert)\)</span> 为赋范空间，<spanclass="math inline">\(e_n\in X(n\ge 1)\)</span>，称 <spanclass="math inline">\((e_n)_{n\ge1}\)</span> 为 <spanclass="math inline">\(X\)</span> 的一组 <strong>Schauder 基</strong>，若<span class="math inline">\(\forall x\in X, \exists !\lambda_n,x=\sum^\infty_n \lambda_n e_n\)</span>。</p><p><strong>命题</strong>：若 <span class="math inline">\(X\)</span> 有Schauder 基，那么 <span class="math inline">\(X\)</span>一定是可分的。</p><p>证明：可以取 <span class="math inline">\(M=\{\sum^n_{i=1}x_ie_i \inX, n\ge1, x_i\in\mathbb{Q} \}\)</span>，是可数个可数集的并。</p><blockquote><p>Hamel 基与 Schauder 基的区别：</p><ol type="1"><li>最主要的区别是 Hamel 基可以是有限维也可以是无穷维的，这由集合 <spanclass="math inline">\(X\)</span> 的维数决定，而 Schauder基则只定义在无穷维上；</li><li>前者针对线性空间，后者针对 Banach 空间。</li></ol></blockquote><h2 id="有限维赋范空间">3. 有限维赋范空间</h2><p>有限维赋范空间相比于一般的赋范空间有很多很好的性质，比如所有范数等价、有限维赋范空间都是Banach 空间。</p><p>假设 <span class="math inline">\(X\)</span> 为 <spanclass="math inline">\(\mathbb{K}\)</span> 上的线性空间，并且存在两个范数<spanclass="math inline">\(\Vert\cdot\Vert_1,\Vert\cdot\Vert_2\)</span>，称二者等价，若<span class="math display">\[\exists \alpha,\beta &gt; 0,\forall x\in X,\quad \alpha\Vert x\Vert_1\le\Vert x\Vert_2\le \beta\Vert x\Vert_2\]</span> 此时 <spanclass="math inline">\((X,\Vert\cdot\Vert_1),(X,\Vert\cdot\Vert_2)\)</span>有：</p><ul><li>相同的收敛列、柯西列；</li><li>相同的开集、闭集、闭包、内部；</li><li><span class="math inline">\((X,\Vert\cdot\Vert_1)\)</span> Banach<span class="math inline">\(\iff (X,\Vert\cdot\Vert_2)\)</span>Banach；</li></ul><blockquote><p><strong>引理</strong>：<spanclass="math inline">\((X,\Vert\cdot\Vert)\)</span>，<spanclass="math inline">\(Y\subset X\)</span> 为有限维线性子空间，设 <spanclass="math inline">\(e_1,...,e_n\)</span> 为 <spanclass="math inline">\(Y\)</span> 的一组基，则 <spanclass="math inline">\(\exists c &gt; 0,\forall \lambda_1,...,\lambda_n\in \mathbb{K}\)</span>，有 <span class="math display">\[c(|\lambda_1|+\cdots+|\lambda_n|) \le \Vert\lambda_1e_1+\cdots+\lambda_n e_n\Vert \le \max_i\Vert e_i\Vert(|\lambda_1|+\cdots+|\lambda_n|)\]</span> 证明：需要用到 Bolzano-Weierstrass定理，即<strong>有界列存在收敛子列</strong>。反证法，证明略。</p><p><strong>定理</strong>：若 <spanclass="math inline">\(\text{dim}X&lt;\infty\)</span>，则 <spanclass="math inline">\(X\)</span>上的<strong>范数互相等价</strong>，且均为 Banach 空间。</p><p>证明：只需要证明所有范数与 <spanclass="math inline">\(\Vert\cdot\Vert_1\)</span> 范数等价，且 <spanclass="math inline">\((X,\Vert\cdot\Vert_1)\)</span> 构成 Banach空间。</p></blockquote><p><strong>推论</strong>：<spanclass="math inline">\((X,\Vert\cdot\Vert)\)</span>，若 <spanclass="math inline">\(Y\subset X\)</span> 为有限维线性子空间，则 <spanclass="math inline">\(Y\)</span> 为闭集。</p><p>有限维赋范空间除了这个良好的性质（一定是 Bananch空间）之外，还有其他的好性质。下面引入紧集的概念。</p><p><strong>定义</strong>：<spanclass="math inline">\((X,d)\)</span>，<spanclass="math inline">\(M\subset X\)</span> 为紧集，若 <spanclass="math inline">\(\forall x_n\in M,\exists n_k\uparrow\infty,\exists x\in M, x_{n_k}\to x(k\to \infty).\)</span></p><p>实际上，紧集的概念跟完备性的概念有点像，前者是任意序列一定存在收敛子列，后者说明柯西列一定是收敛列。他们都跟序列的收敛性有关，后面也可以看到，他们都跟闭集有一定的关系。</p><p>实际上，紧集一定是有界闭集，但是闭集不一定是紧集。不过对于有限维赋范空间来说，二者等价，后面会有定理专门证明。</p><p><strong>定理</strong>：<span class="math inline">\((X,d)\)</span>，若<span class="math inline">\(M\subset X\)</span>为<strong>紧集</strong>，则 <span class="math inline">\(M\)</span>一定<strong>完备</strong>，并且一定是<strong>有界闭集</strong>。</p><p><strong>定理</strong>：<spanclass="math inline">\((X,d)\)</span>，<spanclass="math inline">\(M\subset X\)</span> 为紧集，<spanclass="math inline">\(N\subset M\)</span>，则 <spanclass="math inline">\(N\)</span> 为紧集 <span class="math inline">\(\iffN\)</span> 为闭集。</p><p>证明：略。</p><p><strong>定理</strong>：<spanclass="math inline">\((X,\Vert\cdot\Vert)\)</span>，<spanclass="math inline">\(\text{dim}X=n&lt;\infty\)</span>，<spanclass="math inline">\(M\subset X\)</span> 为紧集 <spanclass="math inline">\(\iff M\)</span> 为有界闭集。</p><p><strong>证明</strong>：必要性易证，充分性证明的关键是首先找到 Hamel基表示，将在 <span class="math inline">\(M\)</span>中寻找收敛子列的任务分解到对每一个坐标维度上寻找收敛子列，而这可以根据Bolzano-Weiertrass 定理得到，然后再根据每个坐标为度上的收敛子列得到<span class="math inline">\(M\)</span> 中的收敛子列。证毕。</p><p><strong>引理</strong>：<spanclass="math inline">\((X,\Vert\cdot\Vert)\)</span>，<spanclass="math inline">\(M\subsetneq X\)</span> 为闭集线性子空间，对于<span class="math inline">\(\forall 0 &lt; \theta &lt; 1\)</span>，<spanclass="math inline">\(\exists z\in X,\Vert z\Vert =1,\forall y\inM,\Vert z-y\Vert \ge \theta.\)</span></p><p><strong>证明</strong>：固定 <span class="math inline">\(\forall v\inY^c\)</span>，令 <span class="math inline">\(a=\inf_{y\in Y}\Vertv-y\Vert\)</span>，那么 <spanclass="math inline">\(a&gt;0\)</span>，否则的话与 <spanclass="math inline">\(Y\)</span> 是闭集相矛盾。因此存在 <spanclass="math inline">\(y_0\in Y\)</span> 使得 <spanclass="math inline">\(a\le \Vert v-y_0\Vert \lea/\varepsilon\)</span>。那么我们就可以把这个 <spanclass="math inline">\(v\)</span> 平移到 <spanclass="math inline">\(0\)</span> 点附近，同时也把对应的 <spanclass="math inline">\(y_0\)</span> 平移到原点附近，也就是取 <spanclass="math inline">\(y=\frac{v-y_0}{\Vert v-y_0\Vert}\)</span>，那么<span class="math inline">\(\Vert y\Vert=1\)</span>，并且可以验证 <spanclass="math inline">\(\forall z\in X\)</span>，都有 <spanclass="math inline">\(\Vert y-z\Vert \ge \varepsilon.\)</span>证毕。</p><p><strong>定理</strong>(F.Riesz)：<spanclass="math inline">\((X,\Vert\cdot\Vert)\)</span>，则 <spanclass="math inline">\(\text{dim}X&lt;\infty \iff \bar{B}(0,1)\)</span>为紧集。</p><p><strong>证明</strong>：必要性易证。充分性可以利用反证法，若维度无穷，则可以构造出特殊的序列，使得序列中任意两个元素的距离都大于<spanclass="math inline">\(1/2\)</span>（这要用到上一个引理），从而不存在收敛子列，即<span class="math inline">\(\bar{B}(0,1)\)</span> 不是紧集。证毕。</p><p><strong>推论</strong>：<spanclass="math inline">\((X,\Vert\cdot\Vert)\)</span>，则 <spanclass="math inline">\(\text{dim}X&lt;\infty\iff S(0,1)=\{x:\Vertx\Vert=1\}\)</span> 为紧集。</p><p><strong>定义</strong>：<spanclass="math inline">\((X,d)\)</span>，<spanclass="math inline">\(M\subset X\)</span> 非空，<spanclass="math inline">\(x_0\in X\)</span>，令 <spanclass="math display">\[\rho(x_0, M) = \inf_{y\in M} d(x_0, y)\]</span> 称为 <span class="math inline">\(x_0\)</span> 到 <spanclass="math inline">\(M\)</span> 的距离。若 <spanclass="math inline">\(\exists y_0\in M\)</span>，使得 <spanclass="math inline">\(\rho(x_0,M)=d(x_0,y_0)\)</span>，则称 <spanclass="math inline">\(y_0\)</span> 为 <spanclass="math inline">\(x_0\)</span> 在 <spanclass="math inline">\(M\)</span> 中的最佳逼近元。</p><p><strong>命题</strong>：设 <span class="math inline">\(M\)</span>为非空紧集，则 <span class="math inline">\(\forall x_0 \inX\)</span>，<span class="math inline">\(x_0\)</span> 在 <spanclass="math inline">\(M\)</span> 中的最佳逼近元存在。</p><p><strong>命题</strong>：<span class="math inline">\((X,d), M\)</span>为 <span class="math inline">\(X\)</span> 的有限维线性子空间，<spanclass="math inline">\(\forall x_0\in X, \rho(x_0,M)=\inf_{y\in M}\{\Vertx_0-y\Vert\}\)</span>，则 <span class="math inline">\(x_0\)</span> 在<span class="math inline">\(M\)</span> 中的最佳逼近元一定存在。</p><p>证明：略。</p><blockquote><p><strong>小结</strong>：本部分主要证明了有限维赋范空间的良好性质：</p><ol type="1"><li>有限维赋范空间<strong>所有范数等价</strong>，且均为 <strong>Banach空间</strong>；</li><li>有限维赋范空间<strong>紧集</strong>（即任意序列存在收敛子列） <spanclass="math inline">\(\iff\)</span> <strong>有界闭集</strong>；</li></ol></blockquote><h2 id="有界线性算子">4. 有界线性算子</h2><h3 id="线性算子">4.1 线性算子</h3><p><strong>定义</strong>：<span class="math inline">\(X,Y\)</span> 为<span class="math inline">\(\mathbb{K}\)</span> 上的线性子空间，<spanclass="math inline">\(D(T)\subset X\)</span> 为线性子空间，<spanclass="math inline">\(T:D(T)\to Y\)</span>为<strong>线性算子</strong>，若 <span class="math inline">\(\forallx,y\in D(T),\forall \lambda \in \mathbb{K}\)</span>，都有 <spanclass="math display">\[T(x+y)=Tx+Ty,\quad T(\lambda x)=\lambda Tx \\\iff T(\lambda x+\mu y) = \lambda Tx + \mu Ty.\]</span> <strong>定义</strong>：零空间 <spanclass="math inline">\(N(T)=\text{ker}(T)=\{x\in D(T),Tx=0\}=T^{-1}(0),\)</span> 像空间 <span class="math inline">\(R(T)=\{Tx,x\in D(T)\}.\)</span></p><p><strong>命题</strong>：<span class="math inline">\(N(T)\)</span> 为<span class="math inline">\(D(T)\)</span> 的线性子空间，<spanclass="math inline">\(R(T)\)</span> 为 <spanclass="math inline">\(Y\)</span> 的线性子空间。</p><p><strong>命题</strong>：<span class="math inline">\(T\)</span> 为单射<span class="math inline">\(N(T)=\{0\}\)</span>。</p><p><strong>命题</strong>：<span class="math inline">\(M\subsetD(T)\)</span> 为 <span class="math inline">\(n\)</span> 维线性子空间，则<span class="math inline">\(\text{dim} T(M) \le n\)</span>。</p><p>证明：略。</p><h3 id="算子范数">4.2 算子范数</h3><p><strong>定义</strong>：对于线性算子，若 <spanclass="math inline">\(\exists c\ge 0,\forall x\in D(T), \Vert Tx\Vert_Y\le c\Vert x\Vert_X\)</span>，则称 <spanclass="math inline">\(T\)</span>是<strong>有界的</strong>。使该式成立的最小 <spanclass="math inline">\(c\)</span> 称为 <spanclass="math inline">\(T\)</span> 的<strong>范数</strong>，等价于 <spanclass="math display">\[\Vert T\Vert = \sup_{x\in D(T),x\ne 0} \frac{\Vert Tx\Vert}{\Vertx\Vert} = \sup_{x\in D(T),\Vert x\Vert \le 1} \frac{\Vert Tx\Vert}{\Vertx\Vert} = \sup_{x\in D(T),\Vert x\Vert &lt; 1} \frac{\VertTx\Vert}{\Vert x\Vert}\]</span> <strong><em>例子 1</em></strong>：<spanclass="math inline">\(X=Y=C[0,1],(Tx)(t)=\int_0^tx(\tau)d\tau\)</span>，则 <span class="math inline">\(\Vert T\Vert = 1,x(t)\equiv1\)</span> 时取到。</p><p><strong><em>例子 2</em></strong>：<spanclass="math inline">\(X=C[-1,1],f(x)=\int_{-1}^0x(t)dt -\in_0^1x(t)dt,|f(x)|\le 2\Vert x\Vert_\infty\)</span>，但是 <spanclass="math inline">\(2\)</span> 取不到。</p><p><strong><em>例子 3</em></strong>：<spanclass="math inline">\(T:C^1[0,1]\to C[0,1],T(x)=x&#39;\)</span>，那么<span class="math inline">\(T\)</span>为线性<strong>无界</strong>算子。令 <spanclass="math inline">\(x_n(t)=t^n,t\in[0,1]\)</span>，则 <spanclass="math inline">\((Tx_n)(t)=nt^{n-1}.\)</span></p><p><strong><em>例子 4</em></strong>：<spanclass="math inline">\(A=(a_{ij})_{n\timesn},a_{ij}\in\mathbb{K},Tx=Ax.\Vert T\Vert=?\)</span></p><p><strong>定理</strong>：<span class="math inline">\(X,Y\)</span> 为<span class="math inline">\(\mathbb{K}\)</span> 上的赋范空间，假设 <spanclass="math inline">\(\text{dim}X=n&lt;\infty\)</span>，<spanclass="math inline">\(T:X\to Y\)</span> 是线性算子，那么 <spanclass="math inline">\(T\)</span> 一定是有界的。</p><p>证明：用基来表示 <span class="math inline">\(X\)</span>中的元素，并利用性质 <span class="math inline">\(\Vert\lambda_1e_1+\cdots+\lambda_n e_n\Vert \gec(|\lambda_1|+\cdots+|\lambda_n|)\)</span> 即可得证。证毕。</p><p><strong>定理</strong>：<span class="math inline">\(X,Y\)</span> 为<span class="math inline">\(\mathbb{K}\)</span> 上的赋范空间，<spanclass="math inline">\(T:X\to Y\)</span> 是线性算子，那么以下命题等价</p><ol type="1"><li><span class="math inline">\(T\)</span> 有界</li><li><span class="math inline">\(T\)</span> 处处连续</li><li><span class="math inline">\(T\)</span> 在 <spanclass="math inline">\(X\)</span> 上某一点连续</li></ol><p><strong>证明</strong>：<spanclass="math inline">\((1)\to(2),(2)\to(3)\)</span> 易证；</p><p><span class="math inline">\((2)\to(1)\)</span>：由于 <spanclass="math inline">\(T\)</span> 连续，在 <spanclass="math inline">\(x=0\)</span> 点附近，存在 <spanclass="math inline">\(\delta&gt;0, \forall x \inB(0,\delta)\)</span>，有 <span class="math inline">\(\VertTx\Vert\le1\)</span>，因而 <span class="math inline">\(\Vert Tx\Vert \le\frac{2}{\delta}\Vert x\Vert\)</span>；</p><p><span class="math inline">\((3)\to(2)\)</span>：由于 <spanclass="math inline">\(T\)</span> 为线性算子，那么只要在任一 <spanclass="math inline">\(x_0\)</span> 点处连续，经过平移可以得到 <spanclass="math inline">\(T\)</span> 在任意一点处都连续。</p><p>证毕。</p><p><strong>推论</strong>：<span class="math inline">\(X,Y\)</span> 为<span class="math inline">\(\mathbb{K}\)</span> 上的赋范空间，<spanclass="math inline">\(T:X\to Y\)</span> 线性有界，那么 <spanclass="math inline">\(N(T)\)</span> 为 <spanclass="math inline">\(X\)</span> 的闭集线性子空间。</p><p>用符号 <span class="math inline">\(B(X,Y)\)</span> 来表示 <spanclass="math inline">\(X\to Y\)</span> 的有界线性算子。</p><p><strong>定理</strong>：假设 <span class="math inline">\(X\)</span>为赋范空间，<span class="math inline">\(Y\)</span> 为 Banach 空间，那么<span class="math inline">\(B(X,Y)\)</span> 为 Banach 空间。</p><p>证明：略。</p><blockquote><p><strong>小结</strong>：本部分定义了线性算子，以及有界线性算子的范数。由于<strong>有界线性算子等价于连续算子</strong>，今后主要研究的也是有界线性算子。</p></blockquote><h2 id="有界线性泛函">5. 有界线性泛函</h2><p>从赋范空间 <span class="math inline">\(X\)</span> 到 <spanclass="math inline">\(\mathbb{K}\)</span> 的线性算子称为 <spanclass="math inline">\(X\)</span> 上的<strong>线性泛函</strong>。</p><p><strong>定义</strong>：<spanclass="math inline">\((X,\Vert\cdot\Vert)\)</span>，用 <spanclass="math inline">\(X&#39;\)</span> 表示 <spanclass="math inline">\(X\)</span> 上所有有界线性泛函全体，称之为 <spanclass="math inline">\(X\)</span> 的<strong>拓扑对偶空间</strong>。</p><p>若 <span class="math inline">\(X\)</span> 上的一组基为 <spanclass="math inline">\(\{e_1,e_2,\cdots\}\)</span>（有限维或者无限维均可），那么<span class="math inline">\(f:X\to\mathbb{K}\)</span> 由 <spanclass="math inline">\(f(e_1),f(e_2),\cdots\)</span> 唯一确定。</p><p><strong>定义</strong>：<span class="math inline">\((X,Y)\)</span>赋范空间，若存在线性算子 <span class="math inline">\(T:X\toY\)</span>，并且 <span class="math inline">\(\Vert Tx\Vert_Y = \Vertx\Vert_X,\forall x\in X\)</span>，则称 <spanclass="math inline">\(X,Y\)</span>为<strong>等距同构</strong>的，因此可以视 <spanclass="math inline">\(X,Y\)</span> 为同一空间。</p><p><strong>命题</strong>：<spanclass="math inline">\((\mathbb{K}^n,\Vert\cdot\Vert_2)&#39; =(\mathbb{K}^n,\Vert\cdot\Vert_2)\)</span>（此命题的含义为 <spanclass="math inline">\((\mathbb{K}^n,\Vert\cdot\Vert_2)\)</span>的对偶空间等价于 <span class="math inline">\(n\)</span>维空间，也就是说每一个有界线性泛函都可以映射为 <spanclass="math inline">\(\mathbb{K}^n\)</span> 上的一个点/向量）</p><p>证明：略。</p><p>对于形如 <span class="math inline">\((X,\Vert\cdot\Vert_1)&#39; =(Y,\Vert\cdot\Vert_2)\)</span> 的命题，证明思路如下。</p><p><strong>证明</strong>：要想证明两个空间等价，那么只需要找到一个线性映射<span class="math inline">\(T:(X,\Vert\cdot\Vert_1)&#39; \to(Y,\Vert\cdot\Vert_2)\)</span>，使得映射前后在两个空间的范数相等。考虑对<span class="math inline">\(\forall f\in(X,\Vert\cdot\Vert_1)&#39;\)</span>，取 <spanclass="math inline">\(f\mapsto(f(e_1),f(e_2),\cdots,f(e_n))\)</span>，那么按照以下步骤证明：</p><ol type="1"><li>证明对于任意 <span class="math inline">\(\forall f\in(X,\Vert\cdot\Vert_1)&#39;\)</span>，的确有 <spanclass="math inline">\((f(e_1),f(e_2),\cdots,f(e_n))\inY\)</span>，即映射的源空间和像空间的确是 <spanclass="math inline">\(X,Y\)</span>；</li><li>证明 <span class="math inline">\(T\)</span> 为单射（即证明若 <spanclass="math inline">\(Tf=Tg\)</span>，那么有 <spanclass="math inline">\(f=g\)</span>）；</li><li>证明 <span class="math inline">\(T\)</span> 为满射，此时 <spanclass="math inline">\(T\)</span> 为双射（即证明 <spanclass="math inline">\(\forall \alpha \in Y\)</span>，存在 <spanclass="math inline">\(f \in (X,\Vert\cdot\Vert_1)&#39;\)</span> 使得<span class="math inline">\(Tf=\alpha\)</span>，一般需要构造线性算子<span class="math inline">\(f\)</span>）；</li><li>证明 <span class="math inline">\(\Vert Tf\Vert = \Vertf\Vert\)</span>。</li></ol><p>证毕。</p><p>因此按照上面的方法，还可以证明如下几个命题。</p><ul><li><span class="math inline">\((\mathbb{K}^n,\Vert\cdot\Vert_p)&#39; =(\mathbb{K}^n,\Vert\cdot\Vert_q),\frac{1}{p}+\frac{1}{q}=1\)</span></li><li><span class="math inline">\((c_0, \Vert\cdot\Vert_\infty)&#39;=(\ell^1,\Vert \cdot\Vert_1)\)</span></li><li><span class="math inline">\((\ell^1,\Vert\cdot\Vert_1)&#39;=(\ell^\infty,\Vert \cdot\Vert_\infty)\)</span></li><li><span class="math inline">\((\ell^p,\Vert\cdot\Vert_p)&#39;=(\ell^q,\Vert \cdot\Vert_q)\)</span></li></ul><blockquote><p><strong>小结</strong>：有界线性泛函可以映射到某个我们熟悉的空间，对于后面的处理很有用。</p></blockquote>]]></content>
    
    
    <categories>
      
      <category>Functional Analysis</category>
      
    </categories>
    
    
    <tags>
      
      <tag>线性空间</tag>
      
      <tag>赋范空间</tag>
      
      <tag>Banach空间</tag>
      
      <tag>Hamel基</tag>
      
      <tag>Schauder基</tag>
      
      <tag>线性算子</tag>
      
      <tag>算子范数</tag>
      
      <tag>线性泛函</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>泛函分析笔记1：度量空间</title>
    <link href="/2020/10/18/functional-analysis/ch1-metric-space/"/>
    <url>/2020/10/18/functional-analysis/ch1-metric-space/</url>
    
    <content type="html"><![CDATA[<p>这一章节研究度量空间的基本结构，在开始前，我们需要思考几个问题：</p><ol type="1"><li>什么是度量空间？</li><li>我们为什么要首先学习度量空间呢？</li></ol><p>在这篇笔记的最后再来回答这个问题。</p><span id="more"></span><h2 id="度量空间定义">1. 度量空间定义</h2><p>对于工科生来说，“空间”这个概念还是比较模糊的，但是我本人在学习数学的过程中发现很多数学的分支学科都是对于某个空间进行研究，比如欧氏空间、内积空间、测度空间、拓扑空间、希尔伯特空间，以及这门课要学习的度量空间等等。</p><p>个人觉得，定义空间的同时往往伴随着相应的某种运算的定义，也就是说我们研究空间的时候，主要还是为了研究某些运算，为了保证运算前后的结果都有比较好的性质（或者说便于处理），我们才抽象出了对应的空间的概念。回到这门课，泛函分析里面将要遇到的空间都是度量空间，因此我们首先需要知道他的定义。</p><p><strong>“度量”实际上指的就是抽象的“距离”</strong>，比如两个点的距离、两个向量的距离、两个无穷长序列的距离、两个连续函数的距离。尽管点、向量、无穷长序列、连续函数的形式差别很大，但是如果我们都把他们抽象成为高维空间中的一个点，我们可以用相似的方式定义距离（也就是度量）的概念。</p><p>这样一来，由于<strong>大多数时候我们关心的是两个高维点之间的相对距离，而不是他们本身的绝对坐标</strong>（比如我们研究数列收敛性<span class="math inline">\(x_n\to x\)</span> 的时候，只需要分析 <spanclass="math inline">\(|x_n-x|\to 0\)</span> 是否成立，而不太关心 <spanclass="math inline">\(x\)</span>具体是什么），因此抽象出距离这个概念之后，我们就可以把点、向量、序列、连续函数都统一的看待，用统一的方法和理论处理相似的问题。</p><p>首先，我们可以抽象出一个集合 <spanclass="math inline">\(X\)</span>。<span class="math inline">\(X\)</span>可以是一个实数点集，比如 <spanclass="math inline">\(X=\mathbb{R}\)</span>；也可以是一个多维实空间<spanclass="math inline">\(X=\mathbb{R}^n\)</span>，他的元素就是向量；也可以是连续函数集<span class="math inline">\(X=C[a,b]\)</span>，表示区间 <spanclass="math inline">\([a,b]\)</span> 上的所有连续函数构成的集合。</p><p>现在问题的关键就是<strong>如何定义度量</strong>？当然不能随意定义，我们必须要他满足一定条件，才能称之为度量：</p><ol type="1"><li><span class="math inline">\(\forall x,y\in X,d(x,y)\ge0\)</span>;</li><li><span class="math inline">\(x,y\in X, d(x,y)=0 \iffx=y\)</span></li><li><span class="math inline">\(\forall x,y\in X,d(x,y)=d(y,x)\)</span></li><li><span class="math inline">\(\forall x,y,z\in X, d(x,y)\led(x,z)+d(z,y)\)</span></li></ol><p>根据定义可以看出来，度量就是一种距离，称 <spanclass="math inline">\((X,d)\)</span>为<strong>度量空间</strong>（或<strong>距离空间</strong>）。下面给出一些度量空间的例子，要证明是否是度量只需要验证几条定义即可。</p><p><strong>注</strong>：后面的内容基本都默认我们是在度量空间 <spanclass="math inline">\((X,d)\)</span>中讨论，为了书写省劲，一般都没有明确写出来“存在度量空间 <spanclass="math inline">\((X,d)\)</span>”，但是需要注意我们是在度量空间中讨论的。</p><p><strong><em>例子 1(离散度量)</em></strong>：定义 <spanclass="math display">\[d(x,y) = \begin{cases}0, &amp; x=y \\1, &amp; x\ne y\end{cases}\]</span> <strong><em>例子 2</em></strong>：记 <spanclass="math inline">\(X=\mathbb{K}\)</span>，其中我们记 <spanclass="math inline">\(\mathbb{K}=\mathbb{R} \text{ or }\mathbb{C}\)</span>（后面的笔记也都保持这个习惯），<spanclass="math inline">\(d(x,y)=|x-y|\)</span>，那么 <spanclass="math inline">\((X,d)\)</span> 是一个度量空间。</p><p><strong><em>例子 3</em></strong>：<spanclass="math inline">\(X=\mathbb{K}^n,d_p(\boldsymbol{x,y})=\|\boldsymbol{x-y}\|_p = (\sum_i|x_i-y_i|^p)^{1/p}\)</span>，对于 <span class="math inline">\(1\le p \le\infty\)</span>，<span class="math inline">\((X,d_p)\)</span>是度量空间。</p><p><strong><em>例子 4</em></strong>：<spanclass="math inline">\(X=\ell^p,d_p(\boldsymbol{x,y})=\|\boldsymbol{x-y}\|_p\)</span>，对于<span class="math inline">\(1\le p\le \infty\)</span>，<spanclass="math inline">\((\ell^p,d_p)\)</span> 是度量空间。其中 <spanclass="math display">\[\ell^p = \left\{(x_n)_{n\ge1},\ x_n\in\mathbb{K},\ \exists c\ge0,\|x_n|\le c  \right\}\]</span> 这个在证明的过程中需要证明 <span class="math inline">\(\forallx,y\in\ell^p\)</span>，都有 <span class="math inline">\(x+y \in\ell^p\)</span>。</p><p>例子3、4的证明过程中还需要用到两个比较重要的不等式：Hölder 不等式和Minkowski 不等式。</p><blockquote><p><strong>Hölder不等式</strong>：<span class="math inline">\(\forall1\le p,q\le\infty, \frac{1}{p}+\frac{1}{q}=1,\forallx,y\in\mathbb{R}^n\)</span>，有 <span class="math display">\[\sum_{i=1}^{n}|x_iy_i| \le \|x\|_p \|y\|_q\]</span> 当 <span class="math inline">\(p=q=2\)</span>的时候，上面的式子就退化成 Cauchy-Schwarz 不等式。</p><p><strong>证明</strong>：可以取 <spanclass="math inline">\(u(t)=t^{p-1},t\ge0\)</span>，反函数就有 <spanclass="math inline">\(t=u^{\frac{1}{p-1}}=u^{q-1},u\ge0\)</span>。考虑可能有下面两种情况：</p><p><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2020/1-holder.png" /></p><p>以第一种情况为例，<span class="math inline">\(\int_0^\alpha t^{p-1}dt+ \int_0^\beta u^{q-1}du = \frac{\alpha^p}{p}+\frac{\beta^q}{q} \ge\alpha\beta\)</span>，第二种情况也有相同的结果。我们可以首先假设 <spanclass="math inline">\(\|x\|_p = \|y\|_q=1\)</span>，因而就有 <spanclass="math display">\[|x_iy_i| \le \frac{|x_i|^p}{p} + \frac{|y_i|^q}{q} \\\Longrightarrow \sum |x_iy_i| \le 1 = \|x\|_p \|y\|_q\]</span> 如果 <span class="math inline">\(\|x\|_p \ne1\)</span>，那么我们可以取 <span class="math inline">\(x&#39; =x/\|x\|_p\)</span>，代入上面的情况就能得到 Hölder 不等式了。证毕。</p><p><strong>Minkowski 不等式</strong>：<spanclass="math inline">\(\forall x,y\in\ell^p, p\ge1\)</span>，都有 <spanclass="math display">\[\|x+y\|_p \le \|x\|_p + \|y\|_p .\]</span> <strong>证明</strong>：</p><p>证毕。</p></blockquote><p>对于空间 <span class="math inline">\(\ell^p\)</span>还有如下有趣的<strong>性质</strong>：</p><ul><li>若 <span class="math inline">\(1\le p\le q\)</span>，则 <spanclass="math inline">\(\ell^p \subset \ell^q\)</span></li><li><span class="math inline">\(\lim_{p\downarrow 1} \|x\|_p =\|x\|_1\)</span></li><li><span class="math inline">\(\lim_{p\uparrow 1} \|x\|_p =\|x\|_\infty\)</span></li></ul><p><strong><em>例子 5(无穷维向量)</em></strong>：定义 <spanclass="math inline">\(S=\{(x_n)_{n\ge1},x_n\in\mathbb{K}\}\)</span>，定义如下度量 <span class="math display">\[d(x,y) = \sum_{n=1}^\infty\frac{1}{2^n}\frac{|x_n-y_n|}{1+|x_n-y_n|}&lt; \infty\]</span> 则 <span class="math inline">\((S,d)\)</span> 是度量空间。</p><p><strong><em>例子 6(连续函数)</em></strong>：<spanclass="math inline">\(X=C[a,b],\ d_p(x,y) = \left(\int_a^b|x(t)-y(t)|^pdt\right)^{1/p},\ 1\le p\le\infty\)</span>，则 <spanclass="math inline">\((X,d)\)</span> 是度量空间。</p><h2 id="开集">2. 开集</h2><p>上面一小节分析了度量空间 <span class="math inline">\((X,d)\)</span>中度量 <span class="math inline">\(d\)</span>的定义，这一部分研究一下集合 <span class="math inline">\(X\)</span>的性质。我们主要从<strong>开集和闭集</strong>这个角度来分析集合的结构。</p><p>需要注意的是在实空间 <span class="math inline">\(\mathbb{R}\)</span>当中我们对开集（开区间）都比较熟悉了，但是还有很多其他很复杂的集合，比如上面提到的连续函数构成的集合<spanclass="math inline">\(C[a,b]\)</span>，这种情况下什么是<strong>开集</strong>呢？这个时候我们就需要抽象出“开集”这个概念最为本质的性质了。</p><h3 id="开集的定义">2.1 开集的定义</h3><p><strong>定义</strong>：开球 <spanclass="math inline">\(B(x_0,\delta)=\{x\in X,\d(x,x_0)&lt;\delta\}\)</span>，闭球 <spanclass="math inline">\(\bar{B}(x_0,\delta)=\{x\in X,\d(x,x_0)\le\delta\}\)</span>，球面 <spanclass="math inline">\(S(x_0,\delta)=\{x\in X,\d(x,x_0)=\delta\}.\)</span></p><p><strong>定义</strong>：<span class="math inline">\((X,d),M\subsetX\)</span>，称 <span class="math inline">\(x_0\in M\)</span> 为 <spanclass="math inline">\(M\)</span> 的<strong>内点</strong>，若 <spanclass="math inline">\(\exists \delta&gt;0, B(x_0,\delta)\subsetM\)</span>，<span class="math inline">\(M\)</span> 的所有内点的集合称为<span class="math inline">\(M\)</span> 的内部，记为 <spanclass="math inline">\(\mathring{M}\)</span>。</p><p><strong>定义</strong>：<span class="math inline">\(M\)</span>为<strong>开集</strong> <span class="math inline">\(\iff M=\mathring{M}\iff \forall x\in M,\ \exists \delta&gt;0,\ B(x,\delta)\subsetM\)</span>。</p><p><strong>定义</strong>：<span class="math inline">\(F\subsetX\)</span> 为<strong>闭集</strong> <span class="math inline">\(\iffF^c=X\setminus F\)</span> 为开集。</p><p><strong>定义</strong>：<strong>闭包</strong> <spanclass="math inline">\(\bar{M}=\{x\in X,\ \forall \delta&gt;0,\B(x,\delta)\cap M\ne \varnothing \}.\)</span></p><p><strong>注 1</strong>：有的集合可能既不是开集，也不是闭集！比如实空间<span class="math inline">\(\mathbb{R}\)</span> 中区间 <spanclass="math inline">\([0,1)\)</span>。</p><p><strong>注 2</strong>：但是假如现在考虑的不是实空间，而是 <spanclass="math inline">\(X=[0,+\infty)\)</span>，那么 <spanclass="math inline">\([0,1)\)</span>就是开集！判断是否是开集还是要根据定义！</p><p><strong><em>例子 1(离散度量空间)</em></strong>：<spanclass="math inline">\((X,d)\)</span> 为离散度量空间，那么任意的 <spanclass="math inline">\(M\subset X\)</span>都是既开又闭的集合。因为我们可以取 <span class="math inline">\(\forallx\in M,\ B(x,1/2)=\{x\}\subset M\)</span>。</p><h3 id="开集的性质">2.2 开集的性质</h3><p><strong>命题</strong>：<spanclass="math inline">\(\mathring{M}\)</span> 为包含在 <spanclass="math inline">\(M\)</span> 中的最大开集。</p><p><strong>证明</strong>：分为三个过程：1）<spanclass="math inline">\(\mathring{M}\subset M\)</span>；<strong>2）<spanclass="math inline">\(\mathring{M}\)</span> 为开集；</strong>3）<spanclass="math inline">\(\mathring{M}\)</span> 最大。注意不要忘了第 2)部分，细节略。</p><p><strong>定理</strong>：<spanclass="math inline">\((X,d)\)</span>，则</p><ul><li><span class="math inline">\(X,\varnothing\)</span> 为开集</li><li><span class="math inline">\((G_i)_{i\in I}\)</span> 为一族开集，则<span class="math inline">\(\bigcup_{i\in I}G_i\)</span>为开集（<strong>开集无限并</strong>仍然是开集）；</li><li><span class="math inline">\(G_1,...,G_n\)</span> 为开集，则 <spanclass="math inline">\(\bigcap_{i=1}^n G_i\)</span>为开集（<strong>开集有限交</strong>仍然是开集）；</li></ul><p>证明：略。</p><p><strong>定理</strong>：<spanclass="math inline">\((X,d)\)</span>，则</p><ul><li><span class="math inline">\(X,\varnothing\)</span> 为闭集（注意<span class="math inline">\(X,\varnothing\)</span> 既开又闭）</li><li><span class="math inline">\((F_i)_{i\in I}\)</span> 为一族开集，则<span class="math inline">\(\bigcap_{i\in I}F_i\)</span>为开集（<strong>闭集无限交</strong>仍然是闭集）；</li><li><span class="math inline">\(F_1,...,F_n\)</span> 为开集，则 <spanclass="math inline">\(\bigcup_{i=1}^n F_i\)</span>为开集（<strong>闭集有限并</strong>仍然是闭集）；</li></ul><p>证明：略。</p><p><strong>性质</strong>：闭包 <spanclass="math inline">\(\bar{M}\)</span> 为闭集，且 <spanclass="math inline">\(\bar{M}\)</span> 为包含 <spanclass="math inline">\(M\)</span> 的最小闭集。</p><p><strong>推论</strong>：<span class="math inline">\((X,d), M\subsetX\)</span>，<span class="math inline">\(M\)</span> 为闭集 <spanclass="math inline">\(\iff M=\bar{M}.\)</span></p><p>证明：略。</p><blockquote><p><strong>拓扑空间</strong></p><p>拓扑的定义是：给集合 <span class="math inline">\(X\)</span>指定拓扑，就是指定集合 <span class="math inline">\(X\)</span>中哪些子集是开集，指定的方式需要满足：</p><ol type="1"><li><span class="math inline">\(R,\varnothing\)</span> 是开集；</li><li>开集的有限交仍然是开集；</li><li>开集的任意并仍然是开集。</li></ol><p><span class="math inline">\(X\)</span> 上的<strong>拓扑</strong><span class="math inline">\(\mathcal{T}\)</span> 是 <spanclass="math inline">\(X\)</span> 的子集族，满足上述的条件。定义了拓扑<span class="math inline">\(\mathcal{T}\)</span> 的集合 <spanclass="math inline">\(X\)</span>称为<strong>拓扑空间</strong>。对于拓扑空间 <spanclass="math inline">\((X,\mathcal{T})\)</span> 有子集 <spanclass="math inline">\(\mathcal{O}\)</span>，若 <spanclass="math inline">\(\mathcal{O}\in \mathcal{T}\)</span>，则称 <spanclass="math inline">\(\mathcal{O}\)</span> 为开集。</p><p><strong>注1</strong>：先有拓扑 <spanclass="math inline">\(\mathcal{T}\)</span>，然后如果 <spanclass="math inline">\(X\)</span> 的子集 <spanclass="math inline">\(\mathcal{O}\in \mathcal{T}\)</span>，才有 <spanclass="math inline">\(\mathcal{O}\)</span> 是开集的说法。</p><p><strong>注2</strong>：拓扑空间跟度量空间类似，首先定义了一种运算，比如度量空间是需要定义度量，拓扑空间是需要定义对开集封闭的运算（有限交、任意并），其中的元素对这些运算封闭，然后才有空间的概念.</p></blockquote><h3 id="稠密与可分">2.3 稠密与可分</h3><p><strong>定义</strong>：称 <span class="math inline">\(M\subsetX\)</span> 是 <span class="math inline">\(X\)</span>的<strong>稠密子集</strong>，若 <spanclass="math inline">\(\bar{M}=X\)</span>。换一种表述方式，也就是说 <spanclass="math inline">\(\forall x\in X,\forall \delta &gt; 0,B(x,\delta)\cap M\ne \varnothing\)</span>。</p><p><strong><em>例子 1</em></strong>：<spanclass="math inline">\((\mathbb{R},d)\)</span>，其中 <spanclass="math inline">\(d(x,y)=|x-y|\)</span>，则 <spanclass="math inline">\(\bar{\mathbb{Q}}=\mathbb{R}.\)</span></p><p><strong><em>例子 2</em></strong>：<spanclass="math inline">\((\mathbb{C},d)\)</span>，其中 <spanclass="math inline">\(d(x,y)=|x-y|\)</span>，则 <spanclass="math inline">\(\overline{\mathbb{Q}+i\mathbb{Q}}=\mathbb{C}.\)</span></p><p><strong><em>例子 3</em></strong>：<spanclass="math inline">\((\mathbb{R}^n,d_2)\)</span>，则 <spanclass="math inline">\(\overline{\mathbb{Q}^n}=\mathbb{R}^n.\)</span></p><p><strong><em>例子 4</em></strong>：对于 <spanclass="math inline">\(1\le p\le \infty\)</span>，定义 <spanclass="math inline">\(M=\{(x_n)_{n\ge1},\ x_n\in\mathbb{Q},\existsN,\forall n\ge N, x_n=0 \}\)</span>，那么对于度量 <spanclass="math inline">\(d_p\)</span>，有 <spanclass="math inline">\(\bar{M}=\ell^p.\)</span></p><p><strong>性质</strong>：对于两个度量 <spanclass="math inline">\(d_1,d_2\)</span>，如果存在 <spanclass="math inline">\(c_1,c_2&gt;0\)</span>，对 <spanclass="math inline">\(\forall x,y\in X\)</span>，都有 <spanclass="math inline">\(c_1d_1(x,y)\le d_2(x,y)\le c_2d_1(x,y)\)</span>，也即这两个度量相互控制，那么对任意 <spanclass="math inline">\(M\subset X\)</span>，有 <spanclass="math inline">\(M\)</span>的<strong>闭包相同</strong>，<strong>内部也相同</strong>。</p><p><strong><em>例子 5</em></strong>：对于离散度量空间，<spanclass="math inline">\(X\)</span> 的稠密子集只有 <spanclass="math inline">\(X\)</span> 本身。</p><p><strong><em>例子 6</em></strong>：<spanclass="math inline">\(X=C[a,b]\)</span>，<spanclass="math inline">\(d_\infty(x,y)=\max_{t\in[a,b]}|x(t)-y(t)|\)</span>，因此 <span class="math inline">\(M=\{多项式p(t)=a_0+a_1t+\cdots+a_Nt^N,a_i\in\mathbb{Q}\}\)</span>，则 <spanclass="math inline">\(\bar{M}=X.\)</span></p><p><strong>定义</strong>：称度量空间 <spanclass="math inline">\((X,d)\)</span> 是<strong>可分</strong>的，若 <spanclass="math inline">\(\exists M\)</span>为至多可数集（有限集或者可数集），并且 <spanclass="math inline">\(\bar{M}=X.\)</span></p><p>这里先介绍几个关于<strong>可数集</strong>的性质：</p><ul><li>若 <span class="math inline">\(X_1,...,X_n\)</span> 可数，则 <spanclass="math inline">\(X_1\times \cdots \times X_n\)</span> 可数</li><li><strong>可数个</strong>可数集的<strong>并集</strong>仍然是可数集</li></ul><p><strong><em>例子 1</em></strong>：<spanclass="math inline">\(\{0,1\}^{\mathbb{N}}\)</span><strong>不是可数集</strong>！其中 <spanclass="math inline">\(\mathbb{N}\)</span> 为自然数集。</p><p><strong><em>例子 2</em></strong>：<spanclass="math inline">\((\mathbb{K}^n, d_p)\)</span> 可分。</p><p><strong><em>例子 3</em></strong>：<spanclass="math inline">\((\ell^p,d_p)\)</span> 可分，<spanclass="math inline">\(M\)</span> 与上面例子 4 的定义相同。</p><p><strong><em>例子 4</em></strong>：<spanclass="math inline">\((C[a,b],d_\infty)\)</span> 可分，<spanclass="math inline">\(M\)</span> 与上面例子 6 的定义相同。</p><p><strong><em>例子 5</em></strong>：<spanclass="math inline">\((\ell^\infty,d_\infty)\)</span><strong>不可分</strong>。</p><p><em>证明</em>：反证法。参考课本 P14，略。</p><h2 id="收敛性与完备性">3. 收敛性与完备性</h2><p>这一部分则开始考虑 <span class="math inline">\(X\)</span>中的元素序列，以及序列的极限是否存在、极限是什么的问题。之所以考虑序列这件事情，是因为我们实际中处理问题的时候往往是用序列去逼近一个元素，序列当中的每个元素可能是简单的，二最后去逼近的这个元素往往是不太显然或者比较复杂的东西。这样我们只需要证明序列中的元素满足某些性质，就能证明最后的极限具有某些特殊性质，更容易处理。</p><h3 id="序列收敛性">3.1 序列收敛性</h3><p>我们对<strong>序列收敛性</strong>的定义是对于 <spanclass="math inline">\(x_n,x\in\mathbb{R}\)</span>，称 <spanclass="math inline">\(x_n\)</span> 收敛到 <spanclass="math inline">\(x\)</span>，记为 <spanclass="math inline">\(x_n\to x\)</span> (<spanclass="math inline">\(\lim_{n\to\infty} x_n=x\)</span>)，若 <spanclass="math inline">\(\forall \varepsilon&gt; 0,\exists N,\ \forall n\geN\)</span>，都有 <spanclass="math inline">\(|x_n-x|&lt;\varepsilon\)</span>。换一种表述方式就是在度量空间<span class="math inline">\((X,d)\)</span> 中，<spanclass="math inline">\(d(x_n,x)\to 0\)</span>。</p><p><strong>注</strong>：需要注意的是只有 <spanclass="math inline">\(x\in X\)</span>，我们才能说 <spanclass="math inline">\(x_n\to x\)</span>。例如取 <spanclass="math inline">\(X=(0,1),x_n=\frac{1}{n+1}\)</span>，那么 <spanclass="math inline">\(x_n\)</span> 在 <spanclass="math inline">\(X\)</span> 中<strong>不收敛</strong>。</p><p><strong>命题</strong>：若 <span class="math inline">\(x_n\tox\)</span>，则 <span class="math inline">\(\{x_n\}_{n\ge1}\)</span>为有界集合，且 <span class="math inline">\(x\)</span> 唯一。</p><p><strong>定理</strong>：度量空间 <spanclass="math inline">\((X,d)\)</span>，有 <spanclass="math inline">\(M\subset X\)</span>，那么</p><ul><li><span class="math inline">\(x\in \bar{M} \iff \exists x_n\in M,\x_n\to x\)</span>；</li><li><span class="math inline">\(M\)</span> 为<strong>闭集</strong> <spanclass="math inline">\(\iff \forall x_n\in M\)</span>，设 <spanclass="math inline">\(x_n\to x\in X\)</span>，则 <spanclass="math inline">\(x\inM\)</span>（即<strong>闭集对极限封闭</strong>）。</li></ul><p>证明：第一条应用定义，第二条应用第一条的结论。细节略。</p><h3 id="柯西列与完备性">3.2 柯西列与完备性</h3><p><strong>定义</strong>：<span class="math inline">\(x_n\inX\)</span>，称 <span class="math inline">\(x_n\)</span>为<strong>柯西列</strong>，若 <span class="math inline">\(\forall\varepsilon &gt; 0,\exists N, \forall m,n\ge N\)</span>，则 <spanclass="math inline">\(d(x_m,x_n)&lt;\varepsilon\)</span>。称 <spanclass="math inline">\(X\)</span> 是<strong>完备</strong>的，若 <spanclass="math inline">\(\forall x_n\in X\)</span> 为柯西列，则 <spanclass="math inline">\(\exists x\in X,x_n \to x\)</span>。</p><p><strong>注</strong>：实际上，收敛列一定是柯西列，即 <spanclass="math inline">\(\{收敛列\} \subset \{柯西列\}\)</span>；而如果<span class="math inline">\(X\)</span>又是完备的，那么说明柯西列也一定是收敛列。因此 <spanclass="math inline">\(X\)</span> 完备 <span class="math inline">\(\iff\{柯西列\}=\{收敛列\}\)</span>。</p><p><strong>命题</strong>：<span class="math inline">\(x_n\)</span>为柯西列，则 <span class="math inline">\(\{x_n,n\ge 1\}\)</span>为有界集。</p><p><strong><em>例子 1</em></strong>：<spanclass="math inline">\((\mathbb{R},d_1)\)</span> 完备；<spanclass="math inline">\((\mathbb{K}^n, d_p)\)</span> 完备；<spanclass="math inline">\((\ell^\infty, d_\infty)\)</span> 完备；<spanclass="math inline">\((\ell^p,d_p)\)</span> 完备；<spanclass="math inline">\((C[a,b],d_\infty)\)</span> 完备。</p><p><strong><em>证明</em></strong>：证明完备性的套路：</p><ol type="1"><li>任取柯西列 <span class="math inline">\(x_n\in X\)</span>；</li><li>找到可能的极限 <span class="math inline">\(x\)</span>；</li><li>证明 <span class="math inline">\(x\in X\)</span>；</li><li>证明 <span class="math inline">\(x_n\to x\)</span>。</li></ol><p><strong><em>例子 2</em></strong>：<spanclass="math inline">\((C[a,b], d_p)\)</span><strong>不完备</strong>（反例如下图所示）；<spanclass="math inline">\(\mathbb{Q}\)</span> 不完备（因为不是闭集）；<spanclass="math inline">\(c_{00}\)</span>（有限个元素不为零的序列）不完备。</p><p><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2020/2-example.jpg" /></p><p><strong>定理</strong>：度量空间 <spanclass="math inline">\((X,d)\)</span></p><ul><li><span class="math inline">\(\forall Y\subset X\)</span> 为完备的，则<span class="math inline">\(Y\)</span> 为闭集；</li><li>若 <span class="math inline">\((X,d)\)</span> 完备，则 <spanclass="math inline">\(\forall Y\subset X\)</span> 完备 <spanclass="math inline">\(\iff Y\)</span> 为闭集。</li></ul><p>证明：第一条应用闭集对极限封闭的性质；第二条反向应用 <spanclass="math inline">\((X,d)\)</span> 完备的性质。细节略。</p><p><strong>定理</strong>：若 <span class="math inline">\(x_n\inC[a,b],x_n\rightrightarrows x\)</span>（一致收敛），则 <spanclass="math inline">\(x\in C[a,b]\)</span>。</p><h2 id="映射与连续性">4. 映射与连续性</h2><p>前面从单个度量空间的角度来考虑元素的性质，现在考虑两个度量空间的对应关系，也就是映射。</p><p>对于实空间的映射 <span class="math inline">\(f:(a,b)\to\mathbb{R}\)</span>，我们对连续性的定义为：<spanclass="math inline">\(f\)</span> 在 <spanclass="math inline">\(t_0\in(a,b)\)</span> 处连续，若 <spanclass="math inline">\(\lim_{t\tot_0}f(t)=f(t_0)\)</span>。由于我们在度量空间中已经定义了距离，因此可以将其推广至度量空间。</p><p>假设有度量空间 <span class="math inline">\((X_1,d_1)\)</span> 和<span class="math inline">\((X_2,d_2)\)</span>，映射 <spanclass="math inline">\(T:X_1 \to X_2\)</span>。</p><p><strong>定义</strong>：称映射 <span class="math inline">\(T\)</span>在 <span class="math inline">\(t=t_0\)</span>处<strong>连续</strong>，若 <span class="math inline">\(\forall\varepsilon &gt; 0,\ \exists \delta &gt; 0\)</span>，使得 <spanclass="math inline">\(\forall t\in X_1,\d_1(t,t_0)&lt;\delta\)</span>，都有 <span class="math inline">\(d_2(Tt,Tt_0)&lt;\varepsilon\)</span>。若 <span class="math inline">\(T\)</span>在 <span class="math inline">\(\forall t\in X_1\)</span> 处都连续，则称<span class="math inline">\(T\)</span> 为<strong>连续映射</strong>。</p><p><strong><em>例子 1</em></strong>：若 <spanclass="math inline">\((X_1,d_1)\)</span> 为离散度量空间，那么任意 <spanclass="math inline">\(T:X_1 \to X_2\)</span>一定是连续映射。证明只需要套用定义，取 <spanclass="math inline">\(\delta=1/2\)</span> 即可。</p><p><strong><em>例子 2</em></strong>(Lipschitz 连续)：<spanclass="math inline">\(\exists c&gt;0,\ \forall s,t\in X_1\)</span> 都有<span class="math inline">\(d_2(Ts,Tt)&lt; c d_1(s,t)\)</span>，那么<span class="math inline">\(T\)</span> 是连续映射。</p><p><strong>定理</strong>：<span class="math inline">\(T\)</span>为<strong>连续映射</strong> <span class="math inline">\(\iff \forallG\subset X_2\)</span> 为开集，那么 <spanclass="math inline">\(T^{-1}(G)=\{x\in X_1, Tx\in G\}\)</span> 是 <spanclass="math inline">\(X_1\)</span> 中的开集。</p><p><strong>证明</strong>："<spanclass="math inline">\(\Longrightarrow\)</span>"：若已知 <spanclass="math inline">\(T\)</span> 连续，<spanclass="math inline">\(G\)</span> 为开集</p><p><span class="math inline">\(G\)</span> 为开集，就有 <spanclass="math inline">\(\forall x_0\in T^{-1}(G),\exists \varepsilon &gt;0,\ B(Tx_0,\varepsilon)\subset G\)</span></p><p>由于 <span class="math inline">\(T\)</span> 连续，则一定 <spanclass="math inline">\(\exists \delta &gt; 0\)</span>，使得 <spanclass="math inline">\(\forall x\in B(x_0, \delta)\)</span>，都有 <spanclass="math inline">\(Tx\in B(Tx_0,\varepsilon)\)</span>，因而 <spanclass="math inline">\(B(x_0,\varepsilon)\subset X_1\)</span></p><p>故 <span class="math inline">\(T^{-1}(G)\)</span> 为开集。</p><p>"<span class="math inline">\(\Longleftarrow\)</span>"：假设 <spanclass="math inline">\(\forall G\subset X_2\)</span> 为开集，<spanclass="math inline">\(T^{-1}(G)\)</span> 在 <spanclass="math inline">\(X_1\)</span>中也是开集，那么套用连续映射的定义，就能证明 <spanclass="math inline">\(T\)</span> 为连续映射。</p><p>证毕。</p><p><strong>推论</strong>：<span class="math inline">\(T\)</span>为<strong>连续映射</strong> <span class="math inline">\(\iff \forallF\subset X_2\)</span> 为闭集，那么 <spanclass="math inline">\(T^{-1}(F)=\{x\in X_1, Tx\in F\}\)</span> 是 <spanclass="math inline">\(X_1\)</span> 中的闭集。</p><p><strong>定理</strong>：<span class="math inline">\(T\)</span> 在<span class="math inline">\(x_0\)</span> 处连续 <spanclass="math inline">\(\iff \forall x_n\in X_1, x_n\to x_0\)</span>，则<span class="math inline">\(Tx_n \to Tx_0\)</span>。</p><p><strong>证明</strong>："<spanclass="math inline">\(\Longrightarrow\)</span>"：应用定义；</p><p>"<span class="math inline">\(\Longleftarrow\)</span>"：反证法，假设<span class="math inline">\(T\)</span> 在 <spanclass="math inline">\(x_0\)</span> 处不连续，</p><p>那么 <span class="math inline">\(\exists \varepsilon_0 &gt; 0,\forall\delta &gt;0, \exists x\in B(x_0, \delta)\)</span>，使得 <spanclass="math inline">\(d(Tx_0, Tx) &gt; \varepsilon_0\)</span></p><p>可以取 <span class="math inline">\(\delta =1/n\)</span>，由此构造出一个序列 <span class="math inline">\(x_n \inB(x_0,1/n)\)</span>，</p><p>可以知道 <span class="math inline">\(x_n\to x_0\)</span>，但是却有<span class="math inline">\(d(x_n,x_0) \ge\varepsilon_0\)</span>，与假设矛盾。</p><p>证毕。</p><p><strong>推论</strong>：<span class="math inline">\(T:X_1\toX_2\)</span> 处处连续 <span class="math inline">\(\iff \forall x_n\to x,Tx_n \to Tx\)</span>。</p><h2 id="banach-不动点定理">5. Banach 不动点定理</h2><p>不动点想必大家在别的地方都或多或少听说过或者用过，应该是解决很多问题的重要工具。在这一部分的内容里面则可以看到，前面讲的序列收敛性、映射在不动点定理当中的应用。</p><p><strong>定义</strong>：考虑 <spanclass="math inline">\(X\ne\varnothing, T:X\to X\)</span>，若 <spanclass="math inline">\(x_0\in X,Tx_0=x_0\)</span>，则称 <spanclass="math inline">\(x_0\)</span> 为 <spanclass="math inline">\(T\)</span> 的<strong>不动点</strong>。</p><p><strong>定义</strong>：<span class="math inline">\(T:X\toX\)</span>，假设 <span class="math inline">\(\exists 0\le \alpha &lt;1\)</span>，使得 <span class="math inline">\(\forall x,y\inX\)</span>，都有 <span class="math inline">\(d(Tx,Ty) \le \alphad(x,y)\)</span>，则称 <span class="math inline">\(T\)</span>为<strong>压缩映射</strong>。</p><p><strong>定理(Banach不动点定理)</strong>：假设 <spanclass="math inline">\((X,d)\)</span>为<strong>非空、完备</strong>度量空间，<spanclass="math inline">\(T:X\to X\)</span> 为压缩映射，则 <spanclass="math inline">\(T\)</span> <strong>存在唯一</strong>的不动点。</p><p><strong>证明</strong>：考虑 <span class="math inline">\(x_0\inX,x_1=Tx_0,\cdots,x_n=Tx_{n-1},\cdots\)</span>，那么可以首先证明 <spanclass="math inline">\(x_n\)</span> 为柯西列，进而存在收敛值 <spanclass="math inline">\(x\)</span>。 由于 <spanclass="math inline">\(d(x_n,x_{n+1})=d(x_n,Tx_n)\to0\)</span>，从而趋向于 <spanclass="math inline">\(x=Tx\)</span>。之后再证明唯一性。证毕。</p><p><strong>定理</strong>：假设 <spanclass="math inline">\((X,d)\)</span> <strong>非空完备</strong>，<spanclass="math inline">\(T:X\to X\)</span>，设 <spanclass="math inline">\(\exists m\ge1\)</span>，<spanclass="math inline">\(T^m\)</span> 为压缩映射，则 <spanclass="math inline">\(\exists! x\in X\)</span> 使得 <spanclass="math inline">\(Tx=x\)</span>。</p><p><strong>证明</strong>：只需要证明 <spanclass="math inline">\(S=T^m\)</span> 的不动点都是 <spanclass="math inline">\(T\)</span> 的不动点，反之 <spanclass="math inline">\(T\)</span> 的不动点也都是 <spanclass="math inline">\(S\)</span> 的不动点即可。</p><p>由不动点定理可知，<span class="math inline">\(S\)</span>存在唯一一个不动点，记为 <span class="math inline">\(y_0\)</span>，即<span class="math inline">\(Sy_0=y_0\)</span>，那么 <spanclass="math inline">\(STy_0=T^{m+1}y_0=TSy_0=Ty_0\)</span>，即 <spanclass="math inline">\(Ty_0\)</span> 也是 <spanclass="math inline">\(S\)</span> 的不动点，因此一定有 <spanclass="math inline">\(Ty_0=y_0\)</span>，即 <spanclass="math inline">\(y_0\)</span> 也是 <spanclass="math inline">\(T\)</span> 的不动点。假设 <spanclass="math inline">\(z_0\)</span> 是 <spanclass="math inline">\(T\)</span> 的不动点，那么很容易证明他也是 <spanclass="math inline">\(S\)</span> 的不动点。因此 <spanclass="math inline">\(T\)</span> 存在唯一不动点。证毕。</p><p><strong><em>例子 1</em></strong>：<spanclass="math inline">\(c&gt;0\)</span>，求 <spanclass="math inline">\(\sqrt{c}\)</span> 的数值解。可以用数值迭代，取<spanclass="math inline">\(f(x)=(x+\frac{c}{x})/2,D=[\sqrt{c},+\infty)\)</span>，求不动点即可。</p><p><strong><em>例子 2</em></strong>：<spanclass="math inline">\((X=\mathbb{K}^n,d_\infty),C\in\mathbb{K}^{n\timesn},b\in\mathbb{K}^n\)</span>，映射 <spanclass="math inline">\(Tx=Cx+b\)</span>。容易证明若 <spanclass="math inline">\(\forall i,\sum_j|a_{ij}|&lt;1\)</span>，则 <spanclass="math inline">\(T\)</span> 为压缩映射。</p><p><strong><em>例子 3</em></strong>：考虑 <spanclass="math inline">\((t_0,x_0)\in\mathbb{R}^2,a,b&gt;0\)</span>，考虑矩形 <spanclass="math inline">\(R=[t_0-a,t_0+a]\times[x_0-b,x_0+b]\)</span>，连续函数<span class="math inline">\(f:R\to\mathbb{R}\)</span>，假设存在 <spanclass="math inline">\(k\ge0,|f(t,u)-f(t,v)|\le k|u-v|,\forall(t,u),(t,v)\in R\)</span>。考虑初值问题 <span class="math display">\[(P):\begin{cases}x&#39;(t)=f(t,x(t)) \\x(t_0)=x_0\end{cases}\]</span> 求上述初值问题的解 <span class="math inline">\(x(t)\inC[t_0-\beta,t_0+\beta],0&lt;\beta\le a\)</span>。</p><p><strong><em>解</em></strong>：首先给出结论：如果给定 <spanclass="math inline">\(c=\max_{(t,x)\inR}|f(t,x)|,0&lt;\beta&lt;\min\{a,\frac{b}{c},\frac{1}{k}\}\)</span>，那么存在唯一的<span class="math inline">\(x\inC^1[t_0-\beta,t_0+\beta]\)</span>，使得当 <spanclass="math inline">\(t\in[t_0-\beta,t_0+\beta]\)</span> 时，有 <spanclass="math inline">\(x(t)\in[x_0-b,x_0+b]\)</span> 且 <spanclass="math inline">\(x\)</span> 满足方程 <spanclass="math inline">\((P)\)</span>。下面给出证明。</p><p>由于 <span class="math inline">\(x&#39;(t)=f(t,x(t)) \Longrightarrow\int_{t_0}^t x&#39;(\tau)d\tau=\int_{t_0}^t f(\tau,x(\tau))d\tau\Longrightarrow x(t)=x_0+\int_{t_0}^tf(\tau,x(\tau))d\tau\)</span>，</p><p>可以证明 <span class="math inline">\(|x(t)-x_0|\le c\beta &lt;b\Longrightarrow (t,x(t))\in R\)</span>。</p><p><span class="math inline">\((X,d_\infty)\)</span> 完备，取 <spanclass="math inline">\(M=\bar{B}(x_0,c\beta)\)</span> 为闭集，因此 <spanclass="math inline">\(M\)</span> 为完备的，</p><p>取 <span class="math inline">\(Tx=x_0+\int_{t_0}^tf(\tau,x(\tau))d\tau\)</span>，也可以证明 <spanclass="math inline">\(d_\infty(Tx,x_0)\le c\beta \Longrightarrow Tx\inM\)</span>，即 <span class="math inline">\(T:M\to M\)</span>，</p><p>又容易证明 <span class="math inline">\(T\)</span>为压缩映射，因而存在唯一的 <span class="math inline">\(x\in M\)</span>使得 <span class="math inline">\(Tx=x\)</span>，只需要迭代即可获得 <spanclass="math inline">\(x(t)\)</span>。</p><p><strong><em>例子 4(隐函数存在定理)</em></strong>：略。</p><h2 id="小结">6. 小结</h2><p>这一章当中讲解了度量空间、开集闭集、序列收敛性、柯西列、集合完备性、映射与连续性，以及最后的Banach不动点定理。现在我们已经完成了度量空间中的内容，你能够回答文章开头的问题了吗？对于度量空间这个概念有什么新的理解吗？</p>]]></content>
    
    
    <categories>
      
      <category>Functional Analysis</category>
      
    </categories>
    
    
    <tags>
      
      <tag>可分性</tag>
      
      <tag>度量空间</tag>
      
      <tag>完备空间</tag>
      
      <tag>开集</tag>
      
      <tag>柯西列</tag>
      
      <tag>连续映射</tag>
      
      <tag>Banach不动点定理</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>泛函分析笔记0：绪论</title>
    <link href="/2020/10/18/functional-analysis/ch0-intro/"/>
    <url>/2020/10/18/functional-analysis/ch0-intro/</url>
    
    <content type="html"><![CDATA[<p>本系列泛函分析课程笔记的参考教材是清华大学出版社，步尚全老师写的《泛函分析基础》。</p><p>笔记的内容基本来自于我的听课记录，以及自己复习过程中的一些想法，由于笔者的数学功底极其不扎实，因此很可能会有不准确甚至错误之处，欢迎大家指正。</p>]]></content>
    
    
    <categories>
      
      <category>Functional Analysis</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>VMWare15 + Ubuntu18.04 踩坑记录</title>
    <link href="/2020/08/11/software/vmware/"/>
    <url>/2020/08/11/software/vmware/</url>
    
    <content type="html"><![CDATA[<h2 id="虚拟机联网问题">1. 虚拟机联网问题</h2><p>VMWare虚拟机大致有 3 种联网方式，以下三种方式联网自由度逐渐递减：</p><ol type="1"><li>桥接：虚拟机就相当于局域网中的另一台主机，有独立的 ip 地址；</li><li>NAT：虚拟机需要借助于主机才能联网，虚拟机也是以物理主机的身份与外界通信；</li><li>Host-only：虚拟机只能与主机通信，不能联网；</li></ol><p>有时候设置好 NAT 或者桥接模式后仍然不能联网，可以尝试输入以下命令</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">sudo service network-manager restart<br></code></pre></td></tr></table></figure><p>也可以尝试先把虚拟机关机，点击 VMWare <code>编辑 &gt;&gt; 更改设置&gt;&gt;还原默认设置 &gt;&gt; 确定</code>，然后虚拟机开机就可以了。</p><p>找不到网络连接图标</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs shell">sudo service network-manager stop<br>sudo rm /var/lib/NetworkManager/NetworkManager.state<br>sudo service network-manager start<br><span class="hljs-meta">#</span><span class="bash"> 将文件里面唯一的<span class="hljs-literal">false</span>改成<span class="hljs-literal">true</span></span><br>sudo gedit /etc/NetworkManager/NetworkManager.conf<br>sudo service network-manager restart<br></code></pre></td></tr></table></figure><h2 id="vi-输入问题">2. vi 输入问题</h2><p>vi 输入模式下方向键会出来 A, B, C, D，而且退格键不好使。</p><h3 id="方法-1">方法 1</h3><p>可以修改文件 <code>/etc/vim/vimrc.tiny</code>，注释掉原来的 <code>setcompatible</code>，改成以下内容</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">set</span> nocompatible<br><span class="hljs-built_in">set</span> backspace=2<br></code></pre></td></tr></table></figure><h3 id="方法-2">方法 2</h3><p>在用户个人目录下创建文件 <code>.vimrc</code>，写入以下内容</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">set</span> nocompatible     <span class="hljs-comment"># 以非兼容模式工作  </span><br><span class="hljs-built_in">set</span> backspace=2<br></code></pre></td></tr></table></figure><h3 id="方法-3">方法 3</h3><p>安装 vim</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">sudo apt-get install vim<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>Software</category>
      
    </categories>
    
    
    <tags>
      
      <tag>虚拟机</tag>
      
      <tag>linux</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>树莓派设置开机自启动程序</title>
    <link href="/2020/07/20/hardware/raspberrypi-autostart/"/>
    <url>/2020/07/20/hardware/raspberrypi-autostart/</url>
    
    <content type="html"><![CDATA[<p>最近调试树莓派，希望<strong>开机运行两个程序</strong>，其中一个是<strong>可执行文件</strong>，另一个是<strong>python脚本</strong>，他们都是无限循环的程序，也就是说不关机不会停止运行。中间还是遇到了很多bug，现在记录一下自启动程序的设置方法以及debug的整个过程。</p><h2 id="自启动程序设置方法">1. 自启动程序设置方法</h2><p>网上用的最多的方法就是修改 <code>/etc/rc.local</code> 文件：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">sudo nano /etc/rc.local<br></code></pre></td></tr></table></figure><p>进入之后在 <code>exit 0</code>这句话上面添加需要运行的程序。比如我想运行 <code>~/test/</code>文件夹下的可执行文件 <code>runme</code> 和 python 脚本<code>runhe.py</code>，那么就需要添加下面两个命令</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta">#</span><span class="bash"> sleep 5</span><br>/home/pi/test/runme &amp;<br>sudo -H -u pi /usr/bin/python3 /home/pi/test/runhe.py &amp;<br></code></pre></td></tr></table></figure><span id="more"></span><p>这里有几个<strong>注意事项</strong>：</p><ol type="1"><li>最好都使用<strong>绝对路径</strong>！</li><li>如果程序是无限循环（不会终止）的，那么需要在行尾添加<code>&amp;</code>，如果不是的话可以不加这个<code>&amp;</code>，这个符号可以理解为允许当前行的程序在后台运行，这样就可以继续启动下一行的程序了。</li><li>第一行的 <code>sleep 5</code> 表示先暂停5s，主要是为了防止有的变量或者环境还没有准备好，可以根据情况决定是否添加。</li><li>运行 python 脚本的时候最好前面用 <code>/usr/bin/python3xxx.py</code> 而不是直接 <code>python3xxx.py</code>，后者不一定会报错，但是像前面说的，还是尽量用绝对路径。</li><li>最重要的一点，也是我的 bug 原因所在：运行 python脚本的时候，网上大多数教程说的是添加 <code>python3 xxx.py</code>就行了，但是我 debug 过程中发现必须要使用 <code>sudo -H -u pi/xxx/python3 xxxx.py</code> 来显式的指定用户，否则可能会报错<code>ModuleNotFoundError: No module named'XXX'</code>，这应该是因为某些包只在某个用户环境中安装了。</li></ol><h2 id="debug技巧">2. debug技巧</h2><p>按照上面的方法修改 <code>rc.local</code>文件还是有可能失败，这里再记录几个 debug 的方法。</p><p>首先是可以利用下面的命令查看是否运行了含有 <code>runme</code>的程序</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">ps aux|grep runme<br></code></pre></td></tr></table></figure><p>另外可以将 <code>rc.local</code> 的第一行 <code>#!/bin/sh</code>修改为</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-meta">#!/bin/sh -e(或者 -x)</span><br></code></pre></td></tr></table></figure><p>这样可以把日志记录到 <code>/var/log/messages</code>文件中，后续可以查看这个文件看看是哪里报错。</p><p>然后是每次修改 <code>rc.local</code>之后都要重启来检验有没有问题，太麻烦了，其实还有更高效的方法，只需要在命令行运行</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">systemctl restart rc-local<br>systemctl status rc-local<br></code></pre></td></tr></table></figure><p>前者模仿开机过程，重新执行一遍 <code>rc.local</code>中的命令，后者查看运行状态。</p><p>此外，还可以使用 <code>nohup</code> 命令使程序后台运行</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">nohup ./calcDynamic &amp;<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>Hardware</category>
      
    </categories>
    
    
    <tags>
      
      <tag>raspberry pi</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>JY901串口数据接收与处理(Python)</title>
    <link href="/2020/07/09/hardware/jy901/"/>
    <url>/2020/07/09/hardware/jy901/</url>
    
    <content type="html"><![CDATA[<p>最近在用JY901做一些实验，关于JY901网上有很多资料了，也有上位机软件，可以方便的查看输出数据。我想做的是对输出的角速度进行积分，对比积分后的结果与输出的角度，如果数据都比较准确地话，那么他们应该相差不大。</p><p>这篇文章里，要完成的事情就是通过串口接收他输出的角速度和角度，然后对角速度进行积分，并实时显示数据结果。下面我首先对各个部分进行分块解释，完整的代码放在最后。</p><span id="more"></span><h2 id="串口通信">1. 串口通信</h2><p>python实现串口通信可以用 <code>pySerial</code>库。我们首先选择串口对应的设备端口：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 获取串口设备对应的端口</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">get_serial_port</span>():</span><br>    ports = <span class="hljs-built_in">list</span>(serial.tools.list_ports.comports())<br>    <span class="hljs-keyword">for</span> port <span class="hljs-keyword">in</span> ports:<br>        <span class="hljs-built_in">print</span>(ports.index(port), port)<br>    selected = -<span class="hljs-number">1</span><br>    <span class="hljs-keyword">while</span> selected &lt; <span class="hljs-number">0</span> <span class="hljs-keyword">or</span> selected &gt;= <span class="hljs-built_in">len</span>(ports):<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;please input serial to use [start from 0]:&quot;</span>)<br>        selected = <span class="hljs-built_in">int</span>(<span class="hljs-built_in">input</span>())<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;selected: &quot;</span>, selected)<br><br>    port = ports[selected]<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;use &quot;</span>, port)<br>    port = <span class="hljs-built_in">list</span>(port)<br>    <span class="hljs-keyword">return</span> port[<span class="hljs-number">0</span>]<br></code></pre></td></tr></table></figure><p>然后打开串口并持续接收数据，在收到的数据中提取IMU数据：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">serial_readers</span>(<span class="hljs-params">self, port = <span class="hljs-literal">None</span>, size = <span class="hljs-number">22</span></span>):</span><br>    <span class="hljs-comment"># port   : 串口端口</span><br>    <span class="hljs-comment"># size   : 默认一次读取数据长度(bytes)</span><br>    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> port:<br>        port = get_serial_port()<br>    total = <span class="hljs-built_in">bytearray</span>()<br>    ser = <span class="hljs-literal">None</span><br>    <span class="hljs-keyword">while</span> <span class="hljs-literal">True</span>:<br>        <span class="hljs-keyword">try</span>:<br>            <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> ser:<br>                ser = serial.Serial(port, <span class="hljs-number">115200</span>, timeout=<span class="hljs-number">60</span>)<br>            <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> ser.is_open:<br>                ser.<span class="hljs-built_in">open</span>()<br>            tmp = ser.read(size)<br>            total.extend(tmp)<br>            total, ext_omega, ext_angle = self.extract_raw_data(total)   <span class="hljs-comment">#提取IMU数据</span><br>        <span class="hljs-keyword">except</span> Exception <span class="hljs-keyword">as</span> e:<br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;exception &quot;</span>, e)<br>            <span class="hljs-keyword">if</span> ser:<br>                ser.close()<br>            time.sleep(<span class="hljs-number">5</span>)<br><br>    <span class="hljs-keyword">return</span> self.record_omega, self.record_angle<br></code></pre></td></tr></table></figure><h2 id="imu数据提取">2. IMU数据提取</h2><p>首先我们来看JY901串口数据的帧结构：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs reStructuredText">加速度：0x55 0x51 AxL AxH AyL AyH AzL AzH TL TH SUM <br>角速度：0x55 0x52 wxL wxH wyL wyH wzL wzH TL TH SUM <br>角度：  0x55 0x53 RollL RollH PitchL PitchH YawL YawH TL TH SUM <br></code></pre></td></tr></table></figure><p>这三种数据帧长度都是 11Bytes，最后一位为校验位，我们从串口数据中提取IMU数据也是根据这个帧结构，先检测帧头，然后读取整个帧（代码里偷了懒，并没有核对校验位）</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">extract_raw_data</span>(<span class="hljs-params">self, data</span>):</span><br>    <span class="hljs-comment"># 根据报文格式读取角速度数据</span><br>    <span class="hljs-comment"># 0x55 0x52 + data + CRC(8bits)</span><br>    length = <span class="hljs-number">9</span><br>    ext_omega = <span class="hljs-literal">None</span><br>    ext_angle = <span class="hljs-literal">None</span><br>    <span class="hljs-keyword">try</span>:<br>        st = data.index(<span class="hljs-string">b&#x27;\x55&#x27;</span>)                <span class="hljs-comment"># 寻找报文引导字</span><br>        <span class="hljs-keyword">if</span> st &gt;= <span class="hljs-number">0</span>:<br>            reserved = data[st+<span class="hljs-number">1</span>]               <span class="hljs-comment"># 数据类型</span><br>            <span class="hljs-keyword">if</span> reserved == <span class="hljs-number">82</span>:                  <span class="hljs-comment"># 0x52，提取角速度消息</span><br>                <span class="hljs-keyword">if</span> st+length+<span class="hljs-number">1</span> &lt; <span class="hljs-built_in">len</span>(data):<br>                    <span class="hljs-keyword">if</span> self.count_omega==<span class="hljs-number">0</span>:<br>                        self.time_now = self.time_last = time.time()<br>                    <span class="hljs-keyword">else</span>:<br>                        self.time_last = self.time_now<br>                        self.time_now = time.time()<br><br>                    ext_omega = data[st:st+length+<span class="hljs-number">2</span>]<br>                    temp = <span class="hljs-built_in">int</span>.from_bytes(ext_omega[<span class="hljs-number">6</span>:<span class="hljs-number">8</span>], byteorder=<span class="hljs-string">&#x27;little&#x27;</span>, signed=<span class="hljs-literal">True</span>)<br>                    self.omega = temp/<span class="hljs-number">32768</span>*<span class="hljs-number">2000</span><br>                    self.record_omega.append(self.omega)   <span class="hljs-comment">#deg/s</span><br>                    data = data[st+length+<span class="hljs-number">2</span>:]<br>                    self.count_omega += <span class="hljs-number">1</span><br><br>                    self.omega_inte += self.omega*(self.time_now - self.time_last)<br>                    self.omega_inte = (self.omega_inte+<span class="hljs-number">180</span>)%<span class="hljs-number">360</span> - <span class="hljs-number">180</span><br>                    self.record_inte.append(self.omega_inte)<br><br>            <span class="hljs-keyword">elif</span> reserved == <span class="hljs-number">83</span>:                <span class="hljs-comment"># 0x53，提取角度消息</span><br>                <span class="hljs-keyword">if</span> st+length+<span class="hljs-number">1</span> &lt; <span class="hljs-built_in">len</span>(data):<br>                    ext_angle = data[st:st+length+<span class="hljs-number">2</span>]<br>                    temp = <span class="hljs-built_in">int</span>.from_bytes(ext_angle[<span class="hljs-number">6</span>:<span class="hljs-number">8</span>], byteorder=<span class="hljs-string">&#x27;little&#x27;</span>, signed=<span class="hljs-literal">True</span>)<br>                    self.yaw = temp/<span class="hljs-number">32768</span>*<span class="hljs-number">180</span><br>                    <span class="hljs-keyword">if</span> self.count_yaw==<span class="hljs-number">0</span>:                   <span class="hljs-comment">#记录初始相位</span><br>                        self.yaw_init = self.yaw<br>                    self.record_angle.append(self.yaw - self.yaw_init)      <span class="hljs-comment">#deg</span><br>                    data = data[st+length+<span class="hljs-number">2</span>:]<br>                    self.count_yaw += <span class="hljs-number">1</span><br><br>            <span class="hljs-keyword">elif</span> reserved == <span class="hljs-number">81</span>:                <span class="hljs-comment"># 0x51, 丢弃加速度消息</span><br>                <span class="hljs-keyword">if</span> st+length+<span class="hljs-number">1</span> &lt; <span class="hljs-built_in">len</span>(data):<br>                    ext_data = <span class="hljs-literal">None</span><br>                    data = data[st+length+<span class="hljs-number">2</span>:]<br>            <span class="hljs-keyword">else</span>:<br>                data = data[st+<span class="hljs-number">2</span>:]<br>    <span class="hljs-keyword">except</span>:<br>        <span class="hljs-keyword">return</span> data, ext_omega, ext_angle<br>    <span class="hljs-keyword">if</span> self.count_yaw%<span class="hljs-number">100</span> == <span class="hljs-number">0</span> <span class="hljs-keyword">and</span> self.count_yaw&gt;<span class="hljs-number">0</span>:<br>        self.save_data()<br>        <span class="hljs-built_in">print</span>(<span class="hljs-built_in">len</span>(self.record_omega),<span class="hljs-string">&#x27; extract omega  &#x27;</span>,ext_omega,self.omega_inte)<br>        <span class="hljs-built_in">print</span>(<span class="hljs-built_in">len</span>(self.record_angle),<span class="hljs-string">&#x27; extract angle  &#x27;</span>,ext_angle,self.yaw - self.yaw_init)<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;*&#x27;</span>*<span class="hljs-number">30</span>)<br>    <span class="hljs-keyword">return</span> data, ext_omega, ext_angle<br></code></pre></td></tr></table></figure><h2 id="绘图显示">3. 绘图显示</h2><p>我把历史接收数据都存在一个 <code>list</code> 里面了，每过 0.1s就重新绘图，看起来就像是在实时更新一样。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">plot</span>(<span class="hljs-params">self</span>):</span><br>    plt.ion()<br>    plt.figure()<br>    <span class="hljs-keyword">while</span> <span class="hljs-literal">True</span>:<br>        <span class="hljs-keyword">try</span>:<br>            <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(self.record_angle)&gt;<span class="hljs-number">0</span> <span class="hljs-keyword">and</span> <span class="hljs-built_in">len</span>(self.record_inte)&gt;<span class="hljs-number">0</span> :<br>                plt.clf()<br>                plt.plot(<span class="hljs-built_in">list</span>(<span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(self.record_angle))),self.record_angle,<span class="hljs-string">&#x27;r&#x27;</span>)<br>                plt.plot(<span class="hljs-built_in">list</span>(<span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(self.record_inte))),self.record_inte,<span class="hljs-string">&#x27;b&#x27;</span>)<br>                plt.xlim(<span class="hljs-built_in">max</span>(<span class="hljs-number">0</span>,self.count_yaw-<span class="hljs-number">3000</span>),self.count_yaw+<span class="hljs-number">200</span>)<br>                plt.legend(labels=[<span class="hljs-string">&#x27;angle&#x27;</span>,<span class="hljs-string">&#x27;integration&#x27;</span>])<br>                plt.pause(<span class="hljs-number">0.1</span>)<br>                plt.ioff()<br>        <span class="hljs-keyword">except</span> Exception <span class="hljs-keyword">as</span> e:<br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;exception &quot;</span>, e)<br></code></pre></td></tr></table></figure><h2 id="运行效果">4. 运行效果</h2><h2 id="完整代码">5. 完整代码</h2><p>为了便于共享数据，定义了一个类<code>JY901</code>，将上面的各个函数放在这个类里面，输出的数据也都记录在<code>JY901</code> 的成员变量里。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> serial<br><span class="hljs-keyword">import</span> serial.tools.list_ports<br><span class="hljs-keyword">import</span> time<br><span class="hljs-keyword">import</span> struct<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> threading<br><br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">JY901</span>():</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self</span>):</span><br>        self.time_last = <span class="hljs-number">0</span><br>        self.time_now = <span class="hljs-number">0</span><br>        self.record_angle = []<br>        self.record_omega = []<br>        self.record_inte = []<br>        self.count_yaw = <span class="hljs-number">0</span><br>        self.count_omega = <span class="hljs-number">0</span><br>        self.omega_inte = <span class="hljs-number">0</span>         <span class="hljs-comment">#角速度积分</span><br>        self.yaw_init = <span class="hljs-number">0</span><br>        self.yaw = <span class="hljs-number">0</span><br>        self.omega = <span class="hljs-number">0</span><br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">extract_raw_data</span>(<span class="hljs-params">self, data</span>):</span><br>        <span class="hljs-comment"># 根据报文格式读取角速度数据</span><br>        <span class="hljs-comment"># 0x55 0x52 + data + CRC(8bits)</span><br>        length = <span class="hljs-number">9</span><br>        ext_omega = <span class="hljs-literal">None</span><br>        ext_angle = <span class="hljs-literal">None</span><br>        <span class="hljs-keyword">try</span>:<br>            st = data.index(<span class="hljs-string">b&#x27;\x55&#x27;</span>)                <span class="hljs-comment"># 寻找报文引导字</span><br>            <span class="hljs-keyword">if</span> st &gt;= <span class="hljs-number">0</span>:<br>                reserved = data[st+<span class="hljs-number">1</span>]               <span class="hljs-comment"># 数据类型</span><br>                <span class="hljs-keyword">if</span> reserved == <span class="hljs-number">82</span>:                  <span class="hljs-comment"># 0x52，提取角速度消息</span><br>                    <span class="hljs-keyword">if</span> st+length+<span class="hljs-number">1</span> &lt; <span class="hljs-built_in">len</span>(data):<br>                        <span class="hljs-keyword">if</span> self.count_omega==<span class="hljs-number">0</span>:<br>                            self.time_now = self.time_last = time.time()<br>                        <span class="hljs-keyword">else</span>:<br>                            self.time_last = self.time_now<br>                            self.time_now = time.time()<br><br>                        ext_omega = data[st:st+length+<span class="hljs-number">2</span>]<br>                        temp = <span class="hljs-built_in">int</span>.from_bytes(ext_omega[<span class="hljs-number">6</span>:<span class="hljs-number">8</span>], byteorder=<span class="hljs-string">&#x27;little&#x27;</span>, signed=<span class="hljs-literal">True</span>)<br>                        self.omega = temp/<span class="hljs-number">32768</span>*<span class="hljs-number">2000</span><br>                        self.record_omega.append(self.omega)   <span class="hljs-comment">#deg/s</span><br>                        data = data[st+length+<span class="hljs-number">2</span>:]<br>                        self.count_omega += <span class="hljs-number">1</span><br><br>                        self.omega_inte += self.omega*(self.time_now - self.time_last)<br>                        self.omega_inte = (self.omega_inte+<span class="hljs-number">180</span>)%<span class="hljs-number">360</span> - <span class="hljs-number">180</span><br>                        self.record_inte.append(self.omega_inte)<br><br>                <span class="hljs-keyword">elif</span> reserved == <span class="hljs-number">83</span>:                <span class="hljs-comment"># 0x53，提取角度消息</span><br>                    <span class="hljs-keyword">if</span> st+length+<span class="hljs-number">1</span> &lt; <span class="hljs-built_in">len</span>(data):<br>                        ext_angle = data[st:st+length+<span class="hljs-number">2</span>]<br>                        temp = <span class="hljs-built_in">int</span>.from_bytes(ext_angle[<span class="hljs-number">6</span>:<span class="hljs-number">8</span>], byteorder=<span class="hljs-string">&#x27;little&#x27;</span>, signed=<span class="hljs-literal">True</span>)<br>                        self.yaw = temp/<span class="hljs-number">32768</span>*<span class="hljs-number">180</span><br>                        <span class="hljs-keyword">if</span> self.count_yaw==<span class="hljs-number">0</span>:                   <span class="hljs-comment">#记录初始相位</span><br>                            self.yaw_init = self.yaw<br>                        self.record_angle.append(self.yaw - self.yaw_init)      <span class="hljs-comment">#deg</span><br>                        data = data[st+length+<span class="hljs-number">2</span>:]<br>                        self.count_yaw += <span class="hljs-number">1</span><br><br>                <span class="hljs-keyword">elif</span> reserved == <span class="hljs-number">81</span>:                <span class="hljs-comment"># 0x51, 丢弃加速度消息</span><br>                    <span class="hljs-keyword">if</span> st+length+<span class="hljs-number">1</span> &lt; <span class="hljs-built_in">len</span>(data):<br>                        ext_data = <span class="hljs-literal">None</span><br>                        data = data[st+length+<span class="hljs-number">2</span>:]<br>                <span class="hljs-keyword">else</span>:<br>                    data = data[st+<span class="hljs-number">2</span>:]<br>        <span class="hljs-keyword">except</span>:<br>            <span class="hljs-keyword">return</span> data, ext_omega, ext_angle<br>        <span class="hljs-keyword">if</span> self.count_yaw%<span class="hljs-number">100</span> == <span class="hljs-number">0</span> <span class="hljs-keyword">and</span> self.count_yaw&gt;<span class="hljs-number">0</span>:<br>            self.save_data()<br>            <span class="hljs-built_in">print</span>(<span class="hljs-built_in">len</span>(self.record_omega),<span class="hljs-string">&#x27; extract omega  &#x27;</span>,ext_omega,self.omega_inte)<br>            <span class="hljs-built_in">print</span>(<span class="hljs-built_in">len</span>(self.record_angle),<span class="hljs-string">&#x27; extract angle  &#x27;</span>,ext_angle,self.yaw - self.yaw_init)<br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;*&#x27;</span>*<span class="hljs-number">30</span>)<br>        <span class="hljs-keyword">return</span> data, ext_omega, ext_angle<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">serial_readers</span>(<span class="hljs-params">self, port = <span class="hljs-literal">None</span>, size = <span class="hljs-number">22</span></span>):</span><br>        <span class="hljs-comment"># port   : 串口端口</span><br>        <span class="hljs-comment"># size   : 默认一次读取数据长度(bytes)</span><br>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> port:<br>            port = get_serial_port()<br>        total = <span class="hljs-built_in">bytearray</span>()<br>        ser = <span class="hljs-literal">None</span><br>        <span class="hljs-keyword">while</span> <span class="hljs-literal">True</span>:<br>            <span class="hljs-keyword">try</span>:<br>                <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> ser:<br>                    ser = serial.Serial(port, <span class="hljs-number">115200</span>, timeout=<span class="hljs-number">60</span>)<br>                <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> ser.is_open:<br>                    ser.<span class="hljs-built_in">open</span>()<br>                tmp = ser.read(size)<br>                total.extend(tmp)<br>                total, ext_omega, ext_angle = self.extract_raw_data(total)<br>            <span class="hljs-keyword">except</span> Exception <span class="hljs-keyword">as</span> e:<br>                <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;exception &quot;</span>, e)<br>                <span class="hljs-keyword">if</span> ser:<br>                    ser.close()<br>                time.sleep(<span class="hljs-number">5</span>)<br><br>        <span class="hljs-keyword">return</span> self.record_omega, self.record_angle<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">save_data</span>(<span class="hljs-params">self</span>):</span><br>        np.savez(<span class="hljs-string">&#x27;record.npz&#x27;</span>,record_omega=self.record_omega, record_angle=self.record_angle)<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">plot</span>(<span class="hljs-params">self</span>):</span><br>        plt.ion()<br>        plt.figure()<br>        <span class="hljs-keyword">while</span> <span class="hljs-literal">True</span>:<br>            <span class="hljs-keyword">try</span>:<br>                <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(self.record_angle)&gt;<span class="hljs-number">0</span> <span class="hljs-keyword">and</span> <span class="hljs-built_in">len</span>(self.record_inte)&gt;<span class="hljs-number">0</span> :<br>                    plt.clf()<br>                    plt.plot(<span class="hljs-built_in">list</span>(<span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(self.record_angle))),self.record_angle,<span class="hljs-string">&#x27;r&#x27;</span>)<br>                    plt.plot(<span class="hljs-built_in">list</span>(<span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(self.record_inte))),self.record_inte,<span class="hljs-string">&#x27;b&#x27;</span>)<br>                    plt.xlim(<span class="hljs-built_in">max</span>(<span class="hljs-number">0</span>,self.count_yaw-<span class="hljs-number">3000</span>),self.count_yaw+<span class="hljs-number">200</span>)<br>                    plt.legend(labels=[<span class="hljs-string">&#x27;angle&#x27;</span>,<span class="hljs-string">&#x27;integration&#x27;</span>])<br>                    plt.pause(<span class="hljs-number">0.1</span>)<br>                    plt.ioff()<br>            <span class="hljs-keyword">except</span> Exception <span class="hljs-keyword">as</span> e:<br>                <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;exception &quot;</span>, e)<br><br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">get_serial_port</span>():</span><br>    ports = <span class="hljs-built_in">list</span>(serial.tools.list_ports.comports())<br>    <span class="hljs-keyword">for</span> port <span class="hljs-keyword">in</span> ports:<br>        <span class="hljs-built_in">print</span>(ports.index(port), port)<br>    selected = -<span class="hljs-number">1</span><br>    <span class="hljs-keyword">while</span> selected &lt; <span class="hljs-number">0</span> <span class="hljs-keyword">or</span> selected &gt;= <span class="hljs-built_in">len</span>(ports):<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;please input serial to use [start from 0]:&quot;</span>)<br>        selected = <span class="hljs-built_in">int</span>(<span class="hljs-built_in">input</span>())<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;selected: &quot;</span>, selected)<br><br>    port = ports[selected]<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;use &quot;</span>, port)<br>    port = <span class="hljs-built_in">list</span>(port)<br>    <span class="hljs-keyword">return</span> port[<span class="hljs-number">0</span>]<br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    imu = JY901()<br>    thread_rcv = threading.Thread(target=imu.serial_readers)<br>    thread_plt = threading.Thread(target=imu.plot)<br>    thread_plt.start()<br>    thread_rcv.start()<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>Hardware</category>
      
    </categories>
    
    
    <tags>
      
      <tag>IMU</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Why Baby Why</title>
    <link href="/2020/06/12/music/WhyBabyWhy/"/>
    <url>/2020/06/12/music/WhyBabyWhy/</url>
    
    <content type="html"><![CDATA[<center><h2>夏天到了🍉</h2></center><span id="more"></span><iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width="330" height="86" src="//music.163.com/outchain/player?type=2&amp;id=509531185&amp;auto=1&amp;height=66"></iframe><blockquote><p>What do you mean, god gave me two left feet? Shooting me glares fromthe passenger seat Come on, baby, we got all dressed up Won't you dancewith me?</p><p>Why, baby, why do you give me trouble? I'm trying to hide as not tobe seen But I know you mean well, step on my feet Come dance with me</p><p>Come on, try to have a good time There's a punch bowl, but youbrought red wine Come on, baby, show me what's a good time Why, baby,why?</p><p>Why must you play me like I play the guitar? She made me jump intothe reservoir And go running 'til we fade to black Like the moviesdo</p><p>Why, baby, why do you give me trouble? I'm trying to hide as not tobe seen But I know you mean well, step on my feet Come dance with me</p><p>Come on, try to have a good time There's a punch bowl, but youbrought red wine Come on, baby, show me what's a good time Why, baby,why?</p><p>Come on, try to have a good time There's a punch bowl, but youbrought red wine Come on, baby, show me what's a good time Why baby why?(Oh-oh) Come on, baby, show me what's a good time Why baby why?</p></blockquote>]]></content>
    
    
    <categories>
      
      <category>Music</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>树莓派使用</title>
    <link href="/2020/06/08/hardware/raspberrypi/"/>
    <url>/2020/06/08/hardware/raspberrypi/</url>
    
    <content type="html"><![CDATA[<h2 id="系统安装">1. 系统安装</h2><p><a href="https://zhuanlan.zhihu.com/p/59027897">参考链接</a></p><h2 id="连接树莓派">2. 连接树莓派</h2><p>如果有显示器和键盘鼠标，可以直接利用HMDI线连接树莓派和显示器，像操作普通电脑一样。</p><p>如果没有显示器，就需要通过ssh连接。首先需要知道树莓派的地址。</p><span id="more"></span><h3 id="方法一wifi">2.1 方法一：wifi</h3><ol type="1"><li><p>在树莓派的 SD 卡里面 <code>boot</code> 分区下面创建文件<code>wpa_supplicant.conf</code>，写入以下内容</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs routeros"><span class="hljs-attribute">country</span>=CN<br><span class="hljs-attribute">ctrl_interface</span>=DIR=/var/run/wpa_supplicant <span class="hljs-attribute">GROUP</span>=netdev<br><span class="hljs-attribute">update_config</span>=1<br> <br>network=&#123;<br>    <span class="hljs-attribute">ssid</span>=<span class="hljs-string">&quot;wifi名&quot;</span><br>    <span class="hljs-attribute">psk</span>=<span class="hljs-string">&quot;密码&quot;</span><br>    <span class="hljs-attribute">key_mgmt</span>=WPA-PSK<br>&#125;<br></code></pre></td></tr></table></figure></li><li><p>同样在 <code>boot</code> 分区里面创建一个空文件，重命名为<code>ssh</code>，注意不是 <code>ssh.txt</code>，没有后缀！！！</p></li><li><p>树莓派上电，可以在浏览器输入 <code>192.168.0.1</code>查看树莓派地址，一般为 <code>192.168.0.x</code></p></li><li><p>用 putty 或者其他软件 ssh 远程连接，默认用户名<code>pi</code>，密码 <code>raspberry</code></p></li><li><p>可以在命令行输入 <code>sudo raspi-config</code> 打开VNC、修改分辨率</p></li></ol><h3 id="方法二网线">2.2 方法二：网线</h3><p>可以用网线直接把树莓派和笔记本电脑连接在一块。之后需要打开<code>控制面板 -&gt; 网络和 Internet -&gt;网络和共享中心</code>，不出意外的话可以看到下面的东西</p><p><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2020/net.PNG" /></p><p>点击 <code>WLAN -&gt; 属性 -&gt; 共享</code>， 如下图勾选对号并且点击<code>设置</code> 勾选 <code>1703</code> ，点击 <code>确定</code>。</p><p><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2020/net2.PNG" /></p><p>再点击 <code>以太网 -&gt; 详细信息</code>，看到那个<code>IPv4地址</code>，记住他 <code>192.168.137.1</code>。</p><p><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2020/net4.PNG" /></p><p>然后打开命令行 <code>win+R -&gt; cmd</code>，输入 <code>arp-a</code>，就可以看到下面的东西，找到那个接口<code>192.168.137.1</code>（就是上面记住的那个地址），看下面的 IP地址（我这里是因为连接了两次，所以分配了两次地址 <code>192.168.137.43 or79</code>，如果是第一次连接的话应该只有一个地址）就是树莓派的地址。</p><p><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2020/net5.PNG" /></p><p>获得这个 IP 地址以后就能跟方法一中一样，用 ssh 连接树莓派了。</p><h2 id="修改系统镜像源">3. 修改系统镜像源</h2><ol type="1"><li><p>备份原文件</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs awk">sudo cp <span class="hljs-regexp">/etc/</span>apt<span class="hljs-regexp">/sources.list /</span>etc<span class="hljs-regexp">/apt/</span>sources.list.bak <br>sudo cp <span class="hljs-regexp">/etc/</span>apt<span class="hljs-regexp">/sources.list.d/</span>raspi.list <span class="hljs-regexp">/etc/</span>apt<span class="hljs-regexp">/sources.list.d/</span>raspi.list.bak<br></code></pre></td></tr></table></figure></li><li><p>修改软件更新源</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs awk">sudo vi <span class="hljs-regexp">/etc/</span>apt/sources.list<br></code></pre></td></tr></table></figure><p>输入以下内容</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs awk">deb http:<span class="hljs-regexp">//mi</span>rrors.tuna.tsinghua.edu.cn<span class="hljs-regexp">/raspbian/</span>raspbian/ buster main contrib non-free rpi<br>deb-src http:<span class="hljs-regexp">//mi</span>rrors.tuna.tsinghua.edu.cn<span class="hljs-regexp">/raspbian/</span>raspbian/ buster main contrib non-free rpi<br></code></pre></td></tr></table></figure></li><li><p>修改系统更新源</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs awk">sudo vi <span class="hljs-regexp">/etc/</span>apt<span class="hljs-regexp">/sources.list.d/</span>raspi.list<br></code></pre></td></tr></table></figure><p>输入以下内容</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs awk">deb http:<span class="hljs-regexp">//mi</span>rrors.tuna.tsinghua.edu.cn<span class="hljs-regexp">/raspberrypi/</span> buster main ui<br></code></pre></td></tr></table></figure></li><li><p>同步更新源及更新软件包</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs routeros">sudo apt-<span class="hljs-builtin-name">get</span> update<br>sudo apt-<span class="hljs-builtin-name">get</span> upgrade<br></code></pre></td></tr></table></figure></li></ol><h2 id="修改-pip-镜像源">4. 修改 pip 镜像源</h2><p><strong>临时更换源</strong>只需要在命令后面加一个参数：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">pip install django -i http://pypi.douban.com/simple<br></code></pre></td></tr></table></figure><p><strong>永久更换源</strong>可以创建文件 <code>~/.pip/pip.conf</code>并写入以下内容：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs shell">[global]<br>index-url=https://pypi.tuna.tsinghua.edu.cn/simple<br>[install]<br>trusted-host=pypi.tuna.tsinghua.edu.cn<br></code></pre></td></tr></table></figure><p>上面是选择的清华源，还有以下国内镜像源可以选择：</p><ul><li>清华：https://pypi.tuna.tsinghua.edu.cn/simple</li><li>阿里云：http://mirrors.aliyun.com/pypi/simple/</li><li>中国科技大学 https://pypi.mirrors.ustc.edu.cn/simple/</li><li>华中理工大学：http://pypi.hustunique.com/</li><li>山东理工大学：http://pypi.sdutlinux.org/</li><li>豆瓣：http://pypi.douban.com/simple/</li></ul><h2 id="串口通信">5. 串口通信</h2><p>树莓派需要手动打开串口，可以在命令行输入 <code>sudoraspi-config</code> 选择 <code>interface options</code> 打开<code>Serial</code>。树莓派 4B 的针脚如图所示，对于 USB转串口模块只需要接树莓派的 6(GND),8(TXD),10(RXD) 口即可，注意 USB转串口的 RXD 要与树莓派的 TXD 连接。</p><p><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2020/pin-raspi.png" /></p>]]></content>
    
    
    <categories>
      
      <category>Hardware</category>
      
    </categories>
    
    
    <tags>
      
      <tag>raspberry pi</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>强大数定律与弱大数定律</title>
    <link href="/2020/05/30/probability/law%20of%20large%20numbers/"/>
    <url>/2020/05/30/probability/law%20of%20large%20numbers/</url>
    
    <content type="html"><![CDATA[<p>最近学习的时候遇到了<strong>强大数定律</strong>与<strong>弱大数定律</strong>，两者的区分提到了“<strong>依概率收敛</strong>”和“<strong>几乎处处收敛</strong>”，由于本人的数学基础太差，一直很难理解这个地方，在网上查阅了一些资料有了一些个人的理解，不知道对不对，不过还是想记录下来。提前说明，这里给出的解释非常的不严格，<del>甚至有点搞笑</del>，不过个人觉得很容易理解。</p><p>首先给出来强弱大数定律的表述。</p><p>对于独立同分布的无穷随机序列 <spanclass="math inline">\(\{X_i\}\)</span>，期望为 <spanclass="math inline">\(\mathbb{E}(X_i)=\mu\)</span>。大数定律要研究的就是样本均值的极限<span class="math display">\[\bar{X}_n=\frac{1}{n}(X_1+\cdots+X_n) \\\bar{X}_n\to \mu \quad\text{ for }\quad n\to \infty\]</span> 他们的主要不同点在于收敛性的强弱不同。</p><p><strong>弱大数定律</strong>：样本均值<strong>依概率收敛(converges inprobability)</strong>于期望 <span class="math display">\[\lim_{n\to\infty}\text{Pr}\left(\vert \bar{X}_n-\mu \vert &gt;\varepsilon\right)=0\]</span><strong>强大数定律</strong>：样本均值<strong>几乎处处收敛(convergesalmost surely)</strong>于期望 <span class="math display">\[\text{Pr}(\lim_{n\to\infty}\vert \bar{X}_n-\mu \vert &gt; \varepsilon)=0\\\iff \text{Pr}(\lim_{n\to\infty} \bar{X}_n =\mu )=1\]</span> <span id="more"></span></p><p>从形式上来看似乎只是把极限和概率交换了一下位置，但是这个交换就导致了本质的区别，后面会解释。这里首先参考<ahref="https://www.zhihu.com/question/21110761/answer/23815273">强大数定律和弱大数定律的本质区别？- runze Zheng的回答 -知乎</a>，这个回答以及网上很多的解释主要是从“依概率收敛”与“几乎处处收敛”的角度出发，我觉得这个对理解很有帮助。下面简单复述这篇回答。</p><blockquote><p><strong>注</strong>：这部分内容摘自<ahref="https://www.zhihu.com/question/21110761/answer/23815273">知乎回答</a></p><h4 id="依概率收敛的例子">1. 依概率收敛的例子</h4><p>考虑下图，图中的每条线都代表一个数列，虚线表示一个非常小的区间。总的来说每个数列都越来越趋近0，且大部分时候不会超过虚线所表示的小边界，但是，偶尔会有一两条线超过虚线、然后再回到虚线之内。而且我们<strong>不能保证，有没有哪一个数列会在未来再次超出虚线的范围然后再回来——虽然概率很小</strong>。注意虚线的范围可以是任意小的实数，此图中大约是<spanclass="math inline">\(\pm 0.04\)</span>，可以把这个边界缩小到<spanclass="math inline">\(\pm 0.004\)</span>，甚至<spanclass="math inline">\(\pm4*10^{-10}\)</span>，随你喜欢，这个性质始终存在。</p><p><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2020/weak-lln.jpg" /></p><h4 id="几乎处处收敛的例子">2. 几乎处处收敛的例子</h4><p>图中的黑线表示一个随机数列，这个数列在大约 <spanclass="math inline">\(n=200\)</span>之后进入了一个我们定的小边界（用虚线表示），之后我们可以确定，它再也不会超出虚线所表示的边界（超出这个边界的概率是0）。跟上面的例子一样，虚线所表示的边界可以定得任意小，而一定会有一个n值，当这个数列超过了n值之后，超出这个边界的概率就是0了。</p><p><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2020/strong-lln.jpg" /></p></blockquote><p>注意上面依概率收敛中有一句“不能保证，有没有哪一个数列会在未来再次超出虚线的范围然后再回来——虽然概率很小”，这个很重要，因为完全有可能有一个序列是这样的（我后面把这种序列叫做“刺头序列”吧）：</p><p><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2020/series-not-cvg.PNG" /></p><p>这个序列大趋势是 <spanclass="math inline">\(X_n=1/n\)</span>，但是每过一段时间就有一个刺头跳出来。我们不能说<spanclass="math inline">\(\lim_{n\to\infty}X_n=0\)</span>，这是因为序列极限的定义为：若若对于任意<span class="math inline">\(\varepsilon &gt; 0\)</span>，都存在一个<span class="math inline">\(N\)</span> 使得 <spanclass="math inline">\(|X_m-\mu| &lt; \varepsilon,\forall m &gt;N\)</span>，则 <span class="math inline">\(\lim_{n\to\infty}X_n=\mu\)</span>。但是对于上面这个例子呢？如果 <spanclass="math inline">\(\varepsilon &lt;0.2\)</span>，我们就找不到这样一个 <spanclass="math inline">\(N\)</span> 满足条件。</p><p>弱大数定律中允许存在这样的“刺头序列”，甚至全部是这种刺头序列也没关系，只要保证你们的“刺头”别挤在一块，偶尔出来跳一下，这样计算一个概率以后，有刺头出现的概率会随着<span class="math inline">\(n\to\infty\)</span> 而趋向于 0。</p><p>强大数定律中则不允许这样的刺头序列（应该说刺头序列出现的概率是0），他要求每个序列的极限都一定是 <spanclass="math inline">\(\mu\)</span>。</p><p>那么为什么把概率和极限交换一个位置就会出现强弱大数定理的这种差别呢？问题就出在<strong>极限<span class="math inline">\(\lim\)</span> 的定义</strong>了，当 <spanclass="math inline">\(\lim\)</span>在内部的时候，我们是盯着每一个序列看到了无穷远处，然后发现这个序列并不会有刺头跳出来，也就是说每个序列都有很好的性质。而当<span class="math inline">\(\lim\)</span>在外部的时候，我们是先求了一个概率，然后再看到无穷远处，那么我们只知道求概率以后几乎没有刺头，谁知道中间有没有滥竽充数的呢？甚至可能所有序列都是滥竽充数的，只不过<span class="math inline">\(n\)</span> 的时候是序列 <spanclass="math inline">\(a\)</span> 跳出来，<spanclass="math inline">\(n+1\)</span> 的时候是序列 <spanclass="math inline">\(b\)</span>，<spanclass="math inline">\(n+2\)</span> 的时候是序列 <spanclass="math inline">\(c\)</span> ……</p>]]></content>
    
    
    <categories>
      
      <category>Probability Theory</category>
      
    </categories>
    
    
    <tags>
      
      <tag>大数定律</tag>
      
      <tag>依概率收敛</tag>
      
      <tag>几乎必然收敛</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>凸优化笔记26：不动点迭代</title>
    <link href="/2020/05/27/optimization/ch26-fixed-point/"/>
    <url>/2020/05/27/optimization/ch26-fixed-point/</url>
    
    <content type="html"><![CDATA[<p>前面讲了很多具体的算法，比如梯度、次梯度、近似点梯度、加速近似点梯度、PPA、DR方法、ADMM、ALM等，对这些方法的迭代过程有了一些了解。这一节则主要是针对算法的<strong>收敛性</strong>进行分析，试图从一个更加抽象的层面，利用<strong>不动点迭代</strong>的思想，把上面的算法综合起来，给一个比较general 的收敛性分析方法。</p><h2 id="什么是不动点">1. 什么是不动点？</h2><p>对于希尔伯特空间(Hilbert space) <spanclass="math inline">\(\mathcal{H}\)</span>，定义了内积 <spanclass="math inline">\(\left&lt;\cdot,\cdot\right&gt;\)</span> 和 范数<span class="math inline">\(\|\cdot\|\)</span>（可以借助于 <spanclass="math inline">\(\mathbb{R}^2\)</span> 来想象）。算子 <spanclass="math inline">\(T:\mathcal{H}\to\mathcal{H}\)</span>（或者是 <spanclass="math inline">\(C\to C\)</span>，<spanclass="math inline">\(C\)</span> 为 <spanclass="math inline">\(\mathcal{H}\)</span> 的闭子集）。那么算子 <spanclass="math inline">\(T\)</span> 的不动点集合就定为 <spanclass="math display">\[\mathrm{Fix} T:=\{x \in \mathcal{H}: x=T(x)\}\]</span> 如果不动点集合非空，想要研究的是不动点迭代 <spanclass="math inline">\(x^{k+1}\leftarrow T(x^k)\)</span>的收敛性。为了简便，常把 <span class="math inline">\(T(x)\)</span> 写为<span class="math inline">\(Tx\)</span>。</p><p>为什么要研究不动点迭代呢？因为前面我们讲的算法里面很多都可以表示为这种形式。</p><span id="more"></span><p><strong><em>例子 1(GD)</em></strong>：对于无约束优化 <spanclass="math inline">\(\min f(x)\)</span>，不假设 <spanclass="math inline">\(f\)</span> 一定是凸的。如果有 <spanclass="math inline">\(\nabla f(x^\star)=0\)</span>，那么 <spanclass="math inline">\(x^\star\)</span> 被称为驻点(stationarypoint)。梯度下降做的什么事呢？<spanclass="math inline">\(x^{k+1}=x^k-\gamma \nablaf(x^k)\)</span>，所以实际上算子 <span class="math inline">\(T\)</span>为 <span class="math display">\[T:=I-\gamma \nabla f\]</span> 我们要找的最优解 <span class="math inline">\(x^\star\)</span>满足 <span class="math inline">\(\nabla f(x^\star)=0\Longrightarrowx^\star=T(x^\star)\)</span>，因此我们要找的就是 <spanclass="math inline">\(T\)</span> 的不动点。</p><p><strong><em>例子 2(PG1)</em></strong>：对于有约束优化 <spanclass="math inline">\(\min f(x),\text{ s.t. }x\in C\)</span>，假设 <spanclass="math inline">\(f\)</span> 为正常的闭凸函数，<spanclass="math inline">\(C\)</span>为非空闭凸集。对于这个带约束的优化问题，我们可以做完一步梯度下降以后再做个投影<span class="math inline">\(x^{k+1}\leftarrow\operatorname{proj}_{C}(x^k-\gamma \nabla f(x^k))\)</span>，所以有 <spanclass="math display">\[T:=\operatorname{proj}_{C}(I-\gamma \nabla f)\]</span> 而我们要找的最优解需要满足 <spanclass="math inline">\(\left\langle\nabla f\left(x^{\star}\right),x-x^{\star}\right\rangle \geq 0 \quad \forall x \in C \iff 0\in \nablaf(x^\star)+\partial \delta_C(x^\star)\)</span>，这实际上还是在找 <spanclass="math inline">\(T\)</span> 的不动点。</p><p><strong><em>例子 3(PG2)</em></strong>：上面向 <spanclass="math inline">\(C\)</span> 的投影实际上也是在算 <spanclass="math inline">\(\text{prox}\)</span> 算子。对于优化问题 <spanclass="math inline">\(\min f(x)+g(x)\)</span> 我们要解的方程是 <spanclass="math display">\[\begin{array}{c}0\in \nabla f(x)+\partial g(x) \iff 0\in x+\nablaf(x)-x+\partial g(x) \\\iff (I-\nabla f)(x)\in (I+\partial g)(x) \\\iffx=(I+\partial g)^{-1}(I-\nabla f)(x)\end{array}\]</span> 上一节讲到了 <span class="math inline">\((I+\partialg)^{-1}\)</span> 就是 <span class="math inline">\(\text{prox}\)</span>算子，所以这个不动点迭代就等价于近似点梯度方法。</p><p><strong><em>例子 4(KKT)</em></strong>：对于优化问题 <spanclass="math display">\[\begin{aligned}\min\quad&amp; f_0(x) \\\text{s.t.}\quad&amp; g(x)\le0\\&amp; h(x)=0\end{aligned}\]</span> 拉格朗日函数为 <spanclass="math inline">\(L(x,\lambda,\nu)=f_0(x)+\lambda^T g(x)+\nu^Th(x),\lambda\ge0\)</span>，KKT 条件就是要求解方程 <spanclass="math display">\[T(x,\lambda,\nu)=\left[\begin{array}{c}\partial_x L(x,\lambda,\nu)\\-f(x)+\partial \delta_{\{\lambda\ge0\}}(x) \\h(x)\end{array}\right]=0\]</span> 也就是要找到 <spanclass="math inline">\(\tilde{T}=I+T\)</span> 的不动点。</p><p>上面几个例子主要为了说明很多优化算法都可以写成不动点迭代的形式，那么要想分析他们的收敛性，只需要分析不动点迭代的收敛性就可以了，下面要讲的就是这件事情。</p><h2 id="收敛性分析">2. 收敛性分析</h2><p>要想分析收敛速度，必须要引入的一个性质就是 Lipschitz 连续。</p><p><strong>定义</strong>：算子 <span class="math inline">\(T\)</span> 是<span class="math inline">\(L\)</span>-Lipschitz 的，<spanclass="math inline">\(L\in[0,+\infty)\)</span>，如果它满足 <spanclass="math display">\[\|T x-T y\| \leq L\|x-y\|, \quad \forall x, y \in \mathcal{H}\]</span> <strong>定义</strong>：算子 <spanclass="math inline">\(T\)</span> 是 <spanclass="math inline">\(L\)</span>-<strong>quasi</strong>-Lipschitz的，<span class="math inline">\(L\in[0,+\infty)\)</span>，如果对任意<span class="math inline">\(x^\star\in \text{Fix}T\)</span> 它满足 <spanclass="math display">\[\|T x-x^\star\| \leq L\|x-x^\star\|, \quad \forall x \in \mathcal{H}\]</span></p><h3 id="收缩算子收敛性">2.1 收缩算子收敛性</h3><p><strong>定义</strong>：算子 <span class="math inline">\(T\)</span>是<strong>收缩算子(contractive)</strong>，如果它满足 <spanclass="math inline">\(L\)</span>-Lipschitz，<spanclass="math inline">\(L\in[0,1)\)</span></p><p><strong>定义</strong>：算子 <span class="math inline">\(T\)</span>是<strong>准收缩算子(quasi-contractive)</strong>，如果它满足 <spanclass="math inline">\(L\)</span>-quasi-Lipschitz，<spanclass="math inline">\(L\in[0,1)\)</span></p><p>准收缩算子很形象，它说明每次迭代之后，我们都会距离不动点 <spanclass="math inline">\(x^\star\)</span> 更近一点。</p><figure><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2020/26-contractive.PNG"alt="contractive" /><figcaption aria-hidden="true">contractive</figcaption></figure><p>下面是一个证明收敛性的重要定理！</p><blockquote><p><strong>定理(Banach fixed-point theorem)</strong>：如果 <spanclass="math inline">\(T\)</span> 是收缩算子，那么</p><ul><li><span class="math inline">\(T\)</span> 有唯一的不动点 <spanclass="math inline">\(x^\star\)</span>（存在且唯一）</li><li><span class="math inline">\(x^k\to x^\star\)</span>（强收敛）</li><li><span class="math inline">\(\| x^k-x^\star\|\leL^k\|x^0-x^\star\|\)</span>（线性收敛速度）</li></ul><p><strong>证明</strong>：略。</p></blockquote><p><strong><em>例子 1(GD)</em></strong>：对于一般的 <spanclass="math inline">\(\min f(x)\)</span>，我们假设 <spanclass="math inline">\(f\)</span> 为 Lipschitz-diﬀerentiable 并且是strongly-convex 的（回忆GD的收敛速度证明）那么就有（假设 <spanclass="math inline">\(f\in C^2\)</span>） <span class="math display">\[mI\le \nabla^2 f\le LI\]</span> 梯度下降的算子为 <span class="math inline">\(T=I-\gamma \nablaf\)</span>，我们需要计算这个算子的 Lipschitz 常数 <spanclass="math display">\[\begin{array}{c}(1-\alpha L)I\le D(I-\alpha\nabla f)=I-\alpha \nabla^2f(x)\le(I-\alpha m)I \\\| D(I-\alpha\nabla f)\| \le \max(|1-\alpham|,|1-\alpha L|)\end{array}\]</span> 注：<span class="math inline">\(T=I-\gamma \nabla f\)</span>里面的 <span class="math inline">\(I\)</span> 表示算子，<spanclass="math inline">\(I-\alpha \nabla^2 f(x)\)</span> 里边的 <spanclass="math inline">\(I\)</span> 就表示对角元素等于 1的矩阵，虽然形式一样，但意义不太一样。</p><p>如果要想 <span class="math inline">\(T\)</span> 是收缩算子，则需要<spanclass="math inline">\(\alpha\in(0,2/L)\)</span>，这也是为什么我们前面章节证明GD 收敛性的时候需要步长 <span class="math inline">\(t\le2/L\)</span>。</p><p><strong><em>例子 2</em></strong>：如果是对于一般的算子，我们想要求解<span class="math inline">\(0\in F(x)\)</span>，类比梯度下降方法，可以有<span class="math inline">\(x^{k+1}=x^k-\alpha Fx^k\)</span>，<spanclass="math inline">\(T=I-\alpha F\)</span>。类似的，我们也假设 <spanclass="math inline">\(F\)</span> 为 <spanclass="math inline">\(m\)</span> strongly monotone，<spanclass="math inline">\(L\)</span>-Lipschitz 的，那么有 <spanclass="math display">\[\begin{aligned}\| Tx-Ty\|^2_2 &amp;=\| (I-\alpha F)(x)-(I-\alphaF)(y)\|^2_2 \\&amp;= \|x-y\|_2^2 -2\alpha(Fx-Fy)^T(x-y)+\alpha^2\|Fx-Fy\|^2_2 \\&amp;\le (1-2\alpham+\alpha^2L^2)\|x-y\|^2\end{aligned}\]</span> 所以当 <spanclass="math inline">\(\alpha\in\left(0,\frac{2m}{L^2}\right)\)</span>的时候 <span class="math inline">\(T\)</span>是收缩算子，可以证明收敛性。</p><p>跟前面梯度下降对比，前面只要求 <span class="math inline">\(\alpha&lt;2/L\)</span>，所以梯度下降的要求更宽松。即使不满足强凸性质，梯度下降也能保证收敛，但是这里就必须要有<span class="math inline">\(m\)</span> stronglymonotone，这是因为梯度算子提供了更多的信息。</p><h3 id="非扩张算子收敛性">2.2 非扩张算子收敛性</h3><p>前面的收缩算子要求 <spanclass="math inline">\(L&lt;1\)</span>，这个条件还是比较强的，很多时候只能得到<span class="math inline">\(L=1\)</span>，这个时候被称为<strong>nonexpansive</strong>，也就是非扩张的。这个时候</p><ul><li><span class="math inline">\(T\)</span> 可能不存在不动点 <spanclass="math inline">\(x^\star\)</span></li><li>如果 <span class="math inline">\(x^\star\)</span> 存在，不动点迭代<span class="math inline">\(x^{k+1}=Tx^k\)</span> 有界</li><li>可能会发散（这个发散我个人不太理解，或许不收敛也被认为是发散）</li></ul><p>比如说旋转、反射操作，如图所示</p><figure><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2020/26-rotation.PNG"alt="rotation" /><figcaption aria-hidden="true">rotation</figcaption></figure><p>那么对于这种算子怎么证明收敛性呢？如果得不到收缩性质，那么我们可以放松一点要求，比如得到下面的<span class="math display">\[\|T x-T y\|^{2} \leq\|x-y\|^{2}-\eta\|R x-R y\|^{2}, \quad \forall x, y\in \mathcal{H}\]</span> 这个算子 <span class="math inline">\(R\)</span>一会再说，虽然我们还是只能有 <spanclass="math inline">\(L=1\)</span>，但是每次迭代之后都可以减少一点小尾巴，累积起来就能收敛到不动点了。那么就让我们再引入一些定义吧。</p><p>定义不动点残差算子 <span class="math inline">\(R:=I-T\)</span>，有<span class="math inline">\(Rx^\star=0\iffx^\star=Tx^\star\)</span>。</p><p><strong>定义</strong>：若 <span class="math inline">\(T\)</span>对于某些 <span class="math inline">\(\eta&gt;0\)</span>满足下式，则称其为平均算子(<strong>averaged operator</strong>) <spanclass="math display">\[\|T x-T y\|^{2} \leq\|x-y\|^{2}-\eta\|R x-R y\|^{2}, \quad \forall x, y\in \mathcal{H}\]</span> <strong>定义</strong>：若 <spanclass="math inline">\(T\)</span> 对于某些 <spanclass="math inline">\(\eta&gt;0\)</span>满足下式，则称其为准平均算子(<strong>quasi-averaged operator</strong>)<span class="math display">\[\left\|T x-x^{*}\right\|^{2} \leq\left\|x-x^{*}\right\|^{2}-\eta\|Rx\|^{2}, \quad \forall x \in \mathcal{H}\]</span> 我们也可以表示为 <spanclass="math inline">\(\eta:=\frac{1-\alpha}{\alpha}\)</span>，从而将上面平均算子称为<span class="math inline">\(\alpha\)</span>-<strong>averagedoperator</strong>。如果 <spanclass="math inline">\(\alpha=1/2\)</span>，称 <spanclass="math inline">\(T\)</span> 为 <strong>firmlynonexpansive</strong>；如果 <spanclass="math inline">\(\alpha=1\)</span>，称 <spanclass="math inline">\(T\)</span> 为 <strong>nonexpansive</strong>。</p><p><strong>引理</strong>：<span class="math inline">\(T\)</span> 是<span class="math inline">\(\alpha\)</span>-averagedoperator，当且仅当存在一个 nonexpansive <spanclass="math inline">\(T&#39;\)</span> 使得 <span class="math display">\[T=(1-\alpha)I+\alpha T&#39;\]</span> 或者等价的有算子 <span class="math display">\[T^{\prime}:=\left(\left(1-\frac{1}{\alpha}\right) I+\frac{1}{\alpha}T\right)\]</span> 是 nonexpansive。</p><p><strong>证明</strong>：通过代数运算可以得到 <spanclass="math display">\[\alpha\left(\|x-y\|^{2}-\left\|T^{\prime} x-T^{\prime}y\right\|^{2}\right)=\|x-y\|^{2}-\|T x-Ty\|^{2}-\frac{1-\alpha}{\alpha}\|R x-R y\|^{2}\]</span> 因此 <span class="math inline">\(T&#39;\)</span> nonexpansive<span class="math inline">\(\iff\)</span> T <spanclass="math inline">\(\alpha\)</span>-averaged。证毕。</p><p>有了 <span class="math inline">\(\alpha\)</span>-averaged性质，我们也可以得到一个收敛性的定理。</p><blockquote><p><strong>定理(Krasnosel’skii)</strong>：<spanclass="math inline">\(T\)</span> 为 <strong><spanclass="math inline">\(\alpha\)</span>-averaged</strong>算子，且不动点存在，则迭代方法 <span class="math display">\[x^{k+1}\leftarrow Tx^k\]</span> 弱收敛至 <span class="math inline">\(T\)</span> 的不动点。</p><p><strong>证明</strong>：略。</p><p><strong>定理(Mann’s version)</strong>：<spanclass="math inline">\(T\)</span> 为 <strong>nonexpansive</strong>算子，且不动点存在，则迭代方法 <span class="math display">\[x^{k+1} \leftarrow\left(1-\lambda_{k}\right) x^{k}+\lambda_{k} T x^{k}\]</span> 弱收敛至 <span class="math inline">\(T\)</span>的不动点，只要满足 <span class="math display">\[\lambda_{k}&gt;0, \quad \sum_{k}\lambda_{k}\left(1-\lambda_{k}\right)=\infty\]</span> <strong>证明</strong>：略。</p></blockquote><p>Mann’s version 相当于是对 Krasnosel’skii的一个推广，每一步都取一个不同的 <spanclass="math inline">\(\alpha\)</span>。</p><p><strong><em>例子 1(PPA)</em></strong>：对于 <spanclass="math inline">\(\min f(x)\)</span>，近似点算子 <spanclass="math display">\[T:=\operatorname{prox}_{\lambda f}\]</span> 就是 <strong>ﬁrmly-nonexpansive</strong>，因此可以弱收敛。</p><h3 id="复合算子">2.3 复合算子</h3><p>对于多个算子复合，有以下性质：</p><ul><li><span class="math inline">\(T_{1}, \ldots, T_{m}: \mathcal{H}\rightarrow \mathcal{H}\)</span> contractive <spanclass="math inline">\(\Longrightarrow T_{1} \circ \cdots \circT_{m}\)</span> contractive</li><li><span class="math inline">\(T_{1}, \ldots, T_{m}: \mathcal{H}\rightarrow \mathcal{H}\)</span> nonexpansive <spanclass="math inline">\(\Longrightarrow T_{1} \circ \cdots \circT_{m}\)</span> nonexpansive</li><li><span class="math inline">\(T_{1}, \ldots, T_{m}: \mathcal{H}\rightarrow \mathcal{H}\)</span> averaged <spanclass="math inline">\(\Longrightarrow T_{1} \circ \cdots \circT_{m}\)</span> averaged</li><li><span class="math inline">\(T_i\)</span> 是 <spanclass="math inline">\(\alpha_i\)</span>-averaged(允许 <spanclass="math inline">\(\alpha_i=1\)</span>) <spanclass="math inline">\(\Longrightarrow T_{1} \circ \cdots \circT_{m}\)</span> 是 <spanclass="math inline">\(\alpha\)</span>-averaged，其中</li></ul><p><span class="math display">\[\alpha=\frac{m}{m-1+\frac{1}{\max _{i} \alpha_{i}}}\]</span></p><p><strong>例子</strong>：如第一小节的投影梯度、PG。</p><h2 id="更一般的情况">3. 更一般的情况</h2><p>我们的优化问题可以概括为求解方程 <span class="math display">\[0\in(A+B)(x)\]</span> 其中 <span class="math inline">\(A,B\)</span>为算子，那么对这个式子做变形就能得到很多方法。</p><p><strong>Forward-backward</strong>： <span class="math display">\[\begin{aligned}0\in(A+B)(x) &amp;\iff 0\in(I+\alpha B)(x)-(I-\alphaA)(x) \\&amp;\iff (I-\alpha A)(x)\in(I+\alpha B)(x) \\&amp;\iffx=(I+\alpha B)^{-1}(I-\alpha A)(x)\end{aligned}\]</span> <strong>Forward-backward-forward</strong>： <spanclass="math display">\[\begin{aligned}0\in(A+B)(x) &amp;\iff x=(I+\alpha B)^{-1}(I-\alpha A)(x)\\&amp;\iff (I-\alpha A)(x)= (I-\alpha A)(I+\alpha B)^{-1}(I-\alphaA)(x) \\&amp;\iff x=\left((I-\alpha A)(I+\alpha B)^{-1}(I-\alphaA)+\alpha A\right)(x)\end{aligned}\]</span> <strong>Combetts-Pesquest</strong>： <spanclass="math display">\[\begin{aligned}0\in(A+B+C)(x) &amp;\iff \begin{cases}0\in Ax+u+Cx \\u\in Bx \end{cases} \\&amp;\iff 0\in \left[\begin{array}{c}Ax \\B^{-1}u\end{array}\right] + \left[\begin{array}{c}u+Cx \\-x\end{array}\right]\end{aligned}\]</span> <strong>DR splitting</strong>： <span class="math display">\[\begin{aligned}0\in(A+B)(x) \iff (\frac{1}{2}I+\frac{1}{2}C_AR_B)(z)=z,\quad x=R_B(z)\\\end{aligned}\]</span> 其中</p><p><span class="math inline">\(C_A\)</span>：Cayley operator，<spanclass="math inline">\(C_A=2R_A-I=2\text{prox}_f-I\)</span></p><p><span class="math inline">\(R_B\)</span>：resolvent operator，<spanclass="math inline">\(R_B=(z)=(I+B)^{-1}(z)\)</span></p>]]></content>
    
    
    <categories>
      
      <category>Convex Optimization</category>
      
    </categories>
    
    
    <tags>
      
      <tag>利普希兹连续</tag>
      
      <tag>强凸函数</tag>
      
      <tag>近似点算子</tag>
      
      <tag>PG 算法</tag>
      
      <tag>PPA</tag>
      
      <tag>算子分裂法</tag>
      
      <tag>不动点迭代</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>凸优化笔记25：原始对偶问题 PDHG</title>
    <link href="/2020/05/24/optimization/ch25-PDHG/"/>
    <url>/2020/05/24/optimization/ch25-PDHG/</url>
    
    <content type="html"><![CDATA[<p>前面的章节要么从原始问题出发，要么从对偶问题出发，通过求解近似点或者一个子优化问题进行迭代，而且推导过程中我们发现根据问题的参数特征，比如矩阵<span class="math inline">\(A\)</span>是瘦高型的还是矮胖型的，采用对偶和原始问题的复杂度会不一样，可以选择一个更简单的。而这一节，我们将要从<strong>原始对偶问题</strong>出发来优化，什么是原始对偶问题呢？就是原始优化变量和对偶优化变量（原始函数和共轭函数）混合在一块，看下面的原理就知道了。</p><span id="more"></span><h2 id="原始对偶问题">1. 原始对偶问题</h2><p>现在考虑原始优化问题，其中 <span class="math inline">\(f,g\)</span>为闭凸函数 <span class="math display">\[\min \quad f(x)+g(Ax)\]</span> 这个问题我们前面遇到好多次了，一般都是取 <spanclass="math inline">\(y=Ax\)</span>加一个约束条件然后计算拉格朗日函数（自己拿小本本写一下），再求解 KKT条件对吧。好，让我们列出来 KKT 条件：</p><ol type="1"><li>原始可行性：<spanclass="math inline">\(x\in\text{dom}f,Ax=y\in\text{dom}g\)</span></li><li><span class="math inline">\(x,z\)</span>是拉格朗日函数的最小值点，因此 <spanclass="math inline">\(-A^Tz\in\partial f(x),z\in\partialg(y)\)</span></li></ol><p>其中 <span class="math inline">\(z\in\partial g(y)\iffAx=y\in\partial g^\star(z)\)</span>。也就是说，要想求解 KKT条件，我们需要的实际上是求解下面一个“方程” <span class="math display">\[0 \in\left[\begin{array}{cc}0 &amp; A^{T} \\-A &amp;0\end{array}\right]\left[\begin{array}{l}x\\z\end{array}\right]+\left[\begin{array}{c}\partial f(x) \\\partialg^{\star}(z)\end{array}\right]\]</span></p><blockquote><p><strong>Remarks</strong>：这个式子可重要啦，后面还会用到！而且他从集合的角度揭示了我们求解最优值问题的本质，那就是找一个<strong>包含关系</strong>。</p><p>比如上面的这个式子我们用一个算子来表示为 <spanclass="math inline">\(T(x,z)\)</span>，我们求解最优值实际上要就是找满足<span class="math inline">\(0\in T(x,z)\)</span> 的解 <spanclass="math inline">\((x^\star,z^\star)\)</span>。而对一个简单的优化问题<span class="math inline">\(\min f(x)\)</span>，我们实际上就是在找满足<span class="math inline">\(0\in\partial f(x)\)</span> 的 <spanclass="math inline">\(x^\star\)</span>，这个时候我们可以把次梯度看作是一个算子。</p><p>在这一章的后面几个小节，我们将从算子的角度重新来看待优化问题，看完之后可以再回到这里细细品味。</p></blockquote><p>好我们先把这个东西放一放，再来看看另一个跟拉格朗日函数有关的函数<span class="math display">\[\begin{aligned}h(x,z)&amp;=\inf_{y}L(x,y,z)\\&amp;=f(x)-g^\star(z)+z^TAx\end{aligned}\]</span> 如果计算 <span class="math inline">\(0\in\partialh(x,z)\)</span>是不是就是上面那个方程？！也就是说上面很重要的那个方程实际上就是在求解<span class="math inline">\(h(x,z)\)</span> 的鞍点！很容易理解，因为 KKT条件本质上就是在求拉格朗日函数的鞍点（当然，如果存在不等式约束就不一定是鞍点了）。大家注意，你看这个<span class="math inline">\(h\)</span> <del>他又长又宽</del>，这个 <spanclass="math inline">\(h\)</span> 同时包含了原始变量 <spanclass="math inline">\(x\)</span> 和对偶变量 <spanclass="math inline">\(z\)</span>，同时还既有原始函数 <spanclass="math inline">\(f\)</span> 又有对偶函数 <spanclass="math inline">\(g^\star\)</span>，所以我们叫他原始对偶优化问题，<spanclass="math inline">\(h\)</span> 也是部分拉格朗日函数(partialLagrangian)。</p><h2 id="pdhg">2. PDHG</h2><p>前面说了我们要求解的问题是 <span class="math display">\[0 \in\left[\begin{array}{cc}0 &amp; A^{T} \\-A &amp; 0\end{array}\right]\left[\begin{array}{l}x \\z\end{array}\right]+\left[\begin{array}{c}\partial f(x) \\\partial g^{\star}(z)\end{array}\right]\]</span></p><blockquote><p><strong>PDHG(Primal-dual hybrid gradientmethod)</strong>的迭代格式是这样的 <span class="math display">\[\begin{array}{l}x_{k+1}=\operatorname{prox}_{\tau f}\left(x_{k}-\tau A^{T} z_{k}\right)\\z_{k+1}=\operatorname{prox}_{\sigma g^{*}}\left(z_{k}+\sigma A\left(2x_{k+1}-x_{k}\right)\right)\end{array}\]</span> 步长需要满足 <spanclass="math inline">\(\sigma\tau\|A\|_2^2\le1\)</span>。</p></blockquote><p>是不是看起来跟 DR方法很像呢？事实上他们两个是等价的，后面会证明。回忆ADMM，我们每次需要求解的优化问题是 <span class="math display">\[x^{k+1}=\arg\min_x f(x)+\frac{t}{2}\| Ax-y^k+\frac{z^k}{t}\|^2\]</span> 要求解这个优化问题，我们往往会得到一个线性方程，还需要计算<span class="math inline">\((A^TA)^{-1}\)</span>，这就很麻烦了。但是观察PDHG 的迭代格式，我们只需要求解 <spanclass="math inline">\(f,g^\star\)</span> 的 <spanclass="math inline">\(\text{prox}\)</span> 算子，我们只需要求解 <spanclass="math inline">\(A,A^T\)</span>之间的乘法而不需要求逆了，这就方便很多了。</p><figure><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2020/25-example.png"alt="example" /><figcaption aria-hidden="true">example</figcaption></figure><p>看上面这个例子，我们前面说过 ADMM 等价于 dual DR，不过这个例子里边PDHG 是最慢的。</p><p>下面我们就来证明一下如何从 PDHG 导出 DR 方法。</p><p>对于优化问题 <span class="math inline">\(\minf(x)+g(x)\)</span>，实际上相当于 <span class="math inline">\(\minf(x)+g(Ax),A=I\)</span>，另外我们再取 PDHG 中的 <spanclass="math inline">\(\sigma=\tau=1\)</span>，那么就可以得到 <spanclass="math display">\[\begin{array}{l}x_{k+1}=\operatorname{prox}_{f}\left(x_{k}-z_{k}\right) \\z_{k+1}=\operatorname{prox}_{g^{*}}\left(z_{k}+2 x_{k+1}-x_{k}\right)\end{array}\]</span> 这实际上就是 DR Splitting 那一节讲的原始对偶形式。</p><p>另外也可以从 DR 方法导出 PDHG。我们可以将原问题 <spanclass="math inline">\(\min f(x)+g(A x)\)</span> 改写为 <spanclass="math display">\[\begin{aligned}\operatorname{minimize} &amp;\quad f(x)+g(A x+B y) \\\text{subject to} &amp;\quad y=0\end{aligned}\]</span> 这里边我们可以选择 <span class="math inline">\(B\)</span> 使<span class="math inline">\(AA^T+BB^T=(1/\alpha)I\)</span>，其中 <spanclass="math inline">\(1/\alpha\ge\|A\|_2^2\)</span>。为什么这么选呢？令<span class="math display">\[\tilde{g}(x,y)=g(Ax+By)=g\left(\tilde{A}\left(\begin{array}{c}x\\y\end{array}\right)\right)\]</span> 那么就有 <spanclass="math inline">\(\tilde{A}\tilde{A}^T=(1/\alpha)I\)</span>，而前面讲<span class="math inline">\(\text{prox}\)</span>算子的时候我们讲了一个性质，满足这个条件的时候 <spanclass="math inline">\(\text{prox}_{\tilde{g}}\)</span> 可以用 <spanclass="math inline">\(\text{prox}_g\)</span> 来表示。</p><blockquote><p>复习：<span class="math inline">\(\text{prox}\)</span> 算子的性质</p><p><span class="math inline">\(f(x)=g(Ax+b)\)</span>，对于一般的 <spanclass="math inline">\(A\)</span> 并不能得到比较好的性质，但如果 <spanclass="math inline">\(AA^T=(1/\alpha)I\)</span>，则有 <spanclass="math display">\[\begin{aligned}\operatorname{prox}_{f}(x) &amp;=\left(I-\alpha A^{T}A\right) x+\alpha A^{T}\left(\operatorname{prox}_{\alpha^{-1} g}(Ax+b)-b\right) \\&amp;=x-\alpha A^{T}\left(Ax+b-\operatorname{prox}_{\alpha^{-1} g}(A x+b)\right)\end{aligned}\]</span></p></blockquote><p>我们还可以取 <spanclass="math inline">\(\tilde{f}(x,y)=f(x)+\delta_{0}(y)\)</span>，那么优化问题就变成了<span class="math inline">\(\min\tilde{f}(x,y)+\tilde{g}(x,y)\)</span>，应用 DR 方法迭代格式为 <spanclass="math display">\[\begin{array}{l}{\left[\begin{array}{c}x_{k+1} \\y_{k+1}\end{array}\right]=\operatorname{prox}_{\tau \tilde{f}}\left(\left[\begin{array}{c}x_{k}-p_{k} \\y_{k}-q_{k}\end{array}\right]\right)} \\{\left[\begin{array}{c}p_{k+1} \\q_{k+1}\end{array}\right]=\operatorname{prox}_{(\tau\tilde{g})^{*}}\left(\left[\begin{array}{c}p_{k}+2 x_{k+1}-x_{k} \\q_{k}+2 y_{k+1}-y_{k}\end{array}\right]\right)}\end{array}\]</span> 我们需要计算 <spanclass="math inline">\(\text{prox}_{\tilde{f}}\)</span> 和 <spanclass="math inline">\(\text{prox}_{\tilde{g}}\)</span> <spanclass="math display">\[\operatorname{prox}_{\tau \tilde{f}}(x, y)=\left[\begin{array}{c}\operatorname{prox}_{\tau f}(x) \\0\end{array}\right]\]</span> <span class="math display">\[\begin{aligned}\operatorname{prox}_{\tau \tilde{g}}(x, y) &amp;=\left[\begin{array}{c}x \\y\end{array}\right]-\alpha\left[\begin{array}{c}A^{T} \\B^{T}\end{array}\right]\left(A x+B y-\operatorname{prox}_{(\tau / \alpha)g}(A x+B y)\right.\\&amp;=\left[\begin{array}{c}x \\y\end{array}\right]-\tau\left[\begin{array}{c}A^{T} \\B^{T}\end{array}\right] \operatorname{prox}_{\sigma g^{\star}}(\sigma(A x+By)) \\&amp;=\left[\begin{array}{c}x \\y\end{array}\right]-\operatorname{prox}_{(\tau \tilde{g})^\star}(x, y)\end{aligned}\]</span></p><p>其中 <span class="math inline">\(\sigma=\alpha/\tau\)</span>。代入到DR 方法的迭代方程 <span class="math display">\[\begin{array}{l}{\left[\begin{array}{c}x_{k+1} \\y_{k+1}\end{array}\right]=\left[\begin{array}{c}\operatorname{prox}_{\tau f}\left(x_{k}-p_{k}\right) \\0\end{array}\right]} \\{\left[\begin{array}{c}p_{k+1} \\q_{k+1}\end{array}\right]=\tau\left[\begin{array}{c}A^{T} \\B^{T}\end{array}\right] \operatorname{prox}_{\sigmag^{*}}\left(\sigma\left[\begin{array}{cc}A &amp; B\end{array}\right]\left[\begin{array}{c}p_{k}+2 x_{k+1}-x_{k} \\q_{k}+2 y_{k+1}-y_{k}\end{array}\right]\right)}\end{array}\]</span> 根据第二个式子应该有 <spanclass="math inline">\(\left[\begin{array}{c} p_{k} \\ q_{k}\end{array}\right] \in \text { range }\left[\begin{array}{c} A^{T} \\B^{T} \end{array}\right]\)</span>，因此存在 <spanclass="math inline">\(z_k\)</span> 满足 <spanclass="math inline">\(\left[\begin{array}{c}p_{k+1} \\q_{k+1}\end{array}\right]=\tau\left[\begin{array}{c}A^{T} \\B^{T}\end{array}\right]z_k\)</span>。同时因为 <spanclass="math inline">\(AA^T+BB^T=(1/\alpha)I\)</span>，所以能找到唯一的<span class="math inline">\(z_k\)</span> 同时满足 <spanclass="math inline">\(z_k=\sigma(Ap_k+Bq_k)\)</span>。那么把 <spanclass="math inline">\(z_k\)</span> 代入到上面的迭代方程，同时消掉 <spanclass="math inline">\(y_k=0\)</span>，就可以得到 <spanclass="math display">\[x_{k+1}=\operatorname{prox}_{\tau f}\left(x_{k}-\tau A^{T}z_{k}\right)\\ z_{k+1}=\operatorname{prox}_{\sigmag^{*}}\left(z_{k}+\sigma A\left(2 x_{k+1}-x_{k}\right)\right)\]</span> 这就是 PDHG 算法，其中 <spanclass="math inline">\(\sigma\tau=\alpha\le 1/\|A\|^2\)</span>。</p><p>当然，我们还可以对 PDHG 算法进行改进，比如：</p><p><strong>PDHG withover relaxation</strong>：<spanclass="math inline">\(\rho_k\in(0,2)\)</span> <spanclass="math display">\[\begin{aligned}\bar{x}_{k+1} &amp;=\operatorname{prox}_{\tau f}\left(x_{k}-\tau A^{T}z_{k}\right) \\\bar{z}_{k+1} &amp;=\operatorname{prox}_{\sigma g^{*}}\left(z_{k}+\sigmaA\left(2 \bar{x}_{k+1}-x_{k}\right)\right) \\\left[\begin{array}{c}x_{k+1} \\z_{k+1}\end{array}\right] &amp;=\left[\begin{array}{c}x_{k} \\z_{k}\end{array}\right]+\rho_{k}\left[\begin{array}{c}\bar{x}_{k+1}-x_{k} \\\bar{z}_{k+1}-z_{k}\end{array}\right]\end{aligned}\]</span> 其收敛性与 DR 方法相同。</p><p><strong>PDHG with acceleration</strong>： <spanclass="math display">\[\begin{array}{l}x_{k+1}=\operatorname{prox}_{\tau_{k} f}\left(x_{k}-\tau_{k} A^{T}z_{k}\right) \\z_{k+1}=\operatorname{prox}_{\sigma_{k} g^{*}}\left(z_{k}+\sigma_{k}A\left(\left(1+\theta_{k}\right) x_{k+1}-\theta_{k} x_{k}\right)\right)\end{array}\]</span> 对于强凸函数 <spanclass="math inline">\(f\)</span>，以及适当的选择 <spanclass="math inline">\(\sigma_k,\tau_k,\theta_k\)</span>，收敛速度可以达到<span class="math inline">\(1/k^2\)</span>。</p><h2 id="单调算子">3. 单调算子</h2><p>单调算子(monotoneoperator)我们在讲次梯度的时候提到过，这次我们从算子的角度理解一下 PDHG方法。</p><h3 id="集值算子">3.1 集值算子</h3><p>集值算子(Multivalued/set-valuedoperator)，就是说映射得到的不是单个的值，而是一个集合。比如算子 <spanclass="math inline">\(F\)</span> 把向量 <span class="math inline">\(x\inR^n\)</span> 映射到集合 <span class="math inline">\(F(x)\subseteqR^n\)</span>。有两个定义</p><ul><li>定义域 <span class="math inline">\(\operatorname{dom} F =\left\{x\in \mathbf{R}^{n} | F(x) \neq \emptyset\right\}\)</span></li><li>图 <span class="math inline">\(\operatorname{gr}(F) =\left\{(x, y)\in \mathbf{R}^{n} \times \mathbf{R}^{n} | x \in \operatorname{dom} F, y\in F(x)\right\}\)</span></li></ul><figure><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2020/25-set-valued.png"alt="set-valued" /><figcaption aria-hidden="true">set-valued</figcaption></figure><p>对算子放缩、求逆等操作都可以表示为对“<strong>图</strong>”的<strong>线性变换</strong>。</p><p><strong>求逆</strong>：<span class="math inline">\(F^{-1}(x)=\{y|x\in F(y)\}\)</span> <span class="math display">\[\operatorname{gr}\left(F^{-1}\right)=\left[\begin{array}{cc}0 &amp; I \\I &amp; 0\end{array}\right] \operatorname{gr}(F)\]</span> <strong>放缩</strong>：<span class="math inline">\((\lambdaF)(x)=\lambda F(x)\)</span> and <spanclass="math inline">\((F\lambda)(x)=F(\lambda x)\)</span> <spanclass="math display">\[\operatorname{gr}(\lambda F)=\left[\begin{array}{cc}I &amp; 0 \\0 &amp; \lambda I\end{array}\right] \operatorname{gr}(F), \quad \operatorname{gr}(F\lambda)=\left[\begin{array}{cc}(1 / \lambda) I &amp; 0 \\0 &amp; I\end{array}\right] \operatorname{gr}(F)\]</span> <strong>相加</strong>：<span class="math inline">\((I+\lambdaF)(x)=\{x+\lambda y | y \in F(x)\}\)</span> <spanclass="math display">\[\operatorname{gr}(I+\lambda F)=\left[\begin{array}{cc}I &amp; 0 \\I &amp; \lambda I\end{array}\right] \operatorname{gr}(F)\]</span> 注意 <span class="math inline">\((I+\lambda F)\)</span>这个形式很特别，如果我们取 <span class="math inline">\(F(x)=\partialf(x)\)</span>，那么 <span class="math inline">\((I+\lambdaF)^{-1}\)</span> 实际上就是 <spanclass="math inline">\(\text{prox}\)</span> 算子（<spanclass="math inline">\(\lambda&gt;0\)</span>），不过我们给他取了另一个名字<strong>Resolvent</strong>，<span class="math inline">\(y\in(I+\lambdaF)^{-1}(x)\iff x-y\in\partial f(y)\)</span>，用图来表示就是 <spanclass="math display">\[\operatorname{gr}\left((I+\lambda F)^{-1}\right)=\left[\begin{array}{cc}I &amp; \lambda I \\I &amp; 0\end{array}\right] \operatorname{gr}(F)\]</span> <strong><em>例子 1</em></strong>：<spanclass="math inline">\((I+\lambda \partialf(x))^{-1}=\text{prox}_{\lambda f}(x)\)</span></p><p><strong><em>例子 2</em></strong>：<spanclass="math inline">\(F(x)=Ax+b\)</span>，<spanclass="math inline">\((I+\lambda F)^{-1}(x)=(I+\lambda A)^{-1}(x-\lambdab)\)</span>，后面这个求逆完全就是矩阵求逆。</p><figure><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2020/25-transformation.PNG"alt="transformation" /><figcaption aria-hidden="true">transformation</figcaption></figure><h3 id="单调算子-1">3.2 单调算子</h3><p><strong>定义</strong>：<span class="math inline">\(F\)</span>是单调算子，若 <span class="math display">\[(y-\hat{y})^{T}(x-\hat{x}) \geq 0 \quad \text { for all } x, \hat{x} \in\operatorname{dom} F, y \in F(x), \hat{y} \in F(\hat{x})\]</span> 如果用图表示，就应该有 <span class="math display">\[\left[\begin{array}{c}x-\hat{x}\\y-\hat{y}\end{array}\right]^{T}\left[\begin{array}{cc}0 &amp; I \\I&amp; 0\end{array}\right]\left[\begin{array}{c}x-\hat{x}\\y-\hat{y}\end{array}\right] \geq 0 \quad \text { for all }(x,y),(\hat{x}, \hat{y}) \in \operatorname{gr}(F) \quad (\bigstar)\]</span> 上面这个式子很重要！！！后面会多次用到。</p><p><strong><em>例子</em></strong>：我们需要用到的单调算子有：</p><ol type="1"><li>凸函数次梯度 <span class="math inline">\(\partial f(x)\)</span></li><li>仿射变换 <spanclass="math inline">\(F(x)=Cx+d\)</span>，并且需要满足 <spanclass="math inline">\(C+C^T\succeq 0\)</span></li><li>他们的组合，比如</li></ol><p><span class="math display">\[F(x, z)=\left[\begin{array}{cc}0 &amp; A^{T} \\-A &amp; 0\end{array}\right]\left[\begin{array}{c}x \\z\end{array}\right]+\left[\begin{array}{c}\partial f(x) \\\partial g^{*}(z)\end{array}\right]\]</span></p><p>除了单调算子，还有个<strong>最大单调算子(Maximal monotoneoperator)</strong>，也就是说它的图不能是其他任意单调算子的真子集，举个栗子就明白了，参考下面的图。我们可以知道b闭凸函数的偏导数、单调仿射变换是最大单调算子，除此之外，还有定理。</p><p><strong>Minty’s Theorem</strong>：单调算子 <spanclass="math inline">\(F\)</span> 是最大单调算子当且仅当 <spanclass="math display">\[\operatorname{im}(I+F)=\bigcup_{x \in \operatorname{dom}F}(x+F(x))=\mathbf{R}^{n}\]</span> <imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2020/25-maximal-monotone.PNG"alt="maximal-monotone" /></p><p>除了单调性质，我们在证明收敛新的时候往往还要用到 Lipschitz连续、强凸性质等等，实际上我们前面已经介绍过很多次了，而且用了一堆名词coercivity、expansive、firmlynonexpansive，我实在是晕了......这里我们就再总结一下。假设算子 <spanclass="math inline">\(F\)</span> 有 <spanclass="math inline">\(y=F(x),\hat{y}=F(\hat{x})\)</span></p><table><thead><tr class="header"><th><span class="math inline">\((y-\hat{y})^T(x-\hat{x})\ge \mu \Vertx-\hat{x}\Vert^2,\mu&gt;0\)</span></th><th><span class="math inline">\((y-\hat{y})^T(x-\hat{x})\ge \gamma \Verty-\hat{y}\Vert^2,\gamma&gt;0\)</span></th><th>$(y-)<sup>T(x-)Lx-</sup>2 $</th></tr></thead><tbody><tr class="odd"><td>coercive</td><td>co-coercive</td><td></td></tr><tr class="even"><td></td><td>ﬁrmly nonexpansive(<spanclass="math inline">\(\gamma=1\)</span>)</td><td>nonexpansive(<span class="math inline">\(L\le 1\)</span>)</td></tr><tr class="odd"><td></td><td></td><td>Lipschitz continuous</td></tr></tbody></table><p><strong>它们之间的关系</strong></p><ol type="1"><li>如果满足 co-coercive 并且有 <spanclass="math inline">\(\gamma=1\)</span>，则其为 firmly nonexpansive</li><li>如果满足 Lipschitz continuous 并且有 <spanclass="math inline">\(L\le 1\)</span>，则其为 nonexpansive</li><li>co-coercivity 可以导出 Lipschitz continuous(<spanclass="math inline">\(L=1/\gamma\)</span>)，但反之不一定。不过对于闭凸函数他们是等价的。</li></ol><p><strong>它们各自的性质</strong></p><p><strong>Coercivity</strong>等价于 <span class="math inline">\(F-\muI\)</span> 是一个单调算子，也等价于 <span class="math display">\[\left[\begin{array}{c}x-\hat{x} \\y-\hat{y}\end{array}\right]^{T}\left[\begin{array}{cc}-2 \mu I &amp; I \\I &amp; 0\end{array}\right]\left[\begin{array}{c}x-\hat{x} \\y-\hat{y}\end{array}\right] \geq 0 \quad \text { for all }(x, y),(\hat{x},\hat{y}) \in \operatorname{gr}(F)\]</span> <strong>Co-coercivity</strong>等价于 <spanclass="math display">\[\left[\begin{array}{c}x-\hat{x} \\y-\hat{y}\end{array}\right]^{T}\left[\begin{array}{cc}0 &amp; I \\I &amp; -2 \gamma I\end{array}\right]\left[\begin{array}{c}x-\hat{x} \\y-\hat{y}\end{array}\right] \geq 0 \quad \text { for all }(x, y),(\hat{x},\hat{y}) \in \operatorname{gr}(F)\]</span></p><p>对前面提到的 resolvent 来说，算子单调性有以下重要性质：</p><blockquote><p>重要性质：<strong>算子是单调的，当且仅当他的 resolvant 是 firmlynonexpansive</strong></p><p>证明只需要根据矩阵等式 <spanclass="math inline">\(\lambda\left[\begin{array}{ll}0 &amp; I \\ I &amp;0\end{array}\right]=\left[\begin{array}{cc}I &amp; I \\ \lambda I &amp;0 \end{array}\right]\left[\begin{array}{cc}0 &amp; I \\ I &amp; -2 I\end{array}\right]\left[\begin{array}{cc}I &amp; \lambda I \\ I &amp; 0\end{array}\right]\)</span> 就可以得到（结合 <spanclass="math inline">\((\bigstar)\)</span> 式）。</p></blockquote><p>另外单调算子 <span class="math inline">\(F\)</span>是最大单调算子，当且仅当 <span class="math display">\[\text{dom}(I+\lambda F)^{-1}=R^n\]</span> 这可以由 Minty’s theorem 得到。</p><h2 id="近似点算法">4. 近似点算法</h2><h3 id="回望-ppa">4.1 回望 PPA</h3><p>前面讲到了 Resolvant <span class="math inline">\((I+\lambdaF)^{-1}\)</span> 实际上就是近似点算子，而 PPA 就是在计算近似点，回忆 PPA的迭代格式为 <span class="math display">\[\begin{aligned}x_{k+1} &amp;= \text{prox}_{t_k f}(x_k) \\&amp;= (1+t_k F)^{-1}(x_k)\end{aligned}\]</span> 我们实际上就是在找 Resolvant 算子 <spanclass="math inline">\(R_t=(I+t F)^{-1}\)</span>的<strong>不动点</strong> <span class="math display">\[x=R_t(x)\iff x\in(1+tF)(x)\iff 0\in F(x)\]</span> 加入松弛后的 PPA 可以写成下面的形式，其中 <spanclass="math inline">\(\rho_k\in(0,2)\)</span> 为松弛参数 <spanclass="math display">\[x_{k+1}=x_k+\rho_k(R_{t_k}(x_k)-x_k)\]</span> 那么<strong>收敛性</strong>是怎么样呢？假如 <spanclass="math inline">\(F^{-1}(0)\neq\varnothing\)</span>，在满足以下条件时 PPA 可以收敛</p><ul><li><span class="math inline">\(t_k=t&gt;0,\rho_k=\rho\in(0,2)\)</span>都选择常数值；或者</li><li><span class="math inline">\(t_k,\rho_k\)</span>随迭代次数变化，但是需要满足 <span class="math inline">\(t_k\get_{\min}&gt; 0,0&lt;\rho_{\min}\le \rho_k\le \rho_{\max}&lt; 2,\forallk\)</span></li></ul><p>这个收敛性的证明可以通过证明 Resolvant 的 firmly nonexpansiveness性质来完成（可以去复习 DR方法的收敛性证明，那里实际上也是一个不动点迭代）。</p><h3 id="再看-ppa">4.2 再看 PPA</h3><p>先打个预防针，这一部分很重要！！！看完以后也许会对 PPA以及其他优化算法有更多的理解！！！</p><p>首先我们回忆 PPA 是什么。对于优化问题 <spanclass="math inline">\(\min f(x)\)</span>，迭代格式为 <spanclass="math inline">\(x^+=\text{prox}_{tf}(x)\)</span>。如果我们把 <spanclass="math inline">\(\partial f(x)\)</span> 用算子 <spanclass="math inline">\(F\)</span> 来表示，那么优化问题实际上就是在找满足<span class="math inline">\(0\in F(x)\)</span> 的解，PPA实际上就是在找不动点 <spanclass="math inline">\(x=(1+tF)^{-1}(x)\)</span>。</p><p>假如我们现在引入一个<strong>非奇异矩阵</strong> <spanclass="math inline">\(A\)</span>，令 <spanclass="math inline">\(x=Ay\)</span>代入到原方程（为什么要这么做？如果合适地选择 <spanclass="math inline">\(A\)</span>的话，有时候可以使问题简化，跟着推导的思路看到最后就能理解了，来吧！）</p><p>记 <spanclass="math inline">\(g(y)=f(Ay)\)</span>，那么优化问题变为了 <spanclass="math inline">\(\min g(y)\)</span>，注意由于 <spanclass="math inline">\(A\)</span> 是非奇异的，所以这个问题跟原问题 <spanclass="math inline">\(\min f(x)\)</span> 是等价的。我们需要找满足 <spanclass="math inline">\(0\in\partial g(y)=A^T\partial f(Ay)\)</span>的解，于是可以定义算子 <span class="math inline">\(G(y)=\partialg(y)=A^TF(Ay)\)</span>，这个时候 <span class="math inline">\(G\)</span>的图就是做一个线性变换 <span class="math display">\[\operatorname{gr}(G)=\left[\begin{array}{cc}A^{-1} &amp; 0 \\0 &amp;A^{T}\end{array}\right] \operatorname{gr}(F)\]</span> 如果 <span class="math inline">\(F\)</span>是一个单调算子的话，那么 <span class="math inline">\(G\)</span>也是一个<strong>单调算子</strong>，这是因为（结合 <spanclass="math inline">\((\bigstar)\)</span> 式） <spanclass="math display">\[\left[\begin{array}{cc}A^{-1} &amp; 0 \\0 &amp;A^{T}\end{array}\right]^{T}\left[\begin{array}{cc}0 &amp; I \\I &amp;0\end{array}\right]\left[\begin{array}{cc}A^{-1} &amp; 0 \\0 &amp;A^{T}\end{array}\right]=\left[\begin{array}{cc}0 &amp; I \\I &amp;0\end{array}\right]\]</span> 然后对 <span class="math inline">\(\min g(y)\)</span> 应用 PPA迭代格式为 <span class="math display">\[y_{k+1}=(I+t_kG)^{-1}(y_k)\]</span> 我们把 <spanclass="math inline">\(x_k=Ay_k,G=A^TF(Ay)\)</span>都代入进去，就能把上面的式子等价表示为 <span class="math display">\[\frac{1}{t_k}H(x_k-x)\in F(x)\]</span> 其中 <span class="math inline">\(H=(AA^T)^{-1}\succ0\)</span>。这个式子又可以表示为 <span class="math display">\[x_{k+1}=(H+t_kF)^{-1}(Hx_k)\]</span> 因为 <span class="math inline">\(\min g(y)\iff \minf(x)\)</span>，所以上面这个迭代格式也完全适用于原问题，如果取 <spanclass="math inline">\(H=I\)</span> 那就是原始形式的PPA，如果取别的形式，那么就获得了推广形式的 PPA！</p><p>引入 <span class="math inline">\(A\)</span> 有什么作用呢？我们看<span class="math display">\[\frac{1}{t_k}H(x_k-x)\in F(x) \iffx_{k+1}=\arg\min_x\left(f(x)+\frac{1}{2t_k}\|x-x_k\|_H^2 \right)\]</span> 其中 <spanclass="math inline">\(\|x\|_H^2=x^THx\)</span>，如果说 <spanclass="math inline">\(f(x)=(1/2)\|Bx-b\|^2\)</span>，那么我们就可以选择<span class="math inline">\(A\)</span> 使 <spanclass="math inline">\(H=(1/\alpha) I-B^TB\)</span>，这样迭代求解 <spanclass="math inline">\(x_{k+1}\)</span>就简单了。当然这个作用范围很有限，下面的例子更能显现他的威力。</p><p>我们再回到原始对偶问题，记算子 <span class="math inline">\(F\)</span>为 <span class="math display">\[F(x,z)=\left[\begin{array}{cc}0 &amp; A^{T} \\-A &amp;0\end{array}\right]\left[\begin{array}{l}x\\z\end{array}\right]+\left[\begin{array}{c}\partial f(x) \\\partialg^{\star}(z)\end{array}\right]\]</span> 优化问题就是要找到 <span class="math inline">\(0\inF(x,z)\)</span>。如果用原始的 PPA 算法，迭代方程为 <spanclass="math inline">\((x_{k+1},z_{k+1})=(I+tF)^{-1}(x_k,z_k)\)</span>，<spanclass="math inline">\((x_{k+1},z_{k+1})\)</span> 是下面方程的解</p><figure><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2020/25-ppa.PNG"alt="ppa" /><figcaption aria-hidden="true">ppa</figcaption></figure><p>注意到 <span class="math inline">\(x,z\)</span>纠缠在一起了，我们想把他们拆开来分别求解 <spanclass="math inline">\(x,z\)</span>，问题就能更简单。怎么做呢，引入一个<span class="math inline">\(H\)</span> <span class="math display">\[H=\left[\begin{array}{cc}I &amp; -\tau A^{T} \\-\tau A &amp; (\tau /\sigma) I\end{array}\right]\]</span> 其中若 <span class="math inline">\(\sigma\tau\|A\|_2^2&lt;1\)</span> 则 <span class="math inline">\(H\)</span>为正定矩阵。这个时候 <spanclass="math inline">\((x_{k+1},z_{k+1})\)</span> 就是下面方程的解 <spanclass="math display">\[\begin{array}{c}{\frac{1}{\tau}\left[\begin{array}{cc}I &amp; -\tau A^{T} \\-\tau A &amp; (\tau / \sigma) I\end{array}\right]\left[\begin{array}{c}x_{k}-x \\z_{k}-z\end{array}\right] \in\left[\begin{array}{cc}0 &amp; A^{T} \\-A &amp; 0\end{array}\right]\left[\begin{array}{c}x \\z\end{array}\right]+\left[\begin{array}{c}\partial f(x) \\\partial g^{*}(z)\end{array}\right] }\\\Updownarrow \\{\begin{array}{l}0 \in \partial f(x)+\frac{1}{\tau}\left(x-x_{k}+\tau A^{T} z_{k}\right)\\0 \in \partial g^{*}(z)+\frac{1}{\sigma}\left(z-z_{k}-\sigma A\left(2x-x_{k}\right)\right)\end{array} }\\\Updownarrow \\{\begin{aligned}x_{k+1} &amp;=(I+\tau \partial f)^{-1}\left(x_{k}-\tau A^{T}z_{k}\right) \\z_{k+1} &amp;=\left(I+\sigma \partialg^{*}\right)^{-1}\left(z_{k}+\sigma A\left(2 x_{k+1}-x_{k}\right)\right)\end{aligned} }\end{array}\]</span> 对于化简后的式子，我们就可以先单独求解 <spanclass="math inline">\(x_{k+1}\)</span>，然后再求解 <spanclass="math inline">\(z_{k+1}\)</span>。这实际上也是 PDHG 的迭代方程<span class="math display">\[\begin{array}{l}x_{k+1}=\operatorname{prox}_{\tau f}\left(x_{k}-\tauA^{T} z_{k}\right) \\z_{k+1}=\operatorname{prox}_{\sigmag^{*}}\left(z_{k}+\sigma A\left(2 x_{k+1}-x_{k}\right)\right)\end{array}\]</span></p>]]></content>
    
    
    <categories>
      
      <category>Convex Optimization</category>
      
    </categories>
    
    
    <tags>
      
      <tag>近似点算子</tag>
      
      <tag>PPA</tag>
      
      <tag>算子分裂法</tag>
      
      <tag>原始对偶问题</tag>
      
      <tag>PDHG</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>凸优化笔记24：ADMM</title>
    <link href="/2020/05/20/optimization/ch24-ADMM/"/>
    <url>/2020/05/20/optimization/ch24-ADMM/</url>
    
    <content type="html"><![CDATA[<p>上一节讲了对偶问题上的 DR-splitting 就等价于原问题的ADMM，这一节在详细的讲一下 ADMM 及其变种。</p><span id="more"></span><h2 id="标准-admm-形式">1. 标准 ADMM 形式</h2><p>首先还是给出 ADMM 要求解的问题的格式，也就是约束存在耦合： <spanclass="math display">\[\begin{align}\min_{x,z} \quad&amp; f(x)+g(z) \\\text{s.t.} \quad&amp; Ax+Bz=b\end{align}\]</span> 这个问题的增广拉格朗日函数为 <span class="math display">\[L_{\beta}(\mathbf{x}, \mathbf{z},\mathbf{w})=f(\mathbf{x})+g(\mathbf{z})-\mathbf{w}^{\top}(\mathbf{A}\mathbf{x}+\mathbf{B z}-\mathbf{b})+\frac{\beta}{2}\|\mathbf{A}\mathbf{x}+\mathbf{B z}-\mathbf{b}\|_{2}^{2}\]</span> ADMM 的迭代方程为 <span class="math display">\[\begin{array}{l}\mathbf{x}^{k+1}=\operatorname{argmin}_{\mathbf{x}}L_{\beta}\left(\mathbf{x}, \mathbf{z}^{\mathbf{k}},\mathbf{w}^{k}\right) \\\mathbf{z}^{k+1}=\operatorname{argmin}_{\mathbf{z}}L_{\beta}\left(\mathbf{x}^{k+1}, \mathbf{z}, \mathbf{w}^{k}\right) \\\mathbf{w}^{k+1}=\mathbf{w}^{k}-\beta\left(\mathbf{A}\mathbf{x}^{k+1}+\mathbf{B} \mathbf{z}^{k+1}-\mathbf{b}\right)\end{array}\]</span> 这实际上就是把 ALM 中关于 <spanclass="math inline">\(x,z\)</span>的联合优化给分开了，分别进行优化。如果取 <spanclass="math inline">\(\mathbf{y}^{k}=\mathbf{w}^{k}/\beta\)</span>，就可以转化为<span class="math display">\[\begin{array}{l}\mathbf{x}^{k+1}=\operatorname{argmin}_{\mathbf{x}}f(\mathbf{x})+g\left(\mathbf{z}^{k}\right)+\frac{\beta}{2}\left\|\mathbf{A}\mathbf{x}+\mathbf{B}\mathbf{z}^{k}-\mathbf{b}-\mathbf{y}^{k}\right\|_{2}^{2} \\\mathbf{z}^{k+1}=\operatorname{argmin}_{\mathbf{z}}f\left(\mathbf{x}^{k+1}\right)+g(\mathbf{z})+\frac{\beta}{2}\left\|\mathbf{A}\mathbf{x}^{k+1}+\mathbf{B}\mathbf{z}-\mathbf{b}-\mathbf{y}^{k}\right\|_{2}^{2} \\\mathbf{y}^{k+1}=\mathbf{y}^{k}-\left(\mathbf{A}\mathbf{x}^{k+1}+\mathbf{B} \mathbf{z}^{k+1}-\mathbf{b}\right)\end{array}\]</span> 最后一步也可以加一个步长系数 <span class="math display">\[\mathbf{y}^{k+1}=\mathbf{y}^{k}-\gamma\left(\mathbf{A}\mathbf{x}^{k+1}+\mathbf{B} \mathbf{z}^{k+1}-\mathbf{b}\right)\]</span></p><h2 id="收敛性分析">2. 收敛性分析</h2><p>假如 <span class="math inline">\(x^\star,z^\star,y^\star\)</span>是该问题的最优解，那么对拉格朗日函数求导可以得到 KKT 条件 <spanclass="math display">\[\begin{array}{ll}(\text {primal feasibility}) &amp; \mathbf{A x}^{\star}+\mathbf{Bz}^{\star}=\mathbf{b} \\(\text {dual feasibility } I) &amp; 0 \in \partialf\left(\mathbf{x}^{\star}\right)+\mathbf{A}^{T} \mathbf{y}^{\star} \\(\text {dual feasibility } I I) &amp; 0 \in \partialg\left(\mathbf{z}^{\star}\right)+\mathbf{B}^{T} \mathbf{y}^{\star}\end{array}\]</span> 由于 <spanclass="math inline">\(\mathbf{z}^{k+1}=\operatorname{argmin}_{\mathbf{z}}g(\mathbf{z})+\frac{\beta}{2}\left\|\mathbf{A}\mathbf{x}^{k+1}+\mathbf{B}\mathbf{z}-\mathbf{b}-\mathbf{y}^{k}\right\|_{2}^{2}\)</span>，求导就可以得到<span class="math display">\[\Rightarrow 0 \in \partialg\left(\mathbf{z}^{k+1}\right)+\mathbf{B}^{T}\left(\mathbf{A}\mathbf{x}^{k+1}+\mathbf{B}\mathbf{z}^{k+1}-\mathbf{b}-\mathbf{y}^{k}\right)=\partialg\left(\mathbf{z}^{k+1}\right)+\mathbf{B}^{T} \mathbf{y}^{k+1}\]</span> 也就是说对偶可行性 <span class="math inline">\(II\)</span>在每次迭代过程中都能满足，但是对偶可行性 <spanclass="math inline">\(I\)</span> 则不能满足，因为有 <spanclass="math display">\[0 \in \partialf\left(\mathbf{x}^{k+1}\right)+\mathbf{A}^{T}\left(\mathbf{y}^{k+1}+\mathbf{B}\left(\mathbf{z}^{k}-\mathbf{z}^{k+1}\right)\right)\]</span> 当 <span class="math inline">\(k\to\infty\)</span> 的时候<span class="math inline">\(I\)</span> 还是可以渐近逼近的。</p><p><strong>收敛性</strong>：如果假设 <spanclass="math inline">\(f,g\)</span> 是闭凸函数，并且 KKT条件的解存在，那么 <span class="math inline">\(\mathbf{A}\mathbf{x}^{k}+\mathbf{B z}^{k} \rightarrow \mathbf{b}\)</span>，<spanclass="math inline">\(f\left(\mathbf{x}^{k}\right)+g\left(\mathbf{z}^{k}\right)\rightarrow p^{*}\)</span>，<spanclass="math inline">\(\mathbf{y}^{k}\)</span> 收敛。并且如果 <spanclass="math inline">\((x^k,y^k)\)</span> 有界，他们也收敛。</p><p><strong>收敛速度</strong>：ADMM 算法的收敛速度没有一个 general的分析和结论。在不同的假设条件下有不同的结论。</p><ul><li>如果每步更新都有关于 <spanclass="math inline">\(x^k,y^k,z^k\)</span> 的准确解，并且 <spanclass="math inline">\(f\)</span> 光滑，<spanclass="math inline">\(\nabla f\)</span> 利普希茨连续，那么收敛速度为<spanclass="math inline">\(O(1/k),O(1/k^2)\)</span>（应该是针对不同情况可能有不同速度，课上也没怎么讲，了解一下就够了）</li><li>......</li></ul><h2 id="admm-变种">3. ADMM 变种</h2><p>在 ADMM的标准形式里比较关键的实际上就是要求一个如下形式的子问题（极小化问题）<span class="math display">\[\min _{\mathbf{x}} f(\mathbf{x})+\frac{\beta}{2}\|\mathbf{A}\mathbf{x}-\mathbf{v}\|_{2}^{2}\]</span> 其中 <spanclass="math inline">\(\mathbf{v}=\mathbf{b}-\mathbf{B}\mathbf{z}^{k}+\mathbf{y}^{k}\)</span>。这个问题对于不同的 <spanclass="math inline">\(f\)</span>求解复杂度也不一样，而且有的时候并不能得到准确的解，只能近似。实际上这也是一个优化问题，可以采用的方法有</p><ol type="1"><li>迭代方法，比如 CG，L-BFGS；</li><li>如果 <span class="math inline">\(f(x)=1/2\|Cx-d\|^2\)</span>，那么子问题就是求解方程 <spanclass="math inline">\((C^TC+\beta A^TA)x^{k+1}=\cdots\)</span>，由于<span class="math inline">\(C\)</span>是固定的参数，因此可以在一开始做一次 Cholesky 分解或者 <spanclass="math inline">\(LDL^T\)</span> 分解，之后求解就很简单了。另外如果<span class="math inline">\((C^TC+\beta A^TA)\)</span> 的结构是简单矩阵+ 低秩矩阵，就可以用 Woodbury 公式矩阵求逆；</li><li>单次梯度下降法 <spanclass="math inline">\(\mathbf{x}^{k+1}=\mathbf{x}^{k}-c^{k}\left(\nablaf\left(\mathbf{x}^{k}\right)+\beta \mathbf{A}^{T}\left(\mathbf{A}\mathbf{x}+\mathbf{B}\mathbf{z}^{k}-\mathbf{b}-\mathbf{y}^{k}\right)\right)\)</span></li><li>如果 <span class="math inline">\(f\)</span>非光滑，也可以把上面的梯度下降换成 proximal 梯度下降；</li><li>可以在后面加一个正则项</li></ol><p><span class="math display">\[\mathbf{x}^{k+1}=\operatorname{argmin}f(\mathbf{x})+\frac{\beta}{2}\left\|\mathbf{A} \mathbf{x}+\mathbf{By}^{k}-\mathbf{b}-\mathbf{z}^{k}\right\|_{2}^{2}+\frac{\beta}{2}\left(\mathbf{x}-\mathbf{x}^{k}\right)^{T}\left(\mathbf{D}-\mathbf{A}^{T}\mathbf{A}\right)\left(\mathbf{x}-\mathbf{x}^{k}\right)\]</span></p><p>这个时候优化问题就变成了 <span class="math inline">\(\minf(x)+(\beta/2)(x-x^k)^TD(x-x^k)\)</span>，如果取一个简单的 <spanclass="math inline">\(D\)</span> 比如 <spanclass="math inline">\(D=I\)</span>，那么问题就可能得到简化。</p><h2 id="分布式-admm">4. 分布式 ADMM</h2><p>回想我们之前在计算近似点以及近似点梯度下降的时候，如果函数 <spanclass="math inline">\(f,g\)</span>有特殊结构是不是可以分布式并行计算，而 ADMM的子问题实际上跟近似点算子很像，所以如果有一定的特殊结构也可以并行处理。</p><p>首先回忆一下 ADMM 子问题的形式 <span class="math display">\[\min _{\mathbf{x}} f(\mathbf{x})+\frac{\beta}{2}\|\mathbf{A}\mathbf{x}-\mathbf{v}\|_{2}^{2}\]</span> 现在这个优化变量 <spanclass="math inline">\(\mathbf{x}\)</span> 是一个向量，我们的思想就是<span class="math inline">\(\mathbf{x}\)</span> 分成多个子块 <spanclass="math inline">\(x_1,...,x_n\)</span>，如果函数有特殊的形式，就能把上面的问题解耦成多个子项的求和，然后针对<span class="math inline">\(x_1,...,x_n\)</span>就能并行求解了。下面看几种特殊形式。</p><h3 id="distributed-admm-ⅰ">4.1 Distributed ADMM Ⅰ</h3><p>函数 <span class="math inline">\(f\)</span> 需要是可分的 <spanclass="math display">\[f(\mathbf{x})=f_{1}\left(\mathbf{x}_{1}\right)+f_{2}\left(\mathbf{x}_{2}\right)+\cdots+f_{N}\left(\mathbf{x}_{N}\right)\]</span> 约束条件 <spanclass="math inline">\(A\mathbf{x}+B\mathbf{z}=\mathbf{b}\)</span>也需要是可分的 <span class="math display">\[\mathbf{A}=\left[\begin{array}{cccc}\mathbf{A}_{1} &amp; &amp; &amp;\mathbf{0} \\&amp; \mathbf{A}_{2} &amp; &amp; \\&amp; &amp; \ddots &amp;\\\mathbf{0} &amp; &amp; &amp; \mathbf{A}_{N}\end{array}\right]\]</span> 如果满足上面的两个性质，那么原本的更新过程 <spanclass="math display">\[\mathbf{x}^{k+1} \leftarrow \minf(\mathbf{x})+\frac{\beta}{2}\left\|\mathbf{A} \mathbf{x}+\mathbf{By}^{k}-\mathbf{b}-\mathbf{z}^{k}\right\|_{2}^{2}\]</span> 就可以分成并行的 <span class="math inline">\(N\)</span>个优化问题 <span class="math display">\[\begin{array}{c}\mathbf{x}_{1}^{k+1} \leftarrow \minf_{1}\left(\mathbf{x}_{1}\right)+\frac{\beta}{2}\left\|\mathbf{A}_{1}\mathbf{x}_{1}+\left(\mathbf{B}\mathbf{y}^{k}-\mathbf{b}-\mathbf{z}^{k}\right)_{1}\right\|_{2}^{2}\\\vdots \\\mathbf{x}_{N}^{k+1} \leftarrow \minf_{N}\left(\mathbf{x}_{N}\right)+\frac{\beta}{2}\left\|\mathbf{A}_{N}\mathbf{x}_{N}+\left(\mathbf{B}\mathbf{y}^{k}-\mathbf{b}-\mathbf{z}^{k}\right)_{N}\right\|_{2}^{2}\end{array}\]</span> <strong>例子 1</strong>(consensus)：假如我们的 <spanclass="math inline">\(f\)</span> 并不像上面那样可分，而是 <spanclass="math inline">\(\min\sum_{i=1}^Nf_i(\mathbf{x})\)</span>，注意上面要求 <spanclass="math inline">\(f_i,f_j\)</span> 的自变量分别是 <spanclass="math inline">\(x_i,x_j\)</span>，而这里的 <spanclass="math inline">\(f_i,f_j\)</span> 的自变量都是 <spanclass="math inline">\(\mathbf{x}\)</span>。可以怎么办呢？引入 <spanclass="math inline">\(\mathbf{x}\)</span> 的 <spanclass="math inline">\(N\)</span> 个 copies，把优化问题写成 <spanclass="math display">\[\begin{align}\min_{\{\mathbf{x}_i\},\mathbf{z}} \quad&amp; \sum_if_i(\mathbf{x}_i) \\\text{s.t.} \quad&amp;\mathbf{x}_i-\mathbf{z}=0,\forall i\end{align}\]</span> <strong>例子 2</strong>(exchange)：优化问题的形式为 <spanclass="math display">\[\begin{align}\min_{\{\mathbf{x}_i\},\mathbf{z}} \quad&amp; \sum_if_i(\mathbf{x}_i) \\\text{s.t.} \quad&amp;\sum_i\mathbf{x}_i=0\end{align}\]</span> 这个问题的满足 <span class="math inline">\(f\)</span>可分了，但是却不满足上面要求的 <span class="math inline">\(A\)</span>的形式。可以怎么做呢？再次引入变量 <span class="math display">\[\begin{align}\min_{\{\mathbf{x}_i\},\mathbf{z}} \quad&amp; \sum_if_i(\mathbf{x}_i) \\\text{s.t.} \quad&amp;\mathbf{x}_i-\mathbf{x}_i&#39;=0,\forall i \\\quad&amp;\sum_i\mathbf{x}_i&#39;=0\end{align}\]</span> 这个时候 <span class="math inline">\(\mathbf{x}_i\)</span>可以并行计算了，但是 <spanclass="math inline">\(\mathbf{x}_i&#39;\)</span> 还需要处理 <spanclass="math display">\[(\mathbf{x}_i&#39;)^{k+1}=\arg\min_{\{\mathbf{x}_i&#39;\}} \sum_i\frac{\beta}{2}\|\mathbf{x}_i^{k+1}-\mathbf{x}_i&#39; +\mathbf{y}_i^k/\beta\| \\\text{s.t.} \sum_i \mathbf{x}_i&#39;=0\]</span> 这个问题可以得到闭式解，代入关于 <spanclass="math inline">\(\mathbf{x}_i\)</span> 的迭代方程里就可以得到 <spanclass="math display">\[\begin{aligned}\mathbf{x}_{i}^{k+1}&amp;=\underset{\mathbf{x}_{i}}{\operatorname{argmin}}f_{i}\left(\mathbf{x}_{i}\right)+\frac{\beta}{2}\left\|\mathbf{x}_{i}-\left(\mathbf{x}_{i}^{k}-\operatorname{mean}\left\{\mathbf{x}_{i}^{k}\right\}-\mathbf{u}^{k}\right)\right\|_{2}^{2}\\\mathbf{u}^{k+1}&amp;=\mathbf{u}^{k}+\operatorname{mean}\left\{\mathbf{x}_{i}^{k+1}\right\}\end{aligned}\]</span> 实际上，这个 exchange 问题还是 consensus问题的对偶形式，只需要写出来拉格朗日函数和 KKT 条件就可以了。</p><h3 id="distributed-admm-ⅱ">4.2 Distributed ADMM Ⅱ</h3><p>前面是对 <span class="math inline">\(\mathbf{x}\)</span>进行分解，其实我们还可以对 <spanclass="math inline">\(\mathbf{z}\)</span> 进行分解。对于约束 <spanclass="math inline">\(A\mathbf{x}+\mathbf{z}=\mathbf{b}\)</span>，可以按行分解<span class="math display">\[\mathbf{A}=\left[\begin{array}{c}\mathbf{A}_{1} \\\vdots\\\mathbf{A}_{L}\end{array}\right],\mathbf{z}=\left[\begin{array}{c}\mathbf{z}_{1} \\\vdots\\\mathbf{z}_{L}\end{array}\right],\mathbf{b}=\left[\begin{array}{c}\mathbf{b}_{1} \\\vdots\\\mathbf{b}_{L}\end{array}\right]\]</span> 这个时候假如优化函数的形式为 <spanclass="math inline">\(\min_{\mathbf{x},\mathbf{z}}\sum_l(f_l(\mathbf{x})+g_l(\mathbf{z}_l)),\text{s.t.}A\mathbf{x}+\mathbf{z}=\mathbf{b}\)</span>，注意到这个时候虽然关于<span class="math inline">\(\mathbf{z}\)</span> 是可分的，但是关于 <spanclass="math inline">\(\mathbf{x}\)</span>却不是，跟前面的方法类似，我们把 <spanclass="math inline">\(\mathbf{z}\)</span> copy 很多份，就可以转化为<span class="math display">\[\begin{align}\min_{\mathbf{x},\{\mathbf{x}_l\},\mathbf{z}} \quad&amp;\sum_l (f_l(\mathbf{x}_l)+g_l(\mathbf{z}_l)) \\\text{s.t.} \quad&amp;A_l\mathbf{x}_l+\mathbf{z}_l=\mathbf{b}_l,\forall i \\\quad&amp;\mathbf{x}_l-\mathbf{x}=0\end{align}\]</span> ADMM 方法中第一步我们更新 <spanclass="math inline">\(\{\mathbf{x}_l\}\)</span>这可以并行处理，第二步我们更新 <spanclass="math inline">\(\mathbf{x},\mathbf{z}\)</span>，巧妙的是我们也可以把他们两个解耦合开再并行处理。</p><h3 id="distributed-admm-ⅲ">4.3 Distributed ADMM Ⅲ</h3><p>实际上前面分别是对矩阵 <span class="math inline">\(A\)</span>按列分解和按行分解，那也很容易想到我们可以既对列分解也对行分解。</p><p>对优化问题 <span class="math display">\[\begin{align}\min \quad&amp; \sum_j f_j(\mathbf{x}_j)+\sum_ig_i(\mathbf{z}_i) \\\text{ s.t.}\quad&amp;A\mathbf{x}+\mathbf{z}=\mathbf{b}\end{align}\]</span> 那么就可以分解为 <span class="math display">\[\mathbf{A}=\left[\begin{array}{cccc}\mathbf{A}_{11} &amp;\mathbf{A}_{12} &amp; \cdots &amp; \mathbf{A}_{1 N} \\\mathbf{A}_{21}&amp; \mathbf{A}_{22} &amp; \cdots &amp; \mathbf{A}_{2 N} \\&amp; &amp;\ldots &amp; \\\mathbf{A}_{M 1} &amp; \mathbf{A}_{M 2} &amp; \cdots&amp; \mathbf{A}_{M N}\end{array}\right], \text { also }\mathbf{b}=\left[\begin{array}{c}\mathbf{b}_{1} \\\mathbf{b}_{2}\\\vdots \\\mathbf{b}_{M}\end{array}\right]\]</span> 优化问题可以转化为 <span class="math display">\[\begin{align}\min \quad&amp; \sum_j f_j(\mathbf{x}_j)+\sum_ig_i(\mathbf{z}_i) \\\text{ s.t.}\quad&amp; \sum_jA_{ij}\mathbf{x}_j+\mathbf{z}_i=\mathbf{b}_i,i=1,...,M\end{align}\]</span> 但是注意到这个时候 <spanclass="math inline">\(\mathbf{x}_j\)</span>之间还是相互耦合的，类比前面的方法，要想解耦合，我们就找一个“替身”，这次是<spanclass="math inline">\(\mathbf{p}_{ij}=A_{ij}\mathbf{x}_j\)</span>，那么新的问题就是<span class="math display">\[\begin{align}\min \quad&amp; \sum_j f_j(\mathbf{x}_j)+\sum_ig_i(\mathbf{z}_i) \\\text{ s.t.}\quad&amp; \sum_j\mathbf{p}_{ij}+\mathbf{z}_i=\mathbf{b}_i,\forall i \\\quad&amp;\mathbf{p}_{ij}=A_{ij}\mathbf{x}_j,\forall i,j\end{align}\]</span> ADMM 中可以交替更新 <spanclass="math inline">\(\{\mathbf{p}_{ij}\}\)</span> 和 <spanclass="math inline">\((\{\mathbf{x}_j\},\{\mathbf{z}_i\})\)</span>。关于<span class="math inline">\(\{\mathbf{p}_{ij}\}\)</span>的求解有闭式解，关于 <spanclass="math inline">\((\{\mathbf{x}_j\},\{\mathbf{z}_i\})\)</span>也是可以分解为分别更新 <spanclass="math inline">\(\{\mathbf{x}_j\},\{\mathbf{z}_i\}\)</span>，但是需要注意的是更新<span class="math inline">\(\mathbf{x}_j\)</span> 的时候 <spanclass="math inline">\(f_j,A_{1j}^TA_{1j},...,A_{Mj}^TA_{Mj}\)</span>都耦合在一起了，实际当中计算应该还是比较麻烦的。</p><h3 id="distributed-admm-ⅳ">4.3 Distributed ADMM Ⅳ</h3><p>既然上面第三类方法中还是有耦合，那我们就可以再引入“替身变量”来解耦合，对每个<span class="math inline">\(\mathbf{x}_j\)</span> 都 copy 出来 <spanclass="math inline">\(\mathbf{x}_{1j},...,\mathbf{x}_{Mj}\)</span>，之后可以得到<span class="math display">\[\begin{align}\min \quad&amp; \sum_j f_j(\mathbf{x}_j)+\sum_ig_i(\mathbf{z}_i) \\\text{ s.t.}\quad&amp; \sum_j\mathbf{p}_{ij}+\mathbf{z}_i=\mathbf{b}_i,\forall i \\\quad&amp;\mathbf{p}_{ij}=A_{ij}\mathbf{x}_{ij},\forall i,j \\\quad&amp;\mathbf{x}_{j}=\mathbf{x}_{ij},\forall i,j\end{align}\]</span> ADMM 中可以交替更新 <spanclass="math inline">\((\{\mathbf{x}_j\},\{\mathbf{p}_{ij}\})\)</span> 和<spanclass="math inline">\((\{\mathbf{x}_{ij}\},\{\mathbf{z}_i\})\)</span></p>]]></content>
    
    
    <categories>
      
      <category>Convex Optimization</category>
      
    </categories>
    
    
    <tags>
      
      <tag>ADMM</tag>
      
      <tag>parallel</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>凸优化笔记23：算子分裂法 &amp; ADMM</title>
    <link href="/2020/05/10/optimization/ch23-DR-splitting-admm/"/>
    <url>/2020/05/10/optimization/ch23-DR-splitting-admm/</url>
    
    <content type="html"><![CDATA[<p>前面章节中，针对 <span class="math inline">\(\min f(x)+g(Ax)\)</span>形式的优化问题，我们介绍了如 PG、dual PG、ALM、PPA 等方法。但是比如 PG方法为 <span class="math display">\[x_{k+1}=\text{prox}_{th}(x_k-t_k\nabla g(x_k))\]</span> ALM 的第一步要解一个联合优化问题 <span class="math display">\[(x^{k+1},y^{k+1}) = \arg\min_{x,y} L_t(x,y,z^k)\]</span> 他们都把 <span class="math inline">\(f,g\)</span>耦合在一起了。如果我们看原始问题 <span class="math inline">\(\minf(x)+g(Ax)\)</span> 实际上就是要找 <spanclass="math inline">\(x^\star\)</span> 使得 <spanclass="math inline">\(0\in\partial f(x^\star)+A^T\partialg(x^\star)\)</span>，这一节要介绍的 Douglas-Rachford splitting method实际上就是要 decoupling。</p><span id="more"></span><h2 id="douglas-rachford-splitting-algorithm">1.Douglas-Rachfordsplitting Algorithm</h2><p>针对如下优化问题，其中 <span class="math inline">\(f,g\)</span>都是闭凸函数 <span class="math display">\[\min f(x)+g(x)\]</span></p><blockquote><p>先给出 DR-splitting 方法的迭代方程 <span class="math display">\[\begin{array}{l}x_{k+1}=\operatorname{prox}_{f}\left(y_{k}\right) \\y_{k+1}=y_{k}+\operatorname{prox}_{g}\left(2x_{k+1}-y_{k}\right)-x_{k+1}\end{array}\]</span></p></blockquote><p>为什么叫做 splitting 呢？回忆 PPA 是不是需要求解 <spanclass="math inline">\(x^+ =\text{prox}_{t(f+g)}(x)\)</span>，而这里则可以分开依次求 <spanclass="math inline">\(\text{prox}_f\)</span> 和 <spanclass="math inline">\(\text{prox}_g\)</span>，所以被称为splitting。这个迭代方程看起来没有规律，那么他能不能收敛呢？答案当然是可以的，<spanclass="math inline">\(x_k\)</span> 最终会收敛到 <spanclass="math inline">\(0\in \partial f(x)+\partialg(x)\)</span>，这个证明放到后面，先来从别的方面认识一下这个方法。</p><p>首先 <span class="math inline">\(f,g\)</span>并没有区分，因此可以交换两者的位置，那么迭代方程也可以写为 <spanclass="math display">\[\begin{array}{l}x_{k+1}=\operatorname{prox}_{g}\left(y_{k}\right) \\y_{k+1}=y_{k}+\operatorname{prox}_{f}\left(2x_{k+1}-y_{k}\right)-x_{k+1}\end{array}\]</span>但需要注意的是这两种不同的迭代方程产生的序列是不一样的，也可能会影响收敛的速度，因此这个方法关于<span class="math inline">\(f,g\)</span> 是不对称的。</p><p>如果把 <span class="math inline">\(x_{k+1}\)</span>带入到第二步，整个过程实际上可以用一个迭代方程表示 <spanclass="math display">\[y_{k+1} = F(y) \notag\\F(y)=y+\operatorname{prox}_{g}\left(2\operatorname{prox}_{f}(y)-y\right)-\operatorname{prox}_{f}(y)\]</span> 这是个什么式子呢？<strong>不动点迭代</strong>(fixed-pointiteration)！就是在找函数 <span class="math inline">\(F(y)\)</span>的不动点。这个函数 <span class="math inline">\(F(y)\)</span>是连续的吗？是的，这是因为上一节中我们证明了 <spanclass="math inline">\(\text{prox}_{h}(x)\)</span> 满足firmlynonexpansive(co-coercivite) 性质 <span class="math display">\[\left(\operatorname{prox}_{h}(x)-\operatorname{prox}_{h}(y)\right)^{T}(x-y)\geq\left\|\operatorname{prox}_{h}(x)-\operatorname{prox}_{h}(y)\right\|_{2}^{2}\]</span> 因此近似点算子是 Lipschitz continuous 的，所以 <spanclass="math inline">\(F(y)\)</span> 也是连续的。那么假如最终找到了不动点<span class="math inline">\(y\)</span>，他有什么性质呢？ <spanclass="math display">\[y=F(y) \notag\\\iff 0 \in \partial f\left(\operatorname{prox}_{f}(y)\right)+\partialg\left(\operatorname{prox}_{f}(y)\right)\]</span> <strong>证明</strong>：对于不动点 <spanclass="math inline">\(y=F(y)\)</span>，取 <spanclass="math inline">\(x=\text{prox}_f(y)\)</span>，我们有 <spanclass="math display">\[\begin{aligned}x=\text{prox}_f(y),&amp;\quad F(y)=y \notag\\\iff x=\text{prox}_f(y),&amp;\quad x=\text{prox}_g(2x-y) \\\iff y-x\in \partial f(x),&amp;\quad x-y\in\partial g(x)\end{aligned}\]</span> 其中第一个等价性只需要把 <spanclass="math inline">\(x\)</span> 带入到 <spanclass="math inline">\(F(y)\)</span> 中，由此我们就可以得到 <spanclass="math display">\[0=(y-x)+(x-y)\in\partial f(x)+\partial g(x)\]</span> 自然而然地我们证明了一开始提到的 <spanclass="math inline">\(x_{k}\)</span> 的收敛性。</p><p><strong>等价形式</strong>：下面这部分则主要是对原始形式做了一些<strong>变量代换</strong>，使其看起来更简洁，并没有新的内容。首先交换<span class="math inline">\(x,y\)</span> 的迭代次序 <spanclass="math display">\[\begin{array}{l}y_{k+1}=y_{k}+\operatorname{prox}_{g}\left(2 x_{k}-y_{k}\right)-x_{k} \\x_{k+1}=\operatorname{prox}_{f}\left(y_{k+1}\right)\end{array}\]</span> 引入新变量 <spanclass="math inline">\(u_{k+1}=\text{prox}_g(2x_k-y_k),w_k=x_k-y_k\)</span><span class="math display">\[\begin{aligned}u_{k+1} &amp;=\operatorname{prox}_{g}\left(x_{k}+w_{k}\right) \\x_{k+1} &amp;=\operatorname{prox}_{f}\left(u_{k+1}-w_{k}\right) \\w_{k+1} &amp;=w_{k}+x_{k+1}-u_{k+1}\end{aligned}\]</span><strong>放缩</strong>：除此之外，我们还可以对原始问题做一个放缩变为<span class="math inline">\(\mintf(x)+tg(x)\)</span>，那么迭代方程就变为如下形式，并没有本质的变化 <spanclass="math display">\[\begin{aligned}u_{k+1} &amp;=\operatorname{prox}_{tg}\left(x_{k}+w_{k}\right) \\x_{k+1} &amp;=\operatorname{prox}_{tf}\left(u_{k+1}-w_{k}\right) \\w_{k+1} &amp;=w_{k}+x_{k+1}-u_{k+1}\end{aligned}\]</span> <strong>松弛</strong>：前面降到了实际上是在对 <spanclass="math inline">\(y\)</span> 做不动点迭代，那么我们可以改为 <spanclass="math display">\[y_{k+1}=y_{k}+\rho_{k}\left(F\left(y_{k}\right)-y_{k}\right)\]</span> 如果 <span class="math inline">\(1&lt;\rho_k&lt;2\)</span>就是超松弛，如果 <span class="math inline">\(0&lt;\rho_k&lt;1\)</span>就是低松弛。这个时候迭代方程稍微复杂了一点点 <spanclass="math display">\[\begin{aligned}u_{k+1} &amp;=\operatorname{prox}_{g}\left(x_{k}+w_{k}\right) \\x_{k+1}&amp;=\operatorname{prox}_{f}\left(x_{k}+\rho_{k}\left(u_{k+1}-x_{k}\right)-w_{k}\right)\\w_{k+1} &amp;=w_{k}+x_{k+1}-x_{k}+\rho_{k}\left(x_{k}-u_{k+1}\right)\end{aligned}\]</span> <strong>共轭函数</strong>：根据 Moreau decomposition <spanclass="math inline">\(\text{prox}_g(x)+\text{prox}_{g^\star}(x)=x\)</span>，如果<span class="math inline">\(\text{prox}_g\)</span>比较难计算，我们就可以换到共轭函数上去计算 <span class="math display">\[\begin{array}{l}x_{k+1}=\operatorname{prox}_{f}\left(y_{k}\right) \\y_{k+1}=x_{k+1}-\operatorname{prox}_{g^{*}}\left(2 x_{k+1}-y_{k}\right)\end{array}\]</span> 下面举几个例子，主要就是练习近似点算子的计算，因为DR-splitting 方法主要就是在计算 <span class="math inline">\(f,g\)</span>的近似点。</p><p><strong><em>例子 1</em></strong>：变量 <spanclass="math inline">\(X\in S^n\)</span>，参数 <spanclass="math inline">\(C\in S_+^n,\gamma&gt;0\)</span> <spanclass="math display">\[\text { minimize } \quad \operatorname{tr}(C X)-\log \operatorname{det}X+\gamma \sum_{i&gt;j}\left|X_{i j}\right|\]</span> 我们取 <span class="math inline">\(f(X)=\operatorname{tr}(CX)-\log \operatorname{det} X,\quad g(X)=\gamma \sum_{i&gt;j}\left|X_{ij}\right|\)</span></p><p><span class="math inline">\(X=\text{prox}_{tf}(\hat{X}) \iffC-X^{-1}+(1/t)(X-\hat{X})\)</span>，这个方程可以通过对 <spanclass="math inline">\(\hat{X}-tC\)</span> 进行特征值分解求解</p><p><span class="math inline">\(X=\text{prox}_{tg}(\hat{X})\)</span>可以通过软阈值(soft-thresholding)求解</p><p><strong><em>例子 2</em></strong>：考虑等式约束的优化问题 <spanclass="math display">\[\begin{aligned}\min \quad&amp; f(x)\\\text{s.t.} \quad&amp; x\in V\end{aligned}\]</span> 等价于 <span class="math inline">\(g=\delta_V\)</span> <spanclass="math display">\[\begin{array}{l}x_{k+1}=\operatorname{prox}_{g}\left(y_{k}\right) \\y_{k+1}=y_{k}+P_V\left(2 x_{k+1}-y_{k}\right)-x_{k+1}\end{array}\]</span> <strong><em>例子 3</em></strong>：考虑这种复合形式 <spanclass="math inline">\(\min f_1(x)+f_2(Ax)\)</span>，可以引入等式约束<span class="math display">\[\begin{aligned}\min \quad&amp; f_1(x)+f_2(y) \\\text{s.t.} \quad&amp; Ax=y\end{aligned}\]</span> 取 <spanclass="math inline">\(f(x_1,x_2)=f_1(x_1)+f_2(x_2)\)</span>，他的近似点算子是可分的<span class="math display">\[\operatorname{prox}_{t f}\left(x_{1},x_{2}\right)=\left(\operatorname{prox}_{t f_{1}}\left(x_{1}\right),\operatorname{prox}_{t f_{2}}\left(x_{2}\right)\right)\]</span> 然后像例子 2 一样，向超平面 <spanclass="math inline">\([A,-I][x_1,x_2]^T=0\)</span> 做个投影。</p><h2 id="admm">2. ADMM</h2><p>交替方向乘子法(Alternating Direction Method ofMultipliers)也是一个很重要而且很受欢迎的算法，下一节还会详细讲，这里主要是看看他与DR-splitting 的联系。</p><p>这里还是先给出结论：<strong>DR-splitting 中取 <spanclass="math inline">\(\rho_k=1\)</span>，应用在对偶问题上，就等价于原问题的ADMM 算法</strong>。我们先推导对偶问题上的 DR-splitting迭代形式，然后再引出 ADMM 方法。</p><p>对可分离的凸优化问题 <span class="math display">\[\begin{aligned}(P)\min \quad&amp; f_1(x_1)+f_2(x_2) \\\text{s.t.} \quad&amp; A_1x_1+A_2x_2=b \\(D)\max \quad&amp; -b^{T} z-f_{1}^{*}\left(-A_{1}^{T}z\right)-f_{2}^{*}\left(-A_{2}^{T} z\right)\end{aligned}\]</span> 取 <span class="math inline">\(g(z)=b^{T}z+f_{1}^{\star}\left(-A_{1}^{T} z\right),f(z)=f_{2}^{\star}\left(-A_{2}^{T} z\right)\)</span>，DR 方法为 <spanclass="math display">\[u^{+}=\operatorname{prox}_{t g}(z+w), \quad z^{+}=\operatorname{prox}_{tf}\left(u^{+}-w\right), \quad w^{+}=w+z^{+}-u^{+}\]</span> <strong>第一步</strong>：他等价于计算 <spanclass="math display">\[\begin{aligned}\hat{x}_{1}&amp;=\underset{x_{1}}{\operatorname{argmin}}\left(f_{1}\left(x_{1}\right)+z^{T}\left(A_{1}x_{1}-b\right)+\frac{t}{2}\left\|A_{1} x_{1}-b+w /t\right\|_{2}^{2}\right) \\u^{+} &amp;=z+w+t\left(A_{1} \hat{x}_{1}-b\right)\end{aligned}\]</span> 这个证明很不直观，上一节分析 PPA 与 ALM的关系的时候，证明了一个很不直观的结论：对 <spanclass="math inline">\(h(z)=g^{\star}(z)+f^{\star}\left(-A^{T}z\right)\)</span>，有 <span class="math display">\[\begin{aligned}z^+&amp;=\text{prox}_{th}(z) = z+t(A\hat{x}-\hat{y}) \\(\hat{x}, \hat{y})&amp;=\underset{x,y}{\operatorname{argmin}}\left(f(x)+g(y)+z^{T}(A x-y)+\frac{t}{2}\|Ax-y\|_{2}^{2}\right)\end{aligned}\]</span> <strong>第二步</strong>：与第一个式子是类似的，等价于 <spanclass="math display">\[\begin{array}{l}\hat{x}_{2}=\underset{x_{2}}{\operatorname{argmin}}\left(f_{2}\left(x_{2}\right)+z^{T}A_{2} x_{2}+\frac{t}{2}\left\|A_{1} \hat{x}_{1}+A_{2}x_{2}-b\right\|_{2}^{2}\right. \\z^{+}=z+t\left(A_{1} \hat{x}_{1}+A_{2} \hat{x}_{2}-b\right)\end{array}\]</span> <strong>第三步</strong>：<spanclass="math inline">\(w^+=tA_2\hat{x}_2\)</span></p><p>现在我们就可以引出 ADMM 方法了，他包括三个步骤 <spanclass="math display">\[\begin{aligned}x_{k+1,1}&amp;=\underset{\tilde{x}_{1}}{\operatorname{argmin}}\left(f_{1}\left(\tilde{x}_{1}\right)+z_{k}^{T}A_{1} \tilde{x}_{1}+\frac{t}{2}\left\|A_{1} \tilde{x}_{1}+A_{2} x_{k,2}-b\right\|_{2}^{2}\right) \\x_{k+1,2}&amp;=\underset{\tilde{x}_{2}}{\operatorname{argmin}}\left(f_{2}\left(\tilde{x}_{2}\right)+z_{k}^{T}A_{2} \tilde{x}_{2}+\frac{t}{2}\left\|A_{1} x_{k+1,1}+A_{2}\tilde{x}_{2}-b\right\|_{2}^{2}\right) \\z_{k+1}&amp;=z_{k}+t\left(A_{1} x_{k+1,1}+A_{2} x_{k+1,2}-b\right)\end{aligned}\]</span> 前两步分别对应了增广拉格朗日函数的两部分，分别对 <spanclass="math inline">\(x_1,x_2\)</span> 进行优化。与原本的 ALM算法相比，ALM 是每次对 <span class="math inline">\((x_1,x_2)\)</span>进行联合优化，即 <span class="math display">\[\begin{aligned}(x_{k+1,1},x_{k+1,2}) = \arg\min_{x_1,x_2} L_t(x_1,x_2,z_k) \\z_{k+1} = z_k + t\left(A_{1} x_{k+1,1}+A_{2} x_{k+1,2}-b\right)\end{aligned}\]</span> 另外我们前面还讲到了 dual PG 方法跟 ALM也很像，也是增广拉格朗日函数先对 <spanclass="math inline">\(x_1\)</span> 优化再对 <spanclass="math inline">\(x_2\)</span> 优化，但注意他跟 ADMM不同的地方在于：前者对 <span class="math inline">\(x_1\)</span>优化的时候不包含后面的二次正则项，而 ADMM 则包含，写出来对比一下就知道了<span class="math display">\[\begin{aligned}(dual\ PG)\hat{x}&amp;=\underset{x}{\operatorname{argmin}}\left(f(x)+z^{T} A x\right) \\\hat{y} &amp;=\underset{y}{\operatorname{argmin}}\left(g(y)-z^{T}y+\frac{t}{2}\|A \hat{x}-y\|_{2}^{2}\right) \\(ADMM)x_{k+1,1}&amp;=\underset{\tilde{x}_{1}}{\operatorname{argmin}}\left(f_{1}\left(\tilde{x}_{1}\right)+z_{k}^{T}A_{1} \tilde{x}_{1}+\frac{t}{2}\left\|A_{1} \tilde{x}_{1}+A_{2} x_{k,2}-b\right\|_{2}^{2}\right) \\x_{k+1,2}&amp;=\underset{\tilde{x}_{2}}{\operatorname{argmin}}\left(f_{2}\left(\tilde{x}_{2}\right)+z_{k}^{T}A_{2} \tilde{x}_{2}+\frac{t}{2}\left\|A_{1} x_{k+1,1}+A_{2}\tilde{x}_{2}-b\right\|_{2}^{2}\right)\end{aligned}\]</span></p><h2 id="收敛性分析">3. 收敛性分析</h2><p>DR方法可以看成是一个不动点迭代，因此要证明收敛性，我们需要证明以下两个结论：</p><ol type="1"><li><span class="math inline">\(y_k\)</span> 收敛到 <spanclass="math inline">\(F(y)\)</span> 的不动点 <spanclass="math inline">\(y^\star\)</span></li><li><span class="math inline">\(x_{k+1}=\text{prox}_f(y_k)\)</span>收敛到 <spanclass="math inline">\(x^\star=\text{prox}_f(y^\star)\)</span></li></ol><p>在证明收敛性之前，需要先定义两个函数 <span class="math display">\[\begin{aligned}F(y) &amp;=y+\operatorname{prox}_{g}\left(2\operatorname{prox}_{f}(y)-y\right)-\operatorname{prox}_{f}(y) \\G(y)&amp;=y-F(y)\\&amp;=\operatorname{prox}_{f}(y)-\operatorname{prox}_{g}\left(2\operatorname{prox}_{f}(y)-y\right)\end{aligned}\]</span> 需要用到的是这两个函数的 firmly nonexpansive(co-coercive withparameter 1) 的性质 <span class="math display">\[\begin{aligned}(F(y)-F(\hat{y}))^{T}(y-\hat{y})&amp;\geq\|F(y)-F(\hat{y})\|_{2}^{2} \quad \text { for all } y, \hat{y}\\(G(y)-G(\hat{y}))^{T}(y-\hat{y})&amp;\geq\|G(y)-G(\hat{y})\|_{2}^{2}\end{aligned}\]</span> <strong>证明</strong>：令 <spanclass="math inline">\(x=\text{prox}_f(y),\hat{x}=\text{prox}_f(\hat{y})\)</span>，<spanclass="math inline">\(v=\operatorname{prox}_{g}(2 x-y), \quad\hat{v}=\operatorname{prox}_{g}(2 \hat{x}-\hat{y})\)</span></p><p>根据 <spanclass="math inline">\(F(y)=y+v-x,F(\hat{y})=\hat{y}+\hat{v}-\hat{x}\)</span>有 <span class="math display">\[\begin{array}{l}(F(y)-F(\hat{y}))^{T}(y-\hat{y}) \\\quad \geq\quad(y+v-x-\hat{y}-\hat{v}+\hat{x})^{T}(y-\hat{y})-(x-\hat{x})^{T}(y-\hat{y})+\|x-\hat{x}\|_{2}^{2}\\\quad=(v-\hat{v})^{T}(y-\hat{y})+\|y-x-\hat{y}+\hat{x}\|_{2}^{2}\\\quad=(v-\hat{v})^{T}(2 x-y-2\hat{x}+\hat{y})-\|v-\hat{v}\|_{2}^{2}+\|F(y)-F(\hat{y})\|_{2}^{2}\\\quad \geq\|F(y)-F(\hat{y})\|_{2}^{2}\end{array}\]</span> 其中用到了 <span class="math inline">\(\text{prox}\)</span>算子的firm nonexpansiveness 性质 <span class="math display">\[(x-\hat{x})^{T}(y-\hat{y}) \geq\|x-\hat{x}\|_{2}^{2}, \quad(2 x-y-2\hat{x}+\hat{y})^{T}(v-\hat{v}) \geq\|v-\hat{v}\|_{2}^{2}\]</span> 证毕。</p><p>然后我们就可以根据以下的不动点迭代方程证明前面提到的收敛性 <spanclass="math display">\[\begin{aligned}y_{k+1} &amp;=\left(1-\rho_{k}\right) y_{k}+\rho_{k}F\left(y_{k}\right) \\&amp;=y_{k}-\rho_{k}G\left(y_{k}\right)\end{aligned}\]</span> 其中需要假设 <span class="math inline">\(F\)</span>的不动点存在，且满足 <span class="math inline">\(0\in\partialf(x)+\partial g(x)\)</span>，以及松弛变量 <spanclass="math inline">\(\rho_k\in[\rho_{\min},\rho_{\max}],0&lt;\rho_{\min}&lt;\rho_{\max}&lt;2\)</span>。</p><p><strong>证明</strong>：设 <spanclass="math inline">\(y^\star\)</span> 为 <spanclass="math inline">\(F(y)\)</span> 的不动点（也即 <spanclass="math inline">\(G(y)\)</span> 的零点），考虑第 <spanclass="math inline">\(k\)</span> 步迭代 <span class="math display">\[\begin{aligned}\left\|y^{+}-y^{\star}\right\|_{2}^{2}-\left\|y-y^{\star}\right\|_{2}^{2}&amp;=2\left(y^{+}-y\right)^{T}\left(y-y^{\star}\right)+\left\|y^{+}-y\right\|_{2}^{2}\\&amp;=-2 \rhoG(y)^{T}\left(y-y^{\star}\right)+\rho^{2}\|G(y)\|_{2}^{2}\\&amp;\leq-\rho(2-\rho) \| G(y)) \|_{2}^{2} \\&amp;\leq-M \| G(y))\|_{2}^{2}\end{aligned}\]</span> 其中 <spanclass="math inline">\(M=\rho_{\min}(2-\rho_{\max})\)</span>。上式表明<span class="math display">\[M \sum_{k=0}^{\infty}\left\|G\left(y_{k}\right)\right\|_{2}^{2}\leq\left\|y_{0}-y^{\star}\right\|_{2}^{2}, \quad \| G(y)\|_2\to 0\]</span> 还可以得到 <span class="math inline">\(\|y_k-y^\star\|_2\)</span> 是单调不增的，因此 <spanclass="math inline">\(y_k\)</span> 有界。</p><p>由于 <span class="math inline">\(\| y_k-y^\star\|_2\)</span>单调不增，故极限 <span class="math inline">\(\lim_{k\to \infty} \|y_k-y^\star\|_2\)</span> 存在；又由于 <spanclass="math inline">\(y_k\)</span> 有界，故存在收敛子序列。</p><p>记 <span class="math inline">\(\bar{y}_k\)</span>为一个收敛子序列，收敛值为 <spanclass="math inline">\(\bar{y}\)</span>，根据 <spanclass="math inline">\(G\)</span> 的连续性有 <spanclass="math inline">\(0=\lim _{k \rightarrow \infty}G\left(\bar{y}_{k}\right)=G(\bar{y})\)</span>，因此 <spanclass="math inline">\(\bar{y}\)</span> 是 <spanclass="math inline">\(G\)</span> 的l零点，且极限 <spanclass="math inline">\(\lim_{k\to \infty} \| y_k-\bar{y}\|_2\)</span>存在。</p><p>接着需要证明唯一性，假设 <spanclass="math inline">\(\bar{u},\bar{v}\)</span>是两个不同的极限点，收敛极限 <span class="math inline">\(\lim_{k\to\infty} \| y_k-\bar{u}\|_2,\lim_{k\to \infty} \|y_k-\bar{v}\|_2\)</span> 存在，因此 <span class="math display">\[\|\bar{u}-\bar{v}\|_{2}=\lim _{k \rightarrow\infty}\left\|y_{k}-\bar{u}\right\|_{2}=\lim _{k \rightarrow\infty}\left\|y_{k}-\bar{v}\right\|_{2}=0\]</span> 证毕。</p>]]></content>
    
    
    <categories>
      
      <category>Convex Optimization</category>
      
    </categories>
    
    
    <tags>
      
      <tag>近似点算子</tag>
      
      <tag>算子分裂法</tag>
      
      <tag>ADMM</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>凸优化笔记22：近似点算法</title>
    <link href="/2020/05/09/optimization/ch22-ppa/"/>
    <url>/2020/05/09/optimization/ch22-ppa/</url>
    
    <content type="html"><![CDATA[<p>在进入具体的优化算法后，我们首先讲了基于梯度的，比如梯度下降(GD)、次梯度下降(SD)；然后又讲了近似点算子，之后讲了基于近似点算子的方法，比如近似点梯度下降(PG)、对偶问题的近似点梯度下降(DPG)、加速近似点梯度下降(APG)。而这一节讲的，还是基于近似点的！他叫<strong>近似点方法(ProximalPoint Algorithm,PPA)</strong>，除此之外还会介绍<strong>增广拉格朗日方法(AugmenttedLarangian Method, ALM)</strong>。我们就开始吧！</p><span id="more"></span><h2 id="近似点方法">1. 近似点方法</h2><p>近似点方法跟近似点梯度下降很像，在此之外我们先简单回顾一下 PG方法。对优化问题 <span class="math display">\[\text{minimize } f(x)=g(x)+h(x)\]</span> 其中 <span class="math inline">\(g\)</span>为光滑凸函数，而且为了保证收敛性需要满足 Lipschitz 光滑性质，<spanclass="math inline">\(h\)</span> 为非光滑函数，只要 <spanclass="math inline">\(h\)</span> 为闭凸函数，对于近似点算子 <spanclass="math inline">\(\text{prox}_{h}(x)\)</span> 自然满足firmlynonexpansive(co-coercivite) 性质，这个也等价于 Lipschitz continuous 性质<span class="math display">\[\left(\operatorname{prox}_{h}(x)-\operatorname{prox}_{h}(y)\right)^{T}(x-y)\geq\left\|\operatorname{prox}_{h}(x)-\operatorname{prox}_{h}(y)\right\|_{2}^{2}\]</span> 迭代格式为 <span class="math display">\[x_{k+1}=\text{prox}_{th}(x_k-t_k\nabla g(x_k))\]</span> 这个表达式实际上可以等价表示为 <span class="math display">\[x^+ = x-tG_t(x), \qquad G_t(x):=\frac{x-x^+}{t}\in \partialh(x^+)+\nabla g(x)\]</span> 然后我们再回顾一下 APG 方法，实际上就是在 PG的基础上引入了一个外差，直观理解就是加入了动量 <spanclass="math display">\[\begin{aligned}x_{k+1} &amp;= \text{prox}_{th}(y_k-t_k\nabla g(y_k)) \\y_k &amp;= x_k + w_k(x_k-x_{k-1})\end{aligned}\]</span> 好了复习结束！那么近似点方法 PPA 针对的优化问题是 <spanclass="math inline">\(\min f\)</span>，其中 <spanclass="math inline">\(f\)</span> 为闭凸函数</p><blockquote><p><strong>迭代格式</strong>为 <span class="math display">\[\begin{aligned}x_{k+1} &amp;= \text{prox}_{t_k f}(x_k) \\&amp;= \arg\min_u \left( f(u)+\frac{1}{2t_k}\Vert u-x_k\Vert_2^2 \right)\end{aligned}\]</span></p></blockquote><p>这实际上可以看作是 PG 方法中取函数 <spanclass="math inline">\(g=0\)</span>，因此所有适用于 PG的收敛性分析也都适用于 PPA 方法，而且由于 <spanclass="math inline">\(g=0\)</span>，因此也不需要对 <spanclass="math inline">\(f\)</span> 做 Lipschitz光滑的假设，因此<strong>步长 <span class="math inline">\(t_k\)</span>可以是任意正实数，而不需要 <span class="math inline">\(0&lt; t_k &lt;1/L\)</span></strong>。类比 PG 中的收敛性分析可以得到 $$t_{i}(f(x_{i+1})-f^{})(|x_{i}-x<sup>{}|<em>{2}<sup>{2}-|x_{i+1}-x</sup>{}|</em>{2}</sup>{2})\</p><p>f(x_{k})-f^{} k <span class="math display">\[同样得，我们也可以引入外差进行加速\]</span> x_{k+1}=<em>{t</em>{k}f}(x_{k}+<em>{k}(-1)(x</em>{k}-x_{k-1})) k <span class="math display">\[其中可以是任意 $t_k&gt; 0$，$\theta_k$ 由以下方程解得\]</span> =(1-_{k}) $$ 并且可以证明加速后的方法收敛速度可以达到 <spanclass="math inline">\(O(1/k^2)\)</span>。</p><p>PPA 的基本原理就没有了，这里简单总结一下，实际上核心的地方只有一个迭代格式 <span class="math display">\[x_{k+1} = \text{prox}_{t_k f}(x_k)\]</span> 其他的收敛性分析以及加速算法都可以类比 PG 得到。</p><h2 id="增广拉格朗日方法">2. 增广拉格朗日方法</h2><p>增广拉格朗日方法(也叫乘子法)一般是为了解决有约束优化问题，并且我们通常考虑等式约束，对于非等式约束可以通过引入松弛变量将其转化为等式约束。这里我们首先介绍一下基本的ALM 形式。对于优化问题 <span class="math display">\[\begin{aligned}\min\quad&amp; f(x) \\\text{s.t.}\quad&amp; C(x)=0\end{aligned}\]</span> <strong>增广拉格朗日函数(重要)</strong>为 <spanclass="math display">\[L_\sigma(x,\nu) = f(x)+\nu^TC(x) + \frac{\sigma}{2}\VertC(x)\Vert_2^2,\quad \sigma&gt;0\]</span> 就是在初始的拉格朗日函数后面加了一个等式约束的二次正则项</p><blockquote><p><strong>ALM 的迭代格式</strong>则为 <span class="math display">\[\begin{aligned}x^{k+1} &amp;= \arg\min_{x} L_\sigma(x,\nu^k) \\\nu^{k+1} &amp;= \nu^k + \sigma C(x^{k+1})\end{aligned}\]</span></p></blockquote><p>一般会将增广拉格朗日函数化简成另一种形式(<strong>重要</strong>) <spanclass="math display">\[L_\sigma(x,\nu) = f(x) + \frac{\sigma}{2}\VertC(x)+\frac{\nu}{\sigma}\Vert_2^2\]</span> 就是做了一个配方，但化简前后的两个函数并不完全等价，因为丢掉了<span class="math inline">\(\nu\)</span>的二次项，不过对于迭代算法没有影响，因为迭代的第一步仅仅是针对 <spanclass="math inline">\(x\)</span> 求最小。</p><p>如果是不等式约束呢？比如优化问题 <span class="math display">\[\begin{aligned}\min_x\quad&amp; f(x) \\\text{s.t.}\quad&amp; C(x)\ge0\end{aligned}\iff\begin{aligned}\min_{x,s}\quad&amp; f(x) \\\text{s.t.}\quad&amp; C(x)-s=0,\quad s\ge0\end{aligned}\]</span> 此时增广拉格朗日函数为 <span class="math display">\[L_\sigma(x,s,\nu) = f(x)-\nu^T(C(x)-s)+\frac{\sigma}{2}\VertC(x)-s\Vert^2,\quad s\ge0\]</span> 迭代方程为 <span class="math display">\[\begin{aligned}(x^{k+1},s^{k+1}) &amp;= \arg\min_{x,s\ge0} L_\sigma(x,s,\nu^k) \\\nu^{k+1} &amp;= \nu^k - \sigma (C(x^{k+1})-s^{k+1})\end{aligned}\]</span> 第一步求极小要怎么计算呢？先把增广拉格朗日函数化为 <spanclass="math display">\[\min_x\left\{f(x)+\min_{s\ge0}\frac{\sigma}{2}\left\VertC(x)-s-\frac{\nu}{\sigma}\right\Vert^2 \right\} \\= \min_x\left\{f(x)+\frac{\sigma}{2}\left\VertC(x)-\frac{\nu}{\sigma}-\Pi_+(C(x)-\frac{\nu}{\sigma})\right\Vert^2\right\}\]</span> 其中 <span class="math inline">\(\Pi_+\)</span> 表示向 <spanclass="math inline">\(R_+^n\)</span> 空间的投影。</p><p><strong><em>例子</em></strong>：这是一个应用 ALM 的例子，考虑优化问题<span class="math inline">\(\min f(x),\text{ s.t. }Ax\in C\)</span>，用ALM 的迭代步骤为 <span class="math display">\[\begin{aligned}\hat{x} &amp;= \arg\min_{x} f(x)+\frac{t}{2}d( Ax+z/t)^2 \\z :&amp;= z + t(A\hat{x}-P_C(A\hat{x}+z/t))\end{aligned}\]</span> 其中 <span class="math inline">\(P_C\)</span> 是向集合 <spanclass="math inline">\(C\)</span> 的投影，<spanclass="math inline">\(d(u)\)</span> 是 <spanclass="math inline">\(u\)</span> 到集合 <spanclass="math inline">\(C\)</span> 的欧氏距离。</p><h2 id="ppa-与-alm-的关系">3. PPA 与 ALM 的关系</h2><p>这里先给出一个结论：<strong>对原始问题应用 ALM 等价于对对偶问题应用PPA</strong>。</p><p>下面看分析，考虑优化问题 <span class="math display">\[\begin{aligned}(P)\text { minimize }\quad&amp; f(x)+g(A x)\\(D)\text { maximize } \quad&amp; -g^{\star}(z)-f^{\star}\left(-A^{T}z\right)\end{aligned}\]</span> 我们就先来看看原始问题应用 ALM 会得到什么。原始问题等价于<span class="math display">\[\begin{aligned}\min\quad&amp; f(x)+g(y) \\\text{s.t.}\quad&amp; Ax=y\end{aligned}\]</span> 拉格朗日函数为 <span class="math display">\[L_t(x,y,z) = f(x)+g(y)+z^T(Ax-y)+\frac{t}{2}\Vert Ax-y\Vert^2\]</span> ALM 迭代方程为 <span class="math display">\[\begin{aligned}(x^{k+1},y^{k+1}) &amp;= \arg\min_{x,y} L_t(x,y,z^k) \\z^{k+1} &amp;= z^k + t(Ax^{k+1}-y^{k+1})\end{aligned}\]</span> 对偶问题应用 PPA 的迭代方程是什么呢？首先我们令 <spanclass="math inline">\(h(z)=g^{\star}(z)+f^{\star}\left(-A^{T}z\right)\)</span>，那么就需要求解 $$ z^{+} = <em>{th}(z) =(f<sup>{}(-A</sup>{T} u)+g^{}(u)+|u-z|</em>{2}^{2}) \</p><p>z-z^+ th(z<sup>+)=t(-Af</sup>(-A<sup>Tz</sup>+)+g<sup>(z</sup>+) $$这个 <span class="math inline">\(z^+\)</span> 乍一看跟 ALM 的 <spanclass="math inline">\(z^{k+1}\)</span>没有一点关系啊，为什么说他们俩等价呢？这就要引出下面一个等式了（先打个预防针，这个等式以及他的推导很不直观，我也没有想到一个很好的解释，但是这个等式以及推导又很重要！在后面章节中也会用到）</p><blockquote><p>很重要的式子： <span class="math display">\[z^+=\text{prox}_{th}(z) = z+t(A\hat{x}-\hat{y})\]</span> 其中 <span class="math inline">\(\hat{x},\hat{y}\)</span> 为<span class="math display">\[(\hat{x}, \hat{y})=\underset{x,y}{\operatorname{argmin}}\left(f(x)+g(y)+z^{T}(A x-y)+\frac{t}{2}\|Ax-y\|_{2}^{2}\right)\]</span></p></blockquote><p>先不管推导，这样看来对偶问题的 PPA 是不是就跟原始问题的 ALM完全等价了呢？！然后我们来看一下证明（更多的是验证上面这两个等式成立，至于怎么推导出来我也不知道......）</p><p>增广拉格朗日函数可以转化为 <span class="math display">\[(\hat{x},\hat{y}) = \underset{x,y}{\operatorname{argmin}}\left(f(x)+g(y)+\frac{t}{2}\|Ax-y+z/t\|_{2}^{2}\right)\]</span> 我们把它表示成一个优化问题，并且引入等式约束 <spanclass="math display">\[\begin{aligned}\text{minimize}_{x, y, w} \quad&amp; f(x)+g(y)+\frac{t}{2}\|w\|_{2}^{2}\\\text{subject to}\quad&amp; A x-y+z / t=w\end{aligned}\]</span> 他的 KKT 条件就是 <span class="math display">\[A x-y+\frac{1}{t} z=w, \quad-A^{T} u \in \partial f(x), \quad u \in\partial g(y), \quad t w=u\]</span> 我们把 <span class="math inline">\(x,y,w\)</span> 消掉就得到了<span class="math inline">\(u = z+t(Ax-y)\)</span>，并且有 <spanclass="math display">\[0 \in-A \partial f^{*}\left(-A^{T} u\right)+\partialg^{*}(u)+\frac{1}{t}(u-z)\]</span> 上面这个式子就等价于 <spanclass="math inline">\(u=\text{prox}_{th}(z)\)</span>。因此就有 <spanclass="math inline">\(\text{prox}_{th}(z) =z+t(A\hat{x}-\hat{y})\)</span>。</p><h2 id="moreauyosida-smoothing">4. Moreau–Yosida smoothing</h2><p>这一部分是从另一个角度看待 PPA 算法。我们知道如果 <spanclass="math inline">\(f\)</span>是光滑函数就可以直接用梯度下降了，如果是非光滑函数则可以用次梯度或者近似点算法，前面复习PG 方法的时候提到了 PG 也可以看成是一种梯度下降，梯度为 <spanclass="math inline">\(G_t(x)\)</span> <span class="math display">\[x_{k+1}=\text{prox}_{th}(x_k-t_k\nabla g(x_k)) \iff x^+ = x-tG_t(x)\]</span> 这一部分要讲的就是从梯度下降的角度认识 PPA 方法。</p><p>这里再次先抛出结论：<strong>PPA 实际上就是对 <spanclass="math inline">\(f\)</span> 的某个光滑近似函数 <spanclass="math inline">\(\tilde{f}\)</span> 做梯度下降</strong>。</p><p>这个光滑近似函数是什么呢？对于闭凸函数 <spanclass="math inline">\(f\)</span>，我们定义 <span class="math display">\[\begin{aligned}f_{(t)}(x) &amp;=\inf _{u}\left(f(u)+\frac{1}{2 t}\|u-x\|_{2}^{2}\right)\quad(\text { with } t&gt;0) \\&amp;=f\left(\operatorname{prox}_{t f}(x)\right)+\frac{1}{2t}\left\|\operatorname{prox}_{t f}(x)-x\right\|_{2}^{2}\end{aligned}\]</span> 为函数 <span class="math inline">\(f\)</span> 的<strong>Moreau Envelop</strong> 。这里是将 <spanclass="math inline">\(\text{prox}_{tf}(x)\)</span>代回到了原函数中。在此之前我们需要首先研究一下这个函数的性质。</p><ol type="1"><li><span class="math inline">\(f_{(t)}\)</span>为<strong>凸函数</strong>。取 <span class="math inline">\(G(x,u) =f(u)+\frac{1}{2t}\Vert u-x\Vert^2_2\)</span> 是关于 <spanclass="math inline">\((x,u)\)</span> 的联合凸函数，因此 <spanclass="math inline">\(f_{(t)}(x)=\inf_u G(x,u)\)</span> 是凸的；</li><li><span class="math inline">\(\text{dom}f_{(t)}=R^n\)</span>。这是因为<span class="math inline">\(\text{prox}_{tf}(x)\)</span> 对任意的 <spanclass="math inline">\(x\)</span> 都有唯一的定义；</li><li><span class="math inline">\(f_{(t)}\in C^1\)</span><strong>连续</strong>；</li></ol><p>另外可以验证共轭函数为 <span class="math display">\[\left(f_{(t)}\right)^{\star}(y)=f^{\star}(y)+\frac{t}{2}\|y\|_{2}^{2}\]</span> 因此还有性质</p><ol start="4" type="1"><li><span class="math inline">\(\left(f_{(t)}\right)^{\star}(y)\)</span>为 <strong>t-强凸函数</strong>，等价的有 <spanclass="math inline">\(f_{(t)}(x)\)</span> 为<strong>1/t-smooth</strong>；</li></ol><p>既然这个 <span class="math inline">\(f_{(t)}\)</span> 为 <spanclass="math inline">\(C^1\)</span> 连续的，那么他的梯度是什么呢？ <spanclass="math display">\[f_{(t)}(x) = \left(f_{(t)}(x)\right)^{\star\star}=\sup _{y}\left(x^{T}y-f^{\star}(y)-\frac{t}{2}\|y\|_{2}^{2}\right)\]</span> 根据 Legendre transform 有 <spanclass="math inline">\(y^\star\in\partialf_{(t)}(x)\)</span>，令上面式子关于 <spanclass="math inline">\(y\)</span> 的次梯度等于 0 可以得到 <spanclass="math display">\[x-ty^\star \in \partial f^\star(y^\star) \iff y^\star\in\partialf(x-ty^\star) \\\Longrightarrow x-ty^\star=\text{prox}_{tf}(x)\]</span> 因此我们就有(<strong>重要</strong>) <spanclass="math display">\[y^\star=\nabla f_{(t)}(x) =\frac{1}{t}\left(x-\text{prox}_{tf}(x)\right)\]</span> 变换一下就是 <span class="math inline">\(\text{prox}_{tf}(x) =x-t\nabla f_{(t)}(x)\)</span>，注意这个式子左边就是 PPA的迭代方程，右边就是光滑函数函数 <spanclass="math inline">\(f_{(t)}(x)\)</span>应用梯度下降法的迭代方程，并且由于这个函数是 <spanclass="math inline">\(L=1/t\)</span>-smooth 的，因此我们取的步长为 <spanclass="math inline">\(t\)</span> 满足要求 <spanclass="math inline">\(0&lt;t\le1/L\)</span>。也就是我们这一小节刚开始说的，PPA 等价于对一个光滑近似函数<span class="math inline">\(f_{(t)}(x)\)</span> 的梯度下降方法。</p><p><strong><em>例子 1</em></strong>：举个例子算一下 MoreauEnvelop，假如函数 <spanclass="math inline">\(f(x)=\delta_C(x)\)</span>，则 <spanclass="math inline">\(f_{(t)}(x)=\frac{1}{2t}d(x)^2\)</span>，这里 <spanclass="math inline">\(d(x)\)</span> 是 <spanclass="math inline">\(x\)</span> 到集合 <spanclass="math inline">\(C\)</span> 的欧氏距离。</p><p><strong><em>例子 2</em></strong>：若 <spanclass="math inline">\(f(x)=\Vert x\Vert_1\)</span>，函数 <spanclass="math inline">\(f_{(t)}(x)=\sum_k \phi_t(x_k)\)</span> 被称为<strong>Huber penalty</strong>，其中 <span class="math display">\[\phi_{t}(z)=\left\{\begin{array}{ll}z^{2} /(2 t) &amp; |z| \leq t\\|z|-t / 2 &amp; |z| \geq t\end{array}\right.\]</span> <imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2020/22-huber.PNG" /></p>]]></content>
    
    
    <categories>
      
      <category>Convex Optimization</category>
      
    </categories>
    
    
    <tags>
      
      <tag>近似点算子</tag>
      
      <tag>ALM</tag>
      
      <tag>增广拉格朗日函数</tag>
      
      <tag>PPA</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Trouble I&#39;m In</title>
    <link href="/2020/05/04/music/TroubleImIn/"/>
    <url>/2020/05/04/music/TroubleImIn/</url>
    
    <content type="html"><![CDATA[<center><h2>Trouble I'm In</h2></center><span id="more"></span><iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width="330" height="86" src="//music.163.com/outchain/player?type=2&amp;id=29758362&amp;auto=1&amp;height=66"></iframe><blockquote><p><strong>Trouble I'm In</strong></p><p>I wanna feel your touch It's burning me like an ember Pretending isnot enough I wanna feel lost together So I'm giving in So I'm giving inTo the trouble I'm in So I'm giving in To the trouble I'm in To thetrouble I'm in</p><p>You are you are my favourite medicine You are you are you're wherethe edge began You are you are just one last time again You are you areYou are the trouble I'm in You are the trouble I'm in You are thetrouble I'm in</p><p>You are you are my favourite medicine You are you are you're wherethe edge began You are you are just one last time again You are you areYou are the trouble I'm in You are the trouble I'm in</p></blockquote><iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width="330" height="86" src="http://music.163.com/song/media/outer/url?id=29797698.mp3"></iframe>]]></content>
    
    
    <categories>
      
      <category>Music</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>凸优化笔记21：加速近似点梯度下降</title>
    <link href="/2020/04/24/optimization/ch21-apg-fista/"/>
    <url>/2020/04/24/optimization/ch21-apg-fista/</url>
    
    <content type="html"><![CDATA[<p>我们证明了梯度方法最快的收敛速度只能是 <spanclass="math inline">\(O(1/k^2)\)</span>（没有强凸假设的话），但是前面的方法最多只能达到<span class="math inline">\(O(1/k)\)</span>的收敛速度，那么有没有方法能达到这一极限呢？有！这一节要讲的<strong>加速近似梯度方法(APG)</strong>就是。这个方法的构造非常的巧妙，证明过程中会发现每一项都恰到好处的抵消了！真不知道作者是怎么想出来这么巧妙地方法，各位可以看看证明过程自行体会。</p><span id="more"></span><h2 id="加速近似梯度方法">1. 加速近似梯度方法</h2><p>首先说我们要考虑的优化问题形式还是 <span class="math display">\[\text{minimize }\quad f(x)=g(x)+h(x)\]</span> 其中 <span class="math inline">\(g\)</span> 为光滑项，<spanclass="math inline">\(\text{dom }g=R^n\)</span>，<spanclass="math inline">\(h\)</span>为不光滑项，且为闭的凸函数，另外为了证明梯度方法的收敛性，跟前面类似，我们需要引入Lipschitz-smooth 条件与强凸性质： <span class="math display">\[\frac{L}{2}x^Tx-g(x),\quad g(x)-\frac{m}{2}x^Tx \quad \text{convex}\]</span> 其中 <span class="math inline">\(L&gt;0,m\ge0\)</span>，<spanclass="math inline">\(m\)</span> 可以等于0，此时就相当于没有强凸性质。</p><p>然后我们就来看看 <strong>APG(Accelerated Proximal GradientMethods)</strong> 方法到底是怎么下降的。首先取 <spanclass="math inline">\(x_0=v_0,\theta_0\in(0,1]\)</span>，对于每次迭代过程，包括以下几个步骤：</p><blockquote><ol type="1"><li>求 <span class="math inline">\(\theta_k\)</span>：<spanclass="math inline">\(\frac{\theta_{k}^{2}}{t_{k}}=\left(1-\theta_{k}\right)\gamma_{k}+m \theta_{k} \quad \text { where }\gamma_{k}=\frac{\theta_{k-1}^{2}}{t_{k-1}}\)</span></li><li>更新 <span class="math inline">\(x_k,v_k\)</span>：</li></ol><p><span class="math display">\[\begin{aligned}y &amp;=x_{k}+\frac{\theta_{k} \gamma_{k}}{\gamma_{k}+m\theta_{k}}\left(v_{k}-x_{k}\right) \quad\left(y=x_{0} \text { if }k=0\right) \\x_{k+1} &amp;=\operatorname{prox}_{t_{k} h}\left(y-t_{k} \nablag(y)\right) \quad(\bigstar)\\v_{k+1} &amp;=x_{k}+\frac{1}{\theta_{k}}\left(x_{k+1}-x_{k}\right)\end{aligned}\]</span></p></blockquote><p>这里面的关键就是上面的 <spanclass="math inline">\((\bigstar)\)</span>式，对比前面讲过的近似梯度下降法实际上是 <span class="math display">\[x_{k+1} =\operatorname{prox}_{t_{k} h}\left(x_k-t_{k} \nablag(x_k)\right)\]</span> 所以这里实际上主要的变化就是将 <spanclass="math inline">\(x_k\)</span> 换成了 <spanclass="math inline">\(y\)</span>，那么 <spanclass="math inline">\(y\)</span> 跟 <spanclass="math inline">\(x_k\)</span> 又有什么不同呢？ <spanclass="math display">\[y=x_{k}+\frac{\theta_{k} \gamma_{k}}{\gamma_{k}+m\theta_{k}}\left(v_{k}-x_{k}\right)=x_{k}+\beta_{k}\left(x_{k}-x_{k-1}\right)\\\beta_{k}=\frac{\theta_{k} \gamma_{k}}{\gamma_{k}+m\theta_{k}}\left(\frac{1}{\theta_{k-1}}-1\right)=\frac{t_{k}\theta_{k-1}\left(1-\theta_{k-1}\right)}{t_{k-1} \theta_{k}+t_{k}\theta_{k-1}^{2}}\]</span> 可以看到 <spanclass="math inline">\(y=x_{k}+\beta_{k}\left(x_{k}-x_{k-1}\right)\)</span>实际上就是在 <span class="math inline">\(x_k\)</span>的基础上增加了一个<strong>“动量(Momentum)”</strong>，如下图所示</p><figure><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2020/21-momentum.PNG"alt="momentum" /><figcaption aria-hidden="true">momentum</figcaption></figure><p>我们自然的要关注 <spanclass="math inline">\(\beta_k,\theta_k\)</span>的大小以及有什么性质。首先对于参数 <spanclass="math inline">\(\theta_k\)</span> 它是根据二次方程一步步迭代出来的<span class="math display">\[\frac{\theta_{k}^{2}}{t_{k}}=\left(1-\theta_{k}\right)\frac{\theta_{k-1}^{2}}{t_{k-1}}+m \theta_{k}\]</span> 可以有几个主要结论：</p><ol type="1"><li>如果 <span class="math inline">\(m&gt;0\)</span> 且 <spanclass="math inline">\(\theta_0=\sqrt{mt_0}\)</span>，那么有 <spanclass="math inline">\(\theta_k=\sqrt{mt_k},\forall k\)</span></li><li>如果 <span class="math inline">\(m&gt;0\)</span> 且 <spanclass="math inline">\(\theta_0\ge\sqrt{mt_0}\)</span>，那么有 <spanclass="math inline">\(\theta_k\ge\sqrt{mt_k},\forall k\)</span></li><li>如果 <span class="math inline">\(mt_k&lt;,\)</span>，那么有 <spanclass="math inline">\(\theta_k&lt;1\)</span></li></ol><p>下面可以看几个关于 <spanclass="math inline">\(\theta_k,\beta_k\)</span> 随着迭代次数 <spanclass="math inline">\(k\)</span> 的变化：</p><figure><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2020/21-beta-theta.PNG"alt="example" /><figcaption aria-hidden="true">example</figcaption></figure><p>如果我们取前面的 APG 方法中的 <spanclass="math inline">\(m=0\)</span>，然后消掉中间变量 <spanclass="math inline">\(v_k\)</span>，就可以得到 <strong>FISTA(FastIterative Shrinkage-Thresholding Algorithm)</strong> 算法 <spanclass="math display">\[\begin{aligned}y&amp;=x_{k}+\theta_{k}\left(\frac{1}{\theta_{k-1}}-1\right)\left(x_{k}-x_{k-1}\right)\quad\left(y=x_{0} \text { if } k=0\right) \\x_{k+1} &amp;=\operatorname{prox}_{t_{k} h}\left(y-t_{k} \nablag(y)\right)\end{aligned}\]</span></p><h2 id="收敛性分析">2. 收敛性分析</h2><p>前面已经了解了基本原理，下面需要证明一下为什么他可以达到 <spanclass="math inline">\(O(1/k^2)\)</span>的收敛速度。作为类比，我们先回忆一下之前是怎么证明梯度方法/近似梯度方法的收敛性的？<span class="math display">\[\begin{aligned}(GD)\quad&amp;  f\left(x^{+}\right)-f^{\star} \leq \nablaf(x)^{T}\left(x-x^{\star}\right)-\frac{t}{2}\|\nablaf(x)\|_{2}^{2}\\\Longrightarrow &amp;f\left(x^{+}\right)-f^{\star}\leq\frac{1}{2t}\left(\left\|x-x^{\star}\right\|_{2}^{2}-\left\|x^{+}-x^{\star}\right\|_{2}^{2}\right)\\(SD)\quad&amp; 2 t\left(f(x)-f^{\star}\right)\leq\left\|x-x^{\star}\right\|_{2}^{2}-\left\|x^{+}-x^{\star}\right\|_{2}^{2}+t^{2}\|g\|_{2}^{2}\\(PD)\quad&amp; f\left(x^+\right) \leqf(z)+G_{t}(x)^{T}(x-z)-\frac{t}{2}\left\|G_{t}(x)\right\|_{2}^{2}-\frac{m}{2}\|x-z\|_{2}^{2}\\\Longrightarrow&amp;f\left(x^{+}\right)-f^{\star} \leq \frac{1}{2t}\left(\left\|x-x^{\star}\right\|_{2}^{2}-\left\|x^{+}-x^{\star}\right\|_{2}^{2}\right)\end{aligned}\]</span> 对于这一节的 APG 方法，证明思路是首先证明下面的迭代式子成立<span class="math display">\[f\left(x_{i+1}\right)-f^{\star}+\frac{\gamma_{i+1}}{2}\left\|v_{i+1}-x^{\star}\right\|_{2}^{2}\\\quad \leq\left(1-\theta_{i}\right)\left(f\left(x_{i}\right)-f^{\star}+\frac{\gamma_{i}}{2}\left\|v_{i}-x^{\star}\right\|_{2}^{2}\right)\quad \text { if } i\ge1\]</span> 对比后发现实际上之前我们考虑的是 <spanclass="math inline">\(f(x^+)-f^\star\)</span>的迭代式子，而这里我们加了一个小尾巴，考虑 <spanclass="math inline">\(f(x^+)-f^\star +\frac{\gamma_{i+1}}{2}\left\|v_{i+1}-x^{\star}\right\|_{2}^{2}\)</span>的收敛速度。证明一会再说，有了这个迭代关系式，那么就可以有 <spanclass="math display">\[\begin{aligned}f\left(x_{k}\right)-f^{\star} &amp; \leq\lambda_{k}\left(\left(1-\theta_{0}\right)\left(f\left(x_{0}\right)-f^{\star}\right)+\frac{\gamma_{1}-m\theta_{0}}{2}\left\|x_{0}-x^{\star}\right\|_{2}^{2}\right) \\&amp; \leq\lambda_{k}\left(\left(1-\theta_{0}\right)\left(f\left(x_{0}\right)-f^{\star}\right)+\frac{\theta_{0}^{2}}{2t_{0}}\left\|x_{0}-x^{\star}\right\|_{2}^{2}\right)\end{aligned}\]</span> 其中 <span class="math inline">\(\lambda_1=1\)</span>，<spanclass="math inline">\(\lambda_{k}=\prod_{i=1}^{k-1}\left(1-\theta_{i}\right)\text { for } k&gt;1\)</span>，如果能证明 <spanclass="math inline">\(\lambda_k\sim O(1/k^2)\)</span>就能证明收敛速度了。好了，下面就是非常巧妙而又繁琐的证明过程了。</p><p>这个证明过程很繁琐，为了更容易顺下来，这里列出来其中几个关键的等式/不等式（为了简便省略了下标）：</p><ol type="1"><li><spanclass="math inline">\(\gamma^+-m\theta=(1-\theta)\gamma\)</span>（易证）</li><li><span class="math inline">\(\gamma^+v^+=\gamma ^+ v+m\theta(y-v)-\theta G_t(y)\)</span></li><li><span class="math inline">\(\begin{aligned}f\left(x^{+}\right)-f^{\star} \leq&amp;(1-\theta)\left(f(x)-f^{\star}\right)-G_{t}(y)^{T}\left((1-\theta)x+\theta x^{\star}-y\right)-\frac{t}{2}\left\|G_{t}(y)\right\|_{2}^{2}-\frac{m\theta}{2}\left\|x^{\star}-y\right\|_{2}^{2} \end{aligned}\)</span></li><li><span class="math inline">\(\begin{aligned}\frac{\gamma^{+}}{2}\left\|v^{+}-x^{\star}\right\|_{2}^{2} \leq &amp;\frac{\gamma^{+}-m\theta}{2}\left\|v-x^{\star}\right\|_{2}^{2}+G_{t}(y)^{T}\left(\thetax^{\star}+(1-\theta) x-y\right)+\frac{t}{2}\left\|G_{t}(y)\right\|_{2}^{2}+\frac{m\theta}{2}\left\|x^{\star}-y\right\|_{2}^{2} \end{aligned}\)</span></li></ol><p>(3,4) 条结合就能得到上面的迭代关系式，很多项刚好消掉。下面就是要证明<span class="math inline">\(\lambda_k\sim O(1/k^2)\)</span>： <spanclass="math display">\[\gamma_{k+1}=(1-\theta_k)\gamma_k+m\theta_k\\\lambda_{i+1}=\left(1-\theta_{i}\right)\lambda_{i}=\frac{\gamma_{i+1}-\theta_{i} m}{\gamma_{i}} \lambda_{i}\leq \frac{\gamma_{i+1}}{\gamma_{i}} \lambda_{i} \Longrightarrow\lambda_k\le \gamma_k/\gamma_1 \\\frac{1}{\sqrt{\lambda_{i+1}}}-\frac{1}{\sqrt{\lambda_{i}}} \ge\frac{\theta_i}{2\sqrt{\lambda_{i+1}}}=\frac{1}{2}\sqrt{\gamma_1t_i}\]</span> 然后就可以有 <span class="math display">\[\lambda_{k} \leq \frac{4}{\left(2+\sqrt{\gamma_{1}} \sum_{i=1}^{k-1}\sqrt{t_{i}}\right)^{2}}=\frac{4 t_{0}}{\left(2 \sqrt{t_{0}}+\theta_{0}\sum_{i=1}^{k-1} \sqrt{t_{i}}\right)^{2}}\]</span> 如果取 <spanclass="math inline">\(t_0=t_k=1/L,\theta_0=1\)</span>，则有 <spanclass="math display">\[\lambda_k\le \frac{4}{(k+1)^2}\]</span> 如果有强凸性质，也即 <spanclass="math inline">\(m&gt;0\)</span>，那么取 <spanclass="math inline">\(\theta_0\ge\sqrt{mt_0}\Longrightarrow \theta_k\ge\sqrt{mt_k}\)</span> <span class="math display">\[\lambda_k \le \Pi_{i=1}^{k-1}(1-\sqrt{mt_i})\]</span> 这就可以变成线性收敛了。</p>]]></content>
    
    
    <categories>
      
      <category>Convex Optimization</category>
      
    </categories>
    
    
    <tags>
      
      <tag>PG 算法</tag>
      
      <tag>APG 算法</tag>
      
      <tag>FISTA 算法</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>凸优化笔记20：对偶近似点梯度下降</title>
    <link href="/2020/04/23/optimization/ch20-dual-proximal-gradient/"/>
    <url>/2020/04/23/optimization/ch20-dual-proximal-gradient/</url>
    
    <content type="html"><![CDATA[<p>前面讲了梯度下降、次梯度下降、近似点梯度下降方法并分析了收敛性。一开始我们还讲了对偶原理，那么如果原问题比较难求解的时候，我们可不可以转化为对偶问题并应用梯度法求解呢？当然可以，不过有一个问题就是对偶函数的梯度或者次梯度怎么计算呢？这就是这一节要关注的问题。</p><p>首先一个问题是哪些形式的问题，其对偶问题相比于原问题更简单呢？可能有很多种，这一节主要关注一种：<strong>线性等式/不等式约束的优化问题</strong>。之所以考虑此类问题是因为如果有线性的等式/不等式约束，应用Lagrange对偶原理之后，我们可以自然的用原函数的<strong>共轭函数</strong>来表示其<strong>对偶问题</strong>，而共轭函数的次梯度是容易求解的，因为我们可以用<strong>Legendretransformation</strong>。那么接下来就是详细的原理和例子了。</p><span id="more"></span><h2 id="对偶分解原理">1. 对偶分解原理</h2><p>假如我们考虑如下无约束优化问题，通过添加线性等式约束以及对偶原理可以容易获得对偶问题的形式<span class="math display">\[\begin{aligned}(P)\quad\min \ &amp; f(x)+g(Ax) \\(D)\quad\max \ &amp; -g^\star(z)-f^\star(-A^Tz)\end{aligned}\]</span>如果我们现在想对偶问题应用梯度下降方法，一个关键的问题就是如何求解 <spanclass="math inline">\(f^\star,g^\star\)</span>的梯度/次梯度？会议一下前面讲共轭函数的时候提到了一些性质：</p><blockquote><p>关于共轭函数有以下性质</p><ol type="1"><li>若 <span class="math inline">\(f\)</span> 为凸的且是闭的(<spanclass="math inline">\(\text{epi }f\)</span> 为闭集)，则 <spanclass="math inline">\(f^{**}=f\)</span>(可以联系上面提到一系列支撑超平面)</li><li>(Fenchel's inequality) <span class="math inline">\(f(x)+f^*(y)\gex^Ty\)</span>，这可以类比均值不等式</li><li>(<strong>Legendre transform</strong>)如果 <spanclass="math inline">\(f\)</span> 且为<strong>凸的、闭的</strong>，设<span class="math inline">\(x^*=\arg\max\{y^Tx-f(x)\}\)</span>，那么有<span class="math inline">\(x^*\in\partial f^*(y)\iff y\in\partialf(x^*)\)</span>。这可以用来求极值，比如 <span class="math inline">\(\minf(x)\Longrightarrow 0\in\partial f(x)\iff x\in\partialf^*(0)\)</span></li></ol></blockquote><p>所以只需要找到 <span class="math display">\[\hat{x}=\arg\max_x -z^TAx-f(x) = \arg\min_x z^TAx+f(x)\]</span> 就可以有 <span class="math inline">\(\hat{x}\in\partialf^\star(-A^Tz)\)</span>。如果函数 <span class="math inline">\(f\)</span>为<strong>严格凸函数</strong>，意味着上面的 <spanclass="math inline">\(\hat{x}\)</span> 唯一，也说明 <spanclass="math inline">\(\partial f^\star=\nablaf^\star\)</span>；如果条件加强，<span class="math inline">\(f\)</span>为<span class="math inline">\(\mu\)</span>-强凸函数那么就有 <spanclass="math display">\[\left\|\nabla f^{*}(y)-\nabla f^{*}\left(y^{\prime}\right)\right\| \leq\frac{1}{\mu}\left\|y-y^{\prime}\right\|_{*} \quad \text { for all } y,y^{\prime}\]</span> 也就是说共轭函数的梯度是 Lipschitz continuous 的，也即共轭函数<span class="math inline">\(f^\star\)</span> 是 <spanclass="math inline">\(1/\mu\)</span>-smooth的，因此我们也能证明对偶问题下用梯度方法的收敛性。</p><p><strong><em>例子</em></strong>：现在我们把上面的 <spanclass="math inline">\(g\)</span>换成一个指示函数，也即表示一个线性等式约束 <span class="math display">\[\begin{aligned}(P)\quad\text{minimize } \quad&amp; f(x) \\\text{subject to } \quad&amp; Ax=b \\(D)\quad\text{minimize } \quad&amp; -b^Tz-f^\star(-A^Tz)\end{aligned}\]</span> 怎么做梯度下降呢？ <span class="math display">\[\begin{aligned}\hat{x} &amp;=\underset{x}{\operatorname{argmin}}\left(f(x)+z^{T} Ax\right) \\z^{+} &amp;=z+t(A \hat{x}-b)\end{aligned}\]</span> 上面第一步就是为了求解 <spanclass="math inline">\(f^\star\)</span> 的次梯度，第二部就是对 <spanclass="math inline">\(z\)</span> 进行梯度上升。我们再来观察一下 Lagrange函数 <span class="math display">\[\begin{aligned}L(x,z)&amp;=f(x)+z^T(Ax-b) \\&amp;=-b^Tz+(f(x)+z^TAx)\end{aligned}\]</span> 我么前面说过最优解实际上是拉格朗日函数的鞍点，也就是关于 <spanclass="math inline">\(x\)</span> 的极小值点，关于 <spanclass="math inline">\(z\)</span>的极大值点。而这里我们要做的两部就分别是对 <spanclass="math inline">\(x\)</span> 求一个极小值点 <spanclass="math inline">\(\hat{x}\)</span>，然后对 <spanclass="math inline">\(z\)</span>并没有求极大值点，而是做了一个梯度上升。</p><p>好了，对偶问题的梯度下降方法原理就这些，但是标题里面“对偶分解”还有一个“<strong>分解</strong>”是什么意思呢？我们说如果原问题比较复杂就可以考虑解对偶问题，那么具体是哪一种问题呢？看个例子<span class="math display">\[\begin{aligned}\text{minimize } \quad&amp; f_1(x_1)+f_2(x_2) \\\text{subject to } \quad&amp; A_1x_1+A_2x_2\preceq b \\\end{aligned}\]</span> 这个问题有什么特点呢？目标函数实际上是由两个不相关的函数 <spanclass="math inline">\(f_1(x_1),f_2(x_2)\)</span> 求和得到的，注意不仅是<span class="math inline">\(f_1,f_2\)</span> 不同，他们的自变量 <spanclass="math inline">\(x_1,x_2\)</span>也是相互独立的，也即是说假如没有这个约束条件，我们完全可以分解为两个独立的最小化问题分别求解。但是现在<strong>由于这个约束条件，这两个问题耦合在一起了</strong>，这就有点麻烦了。那么在对偶问题中能不能解耦合呢？好消息是可以！他们的对偶问题可以写为<span class="math display">\[\begin{aligned}\text{minimize } \quad&amp; -f_1^\star(-A_1^Tz)-f_2^\star(-A_2^Tz)-b^Tz\\\text{subject to } \quad&amp; z\succeq 0 \\\end{aligned}\]</span> 这个时候我们只需要分别求解 <spanclass="math inline">\(f_1^\star,f_2^\star\)</span>的次梯度，这两个是可以并行计算的，即下面的 <spanclass="math inline">\(\hat{x}_1,\hat{x}_2\)</span> 可以并行计算 <spanclass="math display">\[\begin{aligned}&amp;\hat{x}_{j}=\underset{x_{j}}{\operatorname{argmin}}\left(f_{j}\left(x_{j}\right)+z^{T}A_{j} x_{j}\right) \quad \text { for } j=1,2\\&amp;z^{+}=\left(z+t\left(A_{1} \hat{x}_{1}+A_{2}\hat{x}_{2}-b\right)\right)_{+}\end{aligned}\]</span> 所以每次迭代我们都可以先并行计算 <spanclass="math inline">\(\hat{x}_j\)</span>，然后把他们传给中心节点，中心节点再对<span class="math inline">\(z\)</span>计算梯度上升。需要注意的一点是这里对 <spanclass="math inline">\(z^+\)</span> 只取正值，这是因为有 <spanclass="math inline">\(z\succeq 0\)</span> 的约束，从另一个角度理解也是向<span class="math inline">\(C=\{z|z\succeq0\}\)</span>做了投影（回忆上一节的近似点算子与投影的关系，以及近似点梯度下降实际上就是先算梯度再做投影）。</p><p><strong><em>例子 1</em></strong>：来看一个二次优化的例子，假设其中的<span class="math inline">\(P_j\succ0\)</span> <spanclass="math display">\[\begin{array}{ll}\text { minimize } &amp; \sum_{j=1}^{r}\left(\frac{1}{2} x_{j}^{T} P_{j}x_{j}+q_{j}^{T} x_{j}\right) \\\text { subject to } &amp; B_{j} x_{j} \preceq d_{j}, \quad j=1, \ldots,r \\&amp; \sum_{j=1}^{r} A_{j} x_{j} \preceq b\end{array}\]</span> 这里约束条件比较多，我们可以转化一下，考虑 <spanclass="math inline">\(f_j(x_j)=\frac{1}{2} x_{j}^{T} P_{j}x_{j}+q_{j}^{T} x_{j}\)</span>，定义域为 <spanclass="math inline">\(\{x_j|B_jx_j\preceqd_j\}\)</span>。对偶问题就变成了 <span class="math display">\[\begin{aligned}\text{minimize } \quad&amp; -b^Tz-\sum_{j=1}^r f_j^\star(-A_j^Tz) \\\text{subject to } \quad&amp; z\succeq 0 \\\end{aligned}\]</span> 为了保证梯度下降方法的收敛性，还需要验证目标函数的 Lipschitzsmooth 性质，考虑 <span class="math inline">\(h(z)=\sum_jf_j^\star(-A_j^Tz)\)</span>，有 <span class="math display">\[\left\|\nabla h(z)-\nabla h\left(z^{\prime}\right)\right\|_{2} \leq\frac{\|A\|_{2}^{2}}{\min _{j} \lambda_{\min}\left(P_{j}\right)}\left\|z-z^{\prime}\right\|_{2}\]</span> 其中 <spanclass="math inline">\(A=[\begin{array}{ccc}A_1&amp;\cdots&amp;A_r\end{array}]\)</span>。那么怎么求<span class="math inline">\(\hat{x}_j=\partialf_j^\star(-A_j^Tz)\)</span> 呢？就是求解下面的优化问题 <spanclass="math display">\[\begin{array}{ll}\text { minimize } &amp; \frac{1}{2} x_{j}^{T} P_{j}x_{j}+(q_{j}+A_j^Tz)^T x_{j} \\\text { subject to } &amp; B_{j} x_{j} \preceq d_{j}\end{array}\]</span> <strong><em>例子 2</em></strong>：网络优化问题 <spanclass="math display">\[\begin{aligned}(P) \quad \text { maximize } \quad&amp; \sum_{j=1}^{n}U_{j}\left(x_{j}\right)\\\text { subject to } \quad&amp; R x \leq c\\(D) \quad \text { minimize } \quad&amp; c^{T}z+\sum_{j=1}^{n}\left(-U_{j}\right)^{*}\left(-r_{j}^{T} z\right)\\\text { subject to } \quad&amp; z \geq 0\end{aligned}\]</span> 只需要将 <span class="math inline">\(R\)</span>的各列拆分开就行了。</p><h2 id="对偶近似点梯度方法">2. 对偶近似点梯度方法</h2><p>这节的一开始我们考虑的问题是 <span class="math display">\[\begin{aligned}(P)\quad\min \ &amp; f(x)+g(Ax) \\(D)\quad\min \ &amp; g^\star(z)+f^\star(-A^Tz)\end{aligned}\]</span> 不过举得几个例子中都没有见到 <spanclass="math inline">\(g\)</span>的影子，这是因为我们都加了线性等式/不等式约束，也就等价于 <spanclass="math inline">\(g=\delta_C(x)\)</span>是一个指示函数的形式。那如果考虑一般的(不光滑的) <spanclass="math inline">\(g\)</span>呢？很简单，我们本质上还是在做梯度下降(上升)，如果函数不光滑，就可以用上一篇文章的近似点梯度方法，还记得近似点梯度下降的公式吗？<span class="math display">\[z^{+}=\operatorname{prox}_{t g^{*}}\left(z+t A \nabla f^{*}\left(-A^{T}z\right)\right)\]</span>实际上刚刚举得几个例子也都是在做近似点梯度下降，只不过对于指示函数的近似点就是在做投影，比较简单。所以对上面的问题求解实际上就是两步：<span class="math display">\[\begin{aligned}\hat{x} &amp;=\underset{x}{\operatorname{argmin}}\left(f(x)+z^{T} Ax\right) \\z^{+} &amp;=\operatorname{prox}_{t g^{*}}(z+t A \hat{x})\end{aligned}\]</span> 如果有时候 <span class="math inline">\(g^\star\)</span>的近似点不好计算，也可以利用 Moreau分解(参见上上一节近似点算子)，那么可以计算 <span class="math display">\[z^{+} =z+tA\hat{x}-t\operatorname{prox}_{t^{-1} g}(t^{-1}z+A \hat{x})\]</span>这个式子其实可以跟增广拉格朗日方法(后面会讲)联系起来。我们可以令 <spanclass="math inline">\(\hat{y}\)</span> 为 <span class="math display">\[\begin{aligned}\hat{y} &amp;=\operatorname{prox}_{t^{-1} g}\left(t^{-1} z+A\hat{x}\right) \\&amp;=\underset{y}{\operatorname{argmin}}\left(g(y)+\frac{t}{2}\left\|A\hat{x}-t^{-1} z-y\right\|_{2}^{2}\right) \\&amp;=\underset{y}{\operatorname{argmin}}\left(g(y)+z^{T}(A\hat{x}-y)+\frac{t}{2}\|A \hat{x}-y\|_{2}^{2}\right)\end{aligned}\]</span> 那么就有 <spanclass="math inline">\(z^{+}=z+t(A\hat{x}-\hat{y})\)</span>，所以这里<span class="math inline">\(\hat{y}\)</span> 一定程度上可以理解为 <spanclass="math inline">\(g^\star(z)\)</span>的次梯度。把前面的分析综合起来，我们梯度下降的每次迭代过程实际上可以由下面3 个步骤组成 <span class="math display">\[\begin{aligned}\hat{x} &amp;=\underset{x}{\operatorname{argmin}}\left(f(x)+z^{T} Ax\right) \\\hat{y} &amp;=\underset{y}{\operatorname{argmin}}\left(g(y)-z^{T}y+\frac{t}{2}\|A \hat{x}-y\|_{2}^{2}\right) \\z^{+} &amp;=z+t(A \hat{x}-\hat{y})\end{aligned}\]</span> 这个时候可以跟<strong>增广拉格朗日方法(augmented Lagrangianmethod)</strong>比较一下，ALM 的计算公式为 <span class="math display">\[(\hat{x}, \hat{y})=\underset{x,y}{\operatorname{argmin}}\left(f(x)+g(y)+z^{T}(A x-y)+\frac{t}{2}\|Ax-y\|_{2}^{2}\right)\]</span> 首先 ALM要优化的这个增广拉格朗日函数函数是在普通拉格朗日函数的基础上加了一个最后的二阶项，然后对增广拉函数优化<spanclass="math inline">\(x,y\)</span>。而前面的对偶近似梯度方法是怎么做呢？观察增广拉函数实际上可以分解为两项<span class="math display">\[L(x,y,z)=\left(f(x)+z^{T}A x\right)+\left(g(y)-z^Ty+\frac{t}{2}\|Ax-y\|_{2}^{2}\right)\]</span> 而对偶近似梯度方法实际上就是先优化第一项，只考虑 <spanclass="math inline">\(x\)</span>，计算得到 <spanclass="math inline">\(\hat{x}\)</span> 以后再代入到第二项单独优化 <spanclass="math inline">\(y\)</span> 得到 <spanclass="math inline">\(\hat{y}\)</span>，最后对 <spanclass="math inline">\(z\)</span>做梯度上升！巧妙不巧妙！显然对偶近似梯度方法计算起来更简单，但是也有代价，那就是ALM 并不要求函数 <span class="math inline">\(f\)</span>是强凸的，而对偶近似梯度方法则要求 <spanclass="math inline">\(f\)</span> 为强凸的。</p><p>基本的理论就完了，下面主要是一些例子。</p><p><strong><em>例子 1</em></strong>：<spanclass="math inline">\(g\)</span> 为范数正则项 <spanclass="math display">\[\begin{aligned}(P)\quad\text{minimize}\quad&amp; f(x)+\|A x-b\| \\(D)\quad\text{maximize} \quad&amp; -b^{T} z-f^{*}\left(-A^{T} z\right)\\\text{subject to} \quad&amp; \|z\|_{*} \leq 1\end{aligned}\]</span> 我们可以取 <span class="math inline">\(g(y)=\Verty-b\Vert\)</span> <span class="math display">\[g^{*}(z)=\left\{\begin{array}{ll}b^{T} z &amp; \|z\|_{*} \leq 1 \\+\infty &amp; \text { otherwise }\end{array} \quad \operatorname{prox}_{t g *}(z)=P_{C}(z-t b)\right.\]</span> 对偶近似梯度下降方法每次迭代过程为 <spanclass="math display">\[\begin{aligned}\hat{x} &amp;=\underset{x}{\operatorname{argmin}}\left(f(x)+z^{T} Ax\right) \\z^{+} &amp;=P_{C}(z+t(A \hat{x}-b))\end{aligned}\]</span> <strong><em>例子 2(重要)</em></strong>：前面都只有 1 个 <spanclass="math inline">\(g\)</span>，这次考虑 <spanclass="math inline">\(g\)</span> 为多个 <spanclass="math inline">\(g_i\)</span> 求和 <span class="math display">\[\begin{aligned}(P) \quad \text { minimize } \quad&amp; f(x)+\sum_{i=1}^{p}\left\|B_{i}x\right\|_{2}\\(D) \quad \text { maximize } \quad&amp; -f^{*}\left(-B_{1}^{T}z_{1}-\cdots-B_{p}^{T} z_{p}\right)\\\text { subject to }\quad&amp; \left\|z_{i}\right\|_{2} \leq 1, \quadi=1, \ldots, p\end{aligned}\]</span> 这个推导就有点麻烦了，我们考虑一般的情况 <spanclass="math inline">\(g(x)=g_1(B_1x)+...+g_p(B_px)\)</span>，那么可以取<span class="math inline">\(B=[B_1;...;B_p]\)</span>(排成一列)，<spanclass="math inline">\(g(x)=\hat{g}(Bx)\)</span>，那么原问题实际上等价于<span class="math display">\[\begin{aligned}\text{minimize } \quad&amp; f(x)+\hat{g}(y) \\\text{subject to } \quad&amp; y=Bx \\\end{aligned}\]</span> 拉格朗日函数为 <spanclass="math inline">\(L(x,y,z)=f(x)+\sum_i g_i(y_i) + \sum_iz_i^T(B_ix-y_i)\)</span>，对偶问题就变成了 <span class="math display">\[\text{maximize}\quad -f^\star(-\sum_i B_i^Tz_i) - \sum_i g_i^\star(z_i)\]</span> 注意到对偶问题中 <span class="math inline">\(g^\star(z)=\sum_ig^\star_i(z_i)\)</span>，利用近似点算子公式就可以得到 <spanclass="math display">\[\operatorname{prox}_{tg^\star}(x)=\left[\begin{array}{c}\operatorname{prox}_{tg^\star_1}(x_1)\\\vdots \\ \operatorname{prox}_{tg^\star_p}(x_p) \end{array}\right]\]</span> 所以我们的 <span class="math inline">\(z_i^+\)</span>之间的计算是互不相关的，可以并行进行，也即下面的式子中 <spanclass="math inline">\(\hat{x}\)</span>此时不能并行计算了，但是 <spanclass="math inline">\(z_i^+\)</span>可以分别计算 <spanclass="math display">\[\begin{aligned}\hat{x}&amp;=\underset{x}{\operatorname{argmin}}\left(f(x)+\left(\sum_{i=1}^{p}B_{i}^{T} z_{i}\right)^{T} x\right) \\z_{i}^{+} &amp;=P_{C_{i}}\left(z_{i}+t B_{i} \hat{x}\right), \quad i=1,\ldots, p\end{aligned}\]</span> 注意第一部分当中我们考虑 <spanclass="math inline">\(f_1(x_1)+f_2(x_2)\)</span>形式的优化问题，这使得对偶问题可以分解为 <spanclass="math inline">\(\sum_i f^\star(-A_i^Tz)\)</span>，可以并行计算<span class="math inline">\(\hat{x}_i\)</span>，而这里我们考虑 <spanclass="math inline">\(\sum_i g(x)\)</span> 则对偶问题可以表示为 <spanclass="math inline">\(\sum_ig^\star(z_i)\)</span>，这使得计算近似点梯度的时候可以对 <spanclass="math inline">\(z_i^+\)</span> 并行计算，非常的对称！</p>]]></content>
    
    
    <categories>
      
      <category>Convex Optimization</category>
      
    </categories>
    
    
    <tags>
      
      <tag>拉格朗日函数</tag>
      
      <tag>近似点算子</tag>
      
      <tag>共轭函数</tag>
      
      <tag>PG 算法</tag>
      
      <tag>ALM</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>凸优化笔记19：近似点梯度下降</title>
    <link href="/2020/04/17/optimization/ch19-proximal-gradient/"/>
    <url>/2020/04/17/optimization/ch19-proximal-gradient/</url>
    
    <content type="html"><![CDATA[<p>前面讲了梯度下降法、次梯度下降法，并分析了他们的收敛性。上一节讲了近似梯度算子，我们说主要是针对非光滑问题的，这一节就要讲近似梯度算子在非光滑优化问题中的应用。先回顾一下上一节最重要的一部分内容：对于指示函数<span class="math inline">\(\delta_C\)</span>来说近似梯度算子得到的实际上就是向集合 <spanclass="math inline">\(C\)</span> 的投影。</p><h2 id="近似点梯度下降">1. 近似点梯度下降</h2><p>这一部分考虑的问题主要是 <span class="math display">\[\text{minimize } f(x)=g(x)+h(x)\]</span> 这里面 <span class="math inline">\(g\)</span>是全空间可导的凸函数，<span class="math inline">\(\text{dom}g=R^n\)</span>，<span class="math inline">\(h\)</span>是存在不可导部分的凸函数，并且一般需要 <spanclass="math inline">\(h\)</span>的近似点计算较为简单。近似点梯度下降算法是什么呢？ <spanclass="math display">\[x_{k+1}=\text{prox}_{th}(x_k-t_k\nabla g(x_k))\]</span> <span id="more"></span></p><p>这里跟之前的梯度下降(GD)和次梯度下降(SD)的形式都不太一样，实际上看了后面的推导会发现经过转换他们还是很像的。不过怎么理解这个式子呢？举一个例子，假如<span class="math inline">\(h\)</span> 是集合 <spanclass="math inline">\(C\)</span> 的指示函数，那么这个式子实际上是先沿着<span class="math inline">\(g\)</span> 的梯度走步长 <spanclass="math inline">\(t_k\)</span>，然后再投影到集合 <spanclass="math inline">\(C\)</span>里面，可以看下面这张图。而考虑原始优化问题，<spanclass="math inline">\(\min f=g+h\)</span>本身是一个无约束优化问题，但实际上把 <spanclass="math inline">\(h\)</span>用一个约束函数表示，他就是一个带约束的优化问题 <spanclass="math inline">\(\min g(x),\text{ s.t. }x\inC\)</span>，而近似点梯度下降方法要做的事情就是先优化 <spanclass="math inline">\(g\)</span>，然后投影到约束区域 <spanclass="math inline">\(C\)</span> 中，可以参考下图。</p><figure><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2020/19-proximal-gradient.PNG"alt="19-proximal-gradient" /><figcaption aria-hidden="true">19-proximal-gradient</figcaption></figure><p>根据 <span class="math inline">\(\text{prox}_{th}\)</span>的定义，我们把上面的式子展开可以得到 <span class="math display">\[\begin{aligned}x^{+} &amp;=\underset{u}{\operatorname{argmin}}\left(h(u)+\frac{1}{2t}\|u-x+t \nabla g(x)\|_{2}^{2}\right) \\&amp;=\underset{u}{\operatorname{argmin}}\left(h(u)+g(x)+\nablag(x)^{T}(u-x)+\frac{1}{2 t}\|u-x\|_{2}^{2}\right)\end{aligned}\]</span> 可以发现括号里面的式子实际上就是在 <spanclass="math inline">\(x\)</span> 附近对光滑的 <spanclass="math inline">\(g\)</span> 进行了二阶展开，而 <spanclass="math inline">\(x^+\)</span>就是对近似后函数取最小值点。再进一步地 <span class="math display">\[0\in t\partial h(x^+) + (x^+-x+t\nabla g(x)) \\\Longrightarrow G_t(x):=\frac{x-x^+}{t}\in \partial h(x^+)+\nabla g(x)\]</span> 可以发现 <span class="math inline">\(G_t(x)=\partialh(x^+)+\nabla g(x)\)</span> 实际上就近似为函数 <spanclass="math inline">\(f\)</span> 的次梯度，但并不严格是，因为 <spanclass="math inline">\(\partial f(x)=\partial h(x)+\nablag(x)\)</span>。而此时我们也可以将 <spanclass="math inline">\(x^+\)</span> 写成比较简单的形式 <spanclass="math display">\[x^+ = x-tG_t(x)\]</span> 这跟之前的梯度下降法就统一了，并且也说明了 <spanclass="math inline">\(G_t(x)\)</span> 就相当于是 <spanclass="math inline">\(f\)</span> 的梯度。</p><p>这里还需要说明的一点是 <spanclass="math inline">\(G_t(x)=(1/t)(x-\text{prox}_{th}(x-t\nablag(x))\)</span> 这是一个连续函数，这是因为近似点算子是 Lipschitz连续的(在下面一小节中会解释说明)，又由于 <spanclass="math inline">\(G_t(x)=0\iff x=\arg\min f(x)\)</span>，因此 <spanclass="math inline">\(\Vert x-x^+\Vert\le \varepsilon\)</span>就可以作为 stoppingcriterion。与之成对比的是非光滑函数的次梯度下降，<spanclass="math inline">\(\Vert x-x^+\Vert\)</span> 就不是一个很好的stopping criterion，因为即使 <span class="math inline">\(\Vertx-x^+\Vert\)</span> 很小，也可能离最优解比较远。</p><h2 id="收敛速度分析">2. 收敛速度分析</h2><p>在分析收敛速度之前，我们需要首先分析一下 <spanclass="math inline">\(g(x)\)</span> 和 <spanclass="math inline">\(h(x)\)</span> 这两部分函数的性质。</p><p>首先是 <span class="math inline">\(h\)</span>，如果 <spanclass="math inline">\(h\)</span> 为闭的凸函数，那么 <spanclass="math inline">\(\text{prox}_h(x)=\arg\min_u\left(h(u)+(1/2)\Vertu-x\Vert^2\right)\)</span> 对每个 <span class="math inline">\(x\)</span>一定存在唯一的解。并且 <span class="math inline">\(u=\text{prox}_h(x)\iff x-u\in \partial h(u)\)</span>，那么我们就可以得到 <strong>ﬁrmlynonexpansive(co-coercivite)</strong> 性质： <spanclass="math display">\[\left(\operatorname{prox}_{h}(x)-\operatorname{prox}_{h}(y)\right)^{T}(x-y)\geq\left\|\operatorname{prox}_{h}(x)-\operatorname{prox}_{h}(y)\right\|_{2}^{2}\]</span> 证明过程可以取 <spanclass="math inline">\(u=\text{prox}_h(x),v=\text{prox}_h(y)\)</span>，然后根据<span class="math inline">\(x-u\in \partial h(u),y-v\in \partialh(v)\)</span>，再利用次梯度算子的单调性质就可以得到。之前在梯度下降法中第一次讲到co-coercive 性质的时候也提到，他跟 Lipschitz continuous性质实际上是等价的，因此我们也有(<strong>nonexpansiveness</strong>性质)<span class="math display">\[\left\|\operatorname{prox}_{h}(x)-\operatorname{prox}_{h}(y)\right\|_2\le \left\|x-y\right\|_2\]</span> 然后我们再来看函数 <span class="math inline">\(g\)</span>的性质，类似前面梯度下降法中的两个重要性质：</p><ol type="1"><li><strong>L-smooth</strong>：<spanclass="math inline">\(\frac{L}{2}x^Tx-g(x)\)</span> convex</li><li><strong>m-strongly convex</strong>：<spanclass="math inline">\(g(x)-\frac{m}{2}x^Tx\)</span> convex</li></ol><p>然后就可以得到两个二次的界 <span class="math display">\[\frac{m t^{2}}{2}\left\|G_{t}(x)\right\|_{2}^{2} \leq g\left(x-tG_{t}(x)\right)-g(x)+t \nabla g(x)^{T} G_{t}(x) \leq \frac{Lt^{2}}{2}\left\|G_{t}(x)\right\|_{2}^{2}\]</span> 如果取 <span class="math inline">\(0&lt; t\le1/L\)</span>，那么就有 <span class="math inline">\(Lt\le1,mt\le1\)</span>。</p><p>结合上面对 <span class="math inline">\(g\)</span> 和 <spanclass="math inline">\(h\)</span>性质的分析，就能得到下面这个<strong>非常重要</strong>的式子：</p><blockquote><p><span class="math display">\[f\left(x-t G_{t}(x)\right) \leqf(z)+G_{t}(x)^{T}(x-z)-\frac{t}{2}\left\|G_{t}(x)\right\|_{2}^{2}-\frac{m}{2}\|x-z\|_{2}^{2}\qquad (\bigstar)\]</span></p><p><strong>证明</strong>： <span class="math display">\[\begin{aligned}f\left(x-t G_{t}(x)\right) &amp; \\\leq &amp; g(x)-t \nabla g(x)^{T}G_{t}(x)+\frac{t}{2}\left\|G_{t}(x)\right\|_{2}^{2}+h\left(x-tG_{t}(x)\right) \\\leq &amp; g(z)-\nabla g(x)^{T}(z-x)-\frac{m}{2}\|z-x\|_{2}^{2}-t \nablag(x)^{T} G_{t}(x)+\frac{t}{2}\left\|G_{t}(x)\right\|_{2}^{2} \\&amp;+h\left(x-t G_{t}(x)\right) \\\leq &amp; g(z)-\nabla g(x)^{T}(z-x)-\frac{m}{2}\|z-x\|_{2}^{2}-t \nablag(x)^{T} G_{t}(x)+\frac{t}{2}\left\|G_{t}(x)\right\|_{2}^{2} \\&amp;+h(z)-\left(G_{t}(x)-\nabla g(x)\right)^{T}\left(z-x+tG_{t}(x)\right) \\=&amp;g(z)+h(z)+G_{t}(x)^{T}(x-z)-\frac{t}{2}\left\|G_{t}(x)\right\|_{2}^{2}-\frac{m}{2}\|x-z\|_{2}^{2}\end{aligned}\]</span> 其中第一个不等号用到了 <spanclass="math inline">\(g(x)\)</span> 凸函数以及 Lipschitz连续的性质，第二个不等号用到了 <span class="math inline">\(g(x)\)</span>凸函数的性质，第三个不等号用到了 <spanclass="math inline">\(h(x)\)</span> 凸函数的性质。</p></blockquote><p>有了上面这个式子就可以分析收敛性了。</p><p>如果我们取 <spanclass="math inline">\(z=x\)</span>，那么就有下面的式子，说明序列 <spanclass="math inline">\(\{f(x_k\}\)</span> 总是在减小的，如果 <spanclass="math inline">\(f(x)\)</span> 存在下界，那么 <spanclass="math inline">\(f(x_k)\)</span> 将趋向于这个下界。 <spanclass="math display">\[f(x^+)\le f(x)-\frac{t}{2}\Vert G_t(x)\Vert^2\]</span> 如果我们取 <spanclass="math inline">\(z=x^\star\)</span>，那么就有 <spanclass="math display">\[\begin{aligned}f\left(x^{+}\right)-f^{\star} &amp; \leqG_{t}(x)^{T}\left(x-x^{\star}\right)-\frac{t}{2}\left\|G_{t}(x)\right\|_{2}^{2}-\frac{m}{2}\left\|x-x^{\star}\right\|_{2}^{2}\\&amp;=\frac{1}{2t}\left(\left\|x-x^{\star}\right\|_{2}^{2}-\left\|x-x^{\star}-tG_{t}(x)\right\|_{2}^{2}\right)-\frac{m}{2}\left\|x-x^{\star}\right\|_{2}^{2}\\&amp;=\frac{1}{2 t}\left((1-mt)\left\|x-x^{\star}\right\|_{2}^{2}-\left\|x^{+}-x^{\star}\right\|_{2}^{2}\right)\\&amp; \leq \frac{1}{2t}\left(\left\|x-x^{\star}\right\|_{2}^{2}-\left\|x^{+}-x^{\star}\right\|_{2}^{2}\right)\end{aligned}\]</span> 从这个式子就可以看出来很多有用的性质了：</p><ol type="1"><li><spanclass="math inline">\(\left\|x^{+}-x^{\star}\right\|_{2}^{2}\le (1-mt)\left\|x-x^{\star}\right\|_{2}^{2}\)</span>，如果满足强凸性质的话，也即<span class="math inline">\(m&gt;0\)</span>，就有 <spanclass="math inline">\(\left\|x^{+}-x^{\star}\right\|_{2}^{2}\lec^k\left\|x-x^{\star}\right\|_{2}^{2},c=1-m/L\)</span>；</li><li><span class="math inline">\(\sum_i^k (f(x_i)-f^\star) \le\frac{1}{2t}\left\|x^{+}-x^{\star}\right\|_{2}^{2}\)</span>，由于 <spanclass="math inline">\(f(x_i)\)</span> 不增，因此 <spanclass="math inline">\(f(x_k)-f^\star \le\frac{1}{2kt}\left\|x^{+}-x^{\star}\right\|_{2}^{2}\)</span>，因此收敛速度也是<span class="math inline">\(O(1/k)\)</span>。</li></ol><p>注意到前面的分析是针对固定步长 <spanclass="math inline">\(t\in(0,1/L]\)</span>的，如果我们想走的更远一点，下降的快一点呢？就可以用前几节提到的线搜索方法。也就是说每次选择步长<span class="math inline">\(t_k\)</span> 的时候需要迭代 <spanclass="math inline">\(t:=\beta t\)</span> 来进行搜索，使得满足下面的式子<span class="math display">\[g\left(x-t G_{t}(x)\right) \leq g(x)-t \nabla g(x)^{T}G_{t}(x)+\frac{t}{2}\left\|G_{t}(x)\right\|_{2}^{2}\]</span> 这个式子就是 Lipschitz连续导出的二次上界，注意应用线搜索的时候，每次迭代我们都要额外计算一次<span class="math inline">\(g\)</span> 和 <spanclass="math inline">\(\text{prox}_{th}\)</span>，这个计算可能并不简单，因此不一定会使算法收敛更快，需要慎重考虑。另外为了保证能在有限步停止搜索<span class="math inline">\(t_k\)</span>，还需要加入最小步长的约束 <spanclass="math inline">\(t\ge t_{\min}=\min\{\hat{t},\beta/L\}\)</span>。线搜索直观理解可以如下图所示</p><figure><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2020/19-line-search.PNG"alt="19-line-search" /><figcaption aria-hidden="true">19-line-search</figcaption></figure><p>我们再来分析一下收敛性，跟前面固定步长很像，只需要将原来的式子中<span class="math inline">\(t\)</span> 替换为 <spanclass="math inline">\(t_i\)</span>，就可以得到 <spanclass="math display">\[t_{i}\left(f\left(x_{i+1}\right)-f^{\star}\right) \leq\frac{1}{2}\left(\left\|x_{i}-x^{\star}\right\|_{2}^{2}-\left\|x_{i+1}-x^{\star}\right\|_{2}^{2}\right)\]</span> 于是有</p><ol type="1"><li><spanclass="math inline">\(\left\|x^{+}-x^{\star}\right\|_{2}^{2}\le (1-mt_i)\left\|x-x^{\star}\right\|_{2}^{2}\le (1-mt_{\min})\left\|x-x^{\star}\right\|_{2}^{2}\)</span>，如果满足强凸性质的话，也即<span class="math inline">\(m&gt;0\)</span>，就有 <spanclass="math inline">\(\left\|x^{+}-x^{\star}\right\|_{2}^{2}\lec^k\left\|x-x^{\star}\right\|_{2}^{2},c=1-mt_{\min}=\max \{1-\betam/L,1-m\hat{t}\}\)</span>；</li><li><span class="math inline">\(\sum_i^k t_i(f(x_i)-f^\star) \le\frac{1}{2}\left\|x^{+}-x^{\star}\right\|_{2}^{2}\)</span>，由于 <spanclass="math inline">\(f(x_i)\)</span> 不增，因此 <spanclass="math inline">\(f(x_k)-f^\star \le\frac{1}{2kt_{\min}}\left\|x^{+}-x^{\star}\right\|_{2}^{2}\)</span>，因此收敛速度也是<span class="math inline">\(O(1/k)\)</span>。</li></ol>]]></content>
    
    
    <categories>
      
      <category>Convex Optimization</category>
      
    </categories>
    
    
    <tags>
      
      <tag>PG 算法</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>凸优化笔记18：近似点算子 Proximal Mapping</title>
    <link href="/2020/04/16/optimization/ch18-proximal-mapping/"/>
    <url>/2020/04/16/optimization/ch18-proximal-mapping/</url>
    
    <content type="html"><![CDATA[<p>前面讲了梯度下降法，分析了其收敛速度，对于存在不可导的函数介绍了次梯度的计算方法以及次梯度下降法，这一节要介绍的内容叫做<strong>近似点算子(Proximalmapping)</strong>，也是为了处理非光滑问题。</p><span id="more"></span><h2 id="闭函数">1. 闭函数</h2><p>在引入<strong>闭函数(closedfunction)</strong>的概念之前，我们先回顾一下<strong>闭集</strong>的概念：集合<span class="math inline">\(\mathcal{C}\)</span>是闭的，如果它包含边界，也即 <span class="math display">\[x^{k} \in \mathcal{C}, \quad x^{k} \rightarrow \bar{x} \quad \Rightarrow\quad \bar{x} \in \mathcal{C}\]</span> 并且有以下几个简单的原则可以保持集合闭的性质：</p><ol type="1"><li>闭集的<strong>交集</strong>还是闭集；</li><li><strong>有限个</strong>闭集的<strong>并集</strong>还是闭集；</li><li>如果 <span class="math inline">\(\mathcal{C}\)</span>是闭集，则<strong>线性映射</strong>的<strong>原象</strong>也是闭集，也即<span class="math inline">\(\{x|Ax\in\mathcal{C}\}\)</span>是闭集。</li></ol><p>第 3 条原则反过来则不一定成立，也即如果 <spanclass="math inline">\(x\in\mathcal{C}\)</span> 是闭集，那么 <spanclass="math inline">\(\{Ax|x\in\mathcal{C}\}\)</span>则不一定是闭集，比如我们可以取函数 <spanclass="math inline">\(f(x)=1/x\)</span> 的 epigraph 为闭集 <spanclass="math inline">\(\mathcal{C}\)</span>，然而 <spanclass="math inline">\((x,y)\)</span> 向 <spanclass="math inline">\(x\)</span>轴的投影则是一个开集，严格表示与图示如下 <span class="math display">\[\mathcal{C}=\left\{\left(x_{1}, x_{2}\right) \in \mathbb{R}_{+}^{2} |x_{1} x_{2} \geq 1\right\}, \quad A=[1,0], A \mathcal{C}=\mathbb{R}_{++}\]</span></p><table><thead><tr class="header"><th>第3条逆原则反例</th><th>第3条逆原则充分条件</th></tr></thead><tbody><tr class="odd"><td><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2020/18-closed-set.png"alt="counter example" /></td><td><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2020/18-closed-set2.PNG"alt="sufficient condition" /></td></tr></tbody></table><p>当然，如果加一些其他的约束条件，则可以保证第 3 条反过来也成立：<spanclass="math inline">\(A\mathcal{C}\)</span> 是闭的，如果</p><ol type="1"><li><span class="math inline">\(\mathcal{C}\)</span>是闭的且为凸集；</li><li>并且 <span class="math inline">\(\mathcal{C}\)</span>不存在一个可以无穷延伸的方向(recession direction)属于 <spanclass="math inline">\(A\)</span> 的零空间，也即 <spanclass="math inline">\(A y=0, \hat{x} \in \mathcal{C}, \hat{x}+\alpha y\in \mathcal{C}, \forall \alpha&gt;0 \Rightarrowy=0\)</span>，图示即如上。</li></ol><p>然后我们就可以定义<strong>闭函数(closed function)</strong>了，函数<span class="math inline">\(f\)</span> 为闭的，如果他的 epigraph为闭集或者他的所有下水平集为闭集。有以下两种简单的特殊情况：</p><ol type="1"><li>如果 <span class="math inline">\(f\)</span> 连续且定义域 <spanclass="math inline">\(\text{dom}f\)</span> 为闭的，则 <spanclass="math inline">\(f\)</span> 为闭函数；</li><li>如果 <span class="math inline">\(f\)</span> 连续且定义域 <spanclass="math inline">\(\text{dom}f\)</span> 为开的，则 <spanclass="math inline">\(f\)</span> 为闭函数<strong>当且仅当</strong>其在<span class="math inline">\(\text{dom}f\)</span> 边界处收敛至 <spanclass="math inline">\(\infty\)</span>。</li></ol><p><strong><em>例子 1</em></strong>：<spanclass="math inline">\(f(x)=x\logx,\quad\text{dom}f=R_+,f(0)=0\)</span></p><p><strong><em>例子 2</em></strong>：闭集的指示函数 <spanclass="math inline">\(\delta_C(x)=\begin{cases}0&amp;x\in C\\ +\infty&amp; o.w.\end{cases}\)</span></p><p><strong><em>反例 3</em></strong>：<spanclass="math inline">\(f(x)=x\log x,\quad\text{dom}f=R_{++}\)</span> 或者<span class="math inline">\(f(x)=x\logx,\quad\text{dom}f=R_+,f(0)=1\)</span> 不是闭函数</p><p><strong><em>反例 4</em></strong>：开集的指示函数不是闭函数</p><p>闭函数有一些有用的性质，比如：</p><ol type="1"><li><span class="math inline">\(f\)</span>为闭函数<strong>当且仅当</strong>他的所有下水平集都是闭集；</li><li>如果 <span class="math inline">\(f\)</span>为闭函数，且下水平集有界，那么存在<strong>最小值点(minimizer)</strong>。</li></ol><p><strong>Theorem (Weierstrass) </strong>：假设集合 <spanclass="math inline">\(D\subset \mathcal{E}\)</span> (<spanclass="math inline">\(R^n\)</span>空间中有限维向量子空间)非空且闭，并且连续函数 <span class="math inline">\(f:D\to R\)</span>的所有下水平集都有界，则 <span class="math inline">\(f\)</span>存在<strong>全局最小值点(global minimizer)</strong>。</p><p>对于闭函数来说也有一些原则可以保持闭的性质：</p><ol type="1"><li>如果 <span class="math inline">\(f,g\)</span> 均为闭函数，则 <spanclass="math inline">\(f+g\)</span> 为闭函数</li><li>如果 <span class="math inline">\(f\)</span> 为闭函数，则 <spanclass="math inline">\(f(Ax+b)\)</span> 为闭函数</li><li>如果任意 <span class="math inline">\(f_\alpha\)</span>都是闭函数，则 <span class="math inline">\(\sup_\alphaf_\alpha(x)\)</span> 为闭函数</li></ol><h2 id="共轭函数">2. 共轭函数</h2><p><strong>共轭函数(conjugate function)</strong>前面已经讲过了，这里再简单回顾一遍。函数 <spanclass="math inline">\(f\)</span> 的共轭函数定义为 <spanclass="math display">\[f^\star(y)=\sup_{x\in\text{dom}f} (y^Tx-f(x))\]</span></p><blockquote><p>并且共轭函数有一些重要的性质：</p><ol type="1"><li>共轭函数一定是闭函数，且为凸函数，不论 <spanclass="math inline">\(f\)</span> 是否为凸函数或闭函数（因为 <spanclass="math inline">\(f^\star\)</span> 的 epigraph可以看成很多个半空间的交集）；</li><li><strong>(Fenchel’s inequality)</strong> <spanclass="math inline">\(f(x)+f^{\star}(y) \geq x^{\top} y, \forall x,y\)</span></li><li><strong>(Legendre transform)</strong> 如果 <spanclass="math inline">\(f\)</span> 为凸函数且为闭函数，则有 <spanclass="math inline">\(y \in \partial f(x) \Leftrightarrow x \in \partialf^{\star}(y) \Leftrightarrow x^{\top} y=f(x)+f^{\star}(y)\)</span></li><li>如果 <span class="math inline">\(f\)</span> 为凸函数且为闭函数，则<span class="math inline">\(f^{\star\star}=f\)</span></li></ol></blockquote><blockquote><p>除此之外还有一些代数变换的原则，推导也都比较简单：</p><ol type="1"><li><span class="math inline">\(f\left(x_{1},x_{2}\right)=g\left(x_{1}\right)+h\left(x_{2}\right), \quadf^{\star}\left(y_{1},y_{2}\right)=g^{\star}\left(y_{1}\right)+h^{\star}\left(y_{2}\right)\)</span></li><li><span class="math inline">\(f(x)=\alpha g(x), \quad f^{\star}(y) {=}\alpha g^{\star}(y / \alpha) \quad(\bigstar)\)</span></li><li><span class="math inline">\(f(x)=g(x)+a^{\top} x+b \quadf^{\star}(y)=g^{\star}(y-a)-b\)</span></li><li><span class="math inline">\(f(x)=\inf _{u+v=x}(g(u)+h(v)) \quadf^{\star}(y)=g^{\star}(y)+h^{\star}(y)\)</span></li></ol></blockquote><p>共轭函数的计算就不多举例子了，这里主要列出来后面用的比较多的而且比较重要的，其他的可以参考前面的笔记6：</p><p><strong><em>例子 1</em></strong>：<spanclass="math inline">\(C\)</span> 为凸集，则<strong>指示函数</strong><spanclass="math inline">\(f(x)=\delta_C(x)\)</span>，其共轭函数为<strong>支撑函数</strong><span class="math display">\[f^\star(y) = \sup\{y^Tx|x\in C\}\]</span>如果求两次共轭函数也很容易得到：支撑函数的共轭函数为指示函数。</p><p><strong><em>例子 2</em></strong>：范数 <spanclass="math inline">\(f(x)=\Vert x\Vert\)</span>的共轭函数也是<strong>指示函数</strong> <span class="math display">\[f^\star(y) = \left\{\begin{array}{ll}0 &amp; \|y\|_{*} \leq 1 \\\infty &amp; \text { otherwise }\end{array}\right.\]</span></p><h2 id="近似点算子">3. 近似点算子</h2><p>首先给出来<strong>近似点算子(Proximalmapping)</strong>的定义：<strong>闭凸函数</strong> <spanclass="math inline">\(f\)</span> 的近似点算子定义为 <spanclass="math display">\[\operatorname{prox}_{f}(x)=\underset{u}{\operatorname{argmin}}\left(f(u)+\frac{1}{2}\|u-x\|_{2}^{2}\right)\]</span> 根据这个定义，实际上我们是在求解函数 <spanclass="math inline">\(g(u)=f(u)+\frac{1}{2}\|u-x\|_{2}^{2}\)</span>的最小值，由于 <span class="math inline">\(g\)</span>是闭函数且下水平集有界，因此最小值一定<strong>存在</strong>；同时由于<span class="math inline">\(g\)</span>为<strong>强凸函数</strong>，因此最小值点<strong>唯一</strong>。</p><p>那么怎么理解这个算子函数 <spanclass="math inline">\(\text{prox}_f(x)\)</span>呢？可以看到这实际上是一个 <spanclass="math inline">\(\text{prox}_f:R^n\to R^n\)</span> 的映射。如果<span class="math inline">\(u=\text{prox}_f(x)\)</span>，则应该有 <spanclass="math inline">\(x-u\in \partialf(u)\)</span>。下面看一些简单的例子。</p><p><strong><em>例子 1</em></strong>：二次函数 <spanclass="math inline">\(A\succeq 0\)</span> <span class="math display">\[f(x)=\frac{1}{2} x^{T} A x+b^{T} x+c, \quad \operatorname{prox}_{tf}(x)=(I+t A)^{-1}(x-t b)\]</span> <strong><em>例子 2</em></strong>：欧几里得范数 <spanclass="math inline">\(f(x)=\Vert x\Vert_2\)</span> <spanclass="math display">\[\operatorname{prox}_{t f}(x)=\left\{\begin{array}{ll}\left(1-t /\|x\|_{2}\right) x &amp; \|x\|_{2} \geq t \\0 &amp; \text { otherwise }\end{array}\right.\]</span> <strong><em>例子 3</em></strong>：Logarithmic barrier <spanclass="math display">\[f(x)=-\sum_{i=1}^{n} \log x_{i}, \quad \operatorname{prox}_{tf}(x)_{i}=\frac{x_{i}+\sqrt{x_{i}^{2}+4 t}}{2}, \quad i=1, \ldots, n\]</span></p><blockquote><p>上面是比较简单的例子，近似点算子也有一些很容易验证的代数运算规律：</p><ol type="1"><li><span class="math inline">\(f\left(\left[\begin{array}{l} x \\ y\end{array}\right]\right)=g(x)+h(y), \quad\operatorname{prox}_{f}\left(\left[\begin{array}{l} x \\ y\end{array}\right]\right)=\left[\begin{array}{l}\operatorname{prox}_{g}(x) \\ \operatorname{prox}_{h}(y)\end{array}\right]\)</span></li><li><span class="math inline">\(f(x)=g(a x+b), \quad\operatorname{prox}_{f}(x)=\frac{1}{a}\left(\operatorname{prox}_{a^{2}g}(a x+b)-b\right)\)</span> (注意 <spanclass="math inline">\(a\ne0\)</span> 是标量)</li><li><span class="math inline">\(f(x)=\lambda g(x / \lambda), \quad\operatorname{prox}_{f}(x)=\lambda \operatorname{prox}_{\lambda^{-1}g}(x / \lambda) \quad(\bigstar)\)</span></li><li><span class="math inline">\(f(x)=g(x)+a^{T} x, \quad \quad\operatorname{prox}_{f}(x)=\operatorname{prox}_{g}(x-a)\)</span></li><li><span class="math inline">\(f(x)=g(x)+\frac{\mu}{2}\|x-a\|_{2}^{2},\quad \operatorname{prox}_{f}(x)=\operatorname{prox}_{\theta g}(\thetax+(1-\theta) a)\)</span>，其中 <spanclass="math inline">\(\mu&gt;0,\theta=1/(1+\mu)\)</span></li><li><span class="math inline">\(f(x)=g(Ax+b)\)</span>，对于一般的 <spanclass="math inline">\(A\)</span> 并不能得到比较好的性质，但如果 <spanclass="math inline">\(AA^T=(1/\alpha)I\)</span>，则有</li></ol><p><span class="math display">\[\begin{aligned}\operatorname{prox}_{f}(x) &amp;=\left(I-\alpha A^{T}A\right) x+\alpha A^{T}\left(\operatorname{prox}_{\alpha^{-1} g}(Ax+b)-b\right) \\&amp;=x-\alpha A^{T}\left(Ax+b-\operatorname{prox}_{\alpha^{-1} g}(A x+b)\right)\end{aligned}\]</span></p><p>前面几条都比较容易证明，最后一条证明可以等价于求解 <spanclass="math display">\[\begin{aligned}\text { minimize } \quad&amp;g(y)+\frac{1}{2}\|u-x\|_{2}^{2}\\\text { subject to } \quad&amp; Au+b=y\end{aligned}\]</span> 可以先求解 <span class="math inline">\(x\)</span> 向超平面<span class="math inline">\(Au+b=y\)</span> 投影来消去 <spanclass="math inline">\(u\)</span>，然后再计算 <spanclass="math inline">\(\text{prox}_f(y)\)</span>。</p></blockquote><p>除此之外，有一个非常重要的等式：</p><blockquote><p><strong>Moreau decomposition</strong>： <span class="math display">\[x=\operatorname{prox}_{f}(x)+\operatorname{prox}_{f^{*}}(x) \quad\text {for all } x\]</span></p></blockquote><p><strong>Remarks</strong>：为什么说这个式子重要呢？因为他把原函数和共轭函数的proximal mapping联系起来了，如果其中一个比较难计算，那么我们可以通过另一个来计算。这个式子可以怎么理解呢？可以看成是一种正交分解，举个栗子，如果我们取一个子空间<span class="math inline">\(L\)</span>，他的正交空间为 <spanclass="math inline">\(L^\perp\)</span>，令函数 <spanclass="math inline">\(f\)</span> 为子空间 <spanclass="math inline">\(L\)</span> 的指示函数也即 <spanclass="math inline">\(f=\delta_L\)</span>，那么很容易验证共轭函数 <spanclass="math inline">\(f^\star=\delta_{L^\perp}\)</span>。而根据定义也可以得到<span class="math inline">\(\text{prox}_f(x)\)</span> 恰好就是 <spanclass="math inline">\(x\)</span> 在子空间 <spanclass="math inline">\(L\)</span> 上的投影，记为 <spanclass="math inline">\(P_L(x)=\text{prox}_f(x)\)</span>，同样的 <spanclass="math inline">\(P_{L^\perp}(x)=\text{prox}_{f^\star}(x)\)</span>，因此上面的Moreau decomposition 就可以写为 <spanclass="math inline">\(x=P_L(x)+P_{L^\perp}(x)\)</span>，这正好就是一个正交分解。可以根据下图理解</p><figure><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2020/18-moreau.PNG"alt="moreau decomposition" /><figcaption aria-hidden="true">moreau decomposition</figcaption></figure><p>如果对原始的 Moreau decomposition 做简单的代数变换，就可以得到 <spanclass="math inline">\(\lambda&gt;0\)</span> <spanclass="math display">\[x=\operatorname{prox}_{\lambda f}(x)+\lambda\operatorname{prox}_{\lambda^{-1} f^{*}}(x / \lambda) \quad \text { forall } x\]</span> 证明过程用到了共轭函数的性质 <spanclass="math inline">\((\lambda f)^{\star}(y)=\lambda f^{\star}(y /\lambda)\)</span>。</p><p>后面两个小节则主要是近似点算子的应用，一个是计算投影，另一个是与支撑函数、距离相关的内容。</p><h2 id="投影">4. 投影</h2><p>为什么突然讲到投影呢？因为对指示函数应用近似点算子，实质上就是在计算投影。举个栗子就明白了：对于集合<span class="math inline">\(C\)</span> 与集合外一点 <spanclass="math inline">\(x\)</span>，<span class="math inline">\(x\)</span>向集合 <span class="math inline">\(C\)</span> 的投影可以表示为 <spanclass="math display">\[\begin{aligned}\text { minimize } \quad&amp;\frac{1}{2}\|y-x\|_{2}^{2}\\\text { subject to } \quad&amp; y\inC\end{aligned}\]</span> 若投影点为 <spanclass="math inline">\(y^\star\)</span>，则这可以等价表示为 <spanclass="math display">\[\begin{aligned}y^\star &amp;= \arg\min_y\frac{1}{2}\|y-x\|_{2}^{2}+\delta_C(y) \\&amp;=\text{prox}_{\delta}(x)\end{aligned}\]</span> 因此 <spanclass="math inline">\(\text{prox}_{\delta}(x)\)</span> 就是 <spanclass="math inline">\(x\)</span> 向集合 <spanclass="math inline">\(C\)</span> 的投影点(对于 <spanclass="math inline">\(x\in C\)</span> 同样成立)。那么只要我们取不同的<spanclass="math inline">\(C\)</span>，就能得到各种类型集合的投影表达式，下面举一些例子。</p><p><strong>超平面</strong>：<spanclass="math inline">\(C=\{x|a^Tx=b\}\)</span> with <spanclass="math inline">\(a\ne0\)</span> <span class="math display">\[P_{C}(x)=x+\frac{b-a^{T} x}{\|a\|_{2}^{2}} a\]</span> <strong>仿射集</strong>：<span class="math inline">\(C=\{x | Ax=b\}\left(\text { with } A \in \mathbf{R}^{p \times n} \text { and }\operatorname{rank}(A)=p\right)\)</span> <span class="math display">\[P_{C}(x)=x+A^{T}\left(A A^{T}\right)^{-1}(b-A x)\]</span> <strong>半空间</strong>：<spanclass="math inline">\(C=\{x|a^Tx\le b\}\)</span> with <spanclass="math inline">\(a\ne0\)</span> <span class="math display">\[P_{C}(x)=\begin{cases}x+\frac{b-a^{T} x}{\|a\|_{2}^{2}} a &amp; \text{if } a^{T} x&gt;b \\ x &amp; \text {if } a^{T} x \leq b\end{cases}\]</span> <strong>矩形</strong>：<span class="math inline">\(C=[l,u]=\left\{x \in \mathbf{R}^{n} | l \leq x \leq u\right\}\)</span> <spanclass="math display">\[P_{C}(x)_{k}=\left\{\begin{array}{ll}l_{k} &amp; x_{k} \leq l_{k}\\x_{k} &amp; l_{k} \leq x_{k} \leq u_{k} \\u_{k} &amp; x_{k} \gequ_{k}\end{array}\right.\]</span> <strong>非负象限</strong>：<spanclass="math inline">\(C=R_+^n\)</span> <span class="math display">\[P_{C}(x)=x_{+}=\left(\max \left\{0, x_{1}\right\}, \max \left\{0,x_{2}\right\}, \ldots, \max \left\{0, x_{n}\right\}\right)\]</span> <strong>概率单形</strong>：<spanclass="math inline">\(C=\left\{x | \mathbf{1}^{T} x=1, x \geq0\right\}\)</span> <span class="math display">\[P_{C}(x)=(x-\lambda \mathbf{1})_{+}\]</span> 其中 <span class="math inline">\(\lambda\)</span>由以下方程解出 <span class="math display">\[\mathbf{1}^{T}(x-\lambda \mathbf{1})_{+}=\sum_{i=1}^{n} \max \left\{0,x_{k}-\lambda\right\}=1\]</span> 这个的证明有一点难度，关键是首先要把约束条件 <spanclass="math inline">\(x\ge0\)</span> 转换为指示函数表示 <spanclass="math display">\[\begin{aligned}\text { minimize } \quad&amp; \frac{1}{2}\|y-x\|_{2}^{2}+ \delta_{R_+^n}(y) \\\text { subject to } \quad&amp; \mathbf{1}^{T}y=1\end{aligned}\]</span> 然后将拉格朗日函数分解成求和的形式 <spanclass="math display">\[\begin{array}{l}\frac{1}{2}\|y-x\|_{2}^{2}+\delta_{\mathbf{R}_{+}^{n}}(y)+\lambda\left(\mathbf{1}^{T}y-1\right) \\\quad=\quad\sum_{k=1}^{n}\left(\frac{1}{2}\left(y_{k}-x_{k}\right)^{2}+\delta_{\mathbf{R}_{+}}\left(y_{k}\right)+\lambday_{k}\right)-\lambda\end{array}\]</span>对上面这个求和项进行分情况讨论就能得到解析表达式了，不过真的很繁琐。</p><p><strong>超平面与矩形交集</strong>：<spanclass="math inline">\(C=\{x|a^Tx=b,l\preceq x\preceq u\}\)</span> <spanclass="math display">\[P_{C}(x)=P_{[l,u]}(x-\lambda a)\]</span> 其中 <span class="math inline">\(\lambda\)</span>由以下方程解出 <span class="math display">\[a^{T} P_{[l, u]}(x-\lambda a)=b\]</span>证明跟上面的概率单形是类似的，也需要拆写成多项求和的形式分别求解。</p><p><strong>欧几里得球</strong>：<span class="math inline">\(C=\{x| \Vertx\Vert_2\le1\}\)</span> <span class="math display">\[P_{C}(x)=\begin{cases}\frac{x}{\|x\|_{2}} &amp; \text {if } \Vertx\Vert_2&gt;1 \\ x &amp; \text {if } \Vert x\Vert_2\le1\end{cases}\]</span> <strong>1 范数球</strong>：<span class="math inline">\(C=\{x|\Vert x\Vert_1\le1\}\)</span></p><p>若 <span class="math inline">\(\Vert x\Vert_1\le1\)</span> 则 <spanclass="math inline">\(P_C(x)=x\)</span>；否则 <spanclass="math display">\[P_{C}(x)_{k}=\operatorname{sign}\left(x_{k}\right) \max\left\{\left|x_{k}\right|-\lambda,0\right\}=\left\{\begin{array}{ll}x_{k}-\lambda &amp; x_{k}&gt;\lambda\\0 &amp; -\lambda \leq x_{k} \leq \lambda \\x_{k}+\lambda &amp;x_{k}&lt;-\lambda\end{array}\right.\]</span> 其中 <span class="math inline">\(\lambda\)</span>由以下等式获得 <span class="math display">\[\sum_{k=1}^n \max \{\vert x\vert_k-\lambda, 0\}=1\]</span>证明业与前面的类似，需要写成求和项的形式，然后对每一项求解。</p><p><strong>二阶锥</strong>：<span class="math inline">\(C=\{(x,t)\inR^{n\times 1}| \Vert x\Vert_2 \le t \}\)</span> <spanclass="math display">\[P_{C}(x,t)=\begin{cases}(x,t) &amp; \text {if } \Vert x\Vert_2\le t \\(0,0) &amp; \text {if } \Vert x\Vert_2\le -t\\\frac{t+\|x\|_{2}}{2\|x\|_{2}}\left[\begin{array}{c} x \\ \|x\|_{2}\end{array}\right] &amp; \text {if } \Vert x\Vert_2&gt; \vert t\vert\end{cases}\]</span> <strong>正定锥</strong>：<spanclass="math inline">\(C=S^n_+\)</span> <span class="math display">\[P_{C}(X)=\sum_{i=1}^{n} \max \left\{0, \lambda_{i}\right\} q_{i}q_{i}^{T}\]</span> 其中 <span class="math inline">\(X=\sum_i \lambda_iq_iq_i^T\)</span></p><h2 id="支撑函数范数与距离">5. 支撑函数、范数与距离</h2><p>这一小节标题看起来很复杂，牵涉到了支撑函数、范数、到集合的距离，但<strong>实际上都还是在计算投影</strong>，为什么这么说呢？回忆一下，支撑函数的共轭函数是不是<span class="math inline">\(\delta\)</span> 函数？范数的共轭函数是不是<span class="math inline">\(\delta\)</span>函数？到集合的距离是不是就等于到投影点的距离？所以这一小节是上一小节“投影”的自然延伸，其中为了把原函数与共轭函数联系在一起，用到了Moreau decomposition。我们一个一个来看。 <span class="math display">\[x=\operatorname{prox}_{f}(x)+\operatorname{prox}_{f^{*}}(x) \quad\text {for all } x\]</span> <strong>支撑函数</strong>：<spanclass="math inline">\(f(x)=\sup_{y\inC}x^Ty,f^\star(y)=\delta_C(y)\)</span>，因此近似点算子为 <spanclass="math display">\[\begin{aligned}\operatorname{prox}_{t f}(x) &amp;=x-t\operatorname{prox}_{t^{-1} f^{*}}(x / t) \\&amp;=x-t P_{C}(x /t)\end{aligned}\]</span> <strong>范数</strong>：<span class="math inline">\(f(x)=\Vertx\Vert,f^\star(y)=\delta_B(y)\)</span>，其中 <spanclass="math inline">\(B=\{y| \Vert y\Vert_\star \le1\}\)</span>，近似点算子为 <span class="math display">\[\begin{aligned}\operatorname{prox}_{t f}(x) &amp;=x-t\operatorname{prox}_{t^{-1} f^{*}}(x / t) \\&amp;=x-t P_{B}(x / t)\\&amp;=x- P_{tB}(x)\end{aligned}\]</span> 其中 <span class="math inline">\(tB=\{y| \Vert y\Vert_\star\le t\}\)</span></p><p><strong>与一点的距离</strong>：<span class="math inline">\(f(x)=\Vertx-a\Vert\)</span>，可以取 <span class="math inline">\(g(x)=\Vertx\Vert\)</span> <span class="math display">\[\begin{aligned}\operatorname{prox}_{t f}(x) &amp;=a +\operatorname{prox}_{tg}(x-a) \\&amp;=a+x-a-tP_B(\frac{x-a}{t})\\&amp;=x- P_{tB}(x-a)\end{aligned}\]</span> <strong>到集合的距离</strong>：到闭凸集 <spanclass="math inline">\(C\)</span> 的距离定义为 <spanclass="math inline">\(d(x)=\inf_{y\in C}\Vert x-y\Vert_2\)</span> <spanclass="math display">\[\operatorname{prox}_{td}(x)=\left\{\begin{array}{ll}x+\frac{t}{d(x)}\left(P_{C}(x)-x\right)&amp; d(x) \geq t \\P_{C}(x) &amp; \text { otherwise }\end{array}\right.\]</span> 如果是距离取平方 <spanclass="math inline">\(f(x)=d(x)^2/2\)</span>，则有 <spanclass="math display">\[\operatorname{prox}_{t f}(x)=\frac{1}{1+t} x+\frac{t}{1+t} P_{C}(x)\]</span> 这个证明贴在下面</p><figure><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2020/18-distance-proof1.PNG"alt="proof 1" /><figcaption aria-hidden="true">proof 1</figcaption></figure><figure><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2020/18-distance-proof2.PNG"alt="proof 2" /><figcaption aria-hidden="true">proof 2</figcaption></figure>]]></content>
    
    
    <categories>
      
      <category>Convex Optimization</category>
      
    </categories>
    
    
    <tags>
      
      <tag>近似点算子</tag>
      
      <tag>共轭函数</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>凸优化笔记17：次梯度下降</title>
    <link href="/2020/04/10/optimization/ch17-subgradient-descent/"/>
    <url>/2020/04/10/optimization/ch17-subgradient-descent/</url>
    
    <content type="html"><![CDATA[<p>对于光滑函数，我们可以用梯度下降法，并且证明了取不同的步长，可以得到次线性收敛，如果加上强凸性质，还可以得到线性收敛速度。那如果现在对于不可导的函数，我们就只能沿着次梯度下降，同样会面临步长的选择、方向的选择、收敛性分析等问题。</p><span id="more"></span><h2 id="收敛性分析">1. 收敛性分析</h2><p>次梯度下降的一般形式为 <span class="math display">\[x^{(k)}=x^{(k-1)}-t_{k} g^{(k-1)}, \quad k=1,2, \ldots \quadg\in\partial f(x^{(k-1)})\]</span> 一般有 3 种步长的选择方式：</p><ol type="1"><li>fix step： <span class="math inline">\(t_k\)</span> 为常数</li><li>fix length：<spanclass="math inline">\(t_{k}\left\|g^{(k-1)}\right\|_{2}=\left\|x^{(k)}-x^{(k-1)}\right\|_{2}\)</span>为常数</li><li>diminishing：<span class="math inline">\(t_{k} \rightarrow 0,\sum_{k=1}^{\infty} t_{k}=\infty\)</span></li></ol><p>要证明这几种方法的收敛性，需要先引入 Lipschitz continuous 假设，即<span class="math display">\[|f(x)-f(y)| \leq G\|x-y\|_{2} \quad \forall x, y\]</span> 这等价于 <span class="math inline">\(\Vert g\Vert_2\leG\)</span> 对任意 <span class="math inline">\(g\in\partial f(x)\)</span>都成立。</p><p>在分析收敛性之前，我们需要引入一个<strong>非常重要的式子</strong>:arrow_down:！！！在后面的分析中会一直用到：<span class="math display">\[\begin{aligned}\left\|x^{+}-x^{\star}\right\|_{2}^{2} &amp;=\left\|x-tg-x^{\star}\right\|_{2}^{2} \\&amp;=\left\|x-x^{\star}\right\|_{2}^{2}-2 tg^{T}\left(x-x^{\star}\right)+t^{2}\|g\|_{2}^{2} \\&amp; \leq\left\|x-x^{\star}\right\|_{2}^{2}-2t\left(f(x)-f^{\star}\right)+t^{2}\|g\|_{2}^{2}\end{aligned}\]</span> 那么如果定义 <spanclass="math inline">\(f_{\mathrm{best}}^{(k)}=\min _{0 \leq i&lt;k}f\left(x^{(i)}\right)\)</span>，就有 <span class="math display">\[\begin{aligned}2\left(\sum_{i=1}^{k} t_{i}\right)\left(f_{\text {best}}^{(k)}-f^{\star}\right) &amp;\leq\left\|x^{(0)}-x^{\star}\right\|_{2}^{2}-\left\|x^{(k)}-x^{\star}\right\|_{2}^{2}+\sum_{i=1}^{k}t_{i}^{2}\left\|g^{(i-1)}\right\|_{2}^{2} \\&amp; \leq\left\|x^{(0)}-x^{\star}\right\|_{2}^{2}+\sum_{i=1}^{k}t_{i}^{2}\left\|g^{(i-1)}\right\|_{2}^{2}\end{aligned}\]</span> 根据上面的式子，就可以得到对于</p><p><strong>Fixed step size</strong>：<spanclass="math inline">\(t_i=t\)</span> <span class="math display">\[f_{\text {best }}^{(k)}-f^{\star} \leq\frac{\left\|x^{(0)}-x^{\star}\right\|_{2}^{2}}{2 k t}+\frac{G^{2} t}{2}\]</span> <strong>Fixed step length</strong>：<spanclass="math inline">\(t_{i}=s /\left\|g^{(i-1)}\right\|_{2}\)</span><span class="math display">\[f_{\text {best }}^{(k)}-f^{\star} \leq\frac{G\left\|x^{(0)}-x^{\star}\right\|_{2}^{2}}{2 k s}+\frac{G s}{2}\]</span> 这两个式子中的第一项都随着 <spanclass="math inline">\(k\)</span> 增大而趋于0，但第二项却没有办法消掉，也就是与最优解的误差不会趋于0。并且他们有一个微妙的不同点在于，fixed step size 情况下 <spanclass="math inline">\(G^2t/2\sim O(G^2),Gs/2\sim O(G)\)</span>，<spanclass="math inline">\(G\)</span> 一般是较大的。</p><p><strong>Diminishing step size</strong>：<spanclass="math inline">\(t_{k} \rightarrow 0, \sum_{k=1}^{\infty}t_{k}=\infty\)</span> <span class="math display">\[f_{\text {best }}^{(k)}-f^{\star} \leq\frac{\left\|x^{(0)}-x^{\star}\right\|_{2}^{2}+G^{2} \sum_{i=1}^{k}t_{i}^{2}}{2 \sum_{i=1}^{k} t_{i}}\]</span> 可以证明，<span class="math inline">\(\left(\sum_{i=1}^{k}t_{i}^{2}\right) /\left(\sum_{i=1}^{k} t_{i}\right) \rightarrow0\)</span>，因此 <span class="math inline">\(f_{\text {best}}^{(k)}\)</span> 会收敛于 <spanclass="math inline">\(f^\star\)</span>。</p><p>下面看几幅图片，对于优化问题 <span class="math inline">\(\min\VertAx-b\Vert_1\)</span></p><table><thead><tr class="header"><th>Fixed step length</th><th>Diminishing step size</th></tr></thead><tbody><tr class="odd"><td><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2020/17-fixed-step.PNG"alt="fixed-step" /></td><td><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2020/17-diminishing.PNG"alt="diminishing" /></td></tr></tbody></table><p>前面考虑了固定步长的情况，假设现在我们固定总的迭代次数为 <spanclass="math inline">\(k\)</span>，可不可以优化步长 <spanclass="math inline">\(s\)</span> 的大小来尽可能使 <spanclass="math inline">\(f_\text{best}^{(k)}\)</span> 接近 <spanclass="math inline">\(f^\star\)</span> 呢？这实际上可以表示为优化问题<span class="math display">\[f_{\text {best }}^{(k)}-f^{\star} \leq \frac{R^{2}+\sum_{i=1}^{k}s_{i}^{2}}{2 \sum_{i=1}^{k} s_{i}/G} \Longrightarrow \min_s\frac{R^{2}}{2 ks/G}+\frac{s}{2/G}\]</span> 其中 <spanclass="math inline">\(R=\left\|x^{(0)}-x^{\star}\right\|_{2}\)</span>，那么最优步长为<span class="math inline">\(s=R/\sqrt{k}\)</span>，此时 <spanclass="math display">\[f_{\text {best }}^{(k)}-f^{\star} \leq \frac{GR}{\sqrt{k}}\]</span> 因此收敛速度为 <spanclass="math inline">\(O(1/\sqrt{k})\)</span>，对比之前光滑函数的梯度下降，收敛速度为<span class="math inline">\(O(1/k)\)</span>。</p><p>我们对前面的收敛速度并不满意，如果有更多的信息，比如已知最优解 <spanclass="math inline">\(f^\star\)</span>的大小，能不能改进收敛速度呢？根据前面的式子，有 <spanclass="math display">\[\left\|x^{+}-x^{\star}\right\|_{2}^{2}  \leq\left\|x-x^{\star}\right\|_{2}^{2}-2t_i\left(f(x)-f^{\star}\right)+t_i^{2}\|g\|_{2}^{2}\]</span> 这实际上是关于 <span class="math inline">\(t_i\)</span>的一个二次函数，因此可以取 <spanclass="math inline">\(t_{i}=\frac{f\left(x^{(i-1)}\right)-f^{\star}}{\left\|g^{(i-1)}\right\|_{2}^{2}}\)</span>，就可以得到<span class="math display">\[f_{\text {best }}^{(k)}-f^{\star} \leq \frac{GR}{\sqrt{k}}\]</span> 可见还是没有改进收敛速度。</p><p>如果引入<strong>强凸性质</strong>呢？如果假设满足 <spanclass="math inline">\(\mu\)</span> 强凸，则 <spanclass="math inline">\(f^\star \ge f^k+g^{kT}(x^k-x^\star)+\mu/2\Vertx^k-x^\star\Vert_2^2\)</span>，可以取 <spanclass="math inline">\(t_k=\frac{2}{\mu(k+1)}\)</span>，那么就可以得到<span class="math display">\[f_{\text {best }}^{(k)}-f^{\star} \leq \frac{2G^2}{\mu(k+1)}\]</span></p>]]></content>
    
    
    <categories>
      
      <category>Convex Optimization</category>
      
    </categories>
    
    
    <tags>
      
      <tag>梯度下降</tag>
      
      <tag>次梯度</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>凸优化笔记16：次梯度 Subgradient</title>
    <link href="/2020/04/10/optimization/ch16-subgradient/"/>
    <url>/2020/04/10/optimization/ch16-subgradient/</url>
    
    <content type="html"><![CDATA[<p>前面讲了梯度下降的方法，关键在于步长的选择：固定步长、线搜索、BB方法等，但是如果优化函数本身存在不可导的点，就没有办法计算梯度了，这个时候就需要引入<strong>次梯度(Subgradient)</strong>，这一节主要关注次梯度的计算。</p><span id="more"></span><h2 id="次梯度">1. 次梯度</h2><p><strong>次梯度(subgradient)</strong>的定义为 <spanclass="math display">\[\partial f(x)= \{g|f(y)\ge f(x)+g^T(y-x),\forall y\in\text{dom} f \}\]</span> 该如何理解次梯度 <span class="math inline">\(g\)</span>呢？实际上经过变换，我们可以得到 <span class="math display">\[\left[\begin{array}{c}g \\-1\end{array}\right]^{\top}\left(\left[\begin{array}{l}y \\t\end{array}\right]-\left[\begin{array}{c}x \\f(x)\end{array}\right]\right) \leq 0, \forall(y, t) \in \operatorname{epi}f\]</span> 实际上这里 <span class="math inline">\([g^T \ -1]^{T}\)</span>定义了 <strong>epigraph的一个支撑超平面</strong>，并且这个支撑超平面是<strong>非垂直的</strong>，如下面的图所示</p><table><thead><tr class="header"><th>光滑函数</th><th>非光滑函数</th></tr></thead><tbody><tr class="odd"><td><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2020/16-subgradient.PNG"alt="subgradient" /></td><td><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2020/16-subgradient2.PNG"alt="subgradient2" /></td></tr></tbody></table><p>而对于任意的下水平集 <span class="math inline">\(\{y|f(y)\lef(x)\}\)</span>，都有 <span class="math display">\[f(y)\le f(x) \Longrightarrow g^T(y-x)\le0\]</span> 这说明次梯度 <span class="math inline">\(g\)</span>实际上也是下水平集的一个支撑超平面</p><figure><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2020/16-subgradient3.PNG"alt="subgradient3" /><figcaption aria-hidden="true">subgradient3</figcaption></figure><p><strong>Remarks</strong>：很有意思的一件事是函数的<strong>梯度 <spanclass="math inline">\(\nabla f\)</span></strong>包含有大量的信息，他的<strong>方向</strong>代表了函数下降最快的方向，也就是下水平集的法线方向；而他的<strong>模长</strong>代表了下降的速度，<spanclass="math inline">\([\nabla f\ -1]^T\)</span> 是 epigraph的法线方向，可以直观想象，如果 <span class="math inline">\(\Vert \nablaf\Vert\)</span> 越大，那么这个法线方向越趋向于水平，也就是说 epigraph的标面越趋近于竖直，函数下降速度当然也越快。</p><p>每个点的次梯度 <span class="math inline">\(\partial f(x)\)</span>实际上是一个<strong>集合</strong>，我们先来看这个集合有什么性质呢？我们先列出来然后一一解释：</p><ol type="1"><li>次梯度映射是单调算子</li><li>如果 <span class="math inline">\(x\in\text{ri dom}f\)</span>，则<span class="math inline">\(\partial f(x)\ne\varnothing\)</span>，而且是<strong>有界、闭的凸集</strong></li><li><span class="math inline">\(x^\star= \arg\min f(x) \iff 0\in\partial f(x^\star)\)</span></li></ol><p>首先，他是一个 set-valuedmapping，而且是一个<strong>单调算子</strong>，也即 <spanclass="math display">\[(u-v)^T(y-x)\ge0,\forall u\in\partial f(y),v\in\partial f(x)\]</span> 这个性质很容易由定义导出。</p><p>其次，内点处的次梯度总是非空的闭凸集，且有界。</p><p>首先可以证明其<strong>非空</strong>，(默认我们考虑的 <spanclass="math inline">\(f\)</span> 为凸函数)因为函数 <spanclass="math inline">\(f\)</span> 是凸的，其 epigraph 在 <spanclass="math inline">\((x,f(x))\)</span> 一定存在一个支撑超平面 <spanclass="math display">\[\exists(a, b) \neq 0, \quad\left[\begin{array}{l}a \\b\end{array}\right]^{T}\left(\left[\begin{array}{l}y \\t\end{array}\right]-\left[\begin{array}{c}x \\f(x)\end{array}\right]\right) \leq 0 \quad \forall(y, t) \in \text { epi } f\]</span> 由于 <span class="math inline">\(t\)</span> 可以趋于 <spanclass="math inline">\(+\infty\)</span>，因此 <spanclass="math inline">\(b\le0\)</span>，如果 <spanclass="math inline">\(b=0\)</span>，由于 <spanclass="math inline">\(x\)</span> 为内点，也很容易导出矛盾，因此可以证明<span class="math inline">\(b&lt;0\)</span>，于是就可以得到 <spanclass="math inline">\(g=a/|b|\)</span>。</p><p>其次可以证明其为<strong>闭凸集</strong>，次梯度还可以表示为 <spanclass="math display">\[\begin{aligned}\partial f(x)&amp;= \{g|f(y)\ge f(x)+g^T(y-x),\forall y\in\text{dom} f\} \\&amp;= \bigcap_{y\in \text{dom}f} \{g|g^T(y-x)\le f(y)-f(x) \}\end{aligned}\]</span> 这是很多个半空间的交集，因此 <spanclass="math inline">\(\partial f(x)\)</span> 是一个闭的凸集。</p><p>最后可以证明次梯度集合是<strong>有界的</strong>，为了证明他有界，只需证明他的<span class="math inline">\(l_\infty\)</span> 范数有界即可。可以取 <spanclass="math display">\[B=\left\{x \pm r e_{k} | k=1, \ldots, n\right\} \subset\operatorname{dom} f\]</span> 定义 <span class="math inline">\(M=\max _{y \in B}f(y)&lt;\infty\)</span>，应用次梯度的定义就可以得到 <spanclass="math display">\[\|g\|_{\infty} \leq \frac{M-f(x)}{r} \quad \text { for all } g \in\partial f(x)\]</span> 注意上面的非空、有界、闭凸集都要求 <spanclass="math inline">\(x\)</span>为定义域的内点，如果是边界上则无法保证。</p><p><strong><em>例子 1</em></strong>：对于凸集 <spanclass="math inline">\(C\)</span>，定义函数 <spanclass="math inline">\(\delta_C(x)=\begin{cases}0,&amp;x\inC\\+\infty,&amp;x\notin C\end{cases}\)</span>，那么次梯度为 <spanclass="math display">\[\begin{aligned}g\in\partial \delta_C(x) &amp;\iff \delta_C(y)\ge\delta_C(x)+g^T(y-x),\forall y\in C \\&amp;\iff g^T(y-x)\le0, \forall y\in C \\&amp;\iff g\in N_C(x) \quad \text{ (normal cone at $x$)}\end{aligned}\]</span> <strong>Remarks</strong>：集合 <spanclass="math inline">\(C\)</span> 的 normal cone 的定义为 <spanclass="math display">\[\forall x\in C,\quad N_C(x)=\{g| g^T(y-x)\le0,\forall y\in C\}\]</span> <strong><em>例子 2</em></strong>：函数 <spanclass="math inline">\(f(x)=\vert x\vert,\partialf(x)=\begin{cases}1,&amp;x&gt;0\\ [-1,1],&amp;x=0\\-1&amp;x&lt;0\end{cases}\)</span></p><p><strong><em>例子 3</em></strong>：函数 <spanclass="math inline">\(f(x)=\Vert x\Vert_2,\partial f(0)=\{g|\Vertg\Vert_2\le1\}\)</span></p><p><strong><em>例子 4</em></strong>：对于任意范数 <spanclass="math inline">\(f(x)=\Vert x\Vert\)</span> <spanclass="math display">\[\partial f(x)=\{y|\Vert y\Vert_*\le1,\left&lt;y,x\right&gt;=\Vert x\Vert\}\]</span> 证明：<span class="math inline">\(\forall g\in\partialf(x)\)</span>，需要 <span class="math inline">\(\Vert y\Vert \ge \Vertx\Vert+ g^T(y-x)\quad(\Delta)\)</span></p><p>可以取 <span class="math inline">\(y=2x \Longrightarrow \Vert x\Vert\ge g^Tx\)</span>，也可以取 <spanclass="math inline">\(y=0\Longrightarrow 0\ge \Vertx\Vert-g^Tx\)</span>，因此有 <span class="math inline">\(g^Tx=\Vertx\Vert\)</span></p><p>由 <span class="math inline">\((\Delta)\)</span> 式可知应有 <spanclass="math inline">\(\Vert y\Vert \ge g^Ty \iff \Vertg\Vert_*\le1\)</span>。</p><h2 id="次梯度计算">2. 次梯度计算</h2><p>每个点的次梯度是一个集合，这里有两个概念</p><p><strong>Weak subgradientcalculus</strong>：只需要计算其中一个次梯度就够了；</p><p><strong>Strong subgradient calculus</strong>：要计算出 <spanclass="math inline">\(\partial f(x)\)</span> 中的所有元素。</p><p>要想计算出所有的次梯度是很难的，所以大多数时候只需要得到一个次梯度就够了，也就是Weak subgradientcalculus。不过，对于下面这几种特殊情况，我们可以得到完整的次梯度描述(也即Strong subgradient calculus)，他们是：</p><ol type="1"><li>如果 <span class="math inline">\(f\)</span> 在 <spanclass="math inline">\(x\)</span> 是可微的，那么 <spanclass="math inline">\(\partial f(x)=\{\nabla f(x)\}\)</span></li><li>非负线性组合：<span class="math inline">\(f(x)=\alpha_1f_1(x)+\alpha_2 f_2(x)\)</span>，那么 <spanclass="math inline">\(\partial f(x)=\alpha_1 \partial f_1(x)+\alpha_2\partial f_2(x)\)</span>，第二个式子是集合的加法；</li><li>仿射变换：<span class="math inline">\(f(x)=h(Ax+b)\)</span>，那么<span class="math inline">\(\partial f(x)=A^T h(Ax+b)\)</span></li></ol><p>对于第一条的证明，我们可以取 <spanclass="math inline">\(y=x+r(p-\nabla f(x)),p\in\partialf(x)\)</span>，那么根据次梯度的定义就有 <spanclass="math inline">\(\Vert p-\nabla f(x)\Vert^2\le\frac{O(r^2)}{r}\to0\)</span> 随着 <spanclass="math inline">\(r\to0\)</span>，因此就有 <spanclass="math inline">\(\nabla f(x)=p\)</span>。</p><p>对于第三条的证明，只需要分别证明 <span class="math inline">\(A^Th(Ax+b) \subseteq \partial f(x)\)</span> 和 <spanclass="math inline">\(\partial f(x) \subseteq A^Th(Ax+b)\)</span>，前者很容易，主要是后者。由于次梯度 <spanclass="math inline">\(d\in \partial f(x)\)</span> 需要满足 <spanclass="math inline">\(f(z)\ge f(x)+d^T(z-x) \iff h(Az+b)-d^Tz\geh(Ax+b)-d^Tx\)</span>，也就是说 <spanclass="math inline">\((x,Ax+b)\)</span> 实际上是如下问题的最优解 <spanclass="math display">\[\begin{aligned}\min \quad&amp; h(z)-d^Ty \\\text{s.t.}\quad&amp; Ay+b = z,\quad z\in\text{dom}h\end{aligned}\]</span> 如果 <span class="math inline">\((Range(A)+b)\cap \text{ridom}h \ne \varnothing\)</span>，说明 SCQ成立，则强对偶性成立，于是根据拉格朗日对偶原理有 <spanclass="math display">\[\exists \lambda,\text{ s.t. }(x,Ax+b) \in \arg\min\{h(z)-d^Ty+\lambda^T(Ay+b-z)\} \\\Longrightarrow\begin{cases}\nabla_y L(y,z,\lambda)=0 \Longrightarrow 0\in \partial h(z)-\lambda \\\nabla_z L(y,z,\lambda)=0 \Longrightarrow d=A^T\lambda\end{cases}\]</span> <strong>推论</strong>：根据第 3 条，可以得到：如果考虑函数<span class="math inline">\(F(x)=f_1(x)+...+f_m(x)\)</span>，且 $_if_i$，则 <span class="math inline">\(\partial F(x)=\partial f_1(x)+... +\partialf_m(x)\)</span>。（这个实际上可以直接右上面的第二条得到，这里只不过又验证了一次）</p><p><strong>证明</strong>：我们可以考虑函数 <spanclass="math inline">\(f(x)=f_1(x_1)+...+f_m(x_m)\)</span>，在定义 <spanclass="math inline">\(A=[I,...,I]^T\)</span>，那么就有 <spanclass="math inline">\(F(x)=f(Ax)\)</span>，所以 <spanclass="math inline">\(\partial F(x)=A^T \partial f(Ax)=[I\ ...\I][\partial f_1(x),...,\partial f_m(x)]^T = \partial f_1(x)+... +\partial f_m(x)\)</span>。</p><p>上面是能获得 Strong subgradient calculus的几个原则，对于其他情况，我们考虑找到一个次梯度就够了。下面给出一些常见的情况。</p><p><strong>点点最大值</strong>：<spanclass="math inline">\(f(x)=\max\{f_1(x),...,f_m(x) \}\)</span>，可以定义<spanclass="math inline">\(I(x)=\{i|f_i(x)=f(x)\}\)</span>，那么他的</p><ul><li><strong>weak result</strong>：choose any <spanclass="math inline">\(g\in\partial f_k(x)\)</span>，其中 <spanclass="math inline">\(k\in I(x)\)</span></li><li><strong>strong result</strong>：<span class="math inline">\(\partialf(x)=\text{conv}\bigcup_{i\in I(x)}\partial f_i(x)\)</span></li></ul><p><strong>点点上确界</strong>：<spanclass="math inline">\(f(x)=\sup_{\alpha\in \mathcal{A}} f_\alpha(x)\)</span>，其中 <span class="math inline">\(f_\alpha(x)\)</span> 关于<span class="math inline">\(x\)</span> 是凸的，定义 <spanclass="math inline">\(I(x)=\{\alpha\in\mathcal{A}|f_\alpha(x)=f(x)\}\)</span>，那么</p><ul><li><strong>weak result</strong>：choose any <spanclass="math inline">\(g\in\partial f_\beta (\hat{x})\)</span>，其中<span class="math inline">\(f(\hat{x})=f_\beta(\hat{x})\)</span></li><li><strong>strong result</strong>：<spanclass="math inline">\(\text{conv}\bigcup_{\alpha\in I(x)}\partialf_\alpha(x) \subseteq \partialf(x)\)</span>，如果要取等号，需要额外的条件</li></ul><p><strong>下确界</strong>：<span class="math inline">\(f(x)=\inf_yh(x,y)\)</span>，其中 <span class="math inline">\(h(x,y)\)</span> 关于<span class="math inline">\((x,y)\)</span> 是联合凸的，那么</p><ul><li><strong>weak result</strong>：<span class="math inline">\((g,0)\in\partial h(\hat{x},\hat{y})\)</span>，其中 <spanclass="math inline">\(\hat{y}=\arg\min h(\hat{x},y)\)</span></li></ul><p><strong>复合函数</strong>：<spanclass="math inline">\(f(x)=h(f_1(x),...,f_k(x))\)</span>，其中 <spanclass="math inline">\(h\)</span> 为单调不减的凸函数，<spanclass="math inline">\(f_i\)</span> 为凸函数</p><ul><li><strong>weak result</strong>：<spanclass="math inline">\(g=z_1g_1+...+z_kg_k,z\in\partialh(f_1(x),...,f_k(x)),g_i\in \partial f_i(x)\)</span></li></ul><p><strong>期望</strong>：<spanclass="math inline">\(f(x)=\mathbb{E}h(x,u)\)</span>，其中 <spanclass="math inline">\(u\)</span> 为随机变量，<spanclass="math inline">\(h\)</span> 对任意的 <spanclass="math inline">\(u\)</span> 关于 <spanclass="math inline">\(x\)</span> 都是凸的</p><ul><li><strong>weak result</strong>：选择函数 <spanclass="math inline">\(u\mapsto g(u),g(u)\in \partial_xh(\hat{x},u)\)</span>，则 <span class="math inline">\(g=\mathbb{E}_ug(u) \in \partial f(\hat{x})\)</span></li></ul><p><strong><em>例子 1</em></strong>：picewise-linear function <spanclass="math inline">\(f(x)=\max_{i=1,...,m}(a_i^Tx+b_i),\partialf(x)=\text{conv}\{a_i|i\in I(x)\}\)</span></p><figure><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2020/16-picewise-linear.PNG"alt="picewise-linear" /><figcaption aria-hidden="true">picewise-linear</figcaption></figure><p><strong><em>例子 2</em></strong>：<spanclass="math inline">\(l_1\)</span> 范数 <spanclass="math inline">\(f(x)=\Vert x\Vert_1=|x_1|+...+|x_n|,\partialf(x)=J_1\times \cdots \times J_n\)</span>，其中 <spanclass="math inline">\(J_k=\begin{cases}[-1,1]&amp;x_k=0\\{1}&amp;x_k&gt;0\\ {-1}&amp;x_k&lt;0 \end{cases}\)</span></p><figure><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2020/16-l1-norm.PNG"alt="l1-norm" /><figcaption aria-hidden="true">l1-norm</figcaption></figure><p><strong><em>例子 3</em></strong>：<spanclass="math inline">\(f(x)=\lambda_{\max}(A(x))=\sup_{\Verty\Vert_2=1}y^TA(x)y\)</span>，其中 <spanclass="math inline">\(A(x)=A_0+x_1A_1+\cdots +x_nA_n\)</span>，则取<span class="math inline">\(\lambda_{\max}(A(\hat{x}))\)</span>对应的单位特征向量 <spanclass="math inline">\(y\)</span>，次梯度可以表示为 <spanclass="math inline">\((y^TA_1y,...,y^TA_ny)\in \partialf(\hat{x})\)</span></p><p><strong><em>例子 4</em></strong>：到凸集的欧氏距离 <spanclass="math inline">\(f(x)=\inf_{y\in C}\Vert x-y\Vert_2=\inf_{y}h(x,y)\)</span>，其中集合 <span class="math inline">\(C\)</span>为凸集，函数 <span class="math inline">\(h\)</span> 关于 <spanclass="math inline">\((x,y)\)</span> 是联合凸的。 <spanclass="math display">\[g=\begin{cases}0&amp;\hat{x}\in C\\\frac{1}{\|\hat{y}-\hat{x}\|_{2}}(\hat{x}-\hat{y})=\frac{1}{\|\hat{x}-P(\hat{x})\|_{2}}(\hat{x}-P(\hat{x}))&amp; \hat{x}\notin C \end{cases}\]</span> <strong><em>例子 5</em></strong>：定义如下凸优化问题的最优解为<span class="math inline">\(f(u,v)\)</span> <spanclass="math display">\[\begin{aligned}\text{minimize} \quad&amp; f_{0}(x) \\\text{subject to}\quad&amp; f_{i}(x) \leq u_{i}, \quad i=1, \ldots, m\\&amp;A x=b+v\end{aligned}\]</span> 如果假设 <spanclass="math inline">\(f(\hat{u},\hat{v})\)</span>有界且强对偶性成立，那么对于对偶问题如下对偶问题 <spanclass="math display">\[\begin{aligned}\text{maximize} \quad&amp; \inf _{x}\left(f_{0}(x)+\sum_{i}\lambda_{i}\left(f_{i}(x)-\hat{u}_{i}\right)+v^{T}(A x-b-\hat{v})\right)\\\text{subject to}\quad&amp; \lambda\succeq 0\end{aligned}\]</span> 若其最优解为 <spanclass="math inline">\((\hat\lambda,\hat\nu)\)</span>，则有 <spanclass="math inline">\((-\hat\lambda,-\hat\nu)\in \partialf(\hat{u},\hat{v})\)</span>。</p><h2 id="对偶原理与最优解条件">3. 对偶原理与最优解条件</h2><p>前面我们对于可导函数获得了对偶原理以及 KKT条件，那如果是不可导的函数呢？我们有 <span class="math display">\[f(y) \geq f\left(x^{\star}\right)+0^{T}\left(y-x^{\star}\right) \quad\text { for all } y \quad \Longleftrightarrow \quad 0 \in \partialf\left(x^{\star}\right)\]</span> <imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2020/16-optimal.PNG"alt="optimal" /></p><p><strong><em>例子</em></strong>：对于优化问题 <spanclass="math inline">\(\min f(x),\text{s.t. }x\in C \iff \minf(x)+\delta_C(x)=F(x)\)</span>，因此 <span class="math display">\[0\in \partial f(x^\star)+\partial \delta_C(x^\star) \Longrightarrow\exists p\in\partial f(x^\star),\quad\text{s.t.}-p\in\partial\delta_C(x^\star)=N_C(x^\star)\]</span> 如果 <span class="math inline">\(f\in C^1\)</span>，则有 <spanclass="math inline">\(-\nabla f(x^\star)\in N_C(x^\star)\)</span>。</p><p>KKT 条件怎么变呢？只需要修改一下梯度条件：</p><ol type="1"><li>原问题可行性 <span class="math inline">\(x^\star\)</span> is primalfeasible</li><li>对偶问题可行性 <span class="math inline">\(\lambda^\star\succeq0\)</span></li><li>互补性条件 <span class="math inline">\(\lambda_i^\starf_i(x^\star)=0,i=1,...,m\)</span></li><li>梯度条件 <span class="math inline">\(0\in \partialf_0(x^\star)+\sum_i \lambda_i^\star \partial f_i(x^\star)\)</span></li></ol><h2 id="方向导数">4. 方向导数</h2><p><strong>方向导数(directional derivative)</strong>的定义为 <spanclass="math display">\[\begin{aligned}f^{\prime}(x ; y) &amp;=\lim _{\alpha \searrow 0} \frac{f(x+\alphay)-f(x)}{\alpha} \\&amp;=\lim _{t \rightarrow \infty}\left(tf\left(x+\frac{1}{t} y\right)-tf(x)\right)\end{aligned}\]</span> 方向导数是<strong>齐次</strong>的，也即 <spanclass="math display">\[f&#39;(x;\lambda y)=\lambda f&#39;(x;y) \quad \text{for }\lambda\ge0\]</span> 对于<strong>凸函数</strong>，方向导数也可以定义为 <spanclass="math display">\[\begin{aligned}f^{\prime}(x ; y) &amp;=\inf _{\alpha &gt; 0} \frac{f(x+\alphay)-f(x)}{\alpha} \\&amp;=\inf _{t &gt;0}\left(tf\left(x+\frac{1}{t} y\right)-t f(x)\right)\end{aligned}\]</span> 要证明的话，只需要证明 <spanclass="math inline">\(g(\alpha)=\frac{f(x+\alphay)-f(x)}{\alpha}\)</span> 随着 <spanclass="math inline">\(\alpha\)</span> 单调递减有下界。</p><p>实际上方向导数定义了沿着 <span class="math inline">\(y\)</span>方向的函数下界，也即 <span class="math display">\[f(x+\alpha y) \geq f(x)+\alpha f^{\prime}(x ; y) \quad \text { for all }\alpha \geq 0\]</span> 对于凸函数，<span class="math inline">\(x\in\text{intdom}f\)</span>，也有 <span class="math display">\[f^{\prime}(x ; y)=\sup _{g \in \partial f(x)} g^{T} y\]</span> 也即 <span class="math inline">\(f&#39;(x;y)\)</span> 是 <spanclass="math inline">\(\partial f(x)\)</span> 的支撑函数</p><figure><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2020/16-directional-derivate.PNG"alt="directional-derivate" /><figcaption aria-hidden="true">directional-derivate</figcaption></figure><p><strong>Remarks</strong>：需要注意的是<strong>负的次梯度方向</strong>不一定是函数值下降方向，而只有<strong>方向导数&lt;0 的方向</strong>才是函数值下降方向。反例如下图</p><figure><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2020/16-directional-derivate2.PNG"alt="directional-derivate2" /><figcaption aria-hidden="true">directional-derivate2</figcaption></figure><p>如果我们想找到下降最快的方向(Steepest descent direction)，则需要<span class="math display">\[\Delta x_{\mathrm{nsd}}=\underset{\|y\|_{2} \leq1}{\operatorname{argmin}} f^{\prime}(x ; y)\]</span> 根据前面的式子我们知道 <span class="math inline">\(\minf&#39;(x;y)=\min_{\Vert y\Vert_2\le1}\sup_{g\in\partialf(x)}g^Ty\)</span>，如果假设极大极小可以换序，则可以等价为 <spanclass="math inline">\(\sup_g \inf_y g^Ty = \sup_{g\in\partial f(x)}-\Vert g\Vert_2\)</span>，上面过程可以表述为原问题与对偶问题 <spanclass="math display">\[\begin{aligned}\text{minimize} \quad&amp; f&#39;(x;y) \\\text{subject to}\quad&amp; \|y\|_{2} \leq 1\end{aligned}\qquad\begin{aligned}\text{minimize} \quad&amp; -\|g\|_{2} \\\text{subject to}\quad&amp; g \in \partial f(x)\end{aligned}\]</span> 于是就有 <span class="math inline">\(f^{\prime}\left(x ;\Deltax_{\mathrm{nsd}}\right)=-\left\|g^{\star}\right\|_{2}\)</span>，<spanclass="math inline">\(\text { if } 0 \notin \partial f(x), \Deltax_{\mathrm{nsd}}=-g^{\star}/\left\|g^{\star}\right\|_{2}\)</span>，如下图所示</p><figure><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2020/16-steepest-descent.PNG"alt="16-steepest-descent" /><figcaption aria-hidden="true">16-steepest-descent</figcaption></figure>]]></content>
    
    
    <categories>
      
      <category>Convex Optimization</category>
      
    </categories>
    
    
    <tags>
      
      <tag>次梯度</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>MATLAB R2016a 无法启动并行池</title>
    <link href="/2020/04/08/software/matlab-parpool/"/>
    <url>/2020/04/08/software/matlab-parpool/</url>
    
    <content type="html"><![CDATA[<p>最近在用 MATLAB 跑仿真，但是不知怎么回事，之前并行计算 parfor用的好好的，昨天突然就不能用了，一直报错无法启动并行池，报错原因还特别奇怪。在网上找了一大堆教程互相抄来抄去，没一个能用的。最后还是在官网论坛找到了一个答案成功解决问题。</p><span id="more"></span><h2 id="问题描述">1. 问题描述</h2><p>我用的是 MATLAB R2016a，当我运行带有 parfor的代码时，左下角会有如下提示，表示无法启动并行池，而正常情况应该是右边这幅图</p><table><thead><tr class="header"><th>报错情况</th><th>正常情况</th></tr></thead><tbody><tr class="odd"><td><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2020/matlab-parpool-error.png"alt="error info" /></td><td><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2020/matlab-parpool-normal.png"alt="normal info" /></td></tr></tbody></table><p>当我点击查看 more details时，会报如下的错误，参数不对？这不是自带函数吗？</p><figure><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2020/matlab-parpool-error2.png"alt="error info" /><figcaption aria-hidden="true">error info</figcaption></figure><p>然后我参考了网上的教程，查看 <code>Home-&gt;Parallel-&gt;ManageCluster Profiles</code>，但是网上教程说如果是下面这个样子</p><table><thead><tr class="header"><th>我的错误是这样的</th><th>网上只有这样的</th></tr></thead><tbody><tr class="odd"><td><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2020/matlab-parpool-error3.png"alt="my error" /></td><td><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2020/matlab-parpool-error4.png"alt="others" /></td></tr></tbody></table><p>很显然我的第一步就 fail 了，我按照网上的说法运行下面这句话也没用</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs matlab">distcomp.feature( <span class="hljs-string">&#x27;LocalUseMpiexec&#x27;</span>, <span class="hljs-built_in">false</span> )<br></code></pre></td></tr></table></figure><p>最后幸运的是在官网论坛找到了一篇可以解决我的问题的回答，下面给出解决方法。</p><h2 id="解决方法">2. 解决方法</h2><blockquote><p>参考链接：<ahref="https://www.mathworks.com/matlabcentral/answers/92124-why-am-i-unable-to-use-parpool-with-the-local-scheduler-or-validate-my-local-configuration-of-parall">https://www.mathworks.com/matlabcentral/answers/92124-why-am-i-unable-to-use-parpool-with-the-local-scheduler-or-validate-my-local-configuration-of-parall</a></p><p>我用<strong>第 5 步(Clear the local scheduler datafolder)</strong>解决了我的问题，不过下面还是贴出来完整的 debug 过程</p></blockquote><h3 id="检查-license">2.1 检查 license</h3><p>运行命令检查 <code>Parallel Computing Toolbox</code> 的 license正确</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs matlab">license checkout Distrib_Computing_Toolbox<br></code></pre></td></tr></table></figure><p>如果得到的回答是 <code>ans=1</code>，则说明 license没问题。否则需要添加 license。</p><h3 id="确保你的-matlab-版本与-pct-版本匹配">2.2 确保你的 MATLAB 版本与PCT 版本匹配</h3><p>运行命令 <code>ver</code> 查看，如果不匹配则无法使用。这种情况 ......建议重装。</p><h3 id="disable-local-mpiexec">2.3 Disable local mpiexec</h3><p>运行下面的命令</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs matlab">distcomp.feature( <span class="hljs-string">&#x27;LocalUseMpiexec&#x27;</span>, <span class="hljs-built_in">false</span> )<br></code></pre></td></tr></table></figure><p>这也是网上绝大部分教程的方法，不过对我就不适用，如果对你也不适用的话，往下继续看。</p><h3 id="check-your-local-scheduler-configuration">2.4 Check your localscheduler configuration</h3><p>这一部分我贴出原文吧，大概是说如果你修改了默认配置，则可以重置他们。</p><blockquote><p>There are no changes that need to be made in order to use the localscheduler, but if you have made changes to the configuration, you maywant to reset these. This can be done by creating a new local schedulerconfiguration. To do so,</p><ol type="1"><li>Go to the Parallel menu in MATLAB and select "Manage ClusterProfiles..." ("Manage Configurations..." for R2011b or earlier)</li><li>Click on Add &gt; Custom &gt; Local (for older releases: From theFile menu, select New &gt; Local Configuration)</li><li>Click the radio option in the default column to set this as thedefault configuration</li></ol><p>Once complete, close the Manage Configuration windows and tryagain.</p></blockquote><h3 id="clear-the-local-scheduler-data-folder">2.5 Clear the localscheduler data folder</h3><p>出现无法启动并行池的原因也可能是本地的 local scheduler data有问题，可以把他删除。删除的步骤为</p><ol type="1"><li><p>运行命令</p><figure class="highlight taggerscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs taggerscript">&gt;&gt;prefdir<br>ans =<br>C:<span class="hljs-symbol">\U</span>sers<span class="hljs-symbol">\A</span>dministrator<span class="hljs-symbol">\A</span>ppData<span class="hljs-symbol">\R</span>oaming<span class="hljs-symbol">\M</span>athWorks<span class="hljs-symbol">\M</span>ATLAB<span class="hljs-symbol">\R</span>2016a<br></code></pre></td></tr></table></figure><p>然后我们就可以在路径<code>C:\Users\Administrator\AppData\Roaming\MathWorks\MATLAB</code>下面找到文件夹 <code>local_scheduler_data</code> 或者<code>local_cluster_jobs</code></p></li><li><p>关闭 MATLAB</p></li><li><p>将上面的文件夹 <code>local_scheduler_data</code> 或者<code>local_cluster_jobs</code> 重命名或者直接删除</p></li><li><p>重启 MATLAB，试着开启并行池</p></li></ol><p>我做完这一步就能解决问题了，如果还不行，原文还给出了其他可能的原因，后面的我就直接贴出来原文了。</p><h3 id="ensure-that-hostname-resolution-works-on-your-computer">2.6Ensure that hostname resolution works on your computer</h3><p>In order to use the local scheduler, your computer's own hostnamemust be resolvable. To confirm this, run the following command inMATLAB:</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs matlab">!hostname<br></code></pre></td></tr></table></figure><p>This will give you your computer's hostname. You must be able toresolve this hostname to the computer's IP address. To test this you canrun:</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs matlab">!ping &lt;hostname&gt;<br></code></pre></td></tr></table></figure><p>Where <hostname> is the output of the hostname command above. If theresults indicate the wrong IP address or say that your computer is an"unknown host", there is a network issue on your computer that needs tobe resolved in order to use the local scheduler. In that case, ask yournetwork administrator for help.</p><h3id="check-to-see-if-you-have-a-startup.m-file-on-the-matlab-path">2.7Check to see if you have a startup.m file on the MATLAB path</h3><p>It may be causing an error, even if it works fine in MATLAB when runas code.</p><p>To see if you have a startup.m file on the MATLAB path run the belowcommand in MATLAB:</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs matlab">which startup.m<br></code></pre></td></tr></table></figure><p>Either delete or move that file outside of the MATLAB path.</p><p>If you are still unable to run parpool, run a validation of yourlocal scheduler configuration and submit this to support. Tovalidate:</p><ol type="1"><li>Go to the Parallel menu in MATLAB and select "Manage ClusterProfiles..." ("Manage Configurations..." for R2011b or earlier)</li><li>Highlight your local scheduler configuration and click the"Validate" button ("Start Validation" for R201b or earlier)</li><li>Once the validation completes, click the "details" link to see theresults</li></ol><p>You can then forward your output of validation, the results of thetests below, and your license number to support here: <ahref="http://www.mathworks.com/support/contact_us/index.html">http://www.mathworks.com/support/contact_us/index.html</a></p>]]></content>
    
    
    <categories>
      
      <category>Software</category>
      
    </categories>
    
    
    <tags>
      
      <tag>matlab</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>凸优化笔记15：梯度方法 Gradient Method</title>
    <link href="/2020/04/05/optimization/ch15-gradient/"/>
    <url>/2020/04/05/optimization/ch15-gradient/</url>
    
    <content type="html"><![CDATA[<p>前面的章节基本上讲完了凸优化相关的理论部分，在对偶原理以及 KKT条件那里我们已经体会到了理论之美！接下来我们就要进入求解算法的部分，这也是需要浓墨重彩的一部分，毕竟我们学习凸优化就是为了解决实际当中的优化问题。我们今天首先要接触的就是大名鼎鼎的<strong>梯度方法</strong>。现在人工智能和人工神经网络很火，经常可以听到反向传播，这实际上就是梯度下降方法的应用，他的思想其实很简单，就是沿着函数梯度的反方向走就会使函数值不断减小。<span class="math display">\[x_{k+1}=x_{k}-t_k \nabla f(x_k),\quad k=0,1,...\]</span> 上面的式子看起来简单，但是真正应用时你会发现有各种问题：</p><ol type="1"><li>下降方向怎么选？<span class="math inline">\(\nabla f(x_k)\)</span>吗？选择其他方向会不会好一点呢？</li><li>如果 <span class="math inline">\(f(x)\)</span>(在某些点)不可导又怎么办呢？</li><li>步长 <span class="math inline">\(t_k\)</span>怎么选呢？固定值？变化值？选多大比较好？</li><li>收敛速度怎么样呢？我怎么才能知道是否达到精度要求呢？</li><li>...</li></ol><span id="more"></span><h2 id="凸函数">1. 凸函数</h2><p>前面讲凸函数的时候我们提到了很多等价定义：Jensen's不等式、“降维打击”、一阶条件、二阶条件。这里我们主要关注其中两个：</p><ol type="1"><li>Jensen's 不等式：<span class="math inline">\(f(\theta x+(1-\theta)y) \leq \theta f(x)+(1-\theta) f(y)\)</span></li><li>一阶条件等价于<strong>梯度单调性</strong>：<spanclass="math inline">\((\nabla f(x)-\nabla f(y))^{T}(x-y) \geq 0 \quad\text { for all } x, y \in \operatorname{dom} f\)</span></li></ol><p>也就是说凸函数的梯度 <span class="math inline">\(\nabla f: R^n\toR^n\)</span> 是一个<strong>单调映射</strong>。</p><h2 id="lipschitz-continuity">2. Lipschitz continuity</h2><p>函数 <span class="math inline">\(f\)</span>的梯度满足<strong>利普希茨连续(Lipschitz continuous)</strong>的定义为<span class="math display">\[\|\nabla f(x)-\nabla f(y)\|_{*} \leq L\|x-y\| \quad \text { for all } x,y \in \operatorname{dom} f\]</span> 也被称为<strong>L-smooth</strong>。有了这个条件，我们可以推出很多个等价性质，这里省略了证明过程</p><figure><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2020/15-lipschitz.PNG"alt="lipschitz" /><figcaption aria-hidden="true">lipschitz</figcaption></figure><blockquote><p>也就是说下面的式子都是等价的 <span class="math display">\[\|\nabla f(x)-\nabla f(y)\|_{*} \leq L\|x-y\| \quad \text { for all } x,y \in \operatorname{dom} f\]</span></p><p><span class="math display">\[(\nabla f(x)-\nabla f(y))^{T}(x-y) \leq L\|x-y\|^{2} \quad \text { forall } x, y \in \operatorname{dom} f\]</span></p><p><span class="math display">\[f(y) \leq f(x)+\nabla f(x)^{T}(y-x)+\frac{L}{2}\|y-x\|^{2} \quad \text {for all } x, y \in \operatorname{dom} f\]</span></p><p><span class="math display">\[(\nabla f(x)-\nabla f(y))^{T}(x-y) \geq \frac{1}{L}\|\nabla f(x)-\nablaf(y)\|_{*}^{2} \quad \text { for all } x, y\]</span></p><p><span class="math display">\[g(x)=\frac{L}{2}\Vert x\Vert_2^2-f(x) \ \text{ is convex}\]</span></p><p><strong>Remarks 1</strong>：</p><p>上面的第 3 个式子 <span class="math display">\[f(y) \leq f(x)+\nabla f(x)^{T}(y-x)+\frac{L}{2}\Vert y-x\Vert^{2} \quad\text { for all } x, y \in \operatorname{dom} f\]</span>实际上定义了一个<strong>二次曲线</strong>，这个曲线是原始函数的<strong>Quadratic upper bound</strong></p><figure><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2020/15-quadra-upper.PNG"alt="Quadratic upper bound" /><figcaption aria-hidden="true">Quadratic upper bound</figcaption></figure><p>并且由这个式子可以推导出 <span class="math display">\[\frac{1}{2 L}\Vert\nabla f(z)\Vert_{*}^{2} \leqf(z)-f\left(x^{\star}\right) \leq \frac{L}{2}\left\Vertz-x^{\star}\right\Vert^{2} \quad \text { for all } z\]</span> 这个式子中的上界 <spanclass="math inline">\(\frac{L}{2}\left\|z-x^{\star}\right\|^{2}\)</span>带有 <span class="math inline">\(x^\star\)</span>是未知的，而下界只与当前值 <span class="math inline">\(z\)</span>有关，因此在优化过程中我们可以判断当前的 <spanclass="math inline">\(f(z)\)</span> 与最优值的距离至少为 <spanclass="math inline">\(\frac{1}{2 L}\|\nablaf(z)\|_{*}^{2}\)</span>，如果这个值大于0，那么我们一定还没得到最优解。</p><p><strong>Remarks 2</strong>：</p><p>上面的最后一个式子 <span class="math display">\[(\nabla f(x)-\nabla f(y))^{T}(x-y) \geq \frac{1}{L}\|\nabla f(x)-\nablaf(y)\|_{*}^{2} \quad \text { for all } x, y\]</span> 被称为 <span class="math inline">\(\nabla f\)</span> 的<strong>co-coercivity</strong> 性质。（这其实有点像 <spanclass="math inline">\(\nabla f\)</span> 的反函数的 L-smooth性质，所以它跟 <span class="math inline">\(\nabla f\)</span> 的 L-smooth性质是等价的）</p></blockquote><h2 id="强凸函数">3. 强凸函数</h2><p>满足如下性质的函数被称为 <strong>m-强凸(m-strongly convex)</strong>的<span class="math display">\[f(\theta x+(1-\theta) y) \leq \theta f(x)+(1-\theta) f(y)-\frac{m}{2}\theta(1-\theta)\|x-y\|^{2} \quad \text { for all } x,y\in\text{dom}f,\theta\in[0,1]\]</span> m-强凸跟前面的 L-smooth实际上非常像，只不过一个定义了上界，另一个定义了下界。</p><blockquote><p>类似上面的 L-smooth性质，我们课可以得到下面几个式子是<strong>等价</strong>的 <spanclass="math display">\[f \text{ is m-strongly convex}\]</span></p><p><span class="math display">\[(\nabla f(x)-\nabla f(y))^{T}(x-y) \geq m\|x-y\|^{2} \quad \text { forall } x, y \in \operatorname{dom} f\]</span></p><p><span class="math display">\[f(y) \geq f(x)+\nabla f(x)^{T}(y-x)+\frac{m}{2}\|y-x\|^{2} \quad \text {for all } x, y \in \operatorname{dom} f\]</span></p><p><span class="math display">\[g(x) = f(x)-\frac{m}{2}\Vert x\Vert^2 \ \text{ is convex}\]</span></p></blockquote><p>注意上面第3个式子不等号右遍实际上又定义了一个二次曲线，这个二次曲线是原函数的下界。与前面的二次上界类比可以得到</p><table><thead><tr class="header"><th>Quadratic lower bound</th><th>Quadratic upper bound</th></tr></thead><tbody><tr class="odd"><td><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2020/15-quadra-lower.PNG"alt="Quadratic lower bound" /></td><td><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2020/15-quadra-upper.PNG"alt="Quadratic upper bound" /></td></tr><tr class="even"><td><span class="math inline">\(f(y) \geq f(x)+\nablaf(x)^{T}(y-x)+\frac{m}{2}\Vert y-x\Vert^{2}\)</span></td><td><span class="math inline">\(f(y) \leq f(x)+\nablaf(x)^{T}(y-x)+\frac{L}{2}\Vert y-x\Vert^{2}\)</span></td></tr><tr class="odd"><td><span class="math inline">\(\Longrightarrow \frac{m}{2}\left\Vertz-x^{\star}\right\Vert^{2} \leq f(z)-f\left(x^{\star}\right) \leq\frac{1}{2 m}\Vert\nabla f(z)\Vert_{*}^{2}\)</span></td><td><span class="math inline">\(\Longrightarrow \frac{1}{2 L}\Vert\nablaf(z)\Vert_{*}^{2} \leq f(z)-f\left(x^{\star}\right) \leq\frac{L}{2}\left\Vert z-x^{\star}\right\Vert^{2}\)</span></td></tr></tbody></table><p><strong><em>例子</em></strong>：如果函数 <spanclass="math inline">\(f\)</span> 既是 m-强凸的，又是(关于2范数) L-smooth的，那么</p><ol type="1"><li>函数 <span class="math inline">\(h(x)=f(x)-\frac{m}{2}\Vertx\Vert^2\)</span> 是 <strong>(L-m)-smooth</strong> 的</li><li>函数 <span class="math inline">\(h\)</span> 的 co-coercivity可以写为</li></ol><p><span class="math display">\[(\nabla f(x)-\nabla f(y))^{T}(x-y) \geq \frac{mL}{m+L}\|x-y\|_{2}^{2}+\frac{1}{m+L}\|\nabla f(x)-\nabla f(y)\|_{2}^{2}\quad \text { for all } x, y \in \operatorname{dom} f\]</span></p><h2 id="梯度方法收敛性分析">4. 梯度方法收敛性分析</h2><p>下面给出一些常见梯度下降方法的分析。先回顾一下梯度方法的一般表达式<span class="math display">\[x_{k+1}=x_{k}-t_k \nabla f(x_k)\]</span> 首先有一些假设</p><ol type="1"><li><span class="math inline">\(f\)</span> convex 且可导，<spanclass="math inline">\(\text{dom}f=R^n\)</span></li><li><span class="math inline">\(\nabla f\)</span> 关于2范数 L-Lipschitzcontinuous</li><li>最优解有限且可取</li></ol><h3 id="固定步长">4.1 固定步长</h3><p>固定步长为 <span class="math inline">\(t\)</span>，则 <spanclass="math inline">\(x^+=x-t\nabla f(x)\)</span>，根据 L-smooth 性质有<span class="math display">\[f(x-t \nabla f(x)) \leq f(x)-t\left(1-\frac{L t}{2}\right)\|\nablaf(x)\|_{2}^{2}\]</span> 如果 <span class="math inline">\(0 &lt; t \leq1/L\)</span>，则有 <span class="math display">\[f\left(x^{+}\right) \leq f(x)-\frac{t}{2}\|\nabla f(x)\|_{2}^{2}\]</span> 这表明(只要步长 <span class="math inline">\(t\)</span>比较小)<strong>函数值总是在不断减小</strong>的。从上面的式子结合凸函数性质我们还可以得到<span class="math display">\[\begin{aligned}f\left(x^{+}\right)-f^{\star} &amp; \leq \nablaf(x)^{T}\left(x-x^{\star}\right)-\frac{t}{2}\|\nabla f(x)\|_{2}^{2} \\&amp;=\frac{1}{2t}\left(\left\|x-x^{\star}\right\|_{2}^{2}-\left\|x-x^{\star}-t \nablaf(x)\right\|_{2}^{2}\right) \\&amp;=\frac{1}{2t}\left(\left\|x-x^{\star}\right\|_{2}^{2}-\left\|x^{+}-x^{\star}\right\|_{2}^{2}\right)\end{aligned}\]</span> 从这个式子可以得到我们<strong>到最优点 <spanclass="math inline">\(x^\star\)</span>的距离在不断减小</strong>。那么可以得到下面的式子 <spanclass="math display">\[\begin{aligned}\sum_{i=1}^{k}\left(f\left(x_{i}\right)-f^{\star}\right) &amp; \leq\frac{1}{2 t}\sum_{i=1}^{k}\left(\left\|x_{i-1}-x^{\star}\right\|_{2}^{2}-\left\|x_{i}-x^{\star}\right\|_{2}^{2}\right)\\&amp;=\frac{1}{2t}\left(\left\|x_{0}-x^{\star}\right\|_{2}^{2}-\left\|x_{k}-x^{\star}\right\|_{2}^{2}\right)\\&amp; \leq \frac{1}{2 t}\left\|x_{0}-x^{\star}\right\|_{2}^{2}\end{aligned} \\\Longrightarrowf(x_k)-f^\star\leq\frac{1}{k}\sum_{i=1}^{k}\left(f\left(x_{i}\right)-f^{\star}\right)\leq \frac{1}{2 kt}\left\|x_{0}-x^{\star}\right\|_{2}^{2}\]</span> 因此普通的固定步长的梯度下降有以下收敛性质</p><ol type="1"><li><span class="math inline">\(f(x_{k+1}) &lt; f(x_k)\)</span></li><li><span class="math inline">\(\Vert x_{k+1}-x^\star\Vert &lt; \Vertx_{k}-x^\star\Vert\)</span></li><li><span class="math inline">\(f(x_k)-f^\star\leq \frac{1}{2kt}\left\|x_{0}-x^{\star}\right\|_{2}^{2}\)</span>，要想满足精度 <spanclass="math inline">\(f(x_k)-f^\star \leq \epsilon\)</span>需要的迭代次数为 <span class="math inline">\(O(1/\epsilon)\)</span></li></ol><h3 id="线搜索">4.2 线搜索</h3><p>线搜索就是每步都要计算合适的步长，计算方法为不断地迭代 <spanclass="math inline">\(t_k:=\beta t_k,0&lt;\beta&lt;1\)</span> 直到 <spanclass="math inline">\(t_k\)</span> 满足下面的条件 <spanclass="math display">\[f\left(x_{k}-t_{k} \nablaf\left(x_{k}\right)\right)&lt;f\left(x_{k}\right)-\alphat_{k}\left\|\nabla f\left(x_{k}\right)\right\|_{2}^{2}\]</span> 形象理解就是下面这幅图，一开始我们的 <spanclass="math inline">\(t_k\)</span>可能很大，表示梯度下降的步长过大，不能使函数值减小，那我们就减小步长<span class="math inline">\(t_k=\betat_k\)</span>，直到进入绿线与蓝线交点左侧这部分，我们就可以保证一定有<spanclass="math inline">\(f(x_{k+1})&lt;f(x_k)\)</span>，这时就是我们要取的<spanclass="math inline">\(t_k\)</span>，这也是线搜索的含义，线搜索实际上就是在搜索合适的步长<span class="math inline">\(t_k\)</span>。</p><figure><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2020/15-line-search.PNG"alt="line search" /><figcaption aria-hidden="true">line search</figcaption></figure><p>主要到上面的式子中有一个参数 <spanclass="math inline">\(\alpha\)</span> 会影响我们的搜索结果，比如上图中<span class="math inline">\(\alpha\)</span>越大，则绿线的斜率越大，那么最终搜索到的 <spanclass="math inline">\(t_k\)</span>应该就越小，表示我们每一步的步长都会更小。实际中往往取 <spanclass="math inline">\(\alpha=1/2\)</span>，此时理想的搜索结果实际上就是quadratic upper bound的最小值点。也就是说我们用二次上界曲线来近似待优化的函数，而二次上界的最小值点对应的步长就是<spanclass="math inline">\(t=1/L\)</span>，但由于我们是线搜索，实际得到的<span class="math inline">\(t_k\)</span> 一般会比这个值略小一点。</p><figure><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2020/15-line-search2.PNG"alt="line search" /><figcaption aria-hidden="true">line search</figcaption></figure><p>另一方面为了保证线搜索在有限步能够终止，还需要满足 <spanclass="math inline">\(t_k\ge t_\min=\min\{\hat{t},\beta/L\}\)</span>，其中 <spanclass="math inline">\(\hat{t}\)</span> 是预先指定的一个参数。</p><p>那么线搜索的收敛性怎么样呢？首先根据线搜索的定义一定有 <spanclass="math display">\[\begin{aligned}f\left(x_{i+1}\right) &amp; \leqf\left(x_{i}\right)-\frac{t_{i}}{2}\left\|\nablaf\left(x_{i}\right)\right\|_{2}^{2} \\&amp; \leq f^{\star}+\nablaf\left(x_{i}\right)^{T}\left(x_{i}-x^{\star}\right)-\frac{t_{i}}{2}\left\|\nablaf\left(x_{i}\right)\right\|_{2}^{2} \\&amp;=f^{\star}+\frac{1}{2t_{i}}\left(\left\|x_{i}-x^{\star}\right\|_{2}^{2}-\left\|x_{i+1}-x^{\star}\right\|_{2}^{2}\right)\end{aligned}\]</span> 这表明 <spanclass="math inline">\(f(x_{i+1})&lt;f(x_i),\left\|x_{i}-x^{\star}\right\|_{2}&gt;\left\|x_{i+1}-x^{\star}\right\|_{2}\)</span>，类似前面固定步长的分析，可以得到<span class="math display">\[f(x_k)-f^\star\leq\frac{1}{k}\sum_{i=1}^{k}\left(f\left(x_{i}\right)-f^{\star}\right)\leq \frac{1}{2 kt_\min}\left\|x_{0}-x^{\star}\right\|_{2}^{2}\]</span> 因此对于线搜索的方法，我们可以得到如下的收敛性质</p><ol type="1"><li><span class="math inline">\(f(x_{i+1})&lt;f(x_i)\)</span></li><li><spanclass="math inline">\(\left\|x_{i}-x^{\star}\right\|_{2}&gt;\left\|x_{i+1}-x^{\star}\right\|_{2}\)</span></li><li><span class="math inline">\(f(x_k)-f^\star\leq \frac{1}{2kt_\min}\left\|x_{0}-x^{\star}\right\|_{2}^{2}\)</span></li></ol><p>所以线搜索实际上并不能提高收敛速度的阶，他与固定步长的方法都是 <spanclass="math inline">\(O(1/k)\)</span> 的，为 <strong>sublinear收敛</strong>。</p><h3 id="一阶方法的收敛极限">4.3 一阶方法的收敛极限</h3><p>不管是固定步长还是线搜索，前面的方法都是一阶方法，即 <spanclass="math display">\[x_{k+1}\in x_{0}+\operatorname{span}\left\{\nabla f\left(x_{0}\right),\nabla f\left(x_{1}\right), \ldots, \nabla f\left(x_{k}\right)\right\}\]</span> 而理论上也证明一阶方法的收敛速度存在极限。</p><p><strong>定理(Nesterov)</strong>： for every integer <spanclass="math inline">\(k ≤ (n−1)/2\)</span> and every <spanclass="math inline">\(x_0\)</span>, there exist functions in the problemclass such that for any ﬁrst-order method <span class="math display">\[f\left(x_{k}\right)-f^{\star} \geq \frac{3}{32}\frac{L\left\|x_{0}-x^{\star}\right\|_{2}^{2}}{(k+1)^{2}}\]</span> 也就是说收敛速度最多也就是 <spanclass="math inline">\(O(1/k^2)\)</span>。</p><h3 id="强凸函数的梯度方法">4.4 强凸函数的梯度方法</h3><p>对于强凸函数，即使采用固定步长的梯度方法，也可以得到<strong>线性收敛速度</strong>！这就是强凸性带来的好处。</p><p>考虑 <span class="math inline">\(0&lt;t&lt;2/(m+L)\)</span>，我们有<span class="math display">\[\begin{aligned}\left\|x^{+}-x^{\star}\right\|_{2}^{2} &amp;=\left\|x-t \nablaf(x)-x^{\star}\right\|_{2}^{2} \\&amp;=\left\|x-x^{\star}\right\|_{2}^{2}-2 t \nablaf(x)^{T}\left(x-x^{\star}\right)+t^{2}\|\nabla f(x)\|_{2}^{2} \\&amp; \leq\left(1-t \frac{2 mL}{m+L}\right)\left\|x-x^{\star}\right\|_{2}^{2}+t\left(t-\frac{2}{m+L}\right)\|\nablaf(x)\|_{2}^{2} \\&amp; \leq\left(1-t \frac{2 mL}{m+L}\right)\left\|x-x^{\star}\right\|_{2}^{2}\end{aligned}\]</span> 也就是说可以得到 <span class="math display">\[\left\|x_{k}-x^{\star}\right\|_{2}^{2} \leqc^{k}\left\|x_{0}-x^{\star}\right\|_{2}^{2}, \quad c=1-t \frac{2 mL}{m+L} \\f\left(x_{k}\right)-f^{\star} \leq\frac{L}{2}\left\|x_{k}-x^{\star}\right\|_{2}^{2} \leq \frac{c^{k}L}{2}\left\|x_{0}-x^{\star}\right\|_{2}^{2}\]</span> 注意到前面是反比例下降，这里变成了指数下降。如果要打到精度<span class="math inline">\(f(x_k)-f^\star \leq \epsilon\)</span>需要的迭代次数为 <spanclass="math inline">\(O(\log(1/\epsilon))\)</span></p><h2 id="bb-方法">5. BB 方法</h2><p><strong>Barzilai-Borwein (BB) method</strong>也是梯度下降方法的一种，他主要是通过近似牛顿方法来实现更快的收敛速度，同时避免计算二阶导数带来的计算复杂度。</p><p>如果我们记 <span class="math inline">\(\boldsymbol{g}^{(k)}=\nablaf\left(\boldsymbol{x}^{(k)}\right) \text { and }\boldsymbol{F}^{(k)}=\nabla^{2}f\left(\boldsymbol{x}^{(k)}\right)\)</span>，那么<strong>一阶方法</strong>就是<spanclass="math inline">\(\boldsymbol{x}^{(k+1)}=\boldsymbol{x}^{(k)}-\alpha_{k}\boldsymbol{g}^{(k)}\)</span>，其中步长 <spanclass="math inline">\(\alpha_k\)</span>可以是固定的，也可以是线搜索获得的，一阶方法简单但是收敛速度慢。<strong>牛顿方法</strong>就是<spanclass="math inline">\(\boldsymbol{x}^{(k+1)}=\boldsymbol{x}^{(k)}-\left(\boldsymbol{F}^{(k)}\right)^{-1}\boldsymbol{g}^{(k)}\)</span>，其收敛速度更快，但是海森矩阵计算代价较大。而<strong>BB方法</strong>就是用 <span class="math inline">\(\alpha_{k}\boldsymbol{g}^{(k)}\)</span> 来近似 <spanclass="math inline">\(\left(\boldsymbol{F}^{(k)}\right)^{-1}\boldsymbol{g}^{(k)}\)</span>。</p><p>怎么近似呢？假如定义 <spanclass="math inline">\(s^{(k-1)}:=x^{(k)}-x^{(k-1)} \text { and }y^{(k-1)}:=g^{(k)}-g^{(k-1)}\)</span>，那么海森矩阵实际上就是 <spanclass="math display">\[\boldsymbol{F}^{(k)}s^{(k-1)}=y^{(k-1)}\]</span> 现在的想法就是用 <span class="math inline">\((\alpha_kI)^{-1}\)</span> 来近似 <spanclass="math inline">\(\boldsymbol{F}^{(k)}\)</span>，那么应该有 <spanclass="math display">\[(\alpha_k I)^{-1}s^{(k-1)}=y^{(k-1)}\]</span> 这个问题用最小二乘就可以解决了，下面两种选择都可以 <spanclass="math display">\[\alpha_{k}^{-1}=\underset{\beta}{\arg \min } \frac{1}{2}\left\|s^{(k-1)}\beta-\boldsymbol{y}^{(k-1)}\right\|^{2} \Longrightarrow\alpha_{k}^{1}=\frac{\left(s^{(k-1)}\right)^{T}s^{(k-1)}}{\left(s^{(k-1)}\right)^{T} \boldsymbol{y}^{(k-1)}}\\\alpha_{k}=\underset{\alpha}{\arg \min }\frac{1}{2}\left\|s^{(k-1)}-\boldsymbol{y}^{(k-1)} \alpha\right\|^{2}\Longrightarrow\alpha_{k}^{2}=\frac{\left(\boldsymbol{s}^{(k-1)}\right)^{T}\boldsymbol{y}^{(k-1)}}{\left(\boldsymbol{y}^{(k-1)}\right)^{T}\boldsymbol{y}^{(k-1)}}\]</span> 这两个解有一个微妙的不同点在于 <spanclass="math inline">\(\alpha_k^1\)</span> 的分母 <spanclass="math inline">\(\left(s^{(k-1)}\right)^{T}\boldsymbol{y}^{(k-1)}\)</span> 有可能等于 0，这会给计算带来麻烦，而<span class="math inline">\(\alpha_k^2\)</span> 则不会。</p><p>BB方法主要有以下几个特点：</p><ol type="1"><li>几乎不需要额外的计算量，但是往往会带来极大的性能增益；</li><li>实际应用中这两个表达式用哪个都可以，甚至还可以交换使用，用哪个更好一般与具体的问题有关；</li><li>收敛性很难证明，没有收敛性的保证。比如下面的例子，他甚至不是单调下降的。</li></ol><figure><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2020/15-bb.PNG"alt="BB method" /><figcaption aria-hidden="true">BB method</figcaption></figure>]]></content>
    
    
    <categories>
      
      <category>Convex Optimization</category>
      
    </categories>
    
    
    <tags>
      
      <tag>利普希兹连续</tag>
      
      <tag>co-coercivity</tag>
      
      <tag>强凸函数</tag>
      
      <tag>梯度下降</tag>
      
      <tag>线搜索</tag>
      
      <tag>BB方法</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>凸优化笔记14：SDP Representablity</title>
    <link href="/2020/04/05/optimization/ch14-sdp-rep/"/>
    <url>/2020/04/05/optimization/ch14-sdp-rep/</url>
    
    <content type="html"><![CDATA[<p>这一节简单介绍一个 SDPRepresentablity（SDP-Rep），这个概念的提出主要是为了便于判断某个问题是否可以转化为SDP 优化问题。</p><p><strong>定义</strong>：<strong>集合</strong> <spanclass="math inline">\(X\subseteq R^n\)</span> 是<strong>SDP-Rep</strong> 的，如果他可以表示为 <spanclass="math display">\[X=\{x| \text{there exist }u\in R^k \text{ such that for some }\\A_i,B_j,C\in R^{m\times m}:\sum_i x_iA_i+\sum_j u_jB_j +C \succeq0 \}\]</span> 注：它实际上就是下面集合的一个子空间投影 <spanclass="math display">\[\{(x,u)|\sum_i x_iA_i+\sum_j u_jB_j +C \succeq0\}\]</span> 这个定义实际上说明了集合 <spanclass="math inline">\(X\)</span> 可以用一个 LMI 表示，因而如果 <spanclass="math inline">\(X\)</span>为优化问题的定义域，则该定义域可以用一个 SDP 约束条件来表示。例如：如果<span class="math inline">\(X\)</span> 为 SDP-Rep，则 <spanclass="math inline">\(\min_{x\in X}c^Tx\)</span> 是一个 SDP 问题。</p><p><strong>定义</strong>：如果如果<strong>函数</strong> <spanclass="math inline">\(f(x)\)</span> 的 epigraph 是 SDP-Rep 的，那么函数<span class="math inline">\(f(x)\)</span> 就是 <strong>SDP-Rep</strong><span class="math display">\[\text{epi}(f)=\{(x_0,x)|f(x)\le x_0\}\]</span> 该定义表明，如果 <span class="math inline">\(f(x)\)</span> 为SDP-Rep，则优化问题 <span class="math inline">\(\min_x f(x)\)</span>是一个 SDP 问题。</p><p>对 SDP-Rep 集合进行一些变换之后仍然是 SDP-Rep 的：如果 <spanclass="math inline">\(X,Y\)</span> 都是 SDP-Rep 的</p><ul><li>Minkowski sum <span class="math inline">\(X+Y\)</span></li><li>intersection <span class="math inline">\(X\cap Y\)</span></li><li>Affine pre-image <span class="math inline">\(A^{-1}(X)\)</span> if<span class="math inline">\(A\)</span> is affine</li><li>Affine map <span class="math inline">\(A(X)\)</span> if <spanclass="math inline">\(A\)</span> is affine</li><li>Cartesian product <span class="math inline">\(X\times Y=\{(x,y)|x\inX,y\in Y\}\)</span></li></ul>]]></content>
    
    
    <categories>
      
      <category>Convex Optimization</category>
      
    </categories>
    
    
    <tags>
      
      <tag>SDP</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>凸优化笔记13：互补性条件</title>
    <link href="/2020/03/27/optimization/ch13-complementary/"/>
    <url>/2020/03/27/optimization/ch13-complementary/</url>
    
    <content type="html"><![CDATA[<p>前面我们讲了凸优化问题、对偶原理、拉格朗日函数、KKT条件，还从几何角度解释了强对偶性，那么这一节将从<strong>代数角度解释强对偶性</strong>，并给出KKT 条件中的<strong>互补性条件</strong>的新的表达形式。</p><span id="more"></span><h2 id="lp-socp-sdp">1. LP / SOCP / SDP</h2><p>在此之前我们先回顾一下比较重要的三类凸优化问题：LP、SOCP、SDP，为什么这么说呢？因为本质上这三类问题非常相似。我们先来回顾一下三类问题<span class="math display">\[\begin{aligned}LP:\quad \text{minimize} \quad&amp; c^{T} x\\\text{subject to} \quad&amp; A x=b \\&amp; x \succeq 0\qquad(\bigstar)\\SOCP:\quad \text {minimize} \quad&amp; c^{T} x \\\text{subject to} \quad&amp; Ax=b \\&amp; \left\|\bar{x}\right\|_{2} \leq x_0\iff x=(x_0,\bar{x})\succeq_Q 0 \qquad(\bigstar)\\SDP:\quad\text{minimize} \quad&amp; \left&lt;C,X\right&gt;\triangleq tr(CX) \quadX\in S^n \\\text{subject to} \quad&amp; A(X)=b \\&amp; X \succeq 0\qquad(\bigstar)\\\end{aligned}\]</span> 注：上面 SDP 中定义了矩阵内积 <spanclass="math inline">\(\left&lt;C,X\right&gt;\triangleqtr(CX)\)</span>，这跟向量内积非常类似，而且可以交换 <spanclass="math inline">\(\left&lt;C,X\right&gt;=\left&lt;X,C\right&gt;\)</span>；还定义了算子<spanclass="math inline">\(A(X)=\left(\left&lt;A_1,X\right&gt;,\cdots,\left&lt;A_n,X\right&gt;\right)\)</span>。</p><p>上面三种凸优化问题中，不等式约束都用星号标记出来了，可以看出，他们的形式非常相似，其实都是在不同维度的<strong>正常锥</strong>里面。不过LP 的可行域为多面体，最优解往往位于极值点，因此较为简单；但是 SOCP的可行域则是一个多面体与一个锥的交集，同样的 SDP 和 SOCP 的可行域都是Nonpolyhedral 的，这就使他们比 LP 要更难求解。</p><h2 id="强对偶性的代数解释">2. 强对偶性的代数解释</h2><p>考虑 <strong>LP</strong> 问题及其对偶问题 <spanclass="math display">\[\begin{aligned}(P):\quad \text{minimize} \quad&amp; c^{T} x \\\text{subject to} \quad&amp; A x=b \\&amp; x \succeq 0 \\(D):\quad \text {maximize} \quad&amp; b^Ty\\\text {subject to} \quad&amp; A^Ty+s=c \\&amp; s\succeq0\end{aligned}\]</span> 那么原问题与对偶问题的 <strong>duality gap</strong> 就是 <spanclass="math display">\[c^Tx - b^Ty = x^Ts\]</span> 我们很容易验证 <spanclass="math inline">\(x^Ts\ge0\)</span>，也就是弱对偶性。如果满足<strong>强对偶性(Strongduality)</strong>的话，应该有 <span class="math display">\[x^Ts=0 \iff x_is_i=0,i=1,...,n\]</span> 那么我们再来回顾一下 KKT 条件的 4 个部分：</p><ol type="1"><li>Primal feasibility：<spanclass="math inline">\(Ax=b,x\ge0\)</span></li><li>Dual feasibility：<spanclass="math inline">\(A^Ty+s=c,s\ge0\)</span></li><li>Complementarity：<spanclass="math inline">\(x_is_i=0,i=1,...,n\)</span></li><li>梯度条件包含在对偶可行性里面了</li></ol><p>因此实际上利用上面 3 个约束就可以求解最优解了。对于上面的互补性条件<span class="math inline">\(x_is_i=0\)</span> 我们可以定义一个算子 <spanclass="math display">\[x\circ s := (x_1s_1,...,x_ns_n)^T = \text{diag}(x)s:=L_xs=L_xL_s\mathbf{1}\]</span> 它满足 <span class="math inline">\(x\circ\mathbf{1}=x\)</span>。这里其实只是定义了一个新的符号，并没有引入新的东西，之所以这么做是为了与后面的SOCP、SDP 统一起来用类似的符号表示，便于计算机进行优化计算。</p><p>现在我们再来看看 <strong>SOCP</strong> 问题 <spanclass="math display">\[\begin{aligned}(P):\quad \text {minimize} \quad&amp; c^{T} x \\\text {subject to} \quad&amp; Ax=b \\&amp; x\succeq_Q 0 \\(D):\quad \text {maximize} \quad&amp; b^{T} y \\\text {subject to} \quad&amp; A^Ty+s=c \\&amp; s\succeq_Q 0\end{aligned}\]</span></p><blockquote><p><strong>Remarks</strong>：注意<strong>二阶锥(Second ordercone)</strong>的对偶锥还是其自身。</p><p>对偶锥是其自身怎么直观理解呢？大家想象三维中的这样一个锥，我们任取一个过锥的顶点<spanclass="math inline">\((0,0,0)\)</span>的竖直平面，切出来的是应该一个直角吧。那么假如说我们考虑任意的锥呢？切出来的这个角如果不是直角，假如是钝角，那么他的对偶锥一定不是其自身，要比自身“小”，锐角也类似。这里提到这个直观理解在后面会用到。</p><figure><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2020/norm_cone.PNG"alt="SOC" /><figcaption aria-hidden="true">SOC</figcaption></figure></blockquote><p>同样的我们可以得到 dualligity gap 为 <span class="math display">\[x^Ts=c^Tx-b^Ty\ge0\]</span> 如果想得到强对偶性则需要 <span class="math display">\[\begin{aligned}&amp; x^Ts=0,x\succeq_Q 0,s\succeq_Q 0 \\\iff&amp;x_0s_i+x_is_0=0,i=1,...,n \\\iff&amp;x_0\bar{s}+s_0\bar{x}=0\end{aligned}\]</span> 上面这个证明可以利用 Cauchy-Schwarz 不等式 <spanclass="math inline">\(x^Ts=x_0s_0+\sum_ix_is_i\ge0\)</span>，取等条件即为上式。这从几何角度理解就如下图，其中<span class="math inline">\(x,s\)</span> 为正交的，而且他们向后 <spanclass="math inline">\(R^n\)</span> 维子空间的投影 <spanclass="math inline">\(\bar{x},\bar{s}\)</span> 是反向平行的。</p><figure><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2020/13-cone.PNG"alt="SOC" /><figcaption aria-hidden="true">SOC</figcaption></figure><blockquote><p><strong>Remarks</strong>：<span class="math inline">\(x,s\)</span>均为锥 <span class="math inline">\(Q\)</span> 当中的向量，二者内积为0，则表明他们<strong>相互正交</strong>。假如我们固定了 <spanclass="math inline">\(x\)</span>，<span class="math inline">\(x\)</span>作为法向量定义了一个超平面 <spanclass="math inline">\(A\)</span>，超平面内的任意一个向量都应垂直于 <spanclass="math inline">\(x\)</span>，所里直观理解的话 <spanclass="math inline">\(x\)</span>应该有无穷多个单位正交向量。但是根据上面的结果，<spanclass="math inline">\(s=(s_0,s_0\bar{x}/x_0)\)</span>只有一个方向，这说明锥 <span class="math inline">\(Q\)</span>内部只有一个方向上的向量与 <span class="math inline">\(x\)</span>正交！也就是说超平面 <span class="math inline">\(A\)</span> 与锥 <spanclass="math inline">\(Q\)</span> 的交集是一条线，实际上就是说 <spanclass="math inline">\(A\)</span> 与 <spanclass="math inline">\(Q\)</span> <strong>相切</strong>！</p><p>再回想一下我们前面提到这个锥 <span class="math inline">\(Q\)</span>的顶角应该是一个直角，假如 <span class="math inline">\(x\)</span> 位于<span class="math inline">\(Q\)</span> 的内部（不在边界上），那么 <spanclass="math inline">\(A\cap Q=\{(0,0,0)\}\)</span>，只有一个点，<spanclass="math inline">\(s\)</span> 也就不存在。所以如果想要 <spanclass="math inline">\(x^Ts=0\)</span> 有非零解，就<strong>一定要求 <spanclass="math inline">\(x\)</span> 在 <spanclass="math inline">\(Q\)</span> 的边界上</strong>，这个时候实际上就有<spanclass="math inline">\(x_0=\Vert\bar{x}\Vert,s_0=\Vert\bar{s}\Vert\)</span>。这一点很容易从我们上面的式子 <spanclass="math inline">\(x_0s_i+x_is_0=0\)</span> 得到验证。</p></blockquote><p>同样得回顾一下 KKT 条件</p><ol type="1"><li><span class="math inline">\(Ax=b,x\succeq_Q0\)</span></li><li><span class="math inline">\(A^Ty+s=c,s\succeq_Q0\)</span></li><li><span class="math inline">\(x^Ts=0,\quadx_0s_i+x_is_0=0\)</span></li></ol><p>这里再定义一个算子 <span class="math display">\[x\circ s = \left(\begin{array}{c}x_{0} \\x_{1} \\\vdots\\x_{n}\end{array}\right) \circ\left(\begin{array}{c}s_{0} \\s_{1}\\\vdots \\s_{n}\end{array}\right)=\left(\begin{array}{c}x^{\top} s\\x_{0} s_{1}+s_{0} x_{1} \\\vdots \\x_{0} s_{n}+s_{0}x_{n}\end{array}\right) \\\]</span> 为了简化表示可以写成下面的形式，这样跟 LP 就统一了。 <spanclass="math display">\[L_{x}=\operatorname{Arw}(x)=\left(\begin{array}{ll}x_{0} &amp;\bar{x}^{\top} \\\bar{x} &amp; x_{0} I\end{array}\right) \notag\\x \circs=\operatorname{Arw}(x) s=\operatorname{Arw}(x) \operatorname{Arw}(s) e\]</span> 算子满足性质</p><ol type="1"><li><span class="math inline">\(x\circ s = s\circ x\)</span></li><li><span class="math inline">\(x\circ(x\circ x)=(x\circ x)\circx\)</span></li><li><span class="math inline">\(x \circ\left(x^{2} \circ y\right)=x^{2}\circ(x \circ y)\)</span></li><li><span class="math inline">\(e=(1,0,...,0)^T,x\circ e=x\)</span></li></ol><p>但是注意不满足结合律 <span class="math inline">\(x \circ(y \circ z)\neq(x \circ y) \circ z\)</span> 。</p><p>最后我们再来看看 <strong>SDP</strong> 问题及其对偶问题 <spanclass="math display">\[\begin{aligned}(P):\quad \text{minimize} \quad&amp;\left&lt;C,X\right&gt; \\\text{subject to} \quad&amp;\left&lt;A_i,X\right&gt;=b_i,i=1,...,m \\&amp; X \succeq 0\\(D):\quad\text{minimize} \quad&amp; b^Ty \\\text{subject to} \quad&amp; \sum_iy_iA_i+S=C \\&amp; S\succeq 0\end{aligned}\]</span> 同样的 duality gap 为 <span class="math display">\[\begin{aligned}\left&lt;X,S\right&gt; &amp;= \left&lt;C,X\right&gt; -b^Ty \\&amp;= \left&lt;X,S^{1/2}S^{1/2}\right&gt; =\left&lt;S^{1/2}X,S^{1/2}\right&gt; \ge0\end{aligned}\]</span> <strong>强对偶性</strong>则要求 <span class="math display">\[X\succeq0,S\succeq0,\left&lt;X,S\right&gt;=0 \iff XS=0 \iff\frac{XS+SX}{2}=0\]</span> 证明：<spanclass="math inline">\(\left&lt;X,S\right&gt;=\left&lt;S^{1/2}X^{1/2},X^{1/2}S^{1/2}\right&gt;=0\iff X^{1/2}S^{1/2}=0\)</span></p><p>为了简化表达，我们再定义一个算子 <span class="math inline">\(X\circS=\frac{XS+SX}{2}\)</span>，它满足以下性质</p><ol type="1"><li><span class="math inline">\(X\circ S = S\circ X\)</span></li><li><span class="math inline">\(X\circ(X\circ X)=(X\circ X)\circX\)</span></li><li><span class="math inline">\(X \circ\left(X^{2} \circ Y\right)=X^{2}\circ(X \circ Y)\)</span></li><li><span class="math inline">\(X\circ I = X\)</span></li></ol><p>注意不满足结合律 <span class="math inline">\(X \circ(Y \circ Z)\neq(X \circ Y) \circ Z\)</span></p><p>再来复习一下 KKT 条件</p><ol type="1"><li><spanclass="math inline">\(\left&lt;A_i,X\right&gt;=b_i\)</span></li><li><span class="math inline">\(\sum_i y_iA_i+S=C\)</span></li><li><span class="math inline">\(X\circ S=0\)</span></li></ol><p>最后我们总结一下</p><figure><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2020/13-comple.jpg"alt="summary" /><figcaption aria-hidden="true">summary</figcaption></figure>]]></content>
    
    
    <categories>
      
      <category>Convex Optimization</category>
      
    </categories>
    
    
    <tags>
      
      <tag>KKT条件</tag>
      
      <tag>互补性条件</tag>
      
      <tag>LP</tag>
      
      <tag>SOCP</tag>
      
      <tag>SDP</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>凸优化笔记12：KKT 条件</title>
    <link href="/2020/03/26/optimization/ch12-kkt/"/>
    <url>/2020/03/26/optimization/ch12-kkt/</url>
    
    <content type="html"><![CDATA[<p>上一小节讲了拉格朗日函数，可以把原始问题转化为对偶问题，并且对偶问题是凸的。我们还得到了弱对偶性和强对偶性的概念，并且提到了Slater Condition保证凸问题的强对偶性成立，并且给出了一些几何的直观解释。那么在这一节，我们将引出著名的<strong>KKT条件</strong>，它给出了最优解需要满足的必要条件，是求解优化问题最优解的一个重要方式。</p><span id="more"></span><h2 id="kkt-条件">1. KKT 条件</h2><p>我们首先回顾一下拉格朗日函数，考虑下面的优化问题 <spanclass="math display">\[\begin{aligned}\text { minimize } \quad&amp; f_{0}(x)\\\text { subject to } \quad&amp; f_{i}(x) \leq 0, \quad i=1, \ldots, m\\&amp;h_{i}(x)=0, \quad i=1, \ldots, p\end{aligned}\]</span> 那么他的拉格朗日函数就是 <span class="math display">\[L(x,\lambda,\nu)=f_0(x)+\lambda^Tf(x)+\nu^Th(x)\]</span> 首先，我们看对偶函数 <span class="math display">\[g(\lambda,\nu)=\inf_{x\in\mathcal{D}}\left(f_0(x)+\lambda^Tf(x)+\nu^Th(x)\right)\]</span> 对偶问题实际上就是 <span class="math display">\[d^\star = \sup_{\lambda,\nu}g(\lambda,\nu)=\sup_{\lambda,\nu}\inf_xL(x,\lambda,\nu)\]</span> 然后我们再看原问题，由于 <spanclass="math inline">\(\lambda\succeq0,f(x)\preceq0\)</span>，我们有<span class="math display">\[f_0(x)=\sup_{\lambda,\nu}L(x,\lambda,\nu)\]</span> 原问题的最优解实际上就是 <span class="math display">\[p^\star=\inf_x f_0(x)= \inf_x \sup_{\lambda,\nu}L(x,\lambda,\nu)\]</span> <strong>弱对偶性</strong> <span class="math inline">\(p^\star\ge d^\star\)</span> 实际上说的是什么呢？就是 <strong>max-min不等式</strong> <span class="math display">\[\inf_x \sup_{\lambda,\nu}L(x,\lambda,\nu) \ge \sup_{\lambda,\nu}\inf_xL(x,\lambda,\nu)\]</span> <strong>强对偶性</strong>说的又是什么呢？就是上面能够取等号<span class="math display">\[\inf_x \sup_{\lambda,\nu}L(x,\lambda,\nu) = \sup_{\lambda,\nu}\inf_xL(x,\lambda,\nu) = L({x}^\star,{\lambda}^\star,{\nu}^\star)\]</span> 实际上 <spanclass="math inline">\({x}^\star,{\lambda}^\star,{\nu}^\star\)</span>就是<strong>拉格朗日函数的鞍点</strong>！！！（数学家们真实太聪明了！！！妙啊！！！）那么也就是说<strong>强对偶性成立等价于拉格朗日函数存在鞍点(在定义域内)</strong>。</p><p>好，如果存在鞍点的话，我们怎么求解呢？还是看上面取等的式子 <spanclass="math display">\[\begin{aligned}f_0({x}^\star) = g(\lambda^\star,\nu^\star) &amp;= \inf_x \left(f_0(x)+\lambda^{\star T}f(x)+\nu^{\star T}h(x) \right) \\&amp; \le f_0(x^\star)+\lambda^{\star T}f(x^\star)+\nu^{\starT}h(x^\star) \\&amp; \le f_0(x^\star)\end{aligned}\]</span> 这两个不等号必须要取到等号，而第一个不等号取等条件应为 <spanclass="math display">\[\nabla_x \left( f_0(x)+\lambda^{\star T}f(x)+\nu^{\star T}h(x) \right)=0\]</span> 第二个不等号取等条件为 <span class="math display">\[\lambda^\star_i f_i(x^\star)=0,\forall i\]</span> 同时，由于 <spanclass="math inline">\({x}^\star,{\lambda}^\star,{\nu}^\star\)</span>还必须位于定义域内，需要满足约束条件，因此上面的几个条件共同构成了 KKT条件。</p><blockquote><p><strong>KKT 条件</strong></p><ol type="1"><li>原始约束 <span class="math inline">\(f_i(x)\le0,i=1,...,m, \quadh_i(x)=0,i=1,...,p\)</span></li><li>对偶约束 <span class="math inline">\(\lambda\succeq0\)</span></li><li>互补性条件(complementary slackness) <spanclass="math inline">\(\lambda_i f_i(x)=0,i=1,...,m\)</span></li><li>梯度条件</li></ol><p><span class="math display">\[\nabla f_{0}(x)+\sum_{i=1}^{m} \lambda_{i} \nablaf_{i}(x)+\sum_{i=1}^{p} \nu_{i} \nabla h_{i}(x)=0\]</span></p></blockquote><h2 id="kkt-条件与凸问题">2. KKT 条件与凸问题</h2><blockquote><p><strong>Remarks(重要结论)</strong></p><ol type="1"><li>前面推导没有任何凸函数的假设，因此不论是否为凸问题，<strong>如果满足强对偶性，那么最优解一定满足KKT 条件</strong>。</li><li>但是反过来不一定成立，也即 <strong>KKT条件的解不一定是最优解</strong>，因为如果 <spanclass="math inline">\(L(x,\lambda^\star,\nu^\star)\)</span>不是凸的，那么 <span class="math inline">\(\nabla_x L=0\)</span>并不能保证 <span class="math inline">\(g(\lambda^\star,\nu^\star)=\inf_xL(x,\lambda^\star,\nu^\star)\neL(x^\star,\lambda^\star,\nu^\star)\)</span>，也即不能保证 <spanclass="math inline">\({x}^\star,{\lambda}^\star,{\nu}^\star\)</span>就是鞍点。</li></ol></blockquote><p>但是如果我们假设原问题为凸问题的话，那么 <spanclass="math inline">\(L(x,\lambda^\star,\nu^\star)\)</span>就是一个凸函数，由梯度条件 <span class="math inline">\(\nabla_xL=0\)</span> 我们就能得到 <spanclass="math inline">\(g(\lambda^\star,\nu^\star)=L(x^\star,\lambda^\star,\nu^\star)=\inf_xL(x,\lambda^\star,\nu^\star)\)</span>，另一方面根据互补性条件我们有此时<spanclass="math inline">\(f_0(x^\star)=L(x^\star,\lambda^\star,\nu^\star)\)</span>，因此我们可以得到一个结论</p><blockquote><p><strong>Remarks(重要结论)</strong>：</p><ol type="1"><li>考虑原问题为凸的，那么若 KKT 条件有解 <spanclass="math inline">\(\tilde{x},\tilde{\lambda},\tilde{\nu}\)</span>，则原问题一定满足强对偶性，且他们就对应原问题和对偶问题的最优解。</li><li>但是需要注意的是，KKT条件可能无解！此时就意味着原问题不满足强对偶性！</li></ol></blockquote><p>假如我们考虑上一节提到的 SCQ 条件，如果凸优化问题满足 SCQ条件，则意味着强对偶性成立，则此时有结论</p><blockquote><p><strong>Remarks(重要结论)</strong>：</p><p>如果 SCQ 满足，那么 <span class="math inline">\(x\)</span>为最优解<strong>当且仅当</strong>存在 <spanclass="math inline">\(\lambda,\nu\)</span> 满足 KKT 条件！</p></blockquote><p><strong><em>例子 1</em></strong>：等式约束的二次优化问题 <spanclass="math inline">\(P\in S_+^n\)</span> <span class="math display">\[\begin{aligned}\text { minimize } \quad&amp; (1/2)x^TPx+q^Tx+r \\\text { subject to } \quad&amp; Ax=b\end{aligned}\]</span> 那么经过简单计算就可以得到 KKT 条件为 <spanclass="math display">\[\left[\begin{array}{cc}P &amp; A^{T} \\A &amp; 0\end{array}\right]\left[\begin{array}{l}x^{\star} \\\nu^{\star}\end{array}\right]=\left[\begin{array}{c}-q \\b\end{array}\right]\]</span> <strong><em>例子 2</em></strong>：注水问题 <spanclass="math display">\[\begin{aligned}&amp;\text { minimize } \quad-\sum_{i=1}^{n} \log\left(\alpha_{i}+x_{i}\right)\\&amp;\text { subject to } \quad x \succeq 0, \quad \mathbf{1}^{T} x=1\end{aligned}\]</span> 根据上面的结论，<span class="math inline">\(x\)</span>是最优解当且仅当 <span class="math inline">\(x\succeq0,\mathbf{1}^{T}x=1\)</span>，且存在 <span class="math inline">\(\lambda,\nu\)</span>满足 <span class="math display">\[\lambda \succeq 0, \quad \lambda_{i} x_{i}=0, \quad\frac{1}{x_{i}+\alpha_{i}}+\lambda_{i}=\nu\]</span> 根据互补性条件 <span class="math inline">\(\lambda_ix_i=0\)</span> 分情况讨论可以得到</p><ul><li>如果 <span class="math inline">\(\nu&lt;1/\alpha_i\)</span>：<spanclass="math inline">\(\lambda_i=0,x_i=1/\nu-\alpha_i\)</span></li><li>如果 <span class="math inline">\(\nu\ge1/\alpha_i\)</span>：<spanclass="math inline">\(\lambda_i=\nu-1/\alpha_i,x_i=0\)</span></li></ul><p>整理就可以得到 <span class="math inline">\(\mathbf{1}^{T}x=\sum_i\max\{0,1/\nu-\alpha_i\}\)</span>，这个式子怎么理解呢？就像向一个池子里注水一样</p><figure><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2020/12-water.png"alt="water filling" /><figcaption aria-hidden="true">water filling</figcaption></figure><h2 id="扰动与敏感性分析">3. 扰动与敏感性分析</h2><p>现在我们再回到原始问题 <span class="math display">\[\begin{aligned}\text { minimize } \quad&amp; f_{0}(x)\\\text { subject to } \quad&amp; f_{i}(x) \leq 0, \quad i=1, \ldots, m\\&amp;h_{i}(x)=0, \quad i=1, \ldots, p\end{aligned}\]</span> 我们引入了对偶函数 <spanclass="math inline">\(g(\lambda,\nu)\)</span>，那这两个参数 <spanclass="math inline">\(\lambda,\nu\)</span>有什么含义吗？假如我们把原问题放松一下 <span class="math display">\[\begin{aligned}\text { minimize } \quad&amp; f_{0}(x)\\\text { subject to } \quad&amp; f_{i}(x) \leq u_i, \quad i=1, \ldots,m\\&amp;h_{i}(x)=v_i, \quad i=1, \ldots, p\end{aligned}\]</span> 记最优解为 <span class="math inline">\(p^\star(u,v)=\minf_0(x)\)</span>，现在对偶问题变成了 <span class="math display">\[\begin{aligned}\max \quad&amp;  g(\lambda,\nu)-u^T\lambda -v^T\nu\\\text{s.t.} \quad&amp; \lambda\succeq0\end{aligned}\]</span> 假如说原始对偶问题的最优解为 <spanclass="math inline">\(\lambda^\star,\nu^\star\)</span>，松弛后的对偶问题最优解为<spanclass="math inline">\(\tilde{\lambda},\tilde{\nu}\)</span>，那么根据弱对偶性原理，有<span class="math display">\[\begin{aligned}p^\star(u,v) &amp;\ge g(\tilde\lambda,\tilde\nu)-u^T\tilde\lambda-v^T\tilde\nu \\&amp;\ge g(\lambda^\star,\nu^\star)-u^{T}\lambda^\star -v^{T}\nu^\star\\&amp;= p^\star(0,0) - u^{T}\lambda^\star -v^{T}\nu^\star\end{aligned}\]</span> 这像不像关于 <span class="math inline">\(u,v\)</span>的一阶近似？太像了！实际上，我们有 <span class="math display">\[\lambda_{i}^{\star}=-\frac{\partial p^{\star}(0,0)}{\partial u_{i}},\quad \nu_{i}^{\star}=-\frac{\partial p^{\star}(0,0)}{\partial v_{i}}\]</span> <imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2020/12-sensitivity.PNG"alt="sensitivity" /></p><h2 id="reformulation">4. Reformulation</h2><p>前面将凸优化问题的时候，我们提到了Reformulation的几个方法来简化原始问题，比如消去等式约束，添加等式约束，添加松弛变量，epigraph等等。现在当我们学习了对偶问题，再来重新看一下这些方法。</p><h3 id="引入等式约束">4.1 引入等式约束</h3><p><strong><em>例子 1</em></strong>：考虑无约束优化问题 <spanclass="math inline">\(\minf(Ax+b)\)</span>，他的对偶问题跟原问题是一样的。如果我们引入等式约束，原问题和对偶问题变为<span class="math display">\[\begin{aligned}\text{minimize} \quad&amp; f_{0}(y) \quad \\\text{subject to} \quad&amp; A x+b-y=0\end{aligned}\quad\qquad\begin{aligned}\text{minimize} \quad&amp; b^{T} \nu-f_{0}^{*}(\nu) \\\text{subject to} \quad&amp; A^{T} \nu=0\end{aligned}\]</span> <strong><em>例子 2</em></strong>：考虑无约束优化 <spanclass="math inline">\(\min \VertAx-b\Vert\)</span>，类似的引入等式约束后，对偶问题变为 <spanclass="math display">\[\begin{aligned}\text{minimize} \quad&amp; b^{T} \nu \\\text{subject to} \quad&amp; A^{T} \nu=0,\quad \Vert\nu\Vert_*\le1\end{aligned}\]</span></p><h3 id="显示约束与隐式约束的相互转化">4.2显示约束与隐式约束的相互转化</h3><strong><em>例子3</em></strong>：考虑原问题如下，可以看出来对偶问题非常复杂 $$<span class="math display">\[\begin{aligned}\text{minimize} \quad&amp; c^{T} x \\\text{subject to} \quad&amp; A x=b \\\quad&amp; -1 \preceq x \preceq 1\end{aligned}\]</span><span class="math display">\[\begin{aligned}\text{maximize} \quad&amp; -b^{T} \nu-\mathbf{1}^{T}\lambda_{1}-\mathbf{1}^{T} \lambda_{2} \\\text{subject to} \quad&amp; c+A^{T} \nu+\lambda_{1}-\lambda_{2}=0 \\\quad&amp; \lambda_{1} \succeq 0, \quad \lambda_{2} \succeq 0\end{aligned}\]</span><span class="math display">\[如果我们原问题的不等式约束条件转化为隐式约束，则有\]</span><span class="math display">\[\begin{aligned}\text{minimize} \quad&amp; f_{0}(x)=\left\{\begin{array}{ll}c^{T} x&amp; \Vert x\Vert_\infty \preceq 1 \\ \infty &amp; \text { otherwise}\end{array}\right. \\\text{subject to} \quad&amp; A x=b\end{aligned}\]</span><p><span class="math display">\[然后对偶问题就可以转化为无约束优化问题\]</span> -b<sup>T-A</sup>T+c_1 $$</p><h3 id="转化目标函数与约束函数">4.3 转化目标函数与约束函数</h3><p><strong><em>例子 4</em></strong>：还考虑上面提到的无约束优化问题<span class="math inline">\(\min \VertAx-b\Vert\)</span>，我们可以把目标函数平方一下，得到 <spanclass="math display">\[\begin{aligned}\text{minimize} \quad&amp; (1/2)\Vert y\Vert^2 \\\text{subject to} \quad&amp; Ax-b=y\end{aligned}\]</span> 然后对偶问题就可以转化为 <span class="math display">\[\begin{aligned}\text{minimize} \quad&amp; (1/2)\Vert \nu\Vert_*^2+ b^T\nu \\\text{subject to} \quad&amp; A^T\nu=0\end{aligned}\]</span></p>]]></content>
    
    
    <categories>
      
      <category>Convex Optimization</category>
      
    </categories>
    
    
    <tags>
      
      <tag>对偶原理</tag>
      
      <tag>拉格朗日函数</tag>
      
      <tag>KKT条件</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>凸优化笔记 11：对偶原理 &amp; 拉格朗日函数</title>
    <link href="/2020/03/18/optimization/ch11-dual/"/>
    <url>/2020/03/18/optimization/ch11-dual/</url>
    
    <content type="html"><![CDATA[<p>前面讲了凸优化问题的定义，以及一些常见的凸优化问题类型，这一章就要引入著名的拉格朗日函数和对偶问题了。通过对偶问题，我们可以将一些非凸问题转化为凸优化问题，还可以求出原问题的非平凡下界，这对复杂优化问题是很有用的。</p><span id="more"></span><h2 id="拉格朗日函数">1. 拉格朗日函数</h2><p>考虑凸优化问题 <span class="math display">\[\begin{aligned}\text { minimize } \quad&amp; f_{0}(x)\\\text { subject to } \quad&amp; f_{i}(x) \leq 0, \quad i=1, \ldots, m\\&amp;h_{i}(x)=0, \quad i=1, \ldots, p\end{aligned}\]</span> 假设 <span class="math inline">\(x\in R^n\)</span>，定义域为<span class="math inline">\(\mathcal{D}\)</span>，最优解为 <spanclass="math inline">\(p^\star\)</span>。</p><p>我们定义<strong>拉格朗日函数(Lagrangian)</strong>为 <spanclass="math inline">\(L:R^n\times R^m\times R^p\to R\)</span>，<spanclass="math inline">\(\text{dom}L=\mathcal{D}\times R^m\timesR^p\)</span> <span class="math display">\[L(x,\lambda,\nu)=f_0(x)+\lambda^Tf(x)+\nu^Th(x)\]</span> 再取下确界得到<strong>拉格朗日对偶函数(Lagrange dualfunction)</strong> <span class="math inline">\(g:R^m\times R^p\toR\)</span> <span class="math display">\[g(\lambda,\nu)=\inf_{x\in\mathcal{D}}\left(f_0(x)+\lambda^Tf(x)+\nu^Th(x)\right)\]</span> 这个拉格朗日对偶函数可不得了啦！他有两个很重要的性质：</p><blockquote><ol type="1"><li><span class="math inline">\(g(\lambda,\nu)\)</span>是<strong>凹函数</strong>（不论原问题是否为凸问题）</li><li>如果 <span class="math inline">\(\lambda\succeq 0\)</span>，那么<span class="math inline">\(g(\lambda,\nu)\le p^\star\)</span>（对任意<span class="math inline">\(\lambda\succeq0,\nu\)</span> 都成立）</li></ol></blockquote><p><strong>Remarks</strong>：上面两个性质为什么重要呢？首先由于 <spanclass="math inline">\(g(\lambda,\nu)\lep^\star\)</span>，这可以给出原问题最优解的一个<strong>不平凡下界</strong>，这意味着如果原问题很难求解的时候，我们可以转变思路，求解一个新的优化问题：<span class="math display">\[\begin{aligned}\text { maximize } \quad&amp; g(\lambda,\nu)\\\text { subject to } \quad&amp; \lambda\succeq0\end{aligned}\]</span>另一方面，由于不论原函数是否为凸优化问题，新的问题都是凸的，因此可以方便求解。下面举几个例子。</p><p><strong><em>例子 1</em></strong>：原问题为 <spanclass="math display">\[\begin{aligned}\text { maximize } \quad&amp; x^Tx\\\text { subject to } \quad&amp; Ax=b\end{aligned}\]</span> 那么可以很容易得到拉格朗日函数为 <spanclass="math inline">\(L(x,\nu)=x^Tx+\nu^T(Ax-b)\)</span>，对偶函数为<spanclass="math inline">\(g(\nu)=-(1/4)\nu^TAA^T\nu-b^T\nu\)</span>，也即</p><p><span class="math inline">\(p^\star\ge g(\nu)\)</span>。</p><p><strong><em>例子 2</em></strong>：标准形式的线性规划(LP) <spanclass="math display">\[\begin{aligned}\text { maximize } \quad&amp; c^Tx\\\text { subject to } \quad&amp; Ax=b,\quad x\succeq0\end{aligned}\]</span> 按照定义容易得到对偶问题为 <span class="math display">\[\begin{aligned}\text { maximize } \quad&amp; -b^T\nu\\\text { subject to } \quad&amp; A^T\nu+c\succeq0\end{aligned}\]</span> <strong><em>例子 3</em></strong>：原问题为最小化范数 <spanclass="math display">\[\begin{aligned}\text { maximize } \quad&amp; \Vert x\Vert\\\text { subject to } \quad&amp; Ax=b\end{aligned}\]</span> 对偶函数为 <span class="math display">\[g(\nu)=\inf_{x} (\Vert x\Vert+\nu^T(b-Ax))=\begin{cases}b^T\nu &amp; \Vert A^T\nu\Vert_* \le1 \\ -\infty &amp;o.w.\end{cases}\]</span>这个推导过程中用到了<strong>共轭函数</strong>的知识。实际上上面三个例子都是线性等式约束，这种情况下，我们应用定义推导过程中可以很容易联想到共轭函数。（实际上加上线性不等式约束也可以）</p><p><strong><em>例子 4</em></strong>：(原问题非凸)考虑 Two-waypartitioning (不知道怎么翻译了...) <span class="math display">\[\begin{aligned}\text { maximize } \quad&amp; x^TWx\\\text { subject to } \quad&amp; x_i^2=1,\quad i=1,...,n\end{aligned}\]</span> 对偶函数为 <span class="math display">\[\begin{aligned}g(\nu)&amp;=\inf_{x}\left( x^{T}(W+\operatorname{diag}(\nu)) x\right)-\mathbf{1}^{T} \nu \\&amp;=\left\{\begin{array}{ll}-\mathbf{1}^{T} \nu &amp; W+\operatorname{diag}(\nu) \succeq 0 \\-\infty &amp; \text { otherwise }\end{array}\right.\end{aligned}\]</span> 于是可以给出原问题最优解的下界为 <spanclass="math inline">\(p^\star\ge-\mathbf{1}^{T} \nu\)</span> if <spanclass="math inline">\(W+\operatorname{diag}(\nu) \succeq0\)</span>。这个下界是不平凡的，比如可以取 <spanclass="math inline">\(\nu=-\lambda_{\min}(W)\mathbf{1}\)</span>，可以给出<span class="math inline">\(p^\star\ge n\lambda_{\min}(W)\)</span>。</p><h2 id="对偶问题">2. 对偶问题</h2><p>上面已经多次提到<strong>对偶问题(Lagrange dual problem)</strong>了<span class="math display">\[\begin{aligned}\text { maximize } \quad&amp; g(\lambda,\nu)\\\text { subject to } \quad&amp; \lambda\succeq0\end{aligned}\]</span> 假如对偶问题的最优解为 <spanclass="math inline">\(d^\star=\max g(\lambda,\nu)\)</span>，那么我们有<span class="math inline">\(p^\star \ge d^\star\)</span>。</p><p>现在我们当然想知道什么情况下可以取等号，也即 <spanclass="math inline">\(p^\star =d^\star\)</span>，此时我们只需要求解对偶问题就可以获得原问题的最优解了。在此之前，我们先引入两个概念：强对偶和弱对偶。</p><p><strong>弱对偶(weak duality)</strong>：满足 <spanclass="math inline">\(p^\star \ged^\star\)</span>，原问题不论是否为凸，弱对偶总是成立；</p><p><strong>强对偶(strong duality)</strong>：满足 <spanclass="math inline">\(p^\star =d^\star\)</span>，强对偶并不总是成立，如果原问题为凸优化问题，一般情况下都成立。在凸优化问题中，保证强对偶成立的条件为被称为<strong>constraint qualiﬁcations</strong>。</p><p>有很多种不同的 constraint qualiﬁcations，常用到的一种为<strong>Slater’s constraint qualiﬁcation(SCQ)</strong>，其表述为</p><blockquote><p><strong>SCQ</strong>：对于凸优化问题 <span class="math display">\[\begin{aligned}\text { minimize } \quad&amp; f_{0}(x)\\\text { subject to } \quad&amp; f_{i}(x) \leq 0, \quad i=1, \ldots, m\\&amp;Ax=b\end{aligned}\]</span> 如果存在可行解 <spanclass="math inline">\(x\in\text{int}\mathcal{D}\)</span>，使得 <spanclass="math display">\[Ax=b,\quad f_i(x)&lt;0,\quad,i=1,...,m\]</span> 那么就能保证强对偶性。</p><p><strong>Remarks</strong>：</p><ul><li>由于存在线性等式约束，因此实际定义域可能不存在内点，可以将这一条件放松为相对内点<span class="math inline">\(x\in\text{relint}\mathcal{D}\)</span>；</li><li>如果不等式约束中存在线性不等式，那么他也不必严格小于0。也即如果<span class="math inline">\(f_i(x)=C^Tx+d\)</span>，则只需要满足 <spanclass="math inline">\(f_i(x)\le0\)</span> 即可。</li></ul></blockquote><p>下面再举几个例子，看一看他们的 SCQ 条件是什么。</p><p><strong><em>例子 1</em></strong>：还是考虑线性规划(LP)或者二次规划(QP) <span class="math display">\[\begin{aligned}\text { minimize } \quad&amp; c^Tx \quad(\text{ or }x^TPx)\\\text { subject to } \quad&amp; Ax\preceq b\end{aligned}\]</span> 那么根据 SCQ 可以得到，如果想得到强对偶性，应该有 <spanclass="math inline">\(\exist x, \text{ s.t. } Ax\preceq b\)</span>。</p><p><strong><em>例子 2</em></strong>：(原问题非凸) Trust Region Methods<span class="math display">\[\begin{aligned}\text { minimize } \quad&amp; x^TAx+2b^Tx\\\text { subject to } \quad&amp; x^Tx\le1\end{aligned}\]</span> 其中 <span class="math inline">\(A\nsucceq0\)</span>，因此原问题不是凸的。他的对偶函数就是 <spanclass="math display">\[g(\lambda)=\inf_x\left(x^T\left(A+\lambda I\right)x+2b^Tx-\lambda\right)=\begin{cases}-b^T(A+\lambda I)^\dagger b-\lambda &amp; A+\lambdaI\succeq0,b\in \mathcal{R}(A+\lambda I) \\ -\infty &amp; o.w.\end{cases}\]</span> 注意如果不满足 <span class="math inline">\(A+\lambdaI\succeq0\)</span> 或 <span class="math inline">\(b\in\mathcal{R}(A+\lambda I)\)</span>，则 <spanclass="math inline">\(g(\lambda)\to-\infty\)</span>。那么就可以得到对偶问题为<span class="math display">\[\begin{aligned}\text {maximize} \quad&amp; -b^{T}(A+\lambda I)^{\dagger} b -\lambda\\\text {subject to} \quad&amp; A+\lambda I \succeq 0\\&amp;b \in \mathcal{R}(A+\lambda I)\end{aligned}\]</span> 也可以等价转换为 SDP <span class="math display">\[\begin{aligned}\text {maximize} \quad&amp; -t-\lambda\\\text {subject to}\quad&amp; \left[\begin{array}{cc}A+\lambda I &amp; b\\ b^{T} &amp; t\end{array}\right] \succeq 0\end{aligned}\]</span></p><blockquote><p><strong>Remarks</strong>：这里用到了舒尔补(Schurcomplement)的知识。考虑矩阵 <span class="math display">\[X = \left[\begin{array}{cc}A &amp; B \\ B^{T} &amp; C\end{array}\right]\]</span> 其中 <span class="math inline">\(\detA\ne0,S=C-B^TA^{-1}B\)</span>。那么有以下及条性质：</p><ul><li><span class="math inline">\(X\succ0 \iffA\succ0,S\succ0\)</span></li><li>若 <span class="math inline">\(A\succ0\)</span>，则 <spanclass="math inline">\(X\succeq0 \iff S\succeq 0\)</span></li><li><span class="math inline">\(X\succeq0 \iffA\succeq0,(I-AA^\dagger)B=0,S=C-B^TA^{\dagger}B\succeq0\)</span></li></ul><p>关于第 3 条中的第二个要求 <spanclass="math inline">\((I-AA^\dagger)B=0\)</span>，对 <spanclass="math inline">\(A\)</span> 进行奇异值分解，有 <spanclass="math inline">\(A=U\Sigma V\)</span>，那么我们对任意 <spanclass="math inline">\(v\)</span>，有 <spanclass="math inline">\((I-AA^\dagger)Bv=(I-UU^T)Bv=0\)</span>，而 <spanclass="math inline">\(UU^T\)</span> 实际上就是向 <spanclass="math inline">\(\mathcal{R}(A)\)</span> 的投影矩阵，因此就要求<span class="math inline">\(Bv\in\mathcal{R}(A)\)</span>。</p></blockquote><h2 id="scq-几何解释">3. SCQ 几何解释</h2><p>前面给出的是 SCQ的代数描述，那么如何证明呢？另外如何从几何角度直观理解呢？</p><p>首先我们可以考虑最简单的优化问题 <span class="math display">\[\begin{aligned}\text { minimize } \quad&amp; f_0(x)\\\text { subject to } \quad&amp; f_1(x)\end{aligned}\]</span> 定义集合 <spanclass="math inline">\(\mathcal{G}=\{(f_1(x),f_0(x))|x\in\mathcal{D}\}\)</span>，那么对偶函数为<span class="math display">\[g(\lambda)=\inf_{(u,t)\in\mathcal{G}}(t+\lambda u)\]</span> 如果我们画出下面这张图，阴影部分就是可行区域 <spanclass="math inline">\(\mathcal{G}\)</span>，而 <spanclass="math inline">\((\lambda,1)^T\)</span>则正好定义了一个支撑超平面，<spanclass="math inline">\(g(\lambda)\)</span> 就等于 <spanclass="math inline">\(t\)</span> 轴的交点。通过取不同的 <spanclass="math inline">\(\lambda\)</span>我们就可以得到不同的支撑超平面，也可以得到不同的 <spanclass="math inline">\(g(\lambda)\)</span>，最终会有某一个 <spanclass="math inline">\(\lambda^\star\)</span> 对应的是 <spanclass="math inline">\(d^\star=g(\lambda^\star)\)</span>。还需要注意这里的支撑超平面永远不可能是竖直的。</p><table><thead><tr class="header"><th><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2020/11-dual-geo.PNG"alt="dual geometry" /></th><th><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2020/11-dual-geo2.PNG"alt="dual geometry" /></th></tr></thead><tbody><tr class="odd"><td><span class="math inline">\((\lambda,1)^T\)</span>正好定义了一个支撑超平面</td><td>每个 <span class="math inline">\(\lambda\)</span>对应一个支撑超平面</td></tr></tbody></table><p>那么 <span class="math inline">\(p^\star\)</span>体现在哪个点呢？由于对于原优化问题，我们有 <spanclass="math inline">\(f_1(x)\le0\)</span>，因此体现在这个图里面就是<spanclass="math inline">\(u\le0\)</span>，也就是上面左图当中的红色区域，而<span class="math inline">\(p^\star=\min f_0(x)=\min t\)</span>。</p><p>理解了这张图，我们现在开始证明两件事：</p><ol type="1"><li>证明弱对偶性，也即 <span class="math inline">\(p^\star \ged^\star\)</span>；</li><li>证明强对偶性条件 SCQ。</li></ol><p>注：在此之前，我们不妨加入等式约束，也即 <spanclass="math inline">\(g(\lambda,\mu)=\inf_{(u,v,t)\in\mathcal{G}}(t+\lambda^Tu+\mu^T v)\)</span>。</p><p><strong>弱对偶性的证明</strong>：我们有 <spanclass="math inline">\(\lambda\ge0\)</span> <span class="math display">\[\begin{aligned}p^\star &amp;= \inf\{t|(u,v,t)\in\mathcal{G},u\le0,v=0\} \\&amp;\ge \inf\{t+\lambda^Tu+\mu^Tv|(u,v,t)\in\mathcal{G},u\le0,v=0\} \\&amp;\ge \inf\{t+\lambda^Tu+\mu^Tv|(u,v,t)\in\mathcal{G}\} \\&amp;= g(\lambda,\mu)\end{aligned}\]</span> <strong>强对偶性条件 SCQ 的证明</strong>：由 <spanclass="math inline">\(g(\lambda,\mu)=\inf_{(u,v,t)\in\mathcal{G}}(t+\lambda^Tu+\mu^Tv)\)</span> 可以得到 <span class="math display">\[(\lambda,\mu,1)^T(u,v,t)\ge g(\lambda,\mu),\quad \forall(u,v,t)\in\mathcal{G}\]</span> 这实际上定义了 <spanclass="math inline">\(\mathcal{G}\)</span> 的一个超平面。特别的有 <spanclass="math inline">\((0,0,p^\star)\in\text{bd}\mathcal{G}\)</span>，因此也有<span class="math display">\[(\lambda,\mu,1)^T(0,0,p^\star)\ge g(\lambda,\mu)\]</span>这个不等式可以自然地导出弱对偶性，当“=”成立时则可以导出强对偶性。那么什么时候取等号呢？点<span class="math inline">\((0,0,p^\star)\)</span>为<strong>支撑点</strong>的时候！也就是说</p><blockquote><p>如果在边界点 <span class="math inline">\((0,0,p^\star)\)</span>处存在一个<strong>非竖直的支撑超平面</strong>，那么我们就可以找到 <spanclass="math inline">\(\lambda,\mu\)</span>使得上面的等号成立，也就是得到了强对偶性。</p></blockquote><p>注意前面的分析中我们并没有提到 SCQ，那么 SCQ是如何保证强对偶性的呢？注意 SCQ 要求存在 <spanclass="math inline">\(x\in\mathcal{D}\)</span> 使得 <spanclass="math inline">\(f(x)&lt;0\)</span>，这也就意味着 <spanclass="math inline">\(\mathcal{G}\)</span> 在 <spanclass="math inline">\(u&lt; 0\)</span>半平面上有点，因此如果支撑超平面存在的话，就一定不是垂直的。</p><p>但这又引出另一个问题，那就是支撑超平面一定存在吗？答案是一定存在，这是由原问题的凸性质决定的。为了证明这一点，我们可以引入一个类似于epigraph 的概念： <span class="math display">\[\begin{aligned}\mathcal{A} &amp;= \mathcal{G} + (R^m_+\times \{0\}\times R_+) \\&amp;= \left\{(u,v,t) |\ \exist x\in\mathcal{D},s.t. f(x)\leu,h(x)=v,f_0(x)\le t\right\}\end{aligned}\]</span> 由于原优化问题为凸的，可以应用定义证明集合 <spanclass="math inline">\(\mathcal{A}\)</span> 也是凸的，同时 <spanclass="math inline">\((0,0,p^\star)\in\text{bd}\mathcal{A}\)</span>，那么集合<span class="math inline">\(\mathcal{A}\)</span> 在 <spanclass="math inline">\((0,0,p^\star)\)</span>点就一定存在一个支撑超平面。又由 SCQ可知这个支撑超平面一定不是竖直的，因此就可以得到强对偶性了。</p><p>注：<span class="math inline">\((\lambda,\mu,1)^T(u,v,t)\geg(\lambda,\mu),\quad \forall (u,v,t)\in\mathcal{A}\)</span> 也成立。</p><h2 id="广义不等式约束与sdp">4. 广义不等式约束与SDP</h2><p>前面讨论拉格朗日函数的时候都只考虑了标量函数，如果约束函数为<strong>广义不等式</strong>，也即<span class="math display">\[\begin{aligned}\text { minimize } \quad&amp; f_{0}(x)\\\text { subject to } \quad&amp; f_{i}(x) \preceq_{K_i} 0, \quad i=1,\ldots, m\\&amp;h_{i}(x)=0, \quad i=1, \ldots, p\end{aligned}\]</span> 那么他的拉格朗日函数就是 <span class="math display">\[L\left(x, \lambda_{1}, \cdots, \lambda_{m},\nu\right)=f_{0}(x)+\sum_{i=1}^{m} \lambda_{i}^{T}f_{i}(x)+\sum_{i=1}^{p} \nu_{i} h_{i}(x)\]</span> 对偶函数就是 <span class="math display">\[g\left(\lambda_{1}, \ldots, \lambda_{m}, \nu\right)=\inf _{x \in\mathcal{D}} L\left(x, \lambda_{1}, \cdots, \lambda_{m}, \nu\right)\]</span> 其同样满足 <span class="math inline">\(p^\star\geg\left(\lambda_{1}, \ldots, \lambda_{m}, \nu\right)\)</span>。对偶问题为<span class="math display">\[\begin{aligned}\text {maximize} \quad&amp; g\left(\lambda_{1}, \ldots, \lambda_{m},\nu\right) \\\text {subject to}\quad&amp; \lambda_i\succeq_{K_i^*}0,i=1,...,m\end{aligned}\]</span> 强对偶性以及 Slater's Condition 是类似的。</p><p>对于 <strong>SDP 问题</strong> <span class="math display">\[\begin{aligned}\text {maximize} \quad&amp; c^Tx \\\text {subject to}\quad&amp; x_1F_1+\cdots +x_nF_n\preceq G\end{aligned}\]</span> 拉格朗日函数就是 <span class="math display">\[L(x, Z)=c^{T} x+\operatorname{tr}\left(Z\left(x_{1} F_{1}+\cdots+x_{n}F_{n}-G\right)\right)\]</span> 对偶函数为 <span class="math display">\[g(Z)=\inf _{x} L(x, Z)=\left\{\begin{array}{ll}-\operatorname{tr}(G Z) &amp; \operatorname{tr}\left(F_{i}Z\right)+c_{i}=0, \quad i=1, \ldots, n \\-\infty &amp; \text { otherwise }\end{array}\right.\]</span> 对偶问题就是 <span class="math display">\[\begin{aligned}\text {maximize} \quad&amp; -\operatorname{tr}(G Z)\\\text {subject to} \quad&amp; Z \succeq 0, \quad\operatorname{tr}\left(F_{i} Z\right)+c_{i}=0, \quad i=1, \ldots, n\end{aligned}\]</span> 强对偶性以及 Slater's Condition 是类似的。</p><h2 id="对偶问题的强对偶性与可行性">5. 对偶问题的强对偶性与可行性</h2><p>注意我们说<strong>强对偶性</strong>需要<strong>严格满足</strong>不等式约束(也即最优解需要满足<span class="math inline">\(h(x^\star)&lt;0\)</span> 而不能是 <spanclass="math inline">\(h(x^\star)\le0\)</span>)，但如果存在线性不等式约束，则可以取到等号(也即<spanclass="math inline">\(Ax^\star+b\le0\)</span>)。这就会出现下面的现象：</p><ol type="1"><li>对于 <strong>LP</strong>问题，由于约束是线性的，因此强对偶性只要求有可行解，而不要求<strong>strictly feasible</strong>；</li><li>对于其他问题，若存在非线性约束，比如 <strong>SOCP/SDP</strong>问题，如果想要满足强对偶性，就需要满足 <strong>strictlyfeasible</strong>，这就会出现两种情况：1）问题本身的可行域不可能满足<strong>strictly feasible</strong>，那么就达不到强对偶性，于是 <spanclass="math inline">\(p^\star\ned^\star\)</span>；2）问题可行域满足<strong>strictly feasible</strong>，但是由于最优解达不到(比如 <spanclass="math inline">\(\min1/x\)</span>)，那么此时原问题和对偶问题仍满足强队偶性，但是原问题最优解达不到，而对偶问题则可以达到。</li></ol><figure><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2020/11-dual-counter0.PNG"alt="LP duality" /><figcaption aria-hidden="true">LP duality</figcaption></figure><figure><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2020/11-dual-counter1.PNG"alt="SDP/SOCP duality" /><figcaption aria-hidden="true">SDP/SOCP duality</figcaption></figure><figure><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2020/11-dual-counter2.PNG"alt="SOCP duality" /><figcaption aria-hidden="true">SOCP duality</figcaption></figure><figure><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2020/11-dual-counter3.PNG"alt="SDP duality" /><figcaption aria-hidden="true">SDP duality</figcaption></figure>]]></content>
    
    
    <categories>
      
      <category>Convex Optimization</category>
      
    </categories>
    
    
    <tags>
      
      <tag>对偶原理</tag>
      
      <tag>拉格朗日函数</tag>
      
      <tag>SCQ</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>模糊数学笔记 7：层次分析法</title>
    <link href="/2020/03/15/fuzzy/ch7-ahp/"/>
    <url>/2020/03/15/fuzzy/ch7-ahp/</url>
    
    <content type="html"><![CDATA[<p>日常生活中有许多<strong>决策问题</strong>。决策是指在面临多种方案时需要依据一定的标准选择某一种方案。比如买钢笔，一般要依据质量、颜色、实用性、价格、外形等方面的因素选择某一支钢笔。又比如假期旅游，是去风光秀丽的苏州，还是去迷人的北戴河，或者是去山水甲天下的桂林，一般会依据景色、费用、食宿条件、旅途等因素选择去哪个地方。</p><p>我们可以利用上一节讲的<strong>模糊综合评判</strong>的方法，对每一个备选方案都进行一次打分，最后取分最高的。不过既然这是新的一篇笔记，肯定还有其他方法啦。美国运筹学家托马斯.赛迪(T.Saaty等人)20世纪在七十年代为美国国防部提出了一种能有效处理这类问题的实用方法——<strong>层次分析法</strong>。</p><span id="more"></span><h2 id="层次分析法-ahp">1. 层次分析法 AHP</h2><p>层次分析法(Analytic Hierarchy Process,AHP)是一种定性和定量相结合的、系统化的、层次化的分析方法。是系统分析问题的数学工具之一。层次分析法一般包含以下几个主要步骤：</p><ol type="1"><li>建立层次结构模型</li><li>构造成对比较矩阵</li><li>层次单排序及一致性检验</li><li>层次总排序及其一致性检验</li></ol><p>下面逐步解释各个步骤。</p><h3 id="建立层次结构模型">1.1 建立层次结构模型</h3><p>一般分为三层，最上面为目标层，最下面为方案层，中间是准则层或指标层。</p><figure><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2020/7-layers.PNG"alt="layers" /><figcaption aria-hidden="true">layers</figcaption></figure><p>若上层的每个因素都支配着下一层的所有因素，或被下一层所有因素影响，称为<strong>完全层次结构</strong>，否则称为<strong>不完全层次结构</strong>（都是概念性的东西，我觉得不重要，只要理解层次结构就好啦）。</p><h3 id="构造成对比较矩阵">1.2 构造成对比较矩阵</h3><p>设某层有 <span class="math inline">\(n\)</span> 个因素，<spanclass="math inline">\(X=\{x_1,...,x_n\}\)</span>。要比较它们对上一层某一准则（或目标）的影响程度，也就是把 <spanclass="math inline">\(n\)</span> 个因素对上层某一目标的影响程度排序。这种比较是凉凉元素之间的比较，比较时取1~9尺度。用 <span class="math inline">\(a_{ij}\)</span> 表示第 <spanclass="math inline">\(i\)</span> 个因素相对于第 <spanclass="math inline">\(j\)</span> 个因素的比较结果，则有 <spanclass="math inline">\(a_{ij}=1/a_{ji}\)</span>（这里应该完全是人为定义）<span class="math display">\[A=\left(a_{i j}\right)_{n \times n}=\left(\begin{array}{llll}a_{11}&amp; a_{12} &amp; \cdots &amp; a_{1 n} \\a_{21} &amp; a_{22} &amp;\cdots &amp; a_{2 n} \\\cdots &amp; \cdots &amp; \cdots &amp; \cdots\\a_{n 1} &amp; a_{n 2} &amp; \cdots &amp; a_{n n}\end{array}\right)\]</span> <span class="math inline">\(A\)</span>则称为<strong>成对比较矩阵</strong>。</p><p>这里的成对比较矩阵有点像图论里的<strong>邻接矩阵</strong>，就是说任意两个元素都要进行一次比较。</p><p>前边说了比较尺度我们一般选择1~9，并且一般选择奇数（不知道为啥），各尺度含义为</p><table><thead><tr class="header"><th>尺度</th><th>含义</th></tr></thead><tbody><tr class="odd"><td>1</td><td>第 <span class="math inline">\(i\)</span> 个因素与第 <spanclass="math inline">\(j\)</span> 个因素的影响<strong>相同</strong></td></tr><tr class="even"><td>3</td><td>第 <span class="math inline">\(i\)</span> 个因素比第 <spanclass="math inline">\(j\)</span> 个因素的影响<strong>稍强</strong></td></tr><tr class="odd"><td>5</td><td>第 <span class="math inline">\(i\)</span> 个因素比第 <spanclass="math inline">\(j\)</span> 个因素的影响<strong>强</strong></td></tr><tr class="even"><td>7</td><td>第 <span class="math inline">\(i\)</span> 个因素比第 <spanclass="math inline">\(j\)</span>个因素的影响<strong>明显强</strong></td></tr><tr class="odd"><td>9</td><td>第 <span class="math inline">\(i\)</span> 个因素比第 <spanclass="math inline">\(j\)</span>个因素的影响<strong>绝对地强</strong></td></tr></tbody></table><p>2,4,6,8 表示第 <span class="math inline">\(i\)</span> 个因素相对于第<span class="math inline">\(j\)</span>个因素的影响介于上述两个相邻等级之间。</p><p>根据上面的定义，可以知道成对比较矩阵 <spanclass="math inline">\(A\)</span> 满足以下三条性质：</p><ol type="1"><li><span class="math inline">\(a_{ij}&gt;0\)</span></li><li><span class="math inline">\(a_{ij}=1/a_{ji}\)</span></li><li><span class="math inline">\(a_{ii}=1\)</span></li></ol><p>此时 <span class="math inline">\(A\)</span>也成为<strong>正互反阵</strong>。</p><p>比如旅游问题中，第二层 <span class="math inline">\(A\)</span>的各因素对目标层 <span class="math inline">\(Z\)</span>的影响两两比较结果如下：</p><figure><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2020/7-matA.PNG"alt="matrix" /><figcaption aria-hidden="true">matrix</figcaption></figure><blockquote><p><strong>Remarks</strong>：（我个人觉得）一般认为各因素是有序的，也就是说如果<span class="math inline">\(x_1&gt;x_2,x_2&gt;x_3\)</span>，那么应该有<span class="math inline">\(x_1&gt;x_3\)</span>，这样一来互反矩阵 <spanclass="math inline">\(A\)</span> 就需要满足一定的性质了。</p></blockquote><h3 id="层次单排序及一致性检验">1.3 层次单排序及一致性检验</h3><p>层次单排序就是确定下层各因素对上层某因素影响程度的过程。用权值表示影响程度，先从一个简单的例子看如何确定权值。 例如一块石头重量记为 1，打碎分成 n 个小块，各块的重量分别记为 <spanclass="math inline">\(w_1,...,w_n\)</span>，那么可以得到成对比较矩阵<span class="math display">\[A=\left(a_{i j}\right)_{n \times n}=\left(\begin{array}{llll}1 &amp;\frac{w_1}{w_2} &amp; \cdots &amp; \frac{w_1}{w_n} \\\frac{w_2}{w_1}&amp; 1 &amp; \cdots &amp; \frac{w_2}{w_n} \\\cdots &amp; \cdots &amp;\cdots &amp; \cdots \\\frac{w_n}{w_1} &amp; \frac{w_n}{w_2} &amp; \cdots&amp; 1\end{array}\right)\]</span> 根据上面的定义可以有 <spanclass="math inline">\(a_{ik}a_{kj}=a_{ij},\foralli,j\)</span>。前面我们提到的互反矩阵并不满足这个性质，如果互反矩阵 <spanclass="math inline">\(A\)</span>满足此性质，则我们称其为<strong>一致阵</strong>。一致阵有以下性质：</p><ol type="1"><li><span class="math inline">\(a_{ij}=1/a_{ji},a_{ii}=1\)</span></li><li><span class="math inline">\(a_{ik}a_{kj}=a_{ij}\)</span></li><li><span class="math inline">\(A^T\)</span> 也是一致阵</li><li><span class="math inline">\(A\)</span> 的各行成比例，故 <spanclass="math inline">\(rank(A)=1\)</span></li><li><span class="math inline">\(A\)</span> 的最大特征值为 <spanclass="math inline">\(n\)</span>，其余特征值均为 0</li><li><span class="math inline">\(A\)</span>的任一列都是对应于特征根的特征向量。</li></ol><p>若成对比较矩阵是一致阵，则我们自然会取对应于最大特征根 <spanclass="math inline">\(n\)</span> 的归一化<strong>特征向量</strong> <spanclass="math inline">\(\{w_1,...,w_n\}\)</span>，且 <spanclass="math inline">\(\sum w_i=1\)</span>，<spanclass="math inline">\(w_i\)</span> 即表示下层第 <spanclass="math inline">\(i\)</span>个因素对上层某因素影响程度的权值。若成对比较矩阵不是一致阵，Saaty等人建议用其最大特征根对应的归一化特征向量作为权向量<spanclass="math inline">\(\boldsymbol{w}\)</span>，这样确定权向量的方法称为<strong>特征根法</strong>。</p><p><strong>定理</strong>： <span class="math inline">\(n\)</span>阶互反阵 <span class="math inline">\(A\)</span> 的最大特征根 <spanclass="math inline">\(\lambda\ge n\)</span>，当且仅当 <spanclass="math inline">\(\lambda=n\)</span> 时，<spanclass="math inline">\(A\)</span> 为一致阵。</p><p>由于 <span class="math inline">\(\lambda\)</span> 连续的依赖于 <spanclass="math inline">\(a_{ij}\)</span>，则 <spanclass="math inline">\(\lambda\)</span> 比 <spanclass="math inline">\(n\)</span> 大的越多，<spanclass="math inline">\(A\)</span>的不一致性越严重。用最大特征值对应的特征向量作为被比较因素对上层某因素影响程度的权向量，其不一致程度越大，引起的判断误差越大。因而可以用<span class="math inline">\(\lambda-n\)</span> 数值的大小来衡量 <spanclass="math inline">\(A\)</span> 的不一致程度。</p><p><strong>一致性指标</strong>：<spanclass="math inline">\(CI=\frac{\lambda-n}{n-1}\)</span></p><p><strong>随即一致性指标</strong>：构造 500 个成对比较矩阵 <spanclass="math inline">\(A_1,...,A_{500}\)</span>，可得一致性指标 <spanclass="math inline">\(CI_1,...,CI_{500}\)</span> <spanclass="math display">\[R I=\frac{C I_{1}+C I_{2}+\cdots CI_{500}}{500}=\frac{\frac{\lambda_{1}+\lambda_{2}+\cdots+\lambda_{500}}{500}-n}{n-1}\]</span> 对于 1 阶和 2 阶成对比较矩阵，总是有 <spanclass="math inline">\(RI=0\)</span>。一般有以下表格，使用时直接查表</p><figure><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2020/7-ri1.PNG"alt="RI" /><figcaption aria-hidden="true">RI</figcaption></figure><p>有一些文献取随机取 1000 个成对矩阵，分别计算它们的一致性指标 CI进而得到如下的随机一致性指标 RI：</p><figure><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2020/7-ri2.PNG"alt="RI" /><figcaption aria-hidden="true">RI</figcaption></figure><p>一般，当一致性比率 <spanclass="math inline">\(CR=CI/RI&lt;0.1\)</span> 时，认为 <spanclass="math inline">\(A\)</span>的不一致程度在容许范围之内，可用其最大特征值对应的归一化特征向量作为权向量，否则要重新构造成对比较矩阵，对<span class="math inline">\(A\)</span> 加以调整。</p><p><strong>一致性检验</strong>：上面利用一致性指标及随机一致性指标的数值表，进而计算一致性比率并进行判断的过程称为是对<span class="math inline">\(A\)</span> 的一致性检验。</p><h3 id="层次总排序及其一致性检验">1.4 层次总排序及其一致性检验</h3><p>确定某层所有因素对于总目标相对重要性的排序权值过程，称为<strong>层次总排序</strong>。</p><figure><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2020/7-layers2.PNG"alt="layers" /><figcaption aria-hidden="true">layers</figcaption></figure><p>那么 <span class="math inline">\(B\)</span> 层第 <spanclass="math inline">\(i\)</span> 个因素对总目标的权值为 <spanclass="math inline">\(B_i = \sum_j a_jb_{ij}\)</span>。</p><p>假设 <span class="math inline">\(B\)</span> 层 <spanclass="math inline">\(B_1,...,B_n\)</span> 对上层 <spanclass="math inline">\(A\)</span> 中因素 <spanclass="math inline">\(A_j\)</span> 的层次单排序一致性指标为 <spanclass="math inline">\(CI_j\)</span>，随机一致性指标为 <spanclass="math inline">\(RI_j\)</span>，则层次总排序的一致性比率为： <spanclass="math display">\[CR=\frac{a_1CI_1+\cdots+a_mCI_m}{a_1RI_1+\cdots+a_mRI_m}\]</span> 当 <span class="math inline">\(CR&lt;0.1\)</span>时，认为层次总排序通过一致性检验。到此，根据最下层（决策层）的层次总排序做出最后决策。</p>]]></content>
    
    
    <categories>
      
      <category>Fuzzy Mathematics</category>
      
    </categories>
    
    
    <tags>
      
      <tag>层次分析法</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>凸优化笔记 10：凸优化问题</title>
    <link href="/2020/03/14/optimization/ch10-cvx-optimization/"/>
    <url>/2020/03/14/optimization/ch10-cvx-optimization/</url>
    
    <content type="html"><![CDATA[<p>前面讲了那么多关于凸集、凸函数的知识，然而都是铺垫，现在我们才来到了这门课的重头戏部分——凸优化问题！</p><span id="more"></span><h2 id="一般优化问题">1. 一般优化问题</h2><p>一般优化问题的形式为 <span class="math display">\[\begin{aligned}\text { minimize } \quad&amp; f_{0}(x)\\\text { subject to } \quad&amp; f_{i}(x) \leq 0, \quad i=1, \ldots, m\\&amp;h_{i}(x)=0, \quad i=1, \ldots, p\end{aligned}\]</span> 其中 <span class="math inline">\(f_0(x)\)</span>为目标函数，<span class="math inline">\(f_i(x)\)</span>为不等式约束函数， <span class="math inline">\(h_i\)</span>为等式约束函数。优化问题的<strong>最优解</strong>为 <spanclass="math display">\[p^{\star}=\inf \left\{f_{0}(x) | f_{i}(x) \leq 0, i=1, \ldots, m,h_{i}(x)=0, i=1, \ldots, p\right\}\]</span> 如果 <spanclass="math inline">\(p^{\star}=\infty\)</span>，则问题不可行；如果<span class="math inline">\(p^{\star}=-\infty\)</span>则该问题没有下界。</p><p><strong>最优解</strong>则有 <spanclass="math inline">\(f_0(x)=p^{\star}\)</span>，<strong>局部最优解(localoptimal)</strong>有 <span class="math display">\[\begin{aligned}\text{minimize} (\text{over } z) \quad&amp; f_{0}(z) \\\text{subject to} \quad&amp;f_{i}(z) \leq 0, \quad i=1, \ldots, m, \quadh_{i}(z)=0, \quad i=1, \ldots, p \\&amp;\|z-x\|_{2} \leq R\end{aligned}\]</span> 也即只在一个小的邻域内考虑优化问题。</p><p>注意：</p><ul><li>有的优化问题有最小值，但是没有可行解，比如 <spanclass="math inline">\(f_0(x)=1/x\)</span>；</li><li>有的问题根本就没有最小值，比如 <spanclass="math inline">\(f_0(x)=-\log x\)</span></li><li>有的问题只有局部最小值，比如 <spanclass="math inline">\(f_0(x)=x^3-3x\)</span></li></ul><p>上面提到的优化问题中有等式和不等式约束，这些我们都称为<strong>显式约束(explicitconstraints)</strong>，同时由于 <span class="math inline">\(x\)</span>应属于各个函数的定义域内，因此还有<strong>隐式约束(implicitconstraint)</strong>，即 <span class="math display">\[x \in \mathcal{D}=\bigcap_{i=0}^{m} \operatorname{dom} f_{i} \cap\bigcap_{i=1}^{p} \operatorname{dom} h_{i}\]</span>没有显式约束的优化问题被称为<strong>无约束优化问题(unconstrained)</strong>。比如<span class="math display">\[\text { minimize } \quad f_{0}(x)=-\sum_{i=1}^{k} \log\left(b_{i}-a_{i}^{T} x\right)\]</span> 是一个无约束优化问题，包含了隐式约束 <spanclass="math inline">\(a_i^Tx&lt; b_i\)</span>。</p><p>其实有约束优化问题也可以转化为无约束优化问题，只需要加一个指示函数，一开始提到的一般优化问题就可以利用<span class="math inline">\(\delta_C\)</span>转化为下面的无约束优化问题，不过这种转化可能并没有太大的意义 <spanclass="math display">\[\min_x f_0(x)+\delta_{C}(x) \\\delta_C(x)=\begin{cases}0&amp;f_i(x)\le0,h_i(x)=0 \\ \infty \end{cases}\]</span> 除了优化问题，还有一种<strong>可行解问题(Feasibilityproblem)</strong>，也就是给定一系列约束来寻找是否有可行解 <spanclass="math display">\[\begin{aligned}\text {find} \quad&amp; x \\\text { subject to} \quad&amp; f_{i}(x) \leq 0,\quad i=1, \ldots, m \\&amp; h_{i}(x)=0,\quad i=1, \ldots, p\end{aligned}\]</span> 这实际上也可以转化为一般优化问题 <span class="math display">\[\begin{aligned}\text {minimize} \quad&amp; 0 \\\text { subject to} \quad&amp; f_{i}(x) \leq 0,\quad i=1, \ldots, m \\&amp; h_{i}(x)=0,\quad i=1, \ldots, p\end{aligned}\]</span></p><h2 id="凸优化问题">2. 凸优化问题</h2><h3 id="凸优化问题定义">2.1 凸优化问题定义</h3><p><strong>凸优化问题(Convex optimizationproblem)</strong>要求目标函数为凸函数，而且定义域为凸集，这样可以利用凸函数和凸集的优良性质简化问题，因此凸优化问题的一般形式为<span class="math display">\[\begin{aligned}\text { minimize } \quad&amp; f_{0}(x)\\\text { subject to } \quad&amp; f_{i}(x) \leq 0, \quad i=1, \ldots, m\\&amp;Ax=b, \qquad\qquad\qquad\qquad\quad\bigstar\end{aligned}\]</span> 其中要求目标函数和约束函数 <spanclass="math inline">\(f_0,f_1,...,f_m\)</span>均为<strong>凸函数</strong>。</p><blockquote><p><strong>Remarks</strong>：需要注意这里还要求<strong>等式约束均为仿射函数</strong>，这是因为我们希望定义域是凸集，假设等式约束<span class="math inline">\(h_i\)</span> 不是线性的，即使 <spanclass="math inline">\(h_i\)</span> 是凸函数，<spanclass="math inline">\(\{x|h_i(x)=0\}\)</span>也不一定是凸集。比如二次等式约束 <span class="math inline">\(\Vertx\Vert_2=r\)</span>，得到的定义域就是一个球面，显然不是一个凸集，这对优化不利。</p></blockquote><p>有时候我们直接拿到的优化问题并不符合上面的形式，但是可以经过化简得到等价问题，就是凸的了，比如<span class="math display">\[\begin{aligned}\text { minimize } \quad&amp; f_{0}(x)=x_{1}^{2}+x_{2}^{2}\\\text { subject to } \quad&amp; f_{1}(x)=x_{1} /\left(1+x_{2}^{2}\right)\leq 0\\&amp;h_{1}(x)=\left(x_{1}+x_{2}\right)^{2}=0\end{aligned}\]</span> 经过简单化简就有 <span class="math display">\[\begin{aligned}\text { minimize } \quad&amp; x_{1}^{2}+x_{2}^{2}\\\text { subject to } \quad&amp; x_{1} \leq 0\\&amp;x_{1}+x_{2}=0\end{aligned}\]</span></p><h3 id="凸优化问题的最优解">2.2 凸优化问题的最优解</h3><p>对于凸优化问题有一个极其重要的性质，就是</p><blockquote><p><strong>凸优化问题的局部最优解就是全局最优解</strong></p></blockquote><p>证明也很简单，若 <span class="math inline">\(x^{\star}\)</span>为局部最优解，只需要假设另外一个全局最优解 <spanclass="math inline">\(y\nex^{\star},f(y)&lt;x\)</span>，那么利用凸函数的性质，就可以在 <spanclass="math inline">\(x^{\star}\)</span>的邻域内导出矛盾，如下图图示。</p><figure><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2020/10-global-opti.PNG"alt="optimal" /><figcaption aria-hidden="true">optimal</figcaption></figure><p>凸优化问题的最优解还有一个很好的判据</p><blockquote><p><span class="math inline">\(x\)</span>为最优解，<strong>当且仅当</strong> <span class="math display">\[\nabla f_{0}(x)^{T}(y-x) \geq 0 \quad \text { for all feasible } y\]</span></p></blockquote><p>证明过程只需要应用凸函数的一阶等价定义即可，即 <spanclass="math inline">\(f(y)\ge f(x)+\nabla f^T(x)(y-x)\)</span>。</p><p>这个怎么直观理解呢？还记得我们之前在拟凸函数那里提到的“支撑超平面”吗？实际上<span class="math inline">\(f_0(x)\)</span>定义了一个<strong>等高线</strong>，由于 <spanclass="math inline">\(f_0\)</span>是一个凸函数，因此这个等高线实际上围成了一个凸集，这个凸集也就是一个下水平集。而这里的<span class="math inline">\(\nabla f_0(x)\)</span>就是这个下水平集的一个支撑超平面，正如下图所示。同时注意，<spanclass="math inline">\(\nabla f_0(x)\)</span>也代表着函数指上升的方向，如果说对任意定义域内的 <spanclass="math inline">\(y\)</span>，都有 <spanclass="math inline">\(\nabla f_{0}(x)^{T}(y-x) \geq 0\)</span>成立，那么说明我们从 <span class="math inline">\(x\)</span> 走到 <spanclass="math inline">\(y\)</span> 总会使 <spanclass="math inline">\(f_0\)</span> 增大，也就是说 <spanclass="math inline">\(x\)</span> 就是最优解，对应最小值。</p><figure><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2020/10-global-opti2.PNG"alt="gradient" /><figcaption aria-hidden="true">gradient</figcaption></figure><p>利用上面这两个性质，我们可以对很多类型的凸优化问题的最优解有一个认识。</p><p><strong>无约束优化问题</strong>：对无约束优化问题，<spanclass="math inline">\(x\)</span> 为最优解，当且仅当 <spanclass="math display">\[x\in\text{dom} f_0,\quad \nabla f_0(x)=0\]</span> <strong>等式约束优化问题</strong>：<spanclass="math inline">\(\min\quad f_0(x),\qquad s.t.\quadAx=b\)</span>，则有 <span class="math inline">\(x\)</span>为最优解，当且仅当存在 <span class="math inline">\(\nu\)</span> <spanclass="math display">\[x \in \operatorname{dom} f_{0}, \quad A x=b, \quad \nabla f_{0}(x)+A^{T}\nu=0\]</span> 证明：因为 <span class="math inline">\(Ax=b\)</span>实际上定义了一个超平面，如果 <span class="math inline">\(x\)</span>为最优解，那么 <span class="math inline">\(\nabla f_0(x)\)</span>一定没有这个平面内的分量，也就是说 <span class="math inline">\(\nablaf_0(x)\in \ker(A)^\perp\)</span>。</p><p>这个实际上就等价于 <strong>Lagrange乘子法</strong>，我们来看拉格朗日函数的定义 <spanclass="math display">\[L(x,v)=f_0(x)+&lt;Ax-b,v&gt; \\\Longrightarrow\begin{cases}\nabla f_0(x)+A^Tv=0 \\ Ax-b=0\end{cases}\]</span> <strong>非负象限内的优化</strong>：<spanclass="math inline">\(\min\quad f_0(x),\qquad s.t.\quad x\succeq0\)</span>，<span class="math inline">\(x\)</span> 为最优解，当且仅当<span class="math display">\[x \in \operatorname{dom} f_{0}, \quad x \succeq 0,\quad\left\{\begin{array}{l}\nabla f_{0}(x)_{i} \geq 0 \quad x_{i}=0 \\\nabla f_{0}(x)_{i}=0 \quad x_{i}&gt;0\end{array}\right.\]</span> 证明：首先由于定义域为非负象限，意味着 <spanclass="math inline">\((y-x)\)</span> 可以取到正无穷，因此可以推导出<span class="math inline">\(\nabla f_0(x) \succeq 0\)</span>，故 <spanclass="math inline">\(\nablaf_0^T(x)x\ge0\)</span>。另一方面，对于凸优化问题的最优解，有 <spanclass="math inline">\(\nabla f_0^T(x)(y-x)\ge0\)</span>，取 <spanclass="math inline">\(y=0\)</span>，因此有 <spanclass="math inline">\(\nabla f_0^T(x)x\le0\)</span>，故 <spanclass="math inline">\(\nabla f_0^T(x)x=0\)</span>。</p><p>实际上这里被称为<strong>互补性条件(complementarycondition)</strong>，也就是 <strong>KKT 条件</strong>的一部分。</p><h3 id="等价问题化简">2.3 等价问题化简</h3><p>有时原始优化问题比较难，可以通过等价转换进行简化。</p><p><strong>消去等式约束</strong>：比如对一般的凸优化问题，等式约束实际上定义了一个超平面，这可以表示为特解+ 一组基的形式 <span class="math display">\[Ax=b \iff x=Fz+x_0 \text { for some } z\]</span> 原始凸优化问题就可转化为 <span class="math display">\[\begin{aligned}\text { minimize (over }z) \quad&amp; f_{0}\left(F z+x_{0}\right)\\\text { subject to } \quad&amp; f_{i}\left(F z+x_{0}\right) \leq 0,\quad i=1, \dots, m\end{aligned}\]</span><strong>添加等式约束</strong>：实际上就是上面的一个逆过程，这个过程中取药添加一个等式约束<span class="math inline">\(y=Ax+b\)</span>，由于添加了变量 <spanclass="math inline">\(y\)</span>，会使问题变量数增加，同时优化变量也需要加上<span class="math inline">\(y\)</span>。</p><p><strong>引入松弛变量</strong>：比如对于线性不等式约束的优化问题 <spanclass="math display">\[\begin{aligned}\text { minimize } \quad&amp; f_{0}(x)\\\text { subject to } \quad&amp; a_i^Tx\le b_i,\quad i=1,...,m\end{aligned}\]</span> 可以引入松弛因子 <spanclass="math inline">\(s_i\)</span>，得到 <span class="math display">\[\begin{aligned}\text { minimize } \quad&amp; f_{0}(x)\\\text { subject to } \quad&amp; a_i^Tx + s_i = b_i,\quad i=1,...,m \\&amp; s_i \ge0,\quad i=1,...,m\end{aligned}\]</span><strong><em>例子</em></strong>：下面两个优化问题是等价的吗？其中 <spanclass="math inline">\(W^TW=I\)</span> <span class="math display">\[\min_x f(x)+g(Wx) \\\min_c f(W^T c)+g(c)\]</span> 不一定等价。由于 <spanclass="math inline">\(W^TW=I\)</span>，若 <spanclass="math inline">\(W\)</span> 为方针，则二者等价，否则说明 <spanclass="math inline">\(W\in R^{m\times n},m\ge n\)</span>，也即 <spanclass="math inline">\(W\)</span> 为一个瘦高型的矩阵，如果我们取 <spanclass="math inline">\(f\equiv 0\)</span>，那么很显然 <spanclass="math inline">\(\min_x g(Wx)\)</span> 与 <spanclass="math inline">\(\min_c g(c)\)</span> 并不等价，因为 <spanclass="math inline">\(W\)</span> 列不满秩。</p><p><strong>epigraph形式</strong>：任意标准形式的凸优化问题都可以转化为下面的形式 <spanclass="math display">\[\begin{aligned}\text { minimize (over }x,t) \quad&amp; t\\\text { subject to } \quad&amp; f_{0}(x)\\\quad&amp; f_{i}(x) \leq 0, \quad i=1, \ldots, m\\&amp;Ax=b\end{aligned}\]</span>这种变化很重要，可以将优化目标转化为约束函数，对于后面一些典型凸优化问题的转化很有用。</p><p><strong>对某些变量最小化</strong>：实际上就是对于存在多个优化变量时，提前通过计算消去一些变量<span class="math display">\[\begin{aligned}\text { minimize } \quad&amp; f_{0}\left(x_{1}, x_{2}\right)\\\text { subject to } \quad&amp; f_{i}\left(x_{1}\right) \leq 0, \quadi=1, \dots, m\end{aligned}\iff\begin{aligned}\text { minimize } \quad&amp; \tilde{f}_{0}\left(x_{1}\right)\\\text { subject to } \quad&amp; \tilde{f}_{i}\left(x_{1}\right) \leq 0,\quad i=1, \dots, m\end{aligned}\]</span> 其中 <spanclass="math inline">\(\tilde{f}_0(x_1)=\inf_{x_2}f_0(x_1,x_2)\)</span>。</p><h2 id="拟凸优化问题">3. 拟凸优化问题</h2><p>拟凸函数跟凸函数有一些相似的性质，尤其是拟凸函数的任意下水平集都是凸集，因此很多时候对于拟凸问题，也可以用凸优化的一些方法有效解决。</p><p><strong>拟凸优化问题(Quasi convex optimization)</strong>的一般定义为与凸优化基本相同，只不过<strong>目标函数 <spanclass="math inline">\(f_0(x)\)</span>可以是拟凸函数</strong>，但约束函数 <spanclass="math inline">\(f_1,...,f_m\)</span> 仍需要是凸函数。</p><blockquote><p><strong>Remarks</strong>：我个人觉得这里其实约束函数也可以是拟凸函数？因为即使是拟凸函数，<spanclass="math inline">\(f_i(x)\le0\)</span> 也可以得到凸的定义域？</p></blockquote><p>但是此时拟凸优化问题就没有凸优化那么好的性质了，比如局部最优解不一定是全局最优解</p><figure><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2020/10-quasicvx.PNG"alt="quasicvx" /><figcaption aria-hidden="true">quasicvx</figcaption></figure><p>尽管如此，由于拟凸函数任意下水平集 <spanclass="math inline">\(\{x|f(x)\le t\}\)</span>都是凸集，我们可以利用这个性质将其转化为凸函数 <spanclass="math inline">\(\phi_t(x)\le0\)</span>来表示，由此就可以用凸优化来求解。</p><p><strong><em>例子</em></strong></p><p>最简单的例子，拟凸函数 <span class="math inline">\(f(x)\)</span>的下水平集可以表示为 <span class="math inline">\(\{x|f(x)\let\}\)</span>，我们可以用函数 <spanclass="math inline">\(\phi_t(x)\le0\)</span> 来等价表示 <spanclass="math display">\[\phi_t(x)=\begin{cases}0 &amp; f(x)\le t \\ \infty \end{cases}\]</span> 不过这种表示方法意义不大，这个函数不连续不可微。我们还有其他的表示方法比如 <spanclass="math display">\[\phi_t(x)=\text{dist}\left(x,\{z|f(z)\le t\}\right)\]</span> 另外，如果拟凸函数 <span class="math inline">\(f_0(x)\)</span>有一些特定的性质，比如 <spanclass="math inline">\(f_0(x)=p(x)/q(x)\)</span>，其中 <spanclass="math inline">\(p(x)\)</span> 为凸函数，而 <spanclass="math inline">\(q(x)&gt;0\)</span> 为凹函数（容易证明此时 <spanclass="math inline">\(f_0\)</span> 为拟凸函数），那么我们还可以取 <spanclass="math inline">\(\phi_t(x)\)</span> 为 <spanclass="math display">\[\phi_t(x)=p(x)-t q(x)\]</span> <strong>拟凸优化问题的求解</strong></p><p>假如当前拟凸优化问题的最优解为 <spanclass="math inline">\(p^{\star}\)</span>，那么对于寻找可行解问题 <spanclass="math display">\[\begin{aligned}\text{find} \quad&amp; x \\s.t. \quad&amp; \phi_{t}(x) \leq 0, \quad f_{i}(x) \leq 0, \quad i=1,\ldots, m, \\&amp;A x=b\end{aligned}\]</span> 如果 <span class="math inline">\(t\gep^{\star}\)</span>，则该问题有可行解，如果 <spanclass="math inline">\(t&lt;p^{\star}\)</span>，则没有可行解。因此对于原始凸优化问题，可以利用二分法迭代求解</p><figure><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2020/10-quasicvx-solve.PNG"alt="quasicvx-solve" /><figcaption aria-hidden="true">quasicvx-solve</figcaption></figure><h2 id="典型凸优化问题">4. 典型凸优化问题</h2><h3 id="线性规划lp">4.1 线性规划(LP)</h3><p>线性规划(Linear program)问题的一般形式为 <spanclass="math display">\[\begin{aligned}\text{minimize} \quad&amp; c^{T} x+d \\\text{subject to} \quad&amp; G x \preceq h \\&amp;A x=b\end{aligned}\]</span> 联系我们前面提到的凸优化问题最优解性质，有 <spanclass="math inline">\(c^T(y-x)\ge0\)</span>，也即目标函数的等高线是一系列超平面</p><figure><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2020/10-lp4.PNG"alt="LP" /><figcaption aria-hidden="true">LP</figcaption></figure><p><strong><em>例子 1</em></strong>：对于 piecewise-linear minimization问题(无约束优化) <span class="math display">\[\text { minimize } \max _{i=1, \ldots, m}\left(a_{i}^{T} x+b_{i}\right)\]</span> 可以转化为 <span class="math display">\[\begin{aligned}\text { minimize} \quad&amp; t\\\text { subject to} \quad&amp; a_i^Tx + b_i \le t\end{aligned}\]</span> <strong><em>例子2</em></strong>：多面体的切比雪夫中心(Chebyshev center) <spanclass="math display">\[\mathcal{P}=\left\{x | a_{i}^{T} x \leq b_{i}, i=1, \dots, m\right\}\]</span> 可以用优化问题表示为 <span class="math display">\[\begin{aligned}\text{maximize} \quad&amp; r\\\text{subject to} \quad&amp; a_{i}^{T} x_{c}+r\left\|a_{i}\right\|_{2}\leq b_{i}, \quad i=1, \ldots, m\end{aligned}\]</span> <imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2020/10-chebyshev_center.PNG"alt="chebyshev_center" /></p><h3 id="线性分式规划">4.2 线性分式规划</h3><p>线性分式规划(Linear-fractional program) 的一般形式为 <spanclass="math display">\[\begin{aligned}\text{minimize} \quad&amp; f_0(x) \\\text{subject to} \quad&amp; G x \preceq h \\&amp;A x=b\end{aligned}\]</span> 其中 <spanclass="math inline">\(f_0(x)=\frac{c^Tx+d}{e^Tx+f},\quad\text{dom}f_0(x)=\{x|e^Tx+f&gt;0\}\)</span>。这个问题可以等价转化为线性规划。</p><h3 id="二次规划qp">4.3 二次规划(QP)</h3><p>二次规划(Quadratic program)的一般形式为 <span class="math display">\[\begin{aligned}\text{minimize} \quad&amp; (1/2)x^TPx+q^Tx+r \\\text{subject to} \quad&amp; G x \preceq h \\&amp;A x=b\end{aligned}\]</span> 其中 <span class="math inline">\(P\in S_{+}^n\)</span>。</p><p>与线性规划不同的是，目标函数的等高线变成了椭球面</p><figure><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2020/10-qp.PNG"alt="QP" /><figcaption aria-hidden="true">QP</figcaption></figure><p><strong><em>例子</em></strong>：最小二乘就是最经典的二次规划的例子，<spanclass="math inline">\(\min \Vert Ax+b\Vert_2^2\)</span></p><h3 id="二次约束二次规划qcqp">4.4 二次约束二次规划(QCQP)</h3><p>二次约束二次规划(Quadratically constrained quadraticprogram)的一般形式为 <span class="math display">\[\begin{aligned}\text{minimize} \quad&amp; (1/2)x^TP_0x+q_0^Tx+r_0 \\\text{subject to} \quad&amp; (1/2)x^TP_ix+q_i^Tx+r_i \le 0 \\&amp;A x=b\end{aligned}\]</span> 其中 <span class="math inline">\(P_i\in S_{+}^n\)</span>。</p><p>一般会限制 <span class="math inline">\(P_1,...,P_m\inS_{++}^n\)</span>，也就是不能为 0 矩阵(有什么意义吗？不关键)</p><h3 id="二次锥规划socp">4.5 二次锥规划(SOCP)</h3><p>二次锥规划(Second-order cone programming)的一般形式为 <spanclass="math display">\[\begin{array}{cl}\text { minimize } &amp; f^{T} x \\\text { subject to } &amp; \left\|A_{i} x+b_{i}\right\|_{2} \leqc_{i}^{T} x+d_{i}, \quad i=1, \ldots, m \\&amp; F x=g\end{array}\]</span> 其实 SOCP 比前面几种问题都更广泛，他们都可以看作是 SOCP的一种情况</p><figure><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2020/10-socp.PNG"alt="SOCP" /><figcaption aria-hidden="true">SOCP</figcaption></figure><h3 id="鲁棒线性规划">4.6 鲁棒线性规划</h3><p>对于优化问题，有时候我们的参数比如 <spanclass="math inline">\(a_i,b_i\)</span>等都是不确定的，他们可能是在一定范围内属于某个集合，也可能是一个随机变量，这个时候就引入了鲁棒优化的概念。</p><p>对于线性规划问题来说，比如 <span class="math display">\[\begin{aligned}\text{minimize} \quad&amp; c^{T} x+d \\\text{subject to} \quad&amp; a_i^Tx\le b_i\end{aligned}\]</span> 一种是考虑<strong>确定性模型</strong>，也即 <spanclass="math display">\[\begin{aligned}\text{minimize} \quad&amp; c^{T} x+d \\\text{subject to} \quad&amp; a_i^Tx\le b_i \text{ for all }a_i\in\mathcal{E}_i\end{aligned}\]</span> 如果 <spanclass="math inline">\(\mathcal{E}_{i}=\left\{\bar{a}_{i}+P_{i} u|\|u\|_{2} \leq 1\right\}\)</span> 是一个椭球，则该问题可以转化为一个SOCP 问题 <span class="math display">\[\begin{aligned}\text{maximize} \quad&amp; c^Tx\\\text{subject to} \quad&amp; \bar{a}_{i}^{T}x+\left\|P_{i}^Tx\right\|_{2} \leq b_{i}, \quad i=1, \ldots, m\end{aligned}\]</span> 另一种是<strong>随机性模型</strong>，即 <spanclass="math display">\[\begin{aligned}\text{minimize} \quad&amp; c^{T} x \\\text{subject to} \quad&amp; \operatorname{prob}\left(a_{i}^{T} x \leqb_{i}\right) \geq \eta, \quad i=1, \ldots, m\end{aligned}\]</span> 假如 <spanclass="math inline">\(a_i\sim\mathcal{N}(\bar{a}_i,\Sigma_i)\)</span>服从高斯分布，则该问题同样可以转化为一个 SOCP 问题 <spanclass="math display">\[\begin{aligned}\text{maximize} \quad&amp; c^Tx\\\text{subject to} \quad&amp; \bar{a}_{i}^{T}x+\Phi^{-1}(\eta)\left\|\Sigma_{i}^{1 / 2} x\right\|_{2} \leq b_{i},\quad i=1, \ldots, m\end{aligned}\]</span></p><h3 id="几何规划gp">4.7 几何规划(GP)</h3><p>首先定义<strong>单项式函数(monomial function)</strong> <spanclass="math inline">\(f(x)=cx_1^{a_1}x_2^{a_2}\cdots x_n^{a_n},\quad\text{dom}f=R_{++}^n\)</span>，其中 <spanclass="math inline">\(c&gt;0,a_i\)</span> 为任意实数；</p><p><strong>正项式函数(posynomial function)</strong> <spanclass="math inline">\(f(x)=\sum_k c_k x_1^{a_{1k}} x_2^{a_{2k}}\cdotsx_n^{a_{nk}},\quad \text{dom}f=R_{++}^n\)</span></p><p>然后就可以定义<strong>几何规划(geometric program)</strong>了 <spanclass="math display">\[\begin{aligned}\text{minimize} \quad&amp; f_0(x) \\\text{subject to} \quad&amp; f_i(x)\le 1,\quad i=1,...,m \\&amp;h_i(x)=1,\quad i=1,...,p\end{aligned}\]</span> 其中 <span class="math inline">\(f_i\)</span> 为正项式，<spanclass="math inline">\(h_i\)</span> 为单项式。</p><p>首先说明，这个优化问题并不一定是凸的，因为 <spanclass="math inline">\(a_i\)</span> 可以取任意实数，比如 <spanclass="math inline">\(a_i=1/2\)</span>就不是凸的。那么我们这里为什么要介绍这个问题呢？别急，一会稍微做一个变换我们就可以解决这个问题了。那还有一个问题，这种形式的函数有什么意义呢？为什么专门引入这样一种非凸优化问题呢？我们看这个单项式函数<span class="math inline">\(cx_1^{a_1}x_2^{a_2}\cdotsx_n^{a_n}\)</span>，像不像体积或者面积的表达式？这也是他被称为“几何规划”的原因吧。</p><p>好，现在我们怎么把这个非凸的问题转化为凸优化问题呢？加个 <spanclass="math inline">\(\log\)</span> 就行啦！对单项式来说 <spanclass="math display">\[\begin{aligned}\log f(x) &amp;= \sum_i a_i \log x_i +\log c = a^Ty+b \\f(x) &amp;= e^{a^Ty+b}\end{aligned}\]</span> 对多项式来说 <span class="math display">\[\log f(x)=\log \left(\sum_i \exp(a_i^Ty+b_i)\right)\]</span> 这么一来，取完对数后的问题就是凸的了，而且我们也知道 <spanclass="math inline">\(\log\)</span> 是一个单射函数，原始优化问题就变成了<span class="math display">\[\begin{aligned}\text{minimize} \quad&amp; \log \left(\sum_k\exp(a_{0k}^Ty+b_{0k})\right) \\\text{subject to} \quad&amp; \log \left(\sum_k\exp(a_{ik}^Ty+b_{ik})\right)\le 0,\quad i=1,...,m \\&amp;Gy+d=0\end{aligned}\]</span></p><h3 id="半正定规划sdp">4.8 半正定规划(SDP)</h3><p>前面所讲到的都是标量函数，约束条件也都是函数值与 0比大小，而前面的章节中我们也提到了广义不等式，对于正常锥则可以定义不等号。所以我们可以定义一种凸优化问题，这种凸优化问题的约束条件不再是普通不等式，而是广义不等式<span class="math display">\[\begin{aligned}\text{minimize} \quad&amp; f_0(x) \\\text{subject to} \quad&amp; f_i(x)\preceq_{K_i} 0,\quad i=1,...,m \\&amp;Ax=b\end{aligned}\]</span> 其中 <span class="math inline">\(f_0:R^n\to R\)</span>为凸函数，<span class="math inline">\(f_i:R^n\to R^{k_i}\)</span>为关于正常锥 <span class="math inline">\(K_i\)</span> 的凸函数。</p><p>注意这种带有广义不等式约束的凸优化问题与普通凸优化问题有着相同的性质，比如可行集为凸的，局部最优解就是全局最优解等。</p><p>一种简单形式的凸优化问题就是向量形式的，也就是说目标函数与约束都是仿射函数<span class="math display">\[\begin{aligned}\text{minimize} \quad&amp; c^Tx \\\text{subject to} \quad&amp; Fx+g\preceq_K 0 \\&amp;Ax=b\end{aligned}\]</span>这种向量形式的广义不等式实际上就是对每个元素进行比较，因此实际上可以按照每一行拆分成多个不等式，如果取<span class="math inline">\(K=R_+^m\)</span>就与普通的线性规划(LP)没什么区别了。</p><p>接下来要介绍的就是重头戏<strong>半正定规划(Semideﬁniteprogram)</strong>了，我们取 <span class="math inline">\(K=S^n_+\)</span><span class="math display">\[\begin{aligned}\text{minimize} \quad&amp; c^Tx \\\text{subject to} \quad&amp; x_1 F_1+x_2F_2+\cdots+x_nF_n+G\preceq_K 0\\&amp;Ax=b\end{aligned}\]</span> 其中 <span class="math inline">\(F_i,G\in S^n\)</span>。</p><p>这里的不等式约束就是大名鼎鼎的<strong>线性矩阵不等式(linear matrixinequality, LMI)</strong>。</p><p>如果说我们现在有两个不等式约束怎么办呢？ <spanclass="math display">\[x_1 \hat{F}_1+x_2\hat{F}_2+\cdots+x_n\hat{F}_n+G\preceq_K 0 \\x_1 \tilde{F}_1+x_2\tilde{F}_2+\cdots+x_n\tilde{F}_n+G\preceq_K 0\]</span> 合成一个更大的矩阵就可以了，实际上这种操作在后面也会经常见到<span class="math display">\[x_{1}\left[\begin{array}{cc}\hat{F}_{1} &amp; 0 \\0 &amp; \tilde{F}_{1}\end{array}\right]+x_{2}\left[\begin{array}{cc}\hat{F}_{2} &amp; 0 \\0 &amp; \tilde{F}_{2}\end{array}\right]+\cdots+x_{n}\left[\begin{array}{cc}\hat{F}_{n} &amp; 0 \\0 &amp; \tilde{F}_{n}\end{array}\right]+\left[\begin{array}{cc}\hat{G} &amp; 0 \\0 &amp; \tilde{G}\end{array}\right] \preceq 0\]</span>这是因为分块对角矩阵为正定矩阵等价于每一个子块都为正定矩阵。</p><p><strong><em>例子1</em></strong>：半正定规划之所以重要，是因为他的形式更广泛，前面说 SOCP包含了 LP、QP、QCQP，而半正定规划则包含了 SOCP！比如下面的 SOCP问题就可以转化为 SDP <span class="math display">\[\begin{aligned}SOCP:\qquad \text{minimize}&amp;\quad f^{T} x \\\text{subject to}&amp;\quad \left\|A_{i} x+b_{i}\right\|_{2} \leqc_{i}^{T} x+d_{i}, \quad i=1, \ldots, m \\\\SDP:\qquad \text{minimize}&amp;\quad f^{T} x \\\text{subject to}&amp;\quad \left[\begin{array}{cc}\left(c_{i}^{T} x+d_{i}\right) I &amp; A_{i} x+b_{i} \\\left(A_{i} x+b_{i}\right)^{T} &amp; c_{i}^{T} x+d_{i}\end{array}\right] \succeq 0, \quad i=1, \ldots, m\end{aligned}\]</span> <strong><em>例子 2</em></strong>：最小化矩阵的最大特征值 <spanclass="math inline">\(\min\lambda_{\max}(A(x))\)</span>，也可以通过半正定规划来描述 <spanclass="math display">\[\begin{aligned}\text{minimize} \quad&amp; t \\\text{subject to} \quad&amp; A(x)\preceq tI\end{aligned}\]</span> 其中优化变量为 <span class="math inline">\(x\in R^n,t\inR\)</span>。这种等价转化是因为 <spanclass="math inline">\(\lambda_{\max}(A)\le t\iff A\preceqtI\)</span>。</p><p><strong><em>例子 3</em></strong>：最小化矩阵范数 <spanclass="math inline">\(\min \VertA(x)\Vert_2=\left(\lambda\left(A\left(x\right)^TA\left(x\right)\right)\right)^{1/2}\)</span>，也可以等价为SDP<span class="math display">\[\begin{aligned}\text{minimize}&amp;\quad t \\\text{subject to}&amp;\quad \left[\begin{array}{cc}t I &amp; A(x) \\A(x)^T &amp; tI\end{array}\right] \succeq 0\end{aligned}\]</span></p><h3 id="向量优化">4.9 向量优化</h3><p>前面介绍的所有优化问题的目标函数都是标量（尽管约束可能会出现广义不等式），如果目标函数为向量怎么办呢？前面的章节中我们介绍了广义的凸函数，同样也是基于锥定义的（实际上高维空间中“比大小”我们一般都需要通过锥来定义）。</p><p>一般的向量优化问题可以表示为 <span class="math display">\[\begin{alignat}{}&amp;\text{minimize(w.r.t. K)} \quad&amp; f_0(x) \\&amp;\text{subject to} \quad&amp; f_i(x)\le 0,\quad i=1,...,m \\&amp; &amp;h_i(x)=0,\quad i=1,...,p\end{alignat}\]</span> 凸的向量优化问题只需要将上面的等式约束换为仿射函数 <spanclass="math inline">\(Ax=b\)</span>，同时要求 <spanclass="math inline">\(f_0\)</span> 为 <spanclass="math inline">\(K-\)</span>convex 的，<spanclass="math inline">\(f_1,...,f_m\)</span> 为凸的。</p><p>向量约束优化问题的最优解相当于在下面的集合中寻找最优解 <spanclass="math display">\[\mathcal{O}=\{f_0(x)|x \text{ feasible}\}\]</span>前面在将广义不等式和凸集的时候，我们讲过<strong>最小元</strong>和<strong>极小元</strong>的概念，这两个概念是不是已经忘得差不多啦！反正我基本全忘了......让我们来复习一下。</p><blockquote><p><strong>复习</strong>：最小元与极小元</p><p>下面两幅图分别表示最小元和极小元</p><figure><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2020/3-minimum.png"alt="minimum and minimal" /><figcaption aria-hidden="true">minimum and minimal</figcaption></figure><p>利用对偶锥，我们可以获得<strong>最小元</strong>的等价定义，即</p><blockquote><p><span class="math inline">\(x\)</span> 是集合 <spanclass="math inline">\(S\)</span> 关于 <spanclass="math inline">\(\preceq_{K}\)</span> 的最小元 <spanclass="math inline">\(\iff\)</span> 对任意的 <spanclass="math inline">\(\lambda \succ_{K*} 0\)</span>，<spanclass="math inline">\(x\)</span> 为 <spanclass="math inline">\(\lambda^Tz\)</span> 在集合 <spanclass="math inline">\(S\)</span> 上的唯一最小解</p></blockquote><p>什么意思呢？也就是说任意的 <span class="math inline">\(\lambda\inK^{\star}\)</span>，实际上都代表了一个法向量，也就是一个支撑超平面。如果<span class="math inline">\(x\)</span> 是最小元，则意味着对任意一个(<span class="math inline">\(K^{\star}\)</span>所定义的)支撑超平面来说，<span class="math inline">\(x\)</span>都是支撑点，就像下面这条幅图一样</p><figure><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2020/10-minimal.png"alt="minimal" /><figcaption aria-hidden="true">minimal</figcaption></figure><p>而<strong>极小元</strong>的定义是什么呢？</p><blockquote><ul><li>充分条件：若对于某些 <span class="math inline">\(\lambda \succ_{K*}0\)</span>，<span class="math inline">\(x\)</span> minimizes <spanclass="math inline">\(\lambda^Tz\)</span> over <spanclass="math inline">\(S\)</span>，<spanclass="math inline">\(\Longrightarrow\)</span> <spanclass="math inline">\(x\)</span> 为极小元</li><li>必要条件：<span class="math inline">\(x\)</span>为<strong>凸集</strong> <span class="math inline">\(S\)</span>的极小元，<span class="math inline">\(\Longrightarrow\)</span> 存在非 0的 <span class="math inline">\(\lambda \succ_{K*} 0\)</span> 使得 <spanclass="math inline">\(x\)</span> minimizes <spanclass="math inline">\(\lambda^Tz\)</span> over <spanclass="math inline">\(S\)</span></li></ul></blockquote><p>我们来看充分条件，只需要存在某一个 <spanclass="math inline">\(\lambda\in K^{\star}\)</span>，使得 <spanclass="math inline">\(x\)</span>为对应支撑超平面的支撑点就可以了。比如下面这幅图，蓝色的点，我们可以找到这样一个蓝色的支撑超平面，使其为支撑点，所以它就是一个极小元；而对于红色的点来说，无论如何不可能找到一个支撑超平面，使其为支撑点，因此他就有可能不是极小元，因为这只是充分条件（对这个例子来说他就不是极小元）。</p><figure><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2020/10-minimum.PNG"alt="minimum" /><figcaption aria-hidden="true">minimum</figcaption></figure><p>简单总结一下：</p><ul><li>最小元：无论沿着锥 <span class="math inline">\(K^{*}\)</span>里边哪一个方向走，<span class="math inline">\(x\)</span>都是最小值点，那么他就是最小元；</li><li>极小元：如果沿着其中某一个方向走，<spanclass="math inline">\(x\)</span> 是最小值点，那么他就是极小元。</li></ul></blockquote><p>复习完了最小元和极小元，不要忘了正事。我们要考虑向量约束优化问题中的最优解<span class="math display">\[\mathcal{O}=\{f_0(x)|x \text{ feasible}\}\]</span> 这是一个集合，如果 <span class="math inline">\(f_0(x)\)</span>是关于锥 <span class="math inline">\(K\)</span> 的最小元，那么对应的<span class="math inline">\(x\)</span> 就被称为最优解(optimal)；如果<span class="math inline">\(f_0(x)\)</span> 是关于锥 <spanclass="math inline">\(K\)</span> 的极小元，那么对应的 <spanclass="math inline">\(x\)</span> 则被称为 Pareto optimal。</p><figure><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2020/10-vec-optim.PNG"alt="optimal vs Pareto optimal" /><figcaption aria-hidden="true">optimal vs Pareto optimal</figcaption></figure><p><strong><em>例子</em></strong>：假如我们取 <spanclass="math inline">\(K=R_+^q\)</span>，其中 <spanclass="math display">\[f_0(x)=(F_1(x),...,F_q(x))\]</span> 相当于有 <span class="math inline">\(q\)</span> 个不同的目标<span class="math inline">\(F_i\)</span>，最好的情况当然是希望 <spanclass="math inline">\(F_i\)</span> 都是最小的。</p><p>若 <span class="math inline">\(x^{\star}\)</span>为最小元（存在）就说明任意其他可行解 <spanclass="math inline">\(y\)</span> 都有 <spanclass="math inline">\(f_0(x^{\star})\lef(y)\)</span>，正是我们希望的；</p><p>而如果只能得到极小元 <spanclass="math inline">\(x^{po}\)</span>，就有对任意可行解 <spanclass="math inline">\(y\)</span>，<spanclass="math inline">\(f_0(y)\preceq f_0(x^{po})\Longrightarrowf_0(x^{po})=f(y)\)</span>。这是什么意思呢？</p><ol type="1"><li>首先不可能存在另一个 <span class="math inline">\(y\)</span>使得每一个元素都有 <span class="math inline">\(F_i(y)\leF_i(x^{po})\)</span>，要不然 <span class="math inline">\(x^{po}\)</span>出现在这里的意义是什么？我们直接选择 <spanclass="math inline">\(y\)</span>作为极小元不就好了吗？如果存在那也顶多是 <spanclass="math inline">\(F_i(y)=F_i(x^{po}),\forall i\)</span>，这种情况下<span class="math inline">\(y\)</span> 跟 <spanclass="math inline">\(x^{po}\)</span> 其实没什么区别了。</li><li>第二点，有可能存在某些 <spanclass="math inline">\(y\)</span>，满足对一些 <spanclass="math inline">\(i\)</span> 有 <spanclass="math inline">\(F_i(y)&gt;F_i(x^{po})\)</span>，而对另一些 <spanclass="math inline">\(i\)</span> 则有 <spanclass="math inline">\(F_i(y)&lt;F_i(x^{po})\)</span>，这意味着 <spanclass="math inline">\(y\)</span> 在某些方面表现得比 <spanclass="math inline">\(x^{po}\)</span>差，但在另一些方面则表现得更好，这实际上体现了我们在不同因素之间的一种权衡。</li></ol>]]></content>
    
    
    <categories>
      
      <category>Convex Optimization</category>
      
    </categories>
    
    
    <tags>
      
      <tag>LP</tag>
      
      <tag>SOCP</tag>
      
      <tag>SDP</tag>
      
      <tag>凸优化问题</tag>
      
      <tag>QP</tag>
      
      <tag>GP</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>模糊数学笔记 6：模糊综合评判</title>
    <link href="/2020/03/13/fuzzy/ch6-evaluate/"/>
    <url>/2020/03/13/fuzzy/ch6-evaluate/</url>
    
    <content type="html"><![CDATA[<p>假如我们现在设计了一种服装，想要调研一下这种服装的受欢迎程度，该怎么办呢？</p><p>首先是怎么表示受欢迎程度呢？我们可以简单分为三个等级：受欢迎、一般欢迎、不受欢迎，由于不同的人感受可能不同，结合前面模糊集的概念，我们可以引入隶属度，比如调查后得到50% 的人喜欢，30%一般，20%不喜欢，我们就可以取隶属度分别为0.5，0.3，0.2。</p><p>当然这样太粗糙了，我们知道评价一个衣服的因素有很多，比如样式、耐穿性、价格等，而不同因素即使对同一个人的值观感受也是不一样的，比如有的人很喜欢这个样式，但是摸了摸钱包，发现这个衣服是这么的难看！所以要想更好的评价，我们需要对每一个指标分别评估一下受欢迎程度，然后把各种因素综合起来。这就是模糊综合评判要做的事情。</p><span id="more"></span><h2 id="一级模糊综合评判">1. 一级模糊综合评判</h2><p>现在我们把上面描述的过程规范化。我们有<strong>因素集</strong> <spanclass="math inline">\(U=\{u_1,...,u_n\}\)</span>，<strong>评语集</strong><span class="math inline">\(V=\{v_1,...,v_m\}\)</span>。</p><p>综合评判的步骤是什么呢？</p><ol type="1"><li>首先要对每个因素分别进行单因素评判，也就是获得 <spanclass="math inline">\(r_i = (r_{i1},\cdots,r_{im})\)</span></li><li>然后把 <span class="math inline">\(n\)</span>个因素的评判指标拼接成一个 <span class="math inline">\(n\timesm\)</span> 的矩阵，可以获得综合评判矩阵 <spanclass="math inline">\(R=(r_1^T,\cdots,r_n^T)^T\)</span></li><li>之后需要对所有因素进行综合评判，因此可以设置一个权重 <spanclass="math inline">\(A=(a_1,...,a_n)\)</span>，再根据算子 <spanclass="math inline">\(M(\cdot,\cdot)\)</span> 计算 <spanclass="math inline">\(B=A\circR=M(A,R)\)</span>，这个过程实际上就类似于一个加权的过程</li><li>上一步结束后实际上得到的还是一个向量，要想最后给一个总的评价指标，可以对该向量再进行一次加权或者其他操作，获得一个总的指标。</li></ol><p>下面我对第 3，4 条再详细解释一下。</p><p>算子 <span class="math inline">\(M(\cdot,\cdot)\)</span>可以取很多种形式，比如</p><ul><li><span class="math inline">\(M(\wedge,\vee) \Longrightarrow\boldsymbol{b}_{j}=\max \left\{\left(\boldsymbol{a}_{i} \wedge\boldsymbol{r}_{i j}\right), \mathbf{1} \leq \boldsymbol{i} \leq\boldsymbol{n}\right\}(\boldsymbol{j}=\mathbf{1}, \boldsymbol{2},\cdots, \boldsymbol{m})\)</span></li><li><span class="math inline">\(M(\cdot,\vee) \Longrightarrow\boldsymbol{b}_{j}=\max \left\{\left(\boldsymbol{a}_{i} \cdot\boldsymbol{r}_{i j}\right), \mathbf{1} \leq \boldsymbol{i} \leq\boldsymbol{n}\right\}(\boldsymbol{j}=\mathbf{1}, \boldsymbol{2},\cdots, \boldsymbol{m})\)</span></li><li><span class="math inline">\(M(\cdot,+) \Longrightarrow\boldsymbol{b}_{j}=\sum_i \left(\boldsymbol{a}_{i}\cdot\boldsymbol{r}_{i j}\right), (\boldsymbol{j}=\mathbf{1},\boldsymbol{2}, \cdots, \boldsymbol{m})\)</span></li><li><spanclass="math inline">\(M(\wedge,\bigoplus)=\boldsymbol{b}_{j}=\min\left\{1, \sum_{i=1}^{n}\left(a_{i} \wedge r_{i j}\right)\right\}(j=1,2,\cdots, m)\)</span></li><li><span class="math inline">\(M(\wedge,+) \Longrightarrow\boldsymbol{b}_{j}=\sum_i \left(\boldsymbol{a}_{i}\wedge\frac{\boldsymbol{r}_{i j}}{r_0}\right),(\boldsymbol{j}=\mathbf{1}, \boldsymbol{2}, \cdots,\boldsymbol{m}),r_0=\sum_k r_{kj}\)</span></li></ul><p>不同的算子形式有不同特点，也适用于不同情况。</p><p>第 3 步经过 <span class="math inline">\(M(,)\)</span>算子之后，我们得到了模糊评判向量 <spanclass="math inline">\(B\)</span>，要获得综合结论也可以有不同的方式</p><ul><li><span class="math inline">\(u=\max{(b_1,...,b_n)}\)</span></li><li><span class="math inline">\(u=\sum_i \mu_i b_i / \sum_ib_i\)</span></li></ul><h2 id="多级模糊综合评判">2. 多级模糊综合评判</h2><p>有时候对一件事物的评价有很多指标，这些指标又可以分为几大类，比如对高校的评分，可以包括</p><ul><li>教学：教学下面又可以分为师资力量、教学设施、学生质量等等</li><li>科研：...... 可以有很多指标</li><li>图书馆、后勤 ......</li></ul><p>这个时候我们可以划分为多个层次依此评判综合，其步骤可以描述为以下形式：</p><ol type="1"><li>将原始因素集 <span class="math inline">\(U=\{u_1,...,u_n\}\)</span>划分为若干组 <span class="math inline">\(U=\bigcup_i U_i,U_i\capU_j=\varnothing\)</span></li><li>对每组 <span class="math inline">\(U_i\)</span>分别进行模糊评判，得到 <span class="math inline">\(B_i\)</span></li><li>对总的评判矩阵 <spanclass="math inline">\(R=(B_1^T,...,B_k^T)^T\)</span>再次进行综合评判，得到 <span class="math inline">\(B=A\circR\)</span>，然后可以得到总的综合评语</li></ol>]]></content>
    
    
    <categories>
      
      <category>Fuzzy Mathematics</category>
      
    </categories>
    
    
    <tags>
      
      <tag>模糊综合评判</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>凸优化笔记 9：广义凸函数</title>
    <link href="/2020/03/11/optimization/ch9-gene-cvx/"/>
    <url>/2020/03/11/optimization/ch9-gene-cvx/</url>
    
    <content type="html"><![CDATA[<p>有时候函数 <span class="math inline">\(f\)</span>为向量，此时怎么定义凸函数呢？根据广义不等式引入。</p><span id="more"></span><h2 id="广义单调函数">1. 广义单调函数</h2><p>对于 <span class="math inline">\(f:R^n\toR\)</span>，定义其单调性为存在正常锥 <spanclass="math inline">\(K\subseteq R^n\)</span>，有</p><ul><li><strong>K-nondecreasing</strong> <span class="math inline">\(\iff\forall x\preceq_K y,\quad f(x)\le f(y)\)</span></li><li><strong>K-nonincreasing</strong> $$</li></ul><p>实际上相当于在定义域中规定了一个序关系，但是注意这种序关系并不是完全的，也就是说有可能有<span class="math inline">\(x\preceq_K y, y\preceq_K x\)</span>都不成立，意味着有可能定义域中的两个元素之间是不可“比大小的”。</p><p>对于广义单调函数的判定有以下性质</p><blockquote><p><span class="math inline">\(f\)</span> K-nondecreasing <spanclass="math inline">\(\iff \nabla f(x)\succeq_{K^*}0,\forall x\in\text{dom}f\)</span></p></blockquote><p>证明只需要将其转化为一维情形即可，可以用反证法。</p><h2 id="广义凸函数">2. 广义凸函数</h2><p>对于 <span class="math inline">\(f:R^n\toR^m\)</span>，凸函数定义为关于正常锥 <spanclass="math inline">\(K\subseteq R^m\)</span> <spanclass="math display">\[f(\theta x+(1-\theta)y) \preceq_K \theta f(x)+(1-\theta)f(y)\]</span> <strong><em>例子</em></strong></p><ul><li><span class="math inline">\(f:S^n_+\to S^n_+,f(X)=X^2\)</span></li></ul><p>广义凸函数有下面的性质</p><blockquote><p><span class="math inline">\(f\)</span> 为 K-convex <spanclass="math inline">\(\iff \omega^T f(x)\)</span> convex，对任意 <spanclass="math inline">\(\omega\succeq_{K^*}0\)</span></p><p><strong>Remarks</strong>：只需要考虑 <spanclass="math inline">\(g(x)=\omega^T f(x)\)</span>就转化为了普通凸函数，实际上相当于 <span class="math inline">\(\omega\inK^*\)</span> 确定了沿某个方向上的序关系。</p></blockquote>]]></content>
    
    
    <categories>
      
      <category>Convex Optimization</category>
      
    </categories>
    
    
    <tags>
      
      <tag>广义凸函数</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>凸优化笔记 8：对数凹函数 Log-concave Function</title>
    <link href="/2020/03/11/optimization/ch8-log-cvx/"/>
    <url>/2020/03/11/optimization/ch8-log-cvx/</url>
    
    <content type="html"><![CDATA[<p>对数凹函数，顾名思义即取完对数以后 <span class="math inline">\(\logf(x)\)</span> 是凹函数，其应用比如在求最大后验 MAP时，往往会对联合概率密度函数取对数。</p><span id="more"></span><h2 id="定义">1. 定义</h2><p>函数 <span class="math inline">\(f\)</span>被称为<strong>对数凹函数(log-concave)</strong>，如果 <spanclass="math inline">\(\log f\)</span> 是凹的，也即 <spanclass="math display">\[f(\theta x+(1-\theta)y)\ge f(x)^\theta f(y)^{1-\theta}\]</span> <strong><em>对数凹函数的例子</em></strong>：</p><ul><li>幂函数 <span class="math inline">\(x^\alpha\)</span></li><li>正态分布</li><li>高斯分布的累积分布 <spanclass="math inline">\(\Phi(x)=1/\sqrt{2\pi}\int_{-\infty}^{x}e^{-u^2/2}du\)</span></li><li><strong>指示函数</strong> <span class="math inline">\(I(x)=1_{x\inC}\)</span>，其中 <span class="math inline">\(C\)</span> 为凸集</li><li>行列式 <span class="math inline">\(\det X\)</span> 是log-concave，关于 <span class="math inline">\(S^n_{++}\)</span></li><li><span class="math inline">\(\det X/\text{tr}X\)</span> on <spanclass="math inline">\(S^n_{++}\)</span></li></ul><p>根据前面提到的复合函数凹凸性，由于 <spanclass="math inline">\(\log\)</span>本身是凹函数，且为单调递增，因此可以有 <spanclass="math inline">\(f\)</span> concave <spanclass="math inline">\(\Longrightarrow \log f\)</span> concave。</p><p>另外，指数函数取对数以后，变成了线性函数，而高斯分布取对数以后变成了二次函数，是凸的。外面这一层取对数的操作可以直观的想想为把原始函数向下掰弯(划掉)了，比如高斯分布就把接近于0 的值经过 <span class="math inline">\(\log\)</span> 操作掰到了 <spanclass="math inline">\(-\infty\)</span>，从而变成了二次函数。</p><h2 id="性质">2. 性质</h2><blockquote><p>函数 <span class="math inline">\(f\)</span> 的定义域为凸集，<spanclass="math inline">\(f\)</span> 为 log-concave<strong>当且仅当</strong> <span class="math display">\[f(x)\nabla^2 f(x)\preceq \nabla f(x) \nabla f(x)^T,\forall x\in\text{dom}f\]</span></p></blockquote><p>另外</p><ul><li>两个 log-concave 函数的<strong>乘积</strong>仍然是 log-concave</li><li>若 <span class="math inline">\(f(x,y)\)</span> 是 log-concave，则<span class="math inline">\(g(x)=\int f(x,y)dy\)</span> 也是log-concave</li><li>若 <span class="math inline">\(f(x)\)</span> 为 log-concave，则<span class="math inline">\(f(x-y)\)</span> 关于 <spanclass="math inline">\((x,y)\)</span> 都是 log-concave 的</li></ul><p>但是注意，两个 log-concave 函数的<strong>和不一定</strong>是log-concave，反例比如 <span class="math inline">\(f_1=\lambda_1\exp(-\lambda_1 x),f_2=\lambda_2 \exp(-\lambda_2 x)\)</span>。</p><p>类似的，对于<strong>对数凸函数(log-convex)</strong>也有一些性质：</p><ul><li><span class="math inline">\(\log f\)</span> convex <spanclass="math inline">\(\Longrightarrow f\)</span> convex（since <spanclass="math inline">\(f=\exp(\log f)\)</span>）</li><li>对数凸函数的和也是对数凸函数，即 <spanclass="math inline">\(f_1,f_2\)</span> log-convex <spanclass="math inline">\(\Longrightarrow \log(f_1+f_2)\)</span>convex（注意对数凹函数并没有这个性质）</li><li>给定 <span class="math inline">\(y\)</span>，<spanclass="math inline">\(f(x,y)\)</span> 关于 <spanclass="math inline">\(x\)</span> 是 log-convex，则 <spanclass="math inline">\(g(x)=\int f(x,y)dy\)</span> 是 log-convex</li></ul>]]></content>
    
    
    <categories>
      
      <category>Convex Optimization</category>
      
    </categories>
    
    
    <tags>
      
      <tag>对数凹函数</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Hexo NexT 7.7 主题美化</title>
    <link href="/2020/03/11/software/next-beautify/"/>
    <url>/2020/03/11/software/next-beautify/</url>
    
    <content type="html"><![CDATA[<p>网上很多关于主题美化的教程都是老版本 next 5.1 的，最近更新到 next 7之后摸索了好久才找到简单有效的自定义主题方式，下面是具体的操作。</p><span id="more"></span><p>修改主题下 <code>_config.yml</code>文件，找到下面这一部分，也即注释掉最后一行</p><figure class="highlight gradle"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs gradle">custom_file_path:<br>  #head: <span class="hljs-keyword">source</span><span class="hljs-regexp">/_data/</span>head.swig<br>  #header: <span class="hljs-keyword">source</span><span class="hljs-regexp">/_data/</span>header.swig<br>  #sidebar: <span class="hljs-keyword">source</span><span class="hljs-regexp">/_data/</span>sidebar.swig<br>  #postMeta: <span class="hljs-keyword">source</span><span class="hljs-regexp">/_data/</span>post-meta.swig<br>  #postBodyEnd: <span class="hljs-keyword">source</span><span class="hljs-regexp">/_data/</span>post-body-end.swig<br>  #footer: <span class="hljs-keyword">source</span><span class="hljs-regexp">/_data/</span>footer.swig<br>  #bodyEnd: <span class="hljs-keyword">source</span><span class="hljs-regexp">/_data/</span>body-end.swig<br>  #variable: <span class="hljs-keyword">source</span><span class="hljs-regexp">/_data/</span>variables.styl<br>  #mixin: <span class="hljs-keyword">source</span><span class="hljs-regexp">/_data/mi</span>xins.styl<br>  style: <span class="hljs-keyword">source</span><span class="hljs-regexp">/_data/</span>styles.styl<br></code></pre></td></tr></table></figure><p>然后在<strong>博客根目录</strong>下创建文件<code>blog/source/_data/styles.styl</code>，注意是博客根目录而不是主题下的目录，然后我们就可以在这个文件里边添加自定义配置。</p><blockquote><p>注意想自定义博客外观的话尽量都在这个文件里修改，不要修改其他原始文件，毕竟这个修改坏了删掉就是了，后面所有的修改都是在这一个文件里边添加内容，是不是很简答呢？</p></blockquote><figure class="highlight scss"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><code class="hljs scss"><span class="hljs-comment">// 修改背景图片</span><br><span class="hljs-selector-tag">body</span> &#123;<br>    <span class="hljs-attribute">background</span>: url(/images/background/blue.jpg);<br>    <span class="hljs-attribute">background-size</span>: cover;<br>    <span class="hljs-attribute">background-repeat</span>: no-repeat;<br>    <span class="hljs-attribute">background-attachment</span>: fixed;<br>    <span class="hljs-attribute">background-position</span>: <span class="hljs-number">50%</span> <span class="hljs-number">50%</span>;<br>&#125;<br><br><span class="hljs-comment">// 修改主体透明度</span><br><span class="hljs-comment">// 这个设置并不好使，会使整个页面蒙上一层不透明白色图层，不建议使用</span><br><span class="hljs-comment">// 建议使用下面的 .post-block 与 .comments</span><br><span class="hljs-comment">//.main-inner &#123;</span><br><span class="hljs-comment">//    background: #fff;</span><br><span class="hljs-comment">//    opacity: 0.8;</span><br><span class="hljs-comment">//&#125;</span><br><br><span class="hljs-comment">// 修改文章块透明度</span><br><span class="hljs-selector-class">.post-block</span> &#123;<br><span class="hljs-attribute">padding</span>: <span class="hljs-variable">$content-desktop-padding</span>;<br><span class="hljs-attribute">background</span>: rgba(<span class="hljs-number">255</span>,<span class="hljs-number">255</span>,<span class="hljs-number">255</span>,<span class="hljs-number">0.9</span>);   <span class="hljs-comment">//white;</span><br><span class="hljs-attribute">box-shadow</span>: <span class="hljs-variable">$box-shadow-inner</span>;<br><span class="hljs-attribute">border-radius</span>: <span class="hljs-variable">$border-radius-inner</span>;<br>&#125;<br><br><span class="hljs-comment">// Comments blocks.</span><br><span class="hljs-selector-class">.comments</span> &#123;<br><span class="hljs-attribute">padding</span>: <span class="hljs-variable">$content-desktop-padding</span>;<br><span class="hljs-attribute">margin</span>: initial;<br><span class="hljs-attribute">margin-top</span>: sboffset;<br><span class="hljs-attribute">background</span>: rgba(<span class="hljs-number">255</span>,<span class="hljs-number">255</span>,<span class="hljs-number">255</span>,<span class="hljs-number">0.9</span>);   <span class="hljs-comment">//white;</span><br><span class="hljs-attribute">box-shadow</span>: <span class="hljs-variable">$box-shadow</span>;<br><span class="hljs-attribute">border-radius</span>: <span class="hljs-variable">$border-radius</span>;<br>&#125;<br><br><span class="hljs-comment">// 修改菜单栏透明度</span><br><span class="hljs-selector-class">.header-inner</span> &#123;<br>    <span class="hljs-attribute">opacity</span>: <span class="hljs-number">0.8</span>;<br>&#125;<br><br><span class="hljs-comment">// 设置主页面宽度</span><br><span class="hljs-selector-class">.header</span>&#123;<br>    <span class="hljs-attribute">width</span>: <span class="hljs-number">90%</span>;<br>    +tablet() &#123;<br>        <span class="hljs-attribute">width</span>: <span class="hljs-number">100%</span>;<br>    &#125;<br>    +mobile() &#123;<br>        <span class="hljs-attribute">width</span>: <span class="hljs-number">100%</span>;<br>    &#125;<br>&#125;<br><span class="hljs-selector-class">.container</span> <span class="hljs-selector-class">.main-inner</span> &#123;<br>    <span class="hljs-attribute">width</span>: <span class="hljs-number">90%</span>;<br>    +tablet() &#123;<br>        <span class="hljs-attribute">width</span>: <span class="hljs-number">100%</span>;<br>    &#125;<br>    +mobile() &#123;<br>        <span class="hljs-attribute">width</span>: <span class="hljs-number">100%</span>;<br>    &#125;<br>&#125;<br><span class="hljs-selector-class">.content-wrap</span> &#123;<br>    <span class="hljs-attribute">width</span>: calc(<span class="hljs-number">100%</span> - <span class="hljs-number">260px</span>);<br>    +tablet() &#123;<br>        <span class="hljs-attribute">width</span>: <span class="hljs-number">100%</span>;<br>    &#125;<br>    +mobile() &#123;<br>        <span class="hljs-attribute">width</span>: <span class="hljs-number">100%</span>;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>Hexo</category>
      
    </categories>
    
    
    <tags>
      
      <tag>hexo</tag>
      
      <tag>next</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>模糊数学笔记 5：模糊聚类</title>
    <link href="/2020/03/07/fuzzy/ch5-clustering/"/>
    <url>/2020/03/07/fuzzy/ch5-clustering/</url>
    
    <content type="html"><![CDATA[<p>现在想要对 <span class="math inline">\(n\)</span> 个目标 <spanclass="math inline">\(U=\{x_1,...,x_n\}\)</span>分类，并且每个对象都有多个指标，也即 <spanclass="math inline">\(x_i=\{x_{i1},...,x_{im}\}\)</span>。</p><p>模糊聚类通常包括三个步骤：</p><ol type="1"><li>建立模糊矩阵</li><li>建立模糊等价矩阵</li><li>进行聚类</li></ol><span id="more"></span><h2 id="数据标准化">1. 数据标准化</h2><p>实际中各个指标的量纲与数量级很可能相差很大，比如高校评价指标中，可能包括科研经费、论文数量、获奖数量等，数量级差别很大，这个时候就需要先对各项数据进行标准化。常用方法有</p><p><strong>标准差标准化</strong> <span class="math display">\[x_{ij}&#39;=\frac{x_{ij}-\bar{x}_j}{\sigma_j}\]</span> <strong>极差正规化</strong> <span class="math display">\[\boldsymbol{x}_{i j}^{\prime \prime}=\frac{\boldsymbol{x}_{ij}^{\prime}-\min _{1 \leq i \leq n}\left\{\boldsymbol{x}_{ij}^{\prime}\right\}}{\max _{1}\left\{\boldsymbol{x}_{ij}^{\prime}\right\}-\min _{1: i \leqslant n}\left\{\boldsymbol{x}_{ij}^{\prime}\right\}}\]</span> <strong>极差标准化</strong> <span class="math display">\[x_{i j}^{\prime}=\frac{x_{i j}-\bar{x}_{i}}{\max \left\{x_{ij}\right\}-\min \left\{x_{i j}\right\}}\]</span> <strong>最大值规格化</strong> <span class="math display">\[x_{ij}&#39;=\frac{x_{ij}}{\max{(x_{1j},x_{2j},...,x_{nj})}}\]</span></p><h2 id="建立模糊相似矩阵">2. 建立模糊相似矩阵</h2><p>接下来需要确定不同对象之间的相似度，相似度的确定也有几种常用度量：</p><h3 id="相关系数类">1.1 相关系数类</h3><figure><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2020/5-relation.PNG"alt="correlation" /><figcaption aria-hidden="true">correlation</figcaption></figure><h3 id="距离类">1.2 距离类</h3><figure><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2020/5-distance.PNG"alt="distance" /><figcaption aria-hidden="true">distance</figcaption></figure><h3 id="贴近度类">1.3 贴近度类</h3><figure><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2020/5-nearness.PNG"alt="nearness" /><figcaption aria-hidden="true">nearness</figcaption></figure><h2 id="聚类">3. 聚类</h2><p>获得模糊相似矩阵以后，需要首先求出传递闭包 <spanclass="math inline">\(t(R)\)</span>，以获得模糊等价矩阵，然后根据不同的阈值<span class="math inline">\(\lambda\)</span>进行聚类，然后再画出动态聚类图。</p><p><strong><em>举个栗子</em></strong></p><figure><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2020/5-eg1.PNG"alt="exercise" /><figcaption aria-hidden="true">exercise</figcaption></figure><p>求解过程如下</p><table><thead><tr class="header"><th>0. 特性指标矩阵</th><th>1. 数据标准化</th><th>2. 求模糊相似矩阵</th></tr></thead><tbody><tr class="odd"><td><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2020/5-eg2.PNG" /></td><td><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2020/5-eg3.PNG" /></td><td><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2020/5-eg4.PNG" /></td></tr><tr class="even"><td><strong>3. 求传递闭包</strong></td><td><strong>4. 根据不同阈值聚类</strong></td><td><strong>5. 画动态聚类图</strong></td></tr><tr class="odd"><td><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2020/5-eg5.PNG" /></td><td><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2020/5-eg6.PNG" /></td><td><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2020/5-eg7.PNG" /></td></tr></tbody></table><h2 id="其他问题">4. 其他问题</h2><p>在实际应用过程中，还会出现一些其他问题，比如：</p><ul><li><em>在实际应用中，如何选择适当的 <spanclass="math inline">\(\lambda\)</span>？从而给出一个较明确的聚类。</em></li></ul><p>实际中最佳阈值的确定，可以由专家给出值；也可以应用F-统计量确定最佳阈值。</p><ul><li><em>如果不用传递闭包，直接对相似矩阵进行聚类会怎么样？</em></li></ul><p>直接应用模糊相似矩阵进行聚类时，可以首先确定一个阈值 <spanclass="math inline">\(\lambda\)</span>，然后根据截集获得一系列聚类结果，由于模糊相似矩阵并不是等价矩阵，因此此时的聚类结果是不严谨的，后面需要对交集非空的集合进行合并（这里可能表述的不清楚，看下面的例子就明白了）</p><p><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2020/5-eg8.PNG" /></p><p><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2020/5-eg9.PNG" /></p><p><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2020/5-eg10.PNG" /></p><ul><li><em>当样本点很多时（几百万甚至上千万个像素），例如需要对一张图片上的样本点进行聚类，该怎么办？</em></li></ul><p>可以应用<strong>模糊C均值法(FCM)</strong></p><h2 id="模糊c均值法fcm">5. 模糊C均值法(FCM)</h2><p>设 <span class="math inline">\(x_i(i=1,2,...,n)\)</span>是n个样本组成的样本集合，<span class="math inline">\(c\)</span>为预定的类别数目， <span class="math inline">\(u_{ij}\)</span> 是第<span class="math inline">\(i\)</span> 个样本对于第 <spanclass="math inline">\(j\)</span>类的隶属度函数。用隶属度函数定义的聚类损失函数可以写为 <spanclass="math display">\[\sum_{j=1}^{c} \sum_{i=1}^{n} u_{i j}^{m} d_{i j}^{2}=\sum_{j=1}^{c}\sum_{i=1}^{n} u_{ij}^{m}\left\|\mathbf{p}_{j}-\mathbf{x}_{i}\right\|^{2}\]</span> 其中 <span class="math inline">\(m&gt;1\)</span>，<spanclass="math inline">\(P_j\)</span> 是第 <spanclass="math inline">\(j\)</span>类的聚类中心，后面会给出公式。通常也会假设 <spanclass="math inline">\(\sum_j u_{ij}=1\)</span>。</p><p>下面则给出该算法的推导：为了最小化损失函数，则可以应用 Lagrange乘子法 <span class="math display">\[J=\sum_{i=1}^{n} \sum_{j=1}^{c} u_{i j}^{m} d_{i j}^{2}-\sum_{i=1}^{n}\lambda_{i}\left(\left(\sum_{j=1}^{c} u_{i j}\right)-1\right)\]</span> 对 <span class="math inline">\(\lambda_i,u_{ij}\)</span>求偏导等于 0，则可以得到迭代公式为 <span class="math display">\[u_{i j}=\frac{\left(\frac{1}{d_{i j}}\right)^{2/(m-1)}}{\sum_{k=1}^{c}\left(\frac{1}{d_{i k}}\right)^{2 /(m-1)}}\\\mathbf{p}_{j}=\frac{\sum_{i=1}^{n} u_{i j}^{m}\mathbf{x}_{i}}{\sum_{i=1}^{n} u_{i j}^{m}}\]</span> 由此就可以给出 FCM 算法的框架</p><figure><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2020/5-fcm.PNG"alt="FCM" /><figcaption aria-hidden="true">FCM</figcaption></figure>]]></content>
    
    
    <categories>
      
      <category>Fuzzy Mathematics</category>
      
    </categories>
    
    
    <tags>
      
      <tag>模糊矩阵</tag>
      
      <tag>模糊聚类</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>凸优化笔记 7：拟凸函数 Quasiconvex Function</title>
    <link href="/2020/03/06/optimization/ch7-quasicvx/"/>
    <url>/2020/03/06/optimization/ch7-quasicvx/</url>
    
    <content type="html"><![CDATA[<h2 id="拟凸函数定义">1. 拟凸函数定义</h2><p><strong>拟凸函数(quasiconvex function)</strong>的定义为：若 <spanclass="math inline">\(\text{dom}f\)</span> 为凸集，且对任意的 <spanclass="math inline">\(\alpha\)</span>，其下水平集 <spanclass="math display">\[S_\alpha = \{x\in\text{dom}f | f(x)\le\alpha\}\]</span> 都是凸集，则 <span class="math inline">\(f\)</span>为拟凸函数。</p><span id="more"></span><p>类似的有<strong>拟凹函数(quasiconcave)</strong>的定义。如果一个函数既是拟凸的，又是拟凹的，那么它是<strong>拟线性(quasilinear)</strong>的。</p><blockquote><p><strong>Reamrks</strong>：对于拟线性函数，要求其上水平集和下水平集同时是凸集，因此简单理解，其在某种意义上具有“单调性”。比如<span class="math inline">\(e^x,\log x\)</span> 等。</p></blockquote><table><thead><tr class="header"><th>拟凸函数</th><th>各种函数的关系</th></tr></thead><tbody><tr class="odd"><td><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2020/7-quasicvx.PNG"alt="quasiconvex function" /></td><td><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2020/7-quasi.PNG"alt="functions" /></td></tr></tbody></table><p>一些常见的拟凸/拟凹/拟线性函数比如</p><p><strong><em>拟凸函数</em></strong></p><ul><li><span class="math inline">\(f(x)=\sqrt{|x|}\)</span></li><li><span class="math inline">\(f(x)=\frac{\Vert x-a\Vert_2}{\Vertx-b\Vert_2},\text{dom}f=\{x|\Vert x-a\Vert_2 \le \Vertx-b\Vert_2\}\)</span></li></ul><p><strong><em>拟凹函数</em></strong></p><ul><li><span class="math inline">\(f(x)=x_1x_2\)</span> on <spanclass="math inline">\(R^2\)</span></li></ul><p><strong><em>拟线性函数</em></strong></p><ul><li><span class="math inline">\(\text{ceil}(x)=\inf\{z\in Z|z\gex\}\)</span></li><li><span class="math inline">\(\log x\)</span> on <spanclass="math inline">\(R_{++}\)</span></li><li><spanclass="math inline">\(f(x)=\frac{a^Tx+b}{c^Tx+d},\text{dom}f=\{c^Tx+d&gt;0\}\)</span> (注意 <span class="math inline">\(f\)</span>本身不是凸函数，但是是一个保凸变换)</li></ul><h2 id="拟凸函数的判定等价定义">2. 拟凸函数的判定/等价定义</h2><p>对于普通凸函数，有一些等价定义，比如</p><ul><li>Jensen 不等式 / 凸函数原生定义：<span class="math inline">\(f(\thetax+(1-\theta)y)\le \theta f(x)+(1-\theta)f(y)\)</span></li><li>“降维打击”：<span class="math inline">\(g(t)=f(x+tv)\)</span> convex<span class="math inline">\(\iff f(x)\)</span> convex</li><li>一阶条件：<span class="math inline">\(f(x)\)</span> convex <spanclass="math inline">\(\iff f(y)\ge \nabla f^T(x)(y-x)\)</span></li><li>二阶条件：<span class="math inline">\(f(x)\)</span> convex <spanclass="math inline">\(\iff \nabla f^2(x)\succeq 0\)</span></li><li>epigraph：<span class="math inline">\(f(x)\)</span> convex <spanclass="math inline">\(\iff \text{epi}f\)</span> convex</li></ul><h3 id="jensen-不等式">2.1 Jensen 不等式</h3><blockquote><p><strong>等价定义 1</strong>：函数 <spanclass="math inline">\(f\)</span>为拟凸的<strong>等价于</strong>：定义域为凸集，且 <spanclass="math display">\[0\le\theta\le1 \Longrightarrow f(\thetax+(1-\theta)y)\le\max\{f(x),f(y)\}\]</span> 证明可以直接用定义。</p></blockquote><h3 id="降维打击">2.1 “降维打击”</h3><blockquote><p><strong>等价定义 2</strong>：<spanclass="math inline">\(g(t)=f(x+tv)\)</span> quasiconvex <spanclass="math inline">\(\iff f(x)\)</span> quasiconvex</p><p>证明可以直接用定义。</p><p><strong>Reamrks</strong>：这种“降维打击”的定义方式实际上就是要求<span class="math inline">\(f\)</span>沿着任意一个方向都是(拟)凸的，对于一些高维空间中难以判定凸性，而其一维形式又比较简单的函数来说较适用，比如下面的二阶条件的证明。</p></blockquote><h3 id="一阶条件">2.2 一阶条件</h3><blockquote><p><strong>等价定义 3</strong>：<spanclass="math inline">\(f(x)\)</span> quasiconvex<strong>等价于</strong>：定义域为凸集，且 <span class="math display">\[f(y)\le f(x) \Longrightarrow \nabla f^T(x)(y-x)\le0\]</span> <strong>Remarks</strong>：该定义实际上是指 <spanclass="math inline">\(\nabla f(x)\)</span> 定义了一个 <spanclass="math inline">\(R^n\)</span>空间中的超平面(作为法向量)，该超平面就是某一个下水平集的支撑超平面 <spanclass="math display">\[S_\alpha = \{y| f(y)\le f(x)=\alpha \}\subseteq R^n\]</span> 需要注意的是，前面讲的对于凸函数来说 <spanclass="math inline">\(\left[\nabla f^T(x)\ \ -1\right]^T\)</span>定义了一个 <span class="math inline">\(R^{n+1}\)</span>空间中的支撑超平面。注意二者的不同！！！前者是<strong>下水平集的支撑超平面</strong>，后者是<strong>凸函数surface 的支撑超平面</strong>，二者相差一个维度。</p><figure><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2020/7-quasi_support.PNG"alt="support hyperplane" /><figcaption aria-hidden="true">support hyperplane</figcaption></figure><p>上图中三条封闭曲线代表三个水平集，而 <spanclass="math inline">\(\nabla f(x)\)</span>就是其中一个水平集的支撑超平面。这可以联想梯度下降法（牛顿下山法），想象这是一个山谷，每一条线都是一个等高线，<spanclass="math inline">\(\left[\nabla f^T(x)\ \-1\right]^T\)</span>是山坡地面的法向量，指向空中，而<spanclass="math inline">\(\nablaf(x)\)</span>则在这个等高线所在的平面内，且指向山体内部，与等高线相切。。</p></blockquote><h3 id="二阶条件">2.3 二阶条件</h3><p>对于拟凸函数来说，没有二阶的充分必要条件，有充分条件和必要条件。</p><blockquote><p><strong>必要条件</strong>：<span class="math inline">\(f(x)\)</span>quasiconvex <span class="math inline">\(\Longrightarrow\)</span> 对任意<span class="math inline">\(x\in\text{dom}f,y\in R^n\)</span> <spanclass="math display">\[\text{if }\quad  y^T \nabla f(x)=0 \Longrightarrow y^T\nabla^2f(x)y\ge0\]</span> 对于一维函数，只需要 <span class="math inline">\(f&#39;(x)=0\Longrightarrow f&#39;&#39;(x)\ge0\)</span></p><p><strong>充分条件</strong>：<span class="math inline">\(f(x)\)</span>quasiconvex <span class="math inline">\(\Longleftarrow\)</span> 对任意<span class="math inline">\(x\in\text{dom}f,y\in R^n,y\ne0\)</span><span class="math display">\[\text{if }\quad  y^T \nabla f(x)=0 \Longrightarrow y^T\nabla^2f(x)y&gt;0\]</span> 证明：注意这里对于一维函数 <span class="math inline">\(f:R\toR\)</span> 较简单，因此可以应用“降维打击”的等价定义进行证明。</p></blockquote><h2 id="拟凸函数的保凸变换">3. 拟凸函数的保凸变换</h2><p>先来复习一下凸函数的保凸变换</p><ul><li>正权重求和</li><li>与仿射变换复合</li><li>最大值/上确界</li><li>单调凸函数与凸函数的复合</li><li>下确界</li><li>透射变换</li></ul><p>拟凸函数的也是类似的，主要少了第一个和最后一个，也即拟凸函数的正权重求和不一定是拟凸的，也没有透射变换的定义。</p><h3 id="与仿射变换复合">3.1 与仿射变换复合</h3><blockquote><p>若 <span class="math inline">\(f\)</span> 拟凸，则 <spanclass="math inline">\(g(x)=f(Ax+b)\)</span> 也是拟凸的</p></blockquote><p>这个也很简单，因为 <span class="math inline">\(g(x)\)</span>的下水平集就是 <span class="math inline">\(f(y)\)</span>的下水平集外加仿射变换 <spanclass="math inline">\(y=Ax+b\)</span>，仿射变换不改变凸性。</p><h3 id="最大值上确界">3.2 最大值/上确界</h3><blockquote><p><strong>离散情况</strong>：<spanclass="math inline">\(f=\max\{\omega_1 f_1,...,\omega_mf_m\},\omega_i\ge0\)</span></p><p><strong>连续情况</strong>：<spanclass="math inline">\(g(x)=\sup\{w(y)f(x,y),\omega(y)\ge0\}\)</span>是拟凸的，如果 <span class="math inline">\(f(\cdot,y)\)</span>是拟凸的</p></blockquote><p>证明很简单，因为导出函数的下水平集就是多个拟凸函数下水平集的交集，当然也是凸集。</p><h3 id="复合函数">3.3 复合函数</h3><blockquote><p>如果 <span class="math inline">\(g\)</span> 为拟凸函数，且 <spanclass="math inline">\(h\)</span> 单调递增，则 <spanclass="math inline">\(f=h\circ g\)</span> 是拟凸的</p></blockquote><p>证明的话也可以从下水平集的角度理解。</p><p><strong><em>例</em></strong>：若 <spanclass="math inline">\(f\)</span> 是拟凸的，则 <spanclass="math inline">\(g(x)=f(Ax+b)\)</span> 是拟凸的，且 <spanclass="math inline">\(\tilde{g}(x)=f((Ax+b)/(c^Tx+d))\)</span>也是拟凸的，其中 <span class="math display">\[\{x|c^Tx+d&gt;0,(Ax+b)/(c^Tx+d)\in\text{dom}f\}\]</span> 原因很简单，<span class="math inline">\(\tilde{g}(x)\)</span>的下水平集就是 <span class="math inline">\(f(y)\)</span>的下水平集外加一个线性分式变换 <spanclass="math inline">\(y=(Ax+b)/(c^Tx+d)\)</span>，而线性分式函数也不改变凸性。</p><h3 id="下确界">3.4 下确界</h3><blockquote><p><span class="math inline">\(f(x,y)\)</span> 对于 <spanclass="math inline">\((x,y)\)</span> 是拟凸的，则 <spanclass="math inline">\(g(x)=\inf_{y\in C}f(x,y)\)</span> 是拟凸的</p></blockquote><p>证明可以应用 Jensen 不等式。</p><blockquote><p><strong>Reamrks</strong>：这些保凸变换，前三个都可以直接从下水平集的角度来理解和证明，变换后函数的下水平集都是原始函数下水平集外加一个集合保凸变换，最后一个则不太直观，不过也可以由Jensen不等式直接导出。看来要理解拟凸函数，还是要多从下水平集的角度来看，并且集合的保凸变换也是很重要的！</p></blockquote>]]></content>
    
    
    <categories>
      
      <category>Convex Optimization</category>
      
    </categories>
    
    
    <tags>
      
      <tag>拟凸函数</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>凸优化笔记 6：共轭函数 Conjugate Function</title>
    <link href="/2020/03/04/optimization/ch6-conjugate-func/"/>
    <url>/2020/03/04/optimization/ch6-conjugate-func/</url>
    
    <content type="html"><![CDATA[<h2 id="共轭函数">1. 共轭函数</h2><h3 id="定义">1.1 定义</h3><p>一个函数 <span class="math inline">\(f\)</span>的<strong>共轭函数(conjugate function)</strong> 定义为 <spanclass="math display">\[f^*(y)=\sup_{x\in\text{dom}f}(y^Tx-f(x))\]</span> <imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2020/6-conjugate.PNG"alt="conjugate function" /></p><span id="more"></span><p><span class="math inline">\(f^*\)</span>是凸函数，证明也很简单，可以看成是一系列关于 <spanclass="math inline">\(y\)</span> 的凸函数取上确界。</p><p><strong>Remarks</strong>：实际上共轭函数与前面讲的一系列支撑超平面包围<span class="math inline">\(f\)</span> 很类似，通过 <spanclass="math inline">\(y\)</span>取不同的值，也就获得了不同斜率的支撑超平面，最后把 <spanclass="math inline">\(f\)</span> 包围起来，就好像是得到了 <spanclass="math inline">\(\text{epi }f\)</span> 的一个闭包，如下图所示</p><figure><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2020/6-conjugate2.PNG"alt="conjugate function" /><figcaption aria-hidden="true">conjugate function</figcaption></figure><h3 id="性质">1.2 性质</h3><p>关于共轭函数有以下性质</p><ol type="1"><li>若 <span class="math inline">\(f\)</span> 为凸的且是闭的(<spanclass="math inline">\(\text{epi }f\)</span> 为闭集)，则 <spanclass="math inline">\(f^{**}=f\)</span>(可以联系上面提到一系列支撑超平面)</li><li>(Fenchel's inequality) <span class="math inline">\(f(x)+f^*(y)\gex^Ty\)</span>，这可以类比均值不等式</li><li>(Legendre transform)如果 <span class="math inline">\(f\inC^1\)</span>，且为凸的、闭的，设 <spanclass="math inline">\(x^*=\arg\max\{y^Tx-f(x)\}\)</span>，那么有 <spanclass="math inline">\(x^*=\nabla f^*(y)\iff y=\nablaf(x^*)\)</span>。这可以用来求极值，比如 <span class="math inline">\(\minf(x)\Longrightarrow 0=\nabla f(x)\iff x=\nabla f^*(0)\)</span></li></ol><h3 id="例子">1.3 例子</h3><p>常用的共轭函数的例子有</p><p><strong>负对数函数</strong> <span class="math inline">\(f(x)=-\logx\)</span> <span class="math display">\[\begin{aligned}f^{*}(y) &amp;=\sup _{x&gt;0}(x y+\log x) \\&amp;=\left\{\begin{array}{ll}-1-\log (-y) &amp; y&lt;0 \\\infty &amp; \text { otherwise }\end{array}\right.\end{aligned}\]</span> <strong>凸二次函数</strong> <spanclass="math inline">\(f(x)=(1 / 2) x^{T} Q x\)</span> with <spanclass="math inline">\(Q \in \mathbf{S}_{++}^{n}\)</span> <spanclass="math display">\[\begin{aligned}f^{*}(y) &amp;=\sup _{x}\left(y^{T} x-(1 / 2) x^{T} Q x\right) \\&amp;=\frac{1}{2} y^{T} Q^{-1} y\end{aligned}\]</span> <strong>指示函数</strong> <spanclass="math inline">\(I_S(x)=0\)</span> on <spanclass="math inline">\(\text{dom}I_S=S\)</span> <spanclass="math display">\[I_S^*(y)=\sup\{y^Tx|x\in S\}\]</span> <strong>log-sum-exp 函数</strong> <spanclass="math inline">\(f(x)=\log\sum\exp x_i\)</span> <spanclass="math display">\[f^{*}(y)=\left\{\begin{array}{ll}\sum_{i=1}^{n} y_{i} \log y_{i} &amp; \text { if } y \succeq 0 \text {and } \mathbf{1}^{T} y=1 \\\infty &amp; \text { otherwise. }\end{array}\right.\]</span> <strong>范数</strong> <span class="math inline">\(f(x)=\Vertx\Vert\)</span> <span class="math display">\[f^{*}(y)=\left\{\begin{array}{ll}0 &amp; \|y\|_{*} \leq 1 \\\infty &amp; \text { otherwise }\end{array}\right.\]</span> <strong>范数平方</strong> <spanclass="math inline">\(f(x)=(1/2)\Vert x\Vert^2\)</span> <spanclass="math display">\[f^*(y)=(1/2)\Vert y\Vert_*^2\]</span> <strong>负熵</strong> <span class="math inline">\(f(x)=\sumx_i\log x_i\)</span> <span class="math display">\[f^*(y)=\sum e^{y_i-1}\]</span></p>]]></content>
    
    
    <categories>
      
      <category>Convex Optimization</category>
      
    </categories>
    
    
    <tags>
      
      <tag>共轭函数</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>凸优化笔记 5：保凸变换</title>
    <link href="/2020/03/04/optimization/ch5-preserve-cvx/"/>
    <url>/2020/03/04/optimization/ch5-preserve-cvx/</url>
    
    <content type="html"><![CDATA[<h2 id="保凸变换">1. 保凸变换</h2><p>前面提到过一次保凸变换，前面针对的是集合，凸集经过一定的保凸变换，映射后的集合仍然是凸集。这里复习一下</p><ol type="1"><li>任意个凸集的交集</li><li>仿射变换</li><li>透视变换</li><li>分式线性函数</li></ol><p>而这里要讲的是对函数经过操作以后，得到的仍然是凸函数。</p><span id="more"></span><h3 id="正权重求和">1.1 正权重求和</h3><blockquote><p>离散情况：<span class="math inline">\(f=\sum\omega_if_i,\omega_i\ge0\)</span></p><p>连续情况：<spanclass="math inline">\(f=\int\omega(y)f(y)dy,\omega(y)\ge0\)</span></p></blockquote><h3 id="与仿射变换的复合函数">1.2 与仿射变换的复合函数</h3><blockquote><p>若 <span class="math inline">\(f\)</span> 为凸函数，则 <spanclass="math inline">\(f(Ax+b)\)</span> 也为凸函数。</p></blockquote><p><strong>Remarks</strong>：反之则不一定成立，若想成立（根据后面复合函数的原理）则仿射变换应具有一定的单调性。</p><h3 id="逐元素最大值上确界">1.3 逐元素最大值&amp;上确界</h3><blockquote><p>若 <span class="math inline">\(f_i\)</span> 均为凸函数，则 <spanclass="math inline">\(f(x)=\max_i\{f_1(x),...,f_n(x)\}\)</span>也为凸函数。</p></blockquote><p><strong>Remarks</strong>：这实际上可以看成是 <spanclass="math inline">\(\text{epi} f=\bigcap\text{epi}f_i\)</span>，多个凸集的交集仍然是凸集。</p><blockquote><p>若与仿射变换相结合，则可以得到 <spanclass="math inline">\(f(x)=\max_i\{a_1^Tx+b_1,...,a_n^Tx+b_n\}\)</span>也是凸函数。</p></blockquote><p><strong><em>例</em></strong>：根据上述结论，可以推广得到，<spanclass="math inline">\(n\)</span> 个元素中最大的 <spanclass="math inline">\(r\)</span> 的求和也是凸函数，证明很简单。</p><blockquote><p>若 <span class="math inline">\(f(x,y)\)</span> 关于 <spanclass="math inline">\(x\)</span> 是凸的，对任意 <spanclass="math inline">\(y\in\mathcal{A}\)</span>，则 <spanclass="math inline">\(g(x)=\sup_{y\in\mathcal{A}}f(x,y)\)</span>也是凸的。</p></blockquote><p><strong>Remarks</strong>：上述情况跟逐元素最大值是类似的，可以看成是无穷个epigraph 的交集。</p><blockquote><p>由上述结论，可以得到一个重要性质</p><p><strong>Property</strong>：若 <span class="math inline">\(f\)</span>为凸函数，则 <span class="math inline">\(f(x)=\sup\{g(x)| g\ \text{isaffine},g(z)\le f(z),\forall z\}\)</span></p><p><strong>Remarks</strong>：上述性质所描述的事情实际上就是 <spanclass="math inline">\(f\)</span>被很多个支撑超平面(以及更靠下的平面)紧紧的围起来了。证明过程实际上就是找到每个<span class="math inline">\(x\)</span> 对应的(支撑)超平面。</p><figure><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2020/5-support.jpg"alt="support hyperplane" /><figcaption aria-hidden="true">support hyperplane</figcaption></figure><p>通过上面的证明，可以得到的一个结论就是 <spanclass="math inline">\(\forall x\in \text{int dom}f\)</span>，都存在一个<span class="math inline">\(y\)</span> 使得 <spanclass="math display">\[f(z)\ge f(x)+y^T(z-x),\forall z\in\text{dom}f\]</span> 由此可以引出<strong>次梯度(subgradient)</strong>的概念 <spanclass="math display">\[\partial f=\{g| f(z)\ge f(x)+g^T(z-x),\forall z\in\text{dom}f \}\]</span> 注意这里得到的是一系列梯度值的集合，这个集合有以下性质</p><ol type="1"><li><span class="math inline">\(\partial f(x)\ne \varnothing, \text{if}\x\in\text{int dom}f\)</span></li><li><span class="math inline">\(\partial f(x)\)</span> convex andclosed</li><li><span class="math inline">\(\partial f(x)\)</span> bounded if <spanclass="math inline">\(x\in\text{int dom}f\)</span></li></ol></blockquote><p><strong><em>例</em></strong>：应用上述结论，可验证下面这些函数是凸的</p><ol type="1"><li>集合 <span class="math inline">\(C\)</span> 的支撑函数(supportfunction)定义为：<span class="math inline">\(S_C(x)=\sup_{y\inC}y^Tx\)</span> (实际上可以将 <span class="math inline">\(x\)</span>看作某个支撑超平面的法向量)</li><li>到集合 <span class="math inline">\(C\)</span> 的最远距离：<spanclass="math inline">\(f(x)=\sup_{y\in C}\Vert x-y\Vert\)</span>(距离关于 <span class="math inline">\(x,y\)</span> 都是凸的)</li><li>矩阵范数：<span class="math inline">\(\VertX\Vert_{a,b}=\sup\left\{\Vert Xv\Vert_a / \Vertv\Vert_b\right\}\)</span> (证明过程用到了范数的等价定义，可参考 Boyd的书)</li></ol><h3 id="下确界">1.4 下确界</h3><p>前面提到了逐元素上确界，实际上就是 epigraph的交集，而取下确界呢？是类似的，只不过对 <spanclass="math inline">\(f(x,y)\)</span> 的要求更严了</p><blockquote><p>若 <span class="math inline">\(f(x,y)\)</span> 关于 <spanclass="math inline">\((x,y)\)</span> 是凸的，<strong><spanclass="math inline">\(C\)</span> 是一个凸集</strong>，则 <spanclass="math inline">\(g(x)=\inf_{y\in C}f(x,y)\)</span> 是凸的。</p></blockquote><p>上述性质可应用下确性质定义来证明，也可以从 epigraph 角度来理解：<spanclass="math inline">\(\forall(x,t)\in\text{epi }g\)</span>，都有 <spanclass="math inline">\((x,y,t)\in \text{epi }f,\text{ for some }y\inC\)</span>，所以 <span class="math inline">\(\text{epi }g\)</span>实际上可以看作 <span class="math inline">\(\text{epi }f\)</span>向低维空间中的一个投影，也是一个仿射变换/线性变换，因此 <spanclass="math inline">\(\text{epi }g\)</span> 也是凸的。</p><p><strong>Remarks</strong>：注意上面还要求 <spanclass="math inline">\(C\)</span>是一个凸集，因为凸函数要求其定义域也为凸集。</p><p><strong><em>例</em></strong>：到集合 <spanclass="math inline">\(C\)</span> 最近距离：<spanclass="math inline">\(\text{dist}(x,S)=\inf_{y\in S}\Vertx-y\Vert\)</span> 是凸的，如果 <span class="math inline">\(S\)</span>是凸的。</p><h3 id="复合函数">1.5 复合函数</h3><p>两个凸函数的复合函数不一定是凸的，比如 <spanclass="math inline">\(f(x)=-x,g(x)=x^2\)</span>，那么 <spanclass="math inline">\(f(g(x))=-x^3\)</span> 非凸</p><blockquote><h4 id="标量复合函数">1. 标量复合函数</h4><p>有函数 <span class="math inline">\(g:R^n\to R,\ h:R\toR\)</span>，对于复合函数 <span class="math inline">\(f(x)=h(g(x))\)</span></p><ol type="1"><li><span class="math inline">\(f(x)\)</span> 为凸函数，若 <spanclass="math inline">\(g\)</span> convex，<spanclass="math inline">\(h\)</span> convex，<spanclass="math inline">\(h\)</span> <strong>单调不减</strong></li><li><span class="math inline">\(f(x)\)</span> 为凸函数，若 <spanclass="math inline">\(g\)</span> concave，<spanclass="math inline">\(h\)</span> convex，<spanclass="math inline">\(h\)</span> <strong>单调增</strong></li></ol><h4 id="向量复合函数">2. 向量复合函数</h4><p>有函数 <span class="math inline">\(g:R^n\to R^k,\ h:R^k\toR\)</span>，对于复合函数 <span class="math inline">\(f(x)=h(g(x))=h(g_1(x),...,g_n(x))\)</span></p><ol type="1"><li><span class="math inline">\(f(x)\)</span> 为凸函数，若 <spanclass="math inline">\(g_i\)</span> convex，<spanclass="math inline">\(h\)</span> convex，<spanclass="math inline">\(h\)</span><strong>关于每个元素</strong>都单调不减</li><li><span class="math inline">\(f(x)\)</span> 为凸函数，若 <spanclass="math inline">\(g_i\)</span> concave，<spanclass="math inline">\(h\)</span> convex，<spanclass="math inline">\(h\)</span><strong>关于每个元素</strong>都单调增</li></ol></blockquote><p>证明：标量函数 <span class="math inline">\(f^{\prime\prime}(x)=h^{\prime \prime}(g(x)) g^{\prime}(x)^{2}+h^{\prime}(g(x))g^{\prime \prime}(x)\)</span></p><p>向量复合函数 <span class="math inline">\(f^{\prime\prime}(x)=g^{\prime}(x)^{T} \nabla^{2} h(g(x)) g^{\prime}(x)+\nablah(g(x))^{T} g^{\prime \prime}(x)\)</span></p><p><strong>Remarks</strong>：</p><ol type="1"><li>回到刚开始提到仿射变换与凸函数的复合 <spanclass="math inline">\(f(Ax+b)\)</span> 是凸的，但是 <spanclass="math inline">\(Affine(f(x))\)</span>就不一定了，若是凸函数则需要仿射变换具有一定的单调性</li></ol><p><strong><em>例</em></strong>：常见的例子有</p><ol type="1"><li><span class="math inline">\(\exp g(x)\)</span> 是凸的，如果 <spanclass="math inline">\(g(x)\)</span> 是凸的</li><li><span class="math inline">\(1/g(x)\)</span> 是凸的，如果 <spanclass="math inline">\(g(x)\)</span> 是凸的且为正值</li><li><span class="math inline">\(\sum\log g_i(x)\)</span> 为凹的，如果<span class="math inline">\(g_i\)</span> 是凹的且为正值</li><li><span class="math inline">\(\log\sum\exp g_i(x)\)</span>为凸的，如果 <span class="math inline">\(g_i\)</span> 为凸的</li></ol><h3 id="透射变换">1.6 透射变换</h3><p>函数 <span class="math inline">\(f:R^n\to R\)</span> 的透射变换 <spanclass="math inline">\(g:R^n\times R\to R\)</span> 定义为 <spanclass="math display">\[g(x,t)=tf(x/t),\text{dom }g=\{(x,t)|x/t \in\text{dom }f,t&gt;0 \}\]</span></p><blockquote><p>若 <span class="math inline">\(f\)</span> 是凸的，则 <spanclass="math inline">\(g\)</span> 是凸的。</p></blockquote><p><strong>Remarks</strong>：上述变换在一些问题中应该能够对应一些物理意义，不过我暂时还没想起来。证明也可以用epigraph 来证明。</p><p><strong>例</strong>：对负熵 <span class="math inline">\(f(x)=-\logx\)</span>，相对熵为 <span class="math inline">\(g(x,t)=t\log t-t\logx\)</span></p><p>类似的，对向量函数 <spanclass="math inline">\(KL(u,v)=-\sum(u_i\log(u_i/v_i)-u_i+v_i)\)</span>也是凸的，这实际上就就是 KL-divergence。</p>]]></content>
    
    
    <categories>
      
      <category>Convex Optimization</category>
      
    </categories>
    
    
    <tags>
      
      <tag>保凸变换</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>模糊数学笔记 4：模糊关系</title>
    <link href="/2020/03/01/fuzzy/ch4-relation/"/>
    <url>/2020/03/01/fuzzy/ch4-relation/</url>
    
    <content type="html"><![CDATA[<h2 id="模糊关系">1. 模糊关系</h2><p><strong>定义</strong>：模糊关系 <spanclass="math inline">\(R\)</span> 的隶属函数 <spanclass="math inline">\(\mu_R:U\times V\to[0,1]\)</span>，其中 <spanclass="math inline">\(\mu_R(x,y)\)</span> 表示 <spanclass="math inline">\((x,y)\)</span> 具有关系 <spanclass="math inline">\(R\)</span> 的程度</p><blockquote><p><strong>Remarks</strong>：实际上模糊关系 <spanclass="math inline">\(R\)</span> 就是定义在一个笛卡尔积的论域 <spanclass="math inline">\(U\times V\)</span>上的模糊关系，与之前介绍的普通的模糊关系并无太大差别。</p></blockquote><span id="more"></span><p>基本运算定义为：</p><ul><li><strong>并</strong>：<span class="math inline">\(\boldsymbol{\mu}_{R\cup S}(\boldsymbol{x},\boldsymbol{y})=\boldsymbol{\mu}_{R}(\boldsymbol{x}, \boldsymbol{y})\vee \boldsymbol{\mu}_{S}(\boldsymbol{x}, \boldsymbol{y})\)</span></li><li><strong>交</strong>：<span class="math inline">\(\boldsymbol{\mu}_{R\cap S}(\boldsymbol{x},\boldsymbol{y})=\boldsymbol{\mu}_{R}(\boldsymbol{x}, \boldsymbol{y})\wedge \boldsymbol{\mu}_{S}(\boldsymbol{x},\boldsymbol{y})\)</span></li><li><strong>补</strong>：<spanclass="math inline">\(\mu_\bar{R}(x,y)=1-\mu_R(x,y)\)</span></li><li><strong>包含</strong>：<span class="math inline">\(\boldsymbol{R}\subseteq \boldsymbol{S} \Rightarrow\boldsymbol{\mu}_{R}(\boldsymbol{x}, \boldsymbol{y}) \leq\boldsymbol{\mu}_{S}(\boldsymbol{x}, \boldsymbol{y})\)</span></li><li><strong>相等</strong>：<span class="math inline">\(\boldsymbol{R} =\boldsymbol{S} \Rightarrow \boldsymbol{\mu}_{R}(\boldsymbol{x},\boldsymbol{y}) = \boldsymbol{\mu}_{S}(\boldsymbol{x},\boldsymbol{y})\)</span></li></ul><p>一些模糊关系有：</p><ul><li><strong>恒等模糊关系</strong>：<spanclass="math inline">\(R(x,y)=\mathbb{I}_{x=y}\)</span></li><li><strong>零模糊关系</strong>：<spanclass="math inline">\(O(x,y)=0\)</span></li><li><strong>全称模糊关系</strong>：<spanclass="math inline">\(E(x,y)=1\)</span></li></ul><h2 id="模糊矩阵">2. 模糊矩阵</h2><h3 id="定义">2.1 定义</h3><p>对于有限论域 <spanclass="math inline">\(U,V\)</span>，模糊矩阵的定义很容易可以获得 <spanclass="math inline">\(R_{ij}=\mu_R(x_i,y_j)\)</span></p><p>当 <span class="math inline">\(R\)</span> 的对角元素全部为 1时，称为<strong>模糊自反矩阵</strong></p><p>模糊矩阵对应于集合的运算定义为：</p><ul><li><strong>并</strong>：<span class="math inline">\(\boldsymbol{R} \cup\boldsymbol{S} \Leftrightarrow \boldsymbol{R} \cup\boldsymbol{S}=\left(\boldsymbol{r}_{i j} \vee \boldsymbol{s}_{ij}\right)\)</span></li><li><strong>交</strong>：<span class="math inline">\(\boldsymbol{R} \cap\boldsymbol{S} \Leftrightarrow \boldsymbol{R} \cup\boldsymbol{S}=\left(\boldsymbol{r}_{i j} \wedge \boldsymbol{s}_{ij}\right)\)</span></li><li><strong>补</strong>：<spanclass="math inline">\(R^c=(1-r_{ij})\)</span></li><li><strong>包含</strong>：<span class="math inline">\(\boldsymbol{R}\subseteq \boldsymbol{S} \Leftrightarrow\left(\boldsymbol{r}_{ij}\right) \leq\left(\boldsymbol{s}_{i j}\right)\)</span></li><li><strong>相等</strong>：<span class="math inline">\(\boldsymbol{R} =\boldsymbol{S} \Leftrightarrow\left(\boldsymbol{r}_{i j}\right)=\left(\boldsymbol{s}_{i j}\right)\)</span></li></ul><h3 id="运算性质">2.2 运算性质</h3><p><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2020/4-prop1.PNG" /></p><p><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2020/4-prop2.png" /></p><h3 id="截矩阵">2.3 截矩阵</h3><p><strong>截矩阵</strong>的定义为 <spanclass="math inline">\(R_\lambda=(r_{ij}(\lambda))\)</span>，其中 <spanclass="math inline">\(r_{ij}(\lambda)=\mathbb{I}_{r_{ij}\ge\lambda}\)</span></p><blockquote><p><strong>Remarks</strong>：截矩阵的定义对应着截集的概念，截集得到的是普通集合，响应的截矩阵也是布尔矩阵，完全没有不确定度。</p></blockquote><h3 id="模糊关系合成">2.4 模糊关系合成</h3><p><strong>转置</strong>：略</p><p><strong>模糊乘积</strong>：设 <spanclass="math inline">\(Q=(q_{ij})_{n\times m},R=(r_{ij})_{m\timest}\)</span>，定义 <spanclass="math inline">\(S=QR\in\mathcal{F}_{n\times t}\)</span>，有 <spanclass="math inline">\(S_{ik}=\vee_{j=1}^m(q_{ij}\wedger_{jk})\)</span></p><blockquote><p><strong>Remarks</strong>：模糊乘积实际上表示了两个模糊关系的复合，即<span class="math inline">\(Q\in\mathcal{F}(U\timesV),R\in\mathcal{F}(V\times W)\)</span>，最后合成了模糊关系 <spanclass="math inline">\(S\in\mathcal{F}(U\timesW)\)</span>。从公式上来看，模糊矩阵的乘积跟普通矩阵的乘积很像，只不过乘法换成了<span class="math inline">\(\wedge\)</span>，加法换成了 <spanclass="math inline">\(\vee\)</span>。</p></blockquote><p>模糊关系的合成具有以下性质：</p><p><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2020/4-prop3.png" /></p><h2 id="模糊关系性质">3. 模糊关系性质</h2><h3 id="自反性对称性传递性">3.1 自反性、对称性、传递性</h3><p>就像普通集合的关系一样，模糊集合有三个重要性质：自反性、对称性、传递性。</p><p><strong>自反性</strong>：若 <span class="math inline">\(\forall x\inU,\mu_R(x,x)=1\)</span>，则称 <span class="math inline">\(R\)</span>满足<strong>自反性</strong>，相应的有模糊矩阵 <spanclass="math inline">\(I\subseteq R\)</span></p><p><strong>定理 1</strong>：若 <span class="math inline">\(A\)</span>为自反矩阵，则有 <span class="math display">\[I\subseteq A \subseteq A^2 \subseteq \cdots \subseteq A^n \subseteq\cdots\]</span> <strong>对称性</strong>：若 <spanclass="math inline">\(\forall x,y\inU,\mu_R(x,y)=\mu_R(y,x)\)</span>，则称 <spanclass="math inline">\(R\)</span>满足<strong>对称性</strong>，相应的有模糊矩阵 <spanclass="math inline">\(R^T=R\)</span></p><p><strong>传递性</strong>：<spanclass="math inline">\(\mu_R(x,z)\ge\vee_y(\mu_R(x,y)\wedge\mu_R(y,z))\)</span>，则称 <spanclass="math inline">\(R\)</span>满足<strong>传递性</strong>，相应的有模糊矩阵 <spanclass="math inline">\(R^2\subseteq R\)</span></p><p><strong>定理 2</strong>：若 <span class="math inline">\(Q\)</span>为传递矩阵，则有 <span class="math display">\[Q \supseteq Q^{2} \supseteq Q^{3} \supseteq \cdots \supseteqQ^{\mathbf{n}-1} \supseteq Q^{\mathbf{n}} \supseteq \cdots\]</span></p><h3 id="模糊相似关系与等价关系">3.2 模糊相似关系与等价关系</h3><p><strong>模糊相似关系</strong>：<span class="math inline">\(R\inF(U\times U)\)</span>，满足自反性和对称性 <spanclass="math inline">\(\Longrightarrow I\subseteq R\subseteq R^2\subseteq\cdots\subseteq R^n\subseteq \cdots\)</span></p><p><strong>模糊等价关系</strong>：<span class="math inline">\(R\inF(U\times U)\)</span>，满足自反性、对称性和传递性 <spanclass="math inline">\(\LongrightarrowR=R^2=\cdots=R^n=\cdots\)</span></p><blockquote><p><strong>定理</strong>：<span class="math inline">\(R\)</span>为等价关系 <span class="math inline">\(\iff R_\lambda\)</span>为等价关系 <span class="math inline">\(\forall\lambda\in[0,1]\)</span></p><p><strong>Proof</strong>：若 <spanclass="math inline">\(R_\lambda\)</span> 为等价关系，则意味着 <spanclass="math inline">\(\forall i,j,k\)</span>，若 <spanclass="math inline">\(r_{ij}(\lambda)=1,r_{jk}(\lambda)=1\Longrightarrow r_{ik}(\lambda)=1\)</span>。因此对于模糊矩阵来说，应有<span class="math inline">\(r_{ij}\ge\lambda,r_{jk}\ge\lambda\Longrightarrowr_{ik}\ge\lambda\)</span>。在此基础上易证充分必要性。</p><p><strong>Remarks</strong>：这个定理将模糊等价关系转化为普通等价关系，而普通等价关系可以很容易分类。</p></blockquote><h3 id="对称闭包与传递闭包">3.3 对称闭包与传递闭包</h3><p><strong>对称闭包</strong>：设 <spanclass="math inline">\(A,\hat{A},B\in\mathcal{F}(U\times U)\)</span>，若<spanclass="math inline">\(A\subseteq\hat{A},A^T\subseteq\hat{A}\)</span>，且对任意包含<span class="math inline">\(A\)</span> 的对称关系 <spanclass="math inline">\(B\)</span>，都有 <spanclass="math inline">\(\hat{A}\subseteq B\)</span>，则 <spanclass="math inline">\(\hat{A}\)</span> 为 <spanclass="math inline">\(A\)</span> 的对称闭包，记为 <spanclass="math inline">\(s(A)=\hat{A}\)</span>。</p><blockquote><p>实际上对称闭包就是包含 <span class="math inline">\(A\)</span>的<strong>最小的</strong>对称关系，很容易的有 <spanclass="math inline">\(s(A)=A\cup A^T\)</span></p></blockquote><p><strong>传递闭包</strong>：<spanclass="math inline">\(A\subseteq\hat{A},A^2\subseteq\hat{A}\)</span>，且任意包含<span class="math inline">\(A\)</span> 的传递关系 <spanclass="math inline">\(B\)</span> 都有 <spanclass="math inline">\(\hat{A}\subseteq B\)</span>，则 <spanclass="math inline">\(\hat{A}\)</span> 为 <spanclass="math inline">\(A\)</span> 的传递闭包，记为 <spanclass="math inline">\(t(A)=\hat{A}\)</span>。</p><p><strong>传递闭包定理 1</strong>：<spanclass="math inline">\(t(A)=A\cup A^2 \cup\cdots\cupA^n\cup\cdots=\bigcup_{k=1}^\infty A^k\)</span></p><p><strong>传递闭包定理 2</strong>：<spanclass="math inline">\(t(A)=\bigcup_{k=1}^n A^k\)</span>（可以使用鸽巢原理，证明 <span class="math inline">\(A^{n+1}\subseteqA^m,m\le n\)</span>）</p><p><strong>传递闭包定理 3</strong>：相似矩阵 <spanclass="math inline">\(R\in U_{n\times n}\)</span>的传递闭包是等价矩阵，且 <spanclass="math inline">\(t(R)=R^n\)</span></p><p><strong>传递闭包定理 4</strong>：相似矩阵 <spanclass="math inline">\(R\in U_{n\times n}\)</span>，则 <spanclass="math inline">\(\forall m\ge n,t(R)=R^m\)</span></p><p><strong>传递闭包定理 5</strong>：相似矩阵 <spanclass="math inline">\(R\in U_{n\times n}\)</span>，则 <spanclass="math inline">\(\exist k\le n,t(R)=R^k\)</span></p><blockquote><p><strong>Remarks</strong>：</p><ul><li>定理 2 证明了传递闭包在实际中是可计算的</li><li>定理 3-5中对相似矩阵求传递闭包就得到了等价矩阵，对后面的模糊据类很有用，因为模糊等价矩阵可以与普通等价矩阵联系起来，而若想进行分类，则必须依托于等价关系。</li></ul></blockquote>]]></content>
    
    
    <categories>
      
      <category>Fuzzy Mathematics</category>
      
    </categories>
    
    
    <tags>
      
      <tag>模糊关系</tag>
      
      <tag>模糊矩阵</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>模糊数学笔记 3：扩展原理</title>
    <link href="/2020/03/01/fuzzy/ch3-extension/"/>
    <url>/2020/03/01/fuzzy/ch3-extension/</url>
    
    <content type="html"><![CDATA[<p>扩展原理实际上是将普通集合中的<strong>函数映射</strong>的概念扩展到了模糊集合上。</p><span id="more"></span><h2 id="映射的象">1. 映射的象</h2><h3 id="定义">1.1 定义</h3><p>对于普通集合，设 <span class="math inline">\(f:X\to Y,A\subseteqX\)</span>，<span class="math inline">\(f(A)=\{f(x)|x\in A\}\)</span>称为 <span class="math inline">\(A\)</span> 的象</p><p>映射 <span class="math inline">\(f\)</span> 诱导了一个从 <spanclass="math inline">\(P(X)\)</span> 到 <spanclass="math inline">\(P(Y)\)</span> 的新映射</p><h3 id="性质">1.2 性质</h3><p>该映射有以下性质：</p><ul><li><span class="math inline">\(A\subseteq B\Longrightarrowf(A)\subseteq f(B)\)</span></li><li><span class="math inline">\(f(\bigcup_{t\in T}A_t)=\bigcup_{t\inT}f(A_t)\)</span></li><li><span class="math inline">\(f(\bigcap_{t\in T}A_t)=\bigcap_{t\inT}f(A_t)\)</span></li></ul><h2 id="扩展原理">2. 扩展原理</h2><h3 id="定义-1">2.1 定义</h3><p>对于模糊集合，设 <span class="math inline">\(f:X\to Y,A\in\mathcal{F}(X)\)</span>，定义 <spanclass="math inline">\(f(A)\in\mathcal{F}(Y)\)</span> 为 <spanclass="math display">\[\forall y\in Y, \quad (f(A))(y)=\vee_{f(x)=y}A(x)\]</span> 映射 <span class="math inline">\(f\)</span> 诱导了一个从 <spanclass="math inline">\(\mathcal{F}(X)\)</span> 到 <spanclass="math inline">\(\mathcal{F}(Y)\)</span> 的新映射</p><h3 id="性质-1">2.2 性质</h3><p>该映射有以下性质：</p><ul><li><span class="math inline">\(A,B\in \mathcal{F}(X),A\subseteqB\Longrightarrow f(A)\subseteq f(B)\)</span></li><li><span class="math inline">\(A_t\in\mathcal{F}(X),f(\bigcup_{t\inT}A_t)=\bigcup_{t\in T}f(A_t)\)</span></li><li><span class="math inline">\(A_t\in\mathcal{F}(X),f(\bigcap_{t\inT}A_t)=\bigcap_{t\in T}f(A_t)\)</span></li><li><spanclass="math inline">\(A\in\mathcal{F}(X),\alpha\in[0,1]\)</span>，则<spanclass="math inline">\(f(A_{\bar\alpha})=(f(A))_\bar\alpha\)</span></li><li><spanclass="math inline">\(A\in\mathcal{F}(X),\alpha\in[0,1]\)</span>，则<spanclass="math inline">\(f(A_{\alpha})\subseteq(f(A))_\alpha\)</span></li></ul><blockquote><p><strong>Remarks</strong>：从 <span class="math inline">\(X\)</span>到 <span class="math inline">\(Y\)</span>的映射，只是对元素“换了个名称”，并没有改变对应的隶属度，因此映射 <spanclass="math inline">\(f\)</span>与对模糊集的操作比如截集是可以交换顺序的</p></blockquote>]]></content>
    
    
    <categories>
      
      <category>Fuzzy Mathematics</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>模糊数学笔记 2：贴近度</title>
    <link href="/2020/03/01/fuzzy/ch2-nearness/"/>
    <url>/2020/03/01/fuzzy/ch2-nearness/</url>
    
    <content type="html"><![CDATA[<h2 id="贴近度">1. 贴近度</h2><p>给定 <span class="math inline">\(A,B,C\in\mathcal{F}(U)\)</span>，<spanclass="math inline">\(\sigma(*,*)\)</span>满足以下几个条件时，被称为<strong>贴近度</strong></p><ol type="1"><li><span class="math inline">\(\sigma(A,A)=1\)</span></li><li><span class="math inline">\(\sigma(A,B)=\sigma(B,A)\)</span></li><li>若 <span class="math inline">\(A\subset B\subset C\)</span>，则<spanclass="math inline">\(\sigma(A,B)\ge\sigma(A,C),\sigma(B,C)\ge\sigma(A,C)\)</span></li><li><span class="math inline">\(\sigma(U,\varnothing)=0\)</span></li></ol><span id="more"></span><p><strong>严格贴近度</strong>的定义为</p><ol type="1"><li><span class="math inline">\(\sigma(A,B)=1 \iff A=B\)</span></li><li>上述 2.-4. 条</li></ol><p>贴近度的例子：</p><ul><li>严格贴近度：<span class="math inline">\(\sigma(A, B)=\frac{\sum_{n}a_{n} \wedge b_{n}}{\sum_n a_{n} \vee b_{n}}\)</span></li><li><span class="math inline">\(\sigma(A,B)=1-t\left(\sum_{1}^{n}\left|a_{k}-b_{k}\right|^{p}\right)^{q}\)</span></li><li><span class="math inline">\(\sigma(A, B)=\frac{\sum_{n} a_{n} \wedgeb_{n}}{\sum_n (a_{n} + b_{n})/2}\)</span></li><li><span class="math inline">\(\sigma(A,B)=\exp\left(-t\left(\sum_{1}^{n}\left|a_{k}-b_{k}\right|^{p}\right)^{q}\right)\)</span></li></ul><h2 id="内外积">2. 内外积</h2><h3 id="定义">2.1 定义</h3><p><strong>内积</strong>：<spanclass="math inline">\(A,B\in\mathcal{F}(U)\)</span>，称 <spanclass="math inline">\(A\circ B=\underset{u \in U}{\vee}(A(u) \wedgeB(u))\)</span> 为 <span class="math inline">\(A,B\)</span> 的内积</p><p><strong>外积</strong>：<spanclass="math inline">\(A,B\in\mathcal{F}(U)\)</span>，称 <spanclass="math inline">\(A \hat{\circ} B=\underset{u \in U}{\wedge}(A(u)\vee B(u))\)</span> 为 <span class="math inline">\(A,B\)</span>的外积</p><blockquote><p><strong>Remarks</strong>：内外积本身并不是用来表述两个集合的相似程度的，就像向量的内外积，还与向量自身的模长有关。</p></blockquote><h3 id="性质">2.2 性质</h3><ul><li><span class="math inline">\(A \hat{\circ} B = A^c\circ B^c,(A\circB)^c=A^c \hat{\circ} B^c\)</span></li><li><span class="math inline">\(A {\circ} B\le \bar{a}\wedge\bar{b},A\hat{\circ} B\ge\underline{a}\vee\underline{b}\)</span></li><li><span class="math inline">\(A\circ A=\bar{a},A \hat{\circ}A=\underline{a}\)</span></li><li><span class="math inline">\(\underset{B \in \mathcal{F}(U)}{\vee}(A\circ B)=\bar{a}, \quad \underset{B \in \mathcal{F}(U)}{\wedge}\left(A{\hat{\circ}} B\right)=\underline{a}\)</span></li><li><span class="math inline">\(A \subseteq B \Rightarrow A \circB=\bar{a}, A{\hat{\circ}} B=\underline{b}\)</span></li><li><span class="math inline">\(A \circ A^{c} \leq \frac{1}{2}, \quadA{\hat{\circ}} B \geq \frac{1}{2}\)</span></li><li><span class="math inline">\(A \subseteq B \Rightarrow A \circ C \leqB \circ C, A{\hat{\circ}} C \leq B{\hat{o}} C\)</span></li></ul><h2 id="格贴近度">3. 格贴近度</h2><p>给定F集A，让F集B靠近A，会使内积增大而外积减少。即当内积较大且外积较小时，A与B比较贴近。所以，以内外积相结合的“格贴近度”来刻 划两个F集的贴近程度。</p><p><strong>格贴近度</strong>：<span class="math inline">\(N_{1}(A, B)=(A\circ B) \wedge\left(A\hat{\circ} B\right)^{c}\)</span></p><p>格贴近度有以下性质</p><ul><li><span class="math inline">\(0\le N_1(A,B)\le1\)</span></li><li><span class="math inline">\(N_1(A,B)=N_1(B,A)\)</span></li><li><spanclass="math inline">\(N_1(A,A)=\bar{a}\wedge(1-\underline{a})\)</span></li><li><span class="math inline">\(A \subseteq B \subseteq C \RightarrowN_1(A, C) \leq N_1(A, B) \wedge N_1(B, C)\)</span></li></ul><blockquote><p><strong>Remarks</strong>：注意根据第 3条性质可知，格贴近度并不适合描述两个模糊集的相似程度，比如 <spanclass="math inline">\(N_1(U,U)=0\)</span></p></blockquote>]]></content>
    
    
    <categories>
      
      <category>Fuzzy Mathematics</category>
      
    </categories>
    
    
    <tags>
      
      <tag>贴近度</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>凸优化笔记 4：凸函数 Convex Function</title>
    <link href="/2020/02/29/optimization/ch4-cvx-function/"/>
    <url>/2020/02/29/optimization/ch4-cvx-function/</url>
    
    <content type="html"><![CDATA[<h2 id="凸函数">1. 凸函数</h2><h3 id="凸函数定义">1.1 凸函数定义</h3><p><strong>凸函数(convex function)</strong>的定义： <spanclass="math display">\[f(\theta x+(1-\theta)y)\le\theta f(x)+(1-\theta)f(y),\quad \forallx,y\in\text{dom}f,\theta\in[0,1]\]</span> 函数 <span class="math inline">\(f\)</span>的<strong>扩展函数(extended-value extension)</strong> <spanclass="math inline">\(\tilde{f}\)</span> 定义为 <spanclass="math display">\[\tilde{f}(x)=\begin{cases}f(x),&amp;x\in\text{dom}f\\\infty,&amp;x\notin\text{dom}f\end{cases}\]</span> 相当于对原来函数 <span class="math inline">\(f\)</span>的定义域进行了扩展。</p><span id="more"></span><h3 id="常见凸函数">1.2 常见凸函数</h3><h4 id="r">1.2.1 <span class="math inline">\(R\)</span></h4><p>凸函数(convex)</p><ul><li>仿射函数 <span class="math inline">\(ax+b\)</span>，for any <spanclass="math inline">\(a,b\in R\)</span></li><li>指数函数 <span class="math inline">\(e^{ax}\)</span>，for any <spanclass="math inline">\(a\in R\)</span></li><li>幂函数 <span class="math inline">\(x^\alpha,x\inR_{++}\)</span>，for <span class="math inline">\(\alpha\ge1\)</span> or<span class="math inline">\(\alpha\le0\)</span></li><li>绝对值幂函数 <span class="math inline">\(\vert x\vert^p,x\inR\)</span>，for <span class="math inline">\(p\ge 1\)</span></li><li>负熵 <span class="math inline">\(x\log x,x\in R_{++}\)</span></li></ul><p>凹函数(concave)</p><ul><li>仿射函数 <span class="math inline">\(ax+b\)</span>，for any <spanclass="math inline">\(a,b\in R\)</span></li><li>幂函数 <span class="math inline">\(x^\alpha,x\inR_{++}\)</span>，for <spanclass="math inline">\(0\le\alpha\le1\)</span></li><li>对数函数 <span class="math inline">\(\log x,x\inR_{++}\)</span></li></ul><h4 id="rn">1.2.2 <span class="math inline">\(R^n\)</span></h4><ul><li>仿射函数 <span class="math inline">\(a^Tx+b\)</span></li><li>范数 <span class="math inline">\(\Vert x\Vert_p,p\ge 1\)</span></li></ul><h4 id="rmtimes-n">1.2.3 <span class="math inline">\(R^{m\timesn}\)</span></h4><ul><li>仿射函数 <spanclass="math inline">\(f(X)=\text{tr}(A^TX)+b\)</span></li><li>谱范数 <span class="math inline">\(f(X)=\VertX\Vert_2=\sigma_{\max}(X)=(\lambda_\max(X^TX))^{1/2}\)</span></li></ul><h2 id="凸函数判定">2. 凸函数判定</h2><h3 id="降维打击">2.1 “降维打击”</h3><p>“降维打击”是指对于函数 <span class="math inline">\(f:R^n\toR\)</span> 限制在某一个方向上观察，若对于任意一个方向上都是凸函数，则<span class="math inline">\(f\)</span> 就是凸函数。准确的定义如下。</p><blockquote><p>设 <span class="math inline">\(f:R^n\to R\)</span>，有映射 <spanclass="math inline">\(g:R\to R\)</span> <span class="math display">\[g(t)=f(x+tv),\quad \text{dom}\ g=\{t|x+tv\in\text{dom}\ f\}\]</span> 则 <span class="math inline">\(f\)</span>为凸函数<strong>当且仅当</strong> <spanclass="math inline">\(g(t)\)</span> 对任意 <spanclass="math inline">\(x\in\text{dom}f,v\in R^n\)</span> 都是凸函数。</p></blockquote><p><strong><em>例</em></strong>：函数 <spanclass="math inline">\(f:S^n\to R\)</span>，有 <spanclass="math inline">\(f(X)=\log\det X,\text{dom}f=S^n_{++}\)</span><span class="math display">\[\begin{align}g(t)=\log\det(X+tV)&amp;=\log\det X +\log\det(I+tX^{-1/2}VX^{-1/2})\\&amp;=\log\det X + \sum_{i=1}^n\log(1+t\lambda_i)\end{align}\]</span> 由于 <span class="math inline">\(g\)</span> 关于 <spanclass="math inline">\(t\)</span> 是凹函数，因此 <spanclass="math inline">\(f\)</span> 是凹函数。</p><h3 id="一阶条件">2.2 一阶条件</h3><blockquote><p>函数 <span class="math inline">\(f\)</span>为凸函数<strong>当且仅当</strong> <span class="math display">\[f(y)\ge f(x)+\nabla f^T(x)(y-x) \quad \forall x,y\in\text{dom}f\]</span> 证明：略。用定义即可。</p></blockquote><h3 id="二阶条件">2.3 二阶条件</h3><blockquote><p>函数 <span class="math inline">\(f\)</span>为凸函数<strong>当且仅当</strong>海森矩阵(Hessian matrix)（若二阶可微）<span class="math display">\[\nabla^2 f(x)\succeq0 \quad \forall x\in\text{dom}f\]</span></p></blockquote><p>可用海森矩阵验证为凸函数的例子</p><ul><li>二次函数 <span class="math inline">\(f(x)=(1/2)x^TPx+q^Tx+r\)</span>(with <span class="math inline">\(P\in S^n\)</span>)</li><li>最小二乘目标函数 <span class="math inline">\(f(x)=\VertAx-b\Vert_2^2\)</span></li><li>二次函数 <span class="math inline">\(f(x,y)=x^2/y\)</span></li><li>log-sum-exp <span class="math inline">\(f(x)=\log\sum_k\expx_k\)</span></li><li>几何均值 <span class="math inline">\(f(x)=(\Pi_k x_k)^{1/n}\)</span>on <span class="math inline">\(R^n_{++}\)</span></li></ul><h2 id="sublevel-set-epigraph">3. Sublevel set &amp; Epigraph</h2><p>函数 <span class="math inline">\(f:R^n\to R\)</span> 的 <spanclass="math inline">\(\alpha\)</span> <strong>下水平集(<spanclass="math inline">\(\alpha\)</span>-sublevel set)</strong> 的定义为<span class="math display">\[C_\alpha=\{x\in\text{dom}f|f(x)\le\alpha\}\]</span><strong>凸函数的下水平集也是凸集，但是反之不一定成立</strong>。</p><p>针对函数 <span class="math inline">\(f:R^n\to R\)</span> 定义的<strong>epigraph</strong> 为 <span class="math display">\[\text{epi}f=\{(x,t)\in R^{n+1}|x\in\text{dom}f,f(x)\le t\}\]</span></p><blockquote><p>函数 <span class="math inline">\(f\)</span>为凸函数<strong>当且仅当</strong>其 epigraph 为凸集。</p><figure><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2020/4-epigraph.PNG"alt="epigraph" /><figcaption aria-hidden="true">epigraph</figcaption></figure><p><strong>Remarks</strong>：对于 epigraph 内的点，有 <spanclass="math display">\[\begin{align}t\ge f(y)\ge f(x)+\nabla f^T(x)(y-x) \\\iff\left[\begin{array}{cc}\nabla f^T(x)\\-1\end{array}\right]\left(\left[\begin{array}{cc}y\\t\end{array}\right] -\left[\begin{array}{cc}x\\f(x)\end{array}\right]\right)\le0\end{align}\]</span> 上面的式子实际上就是找到了一个在 <spanclass="math inline">\((x,f(x))\)</span>处的<strong>支撑超平面</strong>，<strong>法向量</strong>即为 <spanclass="math inline">\([\begin{array}{cc}\nabla f^T(x)&amp;-1\end{array}]^T\)</span></p></blockquote><h2 id="jensens-inequality">4. Jensen's Inequality</h2><p>对于凸函数 <span class="math inline">\(f\)</span>，有 <spanclass="math display">\[f(\mathbb{E}z)=\mathbb{E}f(z)\]</span> 证明：离散情况易证，连续情况可以用一阶条件证明。</p><p><strong>Lemma</strong>：<span class="math inline">\(f:R^n\toR\)</span> 为凸函数，那么 <span class="math inline">\(f\)</span>在任一<strong>内点</strong>处都<strong>连续</strong>(连续但不一定可导)。</p><p><strong>Remarks</strong>：往往绝大部分点都是可微的，但是我们经常会遇到那些不可微的点，比如ReLU 函数。</p>]]></content>
    
    
    <categories>
      
      <category>Convex Optimization</category>
      
    </categories>
    
    
    <tags>
      
      <tag>凸函数</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>模糊数学笔记 1：模糊集 Fuzzy set</title>
    <link href="/2020/02/26/fuzzy/ch1-set/"/>
    <url>/2020/02/26/fuzzy/ch1-set/</url>
    
    <content type="html"><![CDATA[<p>传统集合中元素要么属于集合，要么不属于集合。但假如我们给出一个“所有年轻人组成的集合”，那么这个时候年龄多大才算年轻人呢？30岁算年轻人嘛？有的人觉得算，有的人觉得不算，这是一个比较模糊的界定，所以就引入了模糊集的概念。</p><span id="more"></span><h2 id="传统集合的定义">1. 传统集合的定义</h2><p><strong>论域</strong> U，<strong>集合</strong>A，这可以用一个映射来表示 <span class="math display">\[\begin{aligned}\chi_{A}: \boldsymbol{U} \rightarrow &amp;\{\mathbf{0}, \mathbf{1}\} \\\boldsymbol{u} \mapsto &amp; \chi_{A}(\boldsymbol{u})\end{aligned}\]</span> 也可以用一个分段函数来表示 <span class="math display">\[\chi_{A}(u)=\left\{\begin{array}{ll}{1,} &amp; {u \in A} \\{0,} &amp; {u \notin A}\end{array}\right.\]</span> <imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2020/1-set.png"alt="set" /></p><h2 id="模糊集合的定义">2. 模糊集合的定义</h2><p>模糊集的含义表示其中的元素 <span class="math inline">\(x\)</span>“有一定的可能性”属于集合 <spanclass="math inline">\(A\)</span>，或者说“一定程度上”属于集合 <spanclass="math inline">\(A\)</span>，那么这个属于的程度就被称为<strong>隶属度</strong><span class="math inline">\(\mu_A(x)\in[0,1]\)</span>。与传统集合相比，传统集合中元素的隶属程度非 0 即1，也即要么属于，要么不属于，是确定的，模糊集里则引入了一定的不确定性。也用一个映射表示为<span class="math display">\[\begin{aligned}\mu_{A}: &amp;\boldsymbol{U} \rightarrow[0,1] \\&amp;\boldsymbol{x} \mapsto \mu_{A}(x) \in[0,1]\end{aligned}\]</span> 其中映射 <span class="math inline">\(\mu_A\)</span> 称为 <spanclass="math inline">\(A\)</span> 的<strong>隶属函数</strong>，<spanclass="math inline">\(\mu_A(x)\)</span> 为 <spanclass="math inline">\(x\)</span> 对 <spanclass="math inline">\(A\)</span> 的<strong>隶属度</strong>。注意 <spanclass="math inline">\(\mu_A(x)=0.5\)</span> 时表示最具有模糊性。</p><h2 id="模糊集的表示方法">3. 模糊集的表示方法</h2><h3 id="zadeh-表示法">3.1 Zadeh 表示法</h3><p><span class="math display">\[A=\frac{A\left(x_{1}\right)}{x_{1}}+\frac{A\left(x_{2}\right)}{x_{2}}+\cdots+\frac{A\left(x_{n}\right)}{x_{n}}\]</span></p><p>这里 <spanclass="math inline">\(\frac{A\left(x_{i}\right)}{x_{i}}\)</span> 表示<span class="math inline">\(x_i\)</span> 对模糊集 <spanclass="math inline">\(A\)</span> 的隶属度为 <spanclass="math inline">\(A(x_i)\)</span>。若论域 <spanclass="math inline">\(U\)</span> 为无限集，则模糊集表示为 <spanclass="math display">\[A=\int_{x\in U} \frac{A(x)}{x}\]</span></p><h3 id="序偶表示法">3.2 序偶表示法</h3><p><span class="math display">\[A=\left\{\left(x_{1}, A\left(x_{1}\right)\right),\left(x_{2},A\left(x_{2}\right)\right), \cdots,\left(x_{n},A\left(x_{n}\right)\right)\right\}\]</span></p><h3 id="向量表示法">3.3 向量表示法</h3><p><span class="math display">\[A=(A(x_1),...,A(x_n))\]</span></p><h2 id="模糊集的运算">4. 模糊集的运算</h2><h3 id="集合基本运算">4.1 集合基本运算</h3><ul><li><strong>相等</strong>：<span class="math inline">\(A=B \iffA(x)=B(x), \forall x\in U\)</span></li><li><strong>包含</strong>：<span class="math inline">\(A\subset B \iffA(x)\le B(x), \forall x\in U\)</span></li><li><strong>交集</strong>：<span class="math inline">\((A\cap B)(x) =A(x)\wedge B(x),\forall x\in U\)</span></li><li><strong>并集</strong>：<span class="math inline">\((A\cup B)(x) =A(x)\vee B(x),\forall x\in U\)</span></li><li><strong>补集</strong>：<spanclass="math inline">\(A^c(x)=1-A(x),\forall x\in U\)</span></li></ul><p>其中记号 <span class="math inline">\(a\wedge b=\min\{a,b\},a\veeb=\max\{a,b\}\)</span></p><h3 id="计算性质">4.2 计算性质</h3><p>很多计算性质都和普通集合差不多</p><figure><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2020/1-prpo1.png"alt="properties 1" /><figcaption aria-hidden="true">properties 1</figcaption></figure><figure><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2020/1-prpo2.png"alt="properties 2" /><figcaption aria-hidden="true">properties 2</figcaption></figure><p>需要注意的是<strong>无穷个</strong>集合的交集与并集的定义 <spanclass="math display">\[\bigcup_{t \in T} A_{t}(a)=\sup_{t \in T} A_{t}(a) \\\bigcap_{t \in T} A_{t}(a)=\inf_{t \in T} A_{t}(a)\]</span></p><h2 id="隶属度的确定">5. 隶属度的确定</h2><h3 id="实验统计法">5.1 实验统计法</h3><h3 id="半解析法">5.2 (半)解析法</h3><p>根据问题性质套用现有模糊分布，然后根据测量数据确定分布中的参数。</p><p>模糊分布大致分为：<strong>偏大型、偏小型、中间型</strong></p><h3 id="专家打分法">5.3 专家打分法</h3><p>根据专家的反馈意见进行统计</p><h2 id="截集与分解定理">6. 截集与分解定理</h2><h3 id="截集的定义">6.1 截集的定义</h3><p><strong>定义</strong>：若 <span class="math inline">\(A\)</span> 为<span class="math inline">\(U\)</span> 上的任一模糊集，对 <spanclass="math inline">\(\forall \lambda\in [0,1]\)</span>，记 <spanclass="math display">\[A_\lambda = \{x|A(x)\ge\lambda,x\in U\}\]</span> 称为 <span class="math inline">\(A\)</span> 的<strong><spanclass="math inline">\(\lambda\)</span>-截集</strong>，其中 <spanclass="math inline">\(\lambda\)</span>称为阈值或置信水平。类似的，<strong>强截集(开截集)</strong>定义为 <spanclass="math display">\[A_\lambda = \{x|A(x)&gt;\lambda,x\in U\}\]</span> 注意：<strong>截集为普通集合，不是模糊集</strong>！</p><h3 id="截集运算性质">6.2 截集运算性质</h3><p>大部分性质都很简单</p><figure><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2020/1-prpo3.png"alt="properties 3" /><figcaption aria-hidden="true">properties 3</figcaption></figure><figure><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2020/1-prpo4.png"alt="properties 4" /><figcaption aria-hidden="true">properties 4</figcaption></figure><p>但注意其中第 3 和第 6 条注意并不是相等！！</p><h3 id="一些定义">6.3 一些定义</h3><ul><li><strong>核</strong>：<spanclass="math inline">\(ker(A)=A_1\)</span></li><li><strong>支集</strong>：<spanclass="math inline">\(supp(A)=A_{\bar{0}}\)</span></li><li><strong>边界</strong>：<spanclass="math inline">\(A_{\bar{0}}\backslash A_1\)</span></li><li><strong>数乘</strong>：<span class="math inline">\(\lambda A(u) =\lambda \wedge A(u),u\in U\)</span><ul><li><span class="math inline">\(A\subset B \Rightarrow \lambda A \subset\lambda B\)</span></li><li><span class="math inline">\(\lambda_1\le\lambda_2\Rightarrow\lambda_1 A \subset \lambda_2 A\)</span></li></ul></li></ul><h3 id="分解定理">6.4 分解定理</h3><p><strong>分解定理 1</strong>：<span class="math inline">\(A\in\mathcal{F}(U)\)</span>，则 <spanclass="math inline">\(A=\bigcup_{\lambda\in[0,1]}\lambdaA_\lambda\)</span></p><p><strong>分解定理 2</strong>：<span class="math inline">\(A\in\mathcal{F}(U)\)</span>，则</p>]]></content>
    
    
    <categories>
      
      <category>Fuzzy Mathematics</category>
      
    </categories>
    
    
    <tags>
      
      <tag>模糊集</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>凸优化笔记 3：广义不等式</title>
    <link href="/2020/02/26/optimization/ch3-gene-ineq/"/>
    <url>/2020/02/26/optimization/ch3-gene-ineq/</url>
    
    <content type="html"><![CDATA[<p>将普通的不等式 <span class="math inline">\(1\le2\)</span>推广到更加复杂的情况，例如两个向量 <span class="math inline">\(x\ley\)</span> 该如何定义？这就是广义不等式(generalized inequality)</p><span id="more"></span><h2 id="正常锥">1. 正常锥</h2><p><strong>正常锥(proper cone)</strong> <spanclass="math inline">\(K\subseteq R^n\)</span> 需要满足</p><ul><li><span class="math inline">\(K\)</span> is closed (contains itsboundary)</li><li><span class="math inline">\(K\)</span> is solid (has nonemptyinterior)</li><li><span class="math inline">\(K\)</span> is pointed (contains noline)</li></ul><h2 id="广义不等式">2. 广义不等式</h2><p>基于正常锥 <span class="math inline">\(K\)</span>定义的不等式(generalized inequality)表示为 <span class="math display">\[x \preceq_{K} y \quad \Longleftrightarrow \quad y-x \in K \\x \prec_{K} y \quad \Longleftrightarrow \quad y-x \in \operatorname{int}K\]</span></p><h2 id="最小元与极小元">3. 最小元与极小元</h2><h3 id="最小元minimum">3.1 最小元(minimum)</h3><p><span class="math inline">\(x\in S\)</span> 为集合 <spanclass="math inline">\(S\)</span> 关于 <spanclass="math inline">\(\preceq_{K}\)</span>的<strong>最小元(minimum)</strong>，如果有 <span class="math display">\[y\in S \Longrightarrow x\preceq_{K}y\]</span> 也等价于 <span class="math inline">\(S\subseteqx+K\)</span></p><p><strong>注意</strong>：1. 最小元可能<strong>不存在</strong>；2.若存在则<strong>唯一</strong></p><h3 id="极小元minimal">3.2 极小元(minimal)</h3><p><span class="math inline">\(x\in S\)</span> 为集合 <spanclass="math inline">\(S\)</span> 关于 <spanclass="math inline">\(\preceq_{K}\)</span>的<strong>极小元(minimum)</strong>，如果有 <span class="math display">\[y\in S\quad y\preceq_{K}x \Longrightarrow y=x\]</span> <strong>注意</strong>：极小元不唯一</p><figure><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2020/3-minimum.png"alt="minimum and minimal" /><figcaption aria-hidden="true">minimum and minimal</figcaption></figure><h2 id="对偶锥">4. 对偶锥</h2><p>锥 <span class="math inline">\(K\)</span> 的<strong>对偶锥(dualcone)</strong> 定义为 <span class="math display">\[K^{*}=\left\{y | y^{T} x \geq 0 \text { for all } x \in K\right\}\]</span> 有一些性质</p><ul><li><span class="math inline">\(K^*\)</span> is convex, closed</li><li><span class="math inline">\(K^{**}=K\)</span> if <spanclass="math inline">\(K\)</span> is closed convex</li><li><span class="math inline">\(K\)</span> is proper cone <spanclass="math inline">\(\Longrightarrow K^{*}\)</span> is proper</li></ul><p>一些例子</p><ul><li><span class="math inline">\(K=\mathbf{R}_{+}^{n}:K^{*}=\mathbf{R}_{+}^{n}\)</span></li><li><span class="math inline">\(K=\mathbf{S}_{+}^{n}:K^{*}=\mathbf{S}_{+}^{n}\)</span></li><li><span class="math inline">\(K=\left\{(x, t) |\|x\|_{2} \leqt\right\}: K^{*}=\left\{(x, t) |\|x\|_{2} \leq t\right\}\)</span></li><li><span class="math inline">\(K=\left\{(x, t) |\|x\|_{1} \leqt\right\}: K^{*}=\left\{(x, t) |\|x\|_{\infty} \leqt\right\}\)</span></li></ul><h2 id="最小元与极小元应用对偶锥定义">5.最小元与极小元(应用对偶锥定义)</h2><h3 id="最小元">5.1 最小元</h3><p><span class="math inline">\(x\)</span> 是集合 <spanclass="math inline">\(S\)</span> 关于 <spanclass="math inline">\(\preceq_{K}\)</span> 的最小元 <spanclass="math inline">\(\iff\)</span> 对任意的 <spanclass="math inline">\(\lambda \succ_{K*} 0\)</span>，<spanclass="math inline">\(x\)</span> 为 <spanclass="math inline">\(\lambda^Tz\)</span> 在集合 <spanclass="math inline">\(S\)</span> 上的唯一最小解</p><blockquote><p><strong>Remarks</strong>：实际上这点可以理解为对任意 <spanclass="math inline">\(\lambda\inK^*\)</span>，其定义了一个支撑超平面，<spanclass="math inline">\(x\)</span> 就是支撑点</p></blockquote><h3 id="极小元">5.2 极小元</h3><ul><li>充分条件：若对于某些 <span class="math inline">\(\lambda \succ_{K*}0\)</span>，<span class="math inline">\(x\)</span> minimizes <spanclass="math inline">\(\lambda^Tz\)</span> over <spanclass="math inline">\(S\)</span>，<spanclass="math inline">\(\Longrightarrow\)</span> <spanclass="math inline">\(x\)</span> 为极小元</li><li>必要条件：<span class="math inline">\(x\)</span>为<strong>凸集</strong> <span class="math inline">\(S\)</span>的极小元，<span class="math inline">\(\Longrightarrow\)</span> 存在非 0的 <span class="math inline">\(\lambda \succ_{K*} 0\)</span> 使得 <spanclass="math inline">\(x\)</span> minimizes <spanclass="math inline">\(\lambda^Tz\)</span> over <spanclass="math inline">\(S\)</span></li></ul>]]></content>
    
    
    <categories>
      
      <category>Convex Optimization</category>
      
    </categories>
    
    
    <tags>
      
      <tag>锥</tag>
      
      <tag>广义不等式</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>凸优化笔记 2：超平面分离定理</title>
    <link href="/2020/02/26/optimization/ch2-separa-hyper/"/>
    <url>/2020/02/26/optimization/ch2-separa-hyper/</url>
    
    <content type="html"><![CDATA[<p>简单理解就是：没有交集的两个凸集，可以被一个超平面完全分隔开。</p><span id="more"></span><h2 id="超平面分离定理">1. 超平面分离定理</h2><p><strong>超平面分离定理(Separating hyperplane theorem)</strong>：若<span class="math inline">\(C,D\)</span> 为非空凸集，且 <spanclass="math inline">\(C\cap D=\varnothing\)</span>，则存在 <spanclass="math inline">\(a\ne 0,b\)</span>，使得 <spanclass="math display">\[a^Tx\le b\quad\text{for}\quad x\in C,\quad a^Tx\ge b\quad\text{for}\quad x\in D\]</span> 也可以等价表示为 <span class="math inline">\(\inf_{x\in D}a^Tx\ge \sup_{x\in C}a^Tx\)</span></p><figure><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2020/2-seperate.png"alt="Separating hyperplane theorem" /><figcaption aria-hidden="true">Separating hyperplanetheorem</figcaption></figure><p><strong>Lemma 1</strong>：<span class="math inline">\(C\)</span><strong>closed，convex</strong>，<span class="math inline">\(y\notinC\)</span>，那么存在<strong>唯一的</strong> <spanclass="math inline">\(x\in C\)</span>，使得 <spanclass="math inline">\(\Vert y-x\Vert=\inf\{\Vert y-z\Vert|z\inC\}=d(y,C)\)</span></p><p>Proof：omit...</p><p><strong>Lemma 2</strong>：<span class="math inline">\(C\)</span><strong>closed，convex</strong>，<span class="math inline">\(y\notinC\)</span>，那么存在 <span class="math inline">\(a\ne 0,b\)</span>，使得<span class="math display">\[a^Ty&lt;b,\quad a^Tx\ge b\quad\forall x\in C\]</span> Proof：omit...</p><blockquote><p><strong>Remark</strong>：上述定理表明存在超平面可以严格分开 <spanclass="math inline">\(y\)</span> 与 <spanclass="math inline">\(C\)</span>。</p></blockquote><p><strong>Lemma 3</strong>：<span class="math inline">\(C\)</span><strong>convex</strong>，<span class="math inline">\(y\notinC\)</span>，那么存在 <span class="math inline">\(a\ne 0,b\)</span>，使得<span class="math display">\[a^Ty\le b,\quad a^Tx\ge b\quad\forall x\in C\]</span> Proof：omit...</p><p><strong>超平面分离定理逆定理</strong>：若 <spanclass="math inline">\(C\)</span> 为开集，且存在超平面分离 <spanclass="math inline">\(C,D\)</span>，则 <span class="math inline">\(C\capD=\varnothing\)</span></p><h2 id="支撑超平面定理">2. 支撑超平面定理</h2><p><strong>支撑超平面</strong>：对于集合 <spanclass="math inline">\(C\)</span> 的边界点 <spanclass="math inline">\(x_0\)</span>，支撑超平面为 <spanclass="math inline">\(\{x|a^Tx=a^Tx_0\}\)</span>，其满足 <spanclass="math inline">\(a\ne0\)</span> 且 <spanclass="math inline">\(a^Tx\le a^Tx_0,\ \forall x\in C\)</span></p><p><strong>支撑超平面定理</strong>：如果 <spanclass="math inline">\(C\)</span> 为凸集，那么 <spanclass="math inline">\(C\)</span> 的每个边界点都存在一个支撑超平面</p>]]></content>
    
    
    <categories>
      
      <category>Convex Optimization</category>
      
    </categories>
    
    
    <tags>
      
      <tag>凸集分离定理</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>凸优化笔记 1：Convex Sets</title>
    <link href="/2020/02/22/optimization/ch1-cvx-sets/"/>
    <url>/2020/02/22/optimization/ch1-cvx-sets/</url>
    
    <content type="html"><![CDATA[<h2 id="凸集">1. 凸集</h2><p>区分两种集合的定义（下面的描述并不是严格的数学语言，领会意思就行了）：</p><ul><li><strong>仿射集(Affine set)</strong>：<spanclass="math inline">\(x=\theta x_1 + (1-\theta)x_2,\quad\theta\in\mathbb{R}\)</span></li><li><strong>凸集(Convex set)</strong>：<spanclass="math inline">\(x=\theta x_1 + (1-\theta)x_2,\quad\theta\in[0,1]\)</span></li></ul><p>主要的区别就在于后面 <span class="math inline">\(\theta\)</span>的取值范围，简单理解就是说仿射集类似<strong>直线</strong>，凸集类似<strong>线段</strong>。</p><p>更一般的，仿射集都可以表示为线性方程组的解集，也即 <spanclass="math inline">\(\{x|Ax=b\}\)</span></p><span id="more"></span><h2 id="常见凸集">2. 常见凸集</h2><h3 id="凸包convec-hull">2.1 凸包(Convec hull)</h3><p>假如集合 <spanclass="math inline">\(S=\{x_1,...,x_k\}\)</span>，则其<strong>凸包</strong>可以表示为<span class="math display">\[\left\{\sum_{i=1}^k\theta_i x_i \vert \sum\theta_i=1,\theta_i\ge0\right\}\]</span> <imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2020/cvx_hull.PNG"alt="cvx hull" /></p><h3 id="超平面hyperplanes">2.2 超平面(Hyperplanes)</h3><p>类比三维空间中的平面，可以有<strong>超平面</strong>的定义 <spanclass="math display">\[\left\{x\vert a^Tx=b\right\}(a\ne0)\]</span> 其中 <span class="math inline">\(a\)</span>就是该平面的法向量。</p><h3 id="半空间halfspaces">2.3 半空间(Halfspaces)</h3><p>类似的，有<strong>半空间</strong>定义为 <span class="math display">\[\left\{x\vert a^Tx\le b\right\}(a\ne0)\]</span></p><h3 id="多面体polyhedra">2.4 多面体(Polyhedra)</h3><p>高维空间中的<strong>多面体</strong>定义为 <spanclass="math display">\[\left\{x\vert A x \preceq b, \quad C x=d \right\}\]</span> 其中 <span class="math inline">\(\preceq\)</span>表示对每个元素都作比较。实际上就是求很多个半空间以及半平面的交集，与三维空间是类似的。</p><h3 id="欧几里得球与椭球euclidean-balls-and-ellipsoids">2.5欧几里得球与椭球(Euclidean balls and ellipsoids)</h3><p>高维空间中的<strong>欧几里得球</strong>的定义为 <spanclass="math display">\[B\left(x_{c}, r\right)=\left\{x |\left\|x-x_{c}\right\|_{2} \leqr\right\}=\left\{x_{c}+r u |\|u\|_{2} \leq 1\right\}\]</span> <strong>椭球</strong>的定义为 <span class="math display">\[\left\{x |\left(x-x_{c}\right)^{T} P^{-1}\left(x-x_{c}\right) \leq1\right\} = \left\{x_{c}+A u |\|u\|_{2} \leq 1\right\}\]</span> 其中 <span class="math inline">\(P \in\mathbf{S}_{++}^{n}\)</span> (也即 <spanclass="math inline">\(P\)</span> 为对称正定矩阵)。中间的矩阵 <spanclass="math inline">\(P\)</span>的作用就相当于在各个特征向量方向上进行了放缩。</p><blockquote><p><strong>Remarks</strong>：关于矩阵性质，可以参考我的矩阵论学习笔记，这里复习一个知识点。</p><ul><li><strong>正规矩阵</strong>的定义为满足 <spanclass="math inline">\(A^HA=AA^H\)</span> 的矩阵 <spanclass="math inline">\(A\)</span>即为正规矩阵，因此<strong>对称矩阵、Hermit矩阵、酉矩阵</strong>都是正规矩阵。而正规矩阵有什么性质呢？正规矩阵可以<strong>对角化</strong>，且<strong>存在一组正交的特征向量</strong>！</li><li><strong>正定矩阵</strong>的定义为满足 <spanclass="math inline">\(x^TAx&gt;0\)</span> 的矩阵 <spanclass="math inline">\(A\)</span>，实际上也就是说矩阵 <spanclass="math inline">\(A\)</span> 的<strong>特征值均大于0</strong>！</li><li>因此对称正定矩阵的性质有：所有特征向量正交，所有特征值大于 0。</li></ul></blockquote><h3 id="范数球norm-balls">2.6 范数球(norm balls)</h3><p><strong>范数</strong> <spanclass="math inline">\(\Vert\cdot\Vert\)</span> 需要满足以下性质</p><ul><li><span class="math inline">\(\Vert x \Vert\ge0;\ \Vert x\Vert=0 \iffx=0\)</span></li><li><span class="math inline">\(\|t x\|=|t|\|x\|\)</span> for <spanclass="math inline">\(t \in \mathbf{R}\)</span></li><li><span class="math inline">\(\|x+y\| \leq\|x\|+\|y\|\)</span></li></ul><p>向量范数如 <span class="math inline">\(\Vert x\Vert_0, \Vertx\Vert_1, \Vert x\Vert_2, \Vert x\Vert_p, \Vertx\Vert_\infty\)</span></p><p>矩阵范数如 <span class="math inline">\(\Vert X\Vert_2, \VertX\Vert_p\)</span></p><p><strong>范数球</strong>的定义为 <span class="math display">\[\left\{x |\left\|x-x_{c}\right\| \leq r\right\}\]</span></p><h3 id="凸锥convex-cone">2.7 凸锥(Convex cone)</h3><p>我们先来看看锥的定义</p><ul><li><strong>锥(cone)</strong>：<span class="math inline">\(x\inC\Rightarrow \theta x\in C, \forall \theta\ge0\)</span></li><li><strong>凸锥(Convex cone)</strong>：<spanclass="math inline">\(x_1,x_2\in C \Rightarrow x=\theta_1 x_1+\theta_2x_2 \in C,\forall \theta_1,\theta_2\ge0\)</span></li></ul><p>注意锥一定包含原点0。锥不一定是凸的，反例如下，这是一个锥，但不是凸锥</p><figure><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2020/cone.PNG"alt="cone" /><figcaption aria-hidden="true">cone</figcaption></figure><h3 id="范数锥norm-cone">2.8 范数锥(norm cone)</h3><p><strong>范数锥</strong>定义如下 <span class="math display">\[\{(x, t) |\|x\| \leq t\}\]</span> 也被称为 Ice creamcone。其中欧几里得范数锥被称为<strong>二阶锥</strong>(second-ordercone)</p><figure><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2020/norm_cone.PNG"alt="norm cone" /><figcaption aria-hidden="true">norm cone</figcaption></figure><h3 id="半正定锥positive-semidefinite-cone">2.9 半正定锥(Positivesemidefinite cone)</h3><p>定义几个符号</p><ul><li><span class="math inline">\(\mathbf{S}^{n}\)</span> 为 <spanclass="math inline">\(n\)</span> 阶对称矩阵</li><li><span class="math inline">\(\mathbf{S}_{+}^{n}=\left\{X \in\mathbf{S}^{n} | X \succeq 0\right\}\)</span>为对称半正定矩阵，为凸锥</li><li><span class="math inline">\(\mathbf{S}_{++}^{n}=\left\{X \in\mathbf{S}^{n} | X \succ 0\right\}\)</span> 为对称正定矩阵</li></ul><p>例如给定二阶矩阵 <span class="math display">\[\left[\begin{array}{ll}{x} &amp; {y} \\{y} &amp; {z}\end{array}\right] \in \mathrm{S}_{+}^{2}\]</span> 其坐标满足如下图</p><figure><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2020/semidef_cone.PNG"alt="positive semidefinite cone" /><figcaption aria-hidden="true">positive semidefinite cone</figcaption></figure><h2 id="保凸变换">3. 保凸变换</h2><p>上面是一些常见的凸集，对于更复杂的情况，怎么判断是否为凸集呢？</p><ul><li>根据定义 <span class="math inline">\(x_{1}, x_{2} \in C, \quad 0\leq \theta \leq 1 \quad \Longrightarrow \quad \theta x_{1}+(1-\theta)x_{2} \in C\)</span></li><li>凸集经过<strong>保凸变换</strong>以后仍然是凸集，如<ul><li>凸集的交集</li><li>仿射变换</li><li>投影变换</li><li>分式线性映射</li></ul></li></ul><h3 id="凸集的交集">3.1 凸集的交集</h3><p>任意个(可以是无数个)凸集的交集仍然是凸集</p><p><strong><em>例子 1</em></strong>：<spanclass="math inline">\(S=\left\{x \in \mathbf{R}^{m}|| p(t) | \leq 1\text { for }|t| \leq \pi / 3\right\}\)</span>，其中 <spanclass="math inline">\(p(t)=x_{1} \cos t+x_{2} \cos 2 t+\cdots+x_{m} \cosm t\)</span></p><h3 id="仿射变换">3.2 仿射变换</h3><p>若映射 <span class="math inline">\(f: \mathbf{R}^{n} \rightarrow\mathbf{R}^{m}\)</span> 是仿射变换 <span class="math display">\[f(x)=A x+b \text { with } A \in \mathbf{R}^{m \times n}, b \in\mathbf{R}^{m}\]</span> 则有</p><ul><li><span class="math inline">\(S \subseteq \mathbf{R}^{n}\)</span>convex <span class="math inline">\(\Longrightarrow f(S)=\{f(x) | x \inS\}\)</span> convex</li><li><span class="math inline">\(C \subseteq \mathbf{R}^{m}\)</span>convex <span class="math inline">\(\Longrightarrow f^{-1}(C)=\left\{x\in \mathbf{R}^{n} | f(x) \in C\right\}\)</span> convex</li></ul><p><strong><em>例子 2</em></strong>：双曲锥 <spanclass="math inline">\(\left\{x | x^{T} P x \leq\left(c^{T} x\right)^{2},c^{T} x \geq 0\right\}\left(\text { with } P \in\mathbf{S}_{+}^{n}\right)\)</span>，因为其可以转化为二阶锥</p><p><strong><em>例子 3</em></strong>：<spanclass="math inline">\(\left\{x | x_{1} A_{1}+\cdots+x_{m} A_{m} \preceqB\right\}\)</span>(with <span class="math inline">\(A_i,P\inS^p\)</span>)<strong>？？？</strong></p><h3 id="投影变换">3.3 投影变换</h3><p><strong>投影函数</strong> <span class="math inline">\(P:\mathbf{R}^{n+1} \rightarrow \mathbf{R}^{n}\)</span> <spanclass="math display">\[P(x, t)=x / t, \quad \operatorname{dom} P=\{(x, t) | t&gt;0\}\]</span> <strong>Proof</strong>：略。应用凸集定义</p><h3 id="分式线性函数">3.4 分式线性函数</h3><p>分式线性映射 <span class="math inline">\(f: \mathbf{R}^{n}\rightarrow \mathbf{R}^{m}\)</span> 为 <span class="math display">\[f(x)=\frac{A x+b}{c^{T} x+d}, \quad \text { dom } f=\left\{x | c^{T}x+d&gt;0\right\}\]</span> 其可以看作先仿射变换再投影变换。</p>]]></content>
    
    
    <categories>
      
      <category>Convex Optimization</category>
      
    </categories>
    
    
    <tags>
      
      <tag>凸集</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>凸优化笔记 0：绪论</title>
    <link href="/2020/02/22/optimization/ch0-intro/"/>
    <url>/2020/02/22/optimization/ch0-intro/</url>
    
    <content type="html"><![CDATA[<h2 id="绪论">0. 绪论</h2><p>首先明确凸优化这门课的主要目的：</p><ol type="1"><li>判断一个问题是否为凸的</li><li>将一个问题转化为凸的</li><li>求解凸优化问题，给出算法性能</li></ol><span id="more"></span><h2 id="优化问题与凸优化">1. 优化问题与凸优化</h2><h3 id="一般优化问题">1.1 一般优化问题</h3><p>一般优化问题的形式为 <span class="math display">\[\begin{aligned}\text{min}\quad &amp; f_{0}(x)\\\text { s.t. } \quad &amp; f_{i}(x) \leq b_{i}, \quad i=1, \dots, m\end{aligned}\]</span> 其中 <span class="math inline">\(f_0\)</span>为优化目标，<span class="math inline">\(f_i\)</span> 为约束函数。</p><p>一般的优化问题都很难求解，可能无法给出一个解析解，甚至数值解法也不能给出最优解。而在众多复杂的优化问题中，有一些问题则较为容易：</p><ul><li>最小二乘问题(least-squares problems)：有解析解</li><li>线性规划问题(linear programming problems )</li><li>凸优化问题(convex optimizationproblems)：通常没有解析解，但是有有效的数值解法</li></ul><h3 id="凸优化问题">1.2 凸优化问题</h3><p>如果目标函数和约束函数都是<strong>凸函数</strong>，则被称为凸优化问题。满足以下条件的函数称为凸函数<span class="math display">\[f(\alpha x+\beta y) \leq \alpha f(x)+\beta f(y),\quad\alpha+\beta=1,\alpha&gt;0,\beta&gt;0\]</span> 凸优化中经常遇到的困难为：</p><ul><li>难以判断一个问题是否为凸的</li><li>将一个问题转化为凸问题需要很多的技巧(tricks)</li></ul>]]></content>
    
    
    <categories>
      
      <category>Convex Optimization</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>PID 控制器</title>
    <link href="/2020/02/21/cybernetics/pid/"/>
    <url>/2020/02/21/cybernetics/pid/</url>
    
    <content type="html"><![CDATA[<p>在过程控制中，按偏差的比例（P）、积分（I）和微分（D）进行控制的PID控制器（亦称PID调节器）是应用最为广泛的一种自动控制器。它具有原理简单，易于实现，适用面广，控制参数相互独立，参数的选定比较简单等优点.</p><span id="more"></span><h2 id="基本原理">1. 基本原理</h2><p><strong>PID控制器</strong>（比例-积分-微分控制器），由比例单元（P）、积分单元（I）和微分单元（D）组成。可以透过调整这三个单元的增益<span class="math inline">\(K_p\)</span>，<spanclass="math inline">\(K_i\)</span> 和 <spanclass="math inline">\(K_d\)</span>来调定其特性。PID控制器主要适用于基本上线性，且动态特性不随时间变化的系统。</p><p>PID控制器的比例单元(P)、积分单元(I)和微分单元(D)分别对应目前误差、过去累计误差及未来误差。若是不知道受控系统的特性，一般认为PID控制器是最适用的控制器。</p><!--more--><h2 id="控制算法">2. 控制算法</h2><p>若定义 <span class="math inline">\(u(t)\)</span>为控制输出，PID算法可以用下式表示 <span class="math display">\[\mathrm{u}(t)=\mathrm{MV}(t)=K_{p} e(t)+K_{i} \int_{0}^{t} e(\tau) d\tau+K_{d} \frac{d}{d t} e(t)\]</span> 其中 <span class="math inline">\(e(t)\)</span> 表示误差。</p><h3 id="比例控件">2.1 比例控件</h3><p>比例控制考虑当前误差，误差值和一个正值的常数 <spanclass="math inline">\(K_p\)</span>（表示比例）相乘。<spanclass="math inline">\(K_p\)</span>只是在控制器的输出和系统的误差成比例的时候成立。 <spanclass="math display">\[P_{\text{out}} = K_p e(t)\]</span>若比例增益大，在相同误差量下，会有较大的输出，但若比例增益太大，会使系统不稳定。相反的，若比例增益小，若在相同误差量下，其输出较小，因此控制器会较不敏感的。若比例增益太小，当有干扰出现时，其控制信号可能不够大，无法修正干扰的影响。</p><figure><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2020/PID_varyingP.jpg"alt="Change K_p" /><figcaption aria-hidden="true">Change K_p</figcaption></figure><p>上图即为改变 <span class="math inline">\(K_p\)</span>对应的控制器。</p><h3 id="积分控件">2.2 积分控件</h3><p>积分控制考虑过去误差，将误差值过去一段时间和（误差和）乘以一个正值的常数<span class="math inline">\(K_i\)</span>。 <span class="math display">\[I_{\mathrm{out}}=K_{i} \int_{0}^{t} e(\tau) d \tau\]</span>积分控制会<strong>加速</strong>系统趋近设定值的过程，并且消除纯比例控制器会出现的稳态误差。积分增益越大，趋近设定值的速度越快，不过因为积分控制会累计过去所有的误差，可能会使回授值出现<strong>过冲</strong>的情形。</p><figure><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2020/Change_with_Ki.png"alt="Change K_i" /><figcaption aria-hidden="true">Change K_i</figcaption></figure><p>上图即为改变 <span class="math inline">\(K_i\)</span>对应的控制器。</p><h3 id="微分控件">2.3 微分控件</h3><p>微分控制考虑将来误差，计算误差的一阶导，并和一个正值的常数 <spanclass="math inline">\(K_d\)</span>相乘。这个导数的控制会对系统的改变作出反应。导数的结果越大，那么控制系统就对输出结果作出更快速的反应。这个<span class="math inline">\(K_d\)</span>参数也是PID被称为可预测的控制器的原因。<spanclass="math inline">\(K_d\)</span>参数对减少控制器短期的改变很有帮助。一些实际中的速度缓慢的系统可以不需要<span class="math inline">\(K_d\)</span> 参数。 <spanclass="math display">\[D_{\mathrm{out}}=K_{d} \frac{d}{d t} e(t)\]</span>微分控制可以提升整定时间及系统<strong>稳定性</strong>。不过因为纯微分器不是因果系统，因此在PID系统实现时，一般会为微分控制加上一个低通滤波器以限制高频增益及噪声。实际上较少用到微分控制，估计PID控制器中只有约20%有用到微分控制。</p><figure><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2020/Change_with_Kd.png"alt="Change K_d" /><figcaption aria-hidden="true">Change K_d</figcaption></figure><p>上图即为改变 <span class="math inline">\(K_d\)</span>对应的控制器。</p><h2 id="位置式和增量式pid算法">3. 位置式和增量式PID算法</h2><p>PID 一般有两种：<strong>位置式 PID</strong> 和<strong>增量式PID</strong>。在小车里一般用增量式，因为位置式 PID的输出与过去的所有状态有关，计算时要对历史上每一次的控制误差进行累加，这个计算量非常大，而且没有必要。增量式则子需要计算每次控制量的变化量。</p><p>将 PID 公式离散化，可以推导出位置式 PID 公式 <spanclass="math display">\[\begin{aligned}u(k)&amp;=K_p\left[e_{k}+\frac{1}{T_i} \sum_{j=0}^{k} e_{j}+T_d\frac{e_{k}-e_{k-1}}{T}\right] \\&amp;=K_p \cdot e_{k}+\frac{K_p}{T_i} \sum_{j=0}^{k} e_{j}+K_p \cdot T_d\frac{e_{k}-e_{k-1}}{T} \\&amp;=A e_{k}+B\left(\sum_{j=0}^{k-1}e_{j}+e_{k}\right)+C\left(e_{k}-e_{k-1}\right)\end{aligned}\]</span> 其中把 <span class="math inline">\(K_i,K_d\)</span> 表示为<span class="math inline">\(K_p/T_i,K_p\cdot T_d\)</span>。</p><p>在此基础上可以推导出增量式 PID 公式 <span class="math display">\[\begin{aligned}\Delta u_{k}&amp;=u_{k}-u_{k-1}=K_p\left[e_{k}-e_{k-1}+\frac{T}{T_i}e_{k}+T_d \frac{e_{k}-2 e_{k-1}+e_{k-2}}{T}\right] \\&amp;=K_p\left(1+\frac{T}{T_i}+\frac{T_d}{T}\right)e_{k}-K_p\left(1+\frac{2 T_d}{T}\right) e_{k-1}+K_p \frac{T_d}{T}e_{k-2} \\&amp;=A e_{k}+B e_{k-1}+C e_{k-2}\end{aligned}\]</span> 其中误差 <span class="math inline">\(e_k = y_0(kT) -y(kT)\)</span>，<span class="math inline">\(y_0\)</span>表示目标值，<span class="math inline">\(y(kT)\)</span> 表示第 <spanclass="math inline">\(k\)</span> 个时刻的值。</p>]]></content>
    
    
    <categories>
      
      <category>Cybernetics</category>
      
    </categories>
    
    
    <tags>
      
      <tag>PID</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>LaSalle&#39;s invariance principle 拉萨尔不变性原理</title>
    <link href="/2020/02/20/cybernetics/lasalle/"/>
    <url>/2020/02/20/cybernetics/lasalle/</url>
    
    <content type="html"><![CDATA[<p>拉萨尔不变原理是李亚普诺夫第二方法的推广。这种观察给出了李亚普诺夫理论的统一认识，且极大地推广了李亚普诺夫第二方法，现在人们称这一推广为拉萨尔不变原理。</p><h2 id="系统模型">1. 系统模型</h2><p>考虑一个控制系统 <span class="math display">\[\dot{x}(t)=f(x(t))\]</span> 其中 <span class="math inline">\(f(0)=0\)</span>。</p><span id="more"></span><h2 id="基本定义">2. 基本定义</h2><p><strong>正极限点(positive limit point)</strong>：p 被称为 <spanclass="math inline">\(x(t)\)</span> 的正极限点，如果存在一个时间序列<span class="math inline">\(\{t_n\}\)</span>，有 <spanclass="math inline">\(n\to\infty\)</span> 时 <spanclass="math inline">\(t_n\to\infty\)</span>，且使得 <spanclass="math inline">\(x(t_n)\to\infty\)</span> 随着 <spanclass="math inline">\(n\to\infty\)</span>。</p><p><strong>正极限集(positive limit set)</strong>：<spanclass="math inline">\(x(t)\)</span>的所有正极限点的集合即为正极限集。</p><blockquote><p><strong>Remarks</strong>：这里举个例子，序列 <spanclass="math inline">\(x(n)=1,-1,1,-1,...\)</span>，那么取奇数项时极限为1，偶数项时极限为 -1.但是对于完整的序列 <spanclass="math inline">\(x(n)\)</span> 则极限不存在，而 <spanclass="math inline">\(x(n)\)</span> 的正极限集则为 <spanclass="math inline">\(\{1,-1\}\)</span>。</p><p>为什么这里会引入<strong>集合</strong>呢？因为控制系统中最终的稳定状态可能不是一个孤立的点，而是在很多个状态之间循环转换，比如一个单位圆。</p></blockquote><p><strong>不变集(invariant set)</strong>：集合 <spanclass="math inline">\(M\)</span> 是关于系统 (1) 的不变集，如果有 <spanclass="math inline">\(x(0)\in M \Rightarrow x(t)\in M, \forall t\in\mathbb{R}\)</span>。如果有 <span class="math inline">\(x(0)\in M\Rightarrow x(t)\in M, \forall t\ge0\)</span> 则称为正不变集(positiveinvariant set)。</p><h2 id="拉萨尔不变性原理">3. 拉萨尔不变性原理</h2><p><strong>LaSalle' Theorem</strong>：令 <spanclass="math inline">\(\Omega\in D\)</span> 是一个紧致集，且是关于系统<span class="math inline">\(\dot{x}(t)=f(x(t))\)</span> 的不变集。令<span class="math inline">\(V:D\to\mathbb{R}\)</span>是一个连续函数，且满足 <span class="math inline">\(\dot{V}(x)\le0\ \ in\\ \Omega\)</span>。令 <span class="math inline">\(M\)</span> 为 <spanclass="math inline">\(\Omega\)</span> 中所有满足 <spanclass="math inline">\(\dot{V}(x)=0\)</span> 的点的集合，令 <spanclass="math inline">\(E\)</span> 为 <spanclass="math inline">\(M\)</span> 中的最大不变集，那么从 <spanclass="math inline">\(\Omega\)</span> 中出发的所有解都将趋于 <spanclass="math inline">\(E\)</span> 随着 <spanclass="math inline">\(t\to\infty\)</span>。</p><blockquote><p><strong>Remarks</strong>：这里的 <spanclass="math inline">\(M\)</span> 和 <spanclass="math inline">\(E\)</span>有什么不同吗？二者不等价吗？不一定等价！因为 <spanclass="math inline">\(\Omega\)</span> 本身是一个不变集，而 <spanclass="math inline">\(M\)</span>又是他的一个子集，如下图所示，那么任意一个起始于 <spanclass="math inline">\(M\)</span> 的轨迹都有可能跑出 <spanclass="math inline">\(M\)</span> 而进入 <spanclass="math inline">\(\Omega\backslash M\)</span>，因此 <spanclass="math inline">\(M\)</span> 并不是一个不变集。</p><p><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2020/lip.png" /></p></blockquote>]]></content>
    
    
    <categories>
      
      <category>Cybernetics</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Lyapunov</tag>
      
      <tag>系统稳定性</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Second-Order Cone Programming(SOCP) 二次锥规划</title>
    <link href="/2020/02/17/optimization/socp/"/>
    <url>/2020/02/17/optimization/socp/</url>
    
    <content type="html"><![CDATA[<p>二次锥规划是凸优化的一部分，可以应用<strong>内点法</strong>快速求解，相比于<strong>半正定规划</strong>更有效。</p><span id="more"></span><h2 id="二阶锥">1. 二阶锥</h2><h3 id="二阶锥定义">1.1 二阶锥定义</h3><p>在此之前，先给出<strong>二阶锥</strong>的定义。</p><p>在 <span class="math inline">\(k\)</span> 维空间中二阶锥(Second-order cone) 的定义为 <span class="math display">\[\mathcal{C}_{k}=\left\{\left[\begin{array}{l}{u} \\{t}\end{array}\right] | u \in \mathbb{R}^{k-1}, t \in \mathbb{R},\|u\| \leqt\right\} \notag\]</span> 其也被称为 quadratic，ice-cream，Lorentz cone。</p><h3 id="二阶锥约束">1.2 二阶锥约束</h3><p>在此基础上，<strong>二阶锥约束</strong>即为 <spanclass="math display">\[\|A x+b\| \leq c^{T} x+d \Longleftrightarrow\left[\begin{array}{c}{A} \\{c^{T}}\end{array}\right] x+\left[\begin{array}{l}{b} \\{d}\end{array}\right] \in \mathcal{C}_{k}\]</span> 其中 <span class="math inline">\(x\in \mathbb{R}^{n},A\in\mathbb{R}^{(k-1)\times n},b\in\mathbb{R}^{k-1},c\in\mathbb{R}^{n},\mathbb{R}\)</span>。实际上是对<span class="math inline">\(x\)</span>进行了仿射变换，由于仿射变换不改变凹凸性，因此二阶锥也是凸锥。</p><h2 id="优化问题建模">2. 优化问题建模</h2><p>优化目标如下，其中 <span class="math inline">\(f \in \mathbb{R}^{n},A_{i} \in \mathbb{R}^{n_{i} \times n}, b_{i} \in \mathbb{R}^{n_{i}},c_{i} \in \mathbb{R}^{n}, d_{i} \in \mathbb{R}, F \in \mathbb{R}^{p\times n},\)</span> and <span class="math inline">\(g \in\mathbb{R}^{p}, x \in \mathbb{R}^{n}\)</span> <spanclass="math display">\[\begin{align}\text{minize}\quad&amp; f^{T} x \notag\\\text{subject to}\quad&amp; {\left\|A_{i} x+b_{i}\right\|_{2} \leqc_{i}^{T} x+d_{i}, \quad i=1, \ldots, m} \notag\\&amp;{F x=g}\notag\end{align}\notag\]</span>上述问题被称为<strong>二次锥规划</strong>是因为其约束，要求仿射函数<span class="math inline">\((Ax+b,c^T x+d)\)</span> 为 <spanclass="math inline">\(\mathbb{R}^{k+1}\)</span> 空间中的二阶锥。</p><h2 id="类似问题转化">3. 类似问题转化</h2><p>一些其他优化问题也可以转化为 SOCP，例如</p><h3 id="二次规划">3.1 二次规划</h3><p>考虑二次约束 <span class="math display">\[x^{T} A^{T} A x+b^{T} x+c \leq 0  \notag\]</span> 可以等价转化为 SOC 约束 <span class="math display">\[\left\|\begin{array}{c}\left(1+b^{T} x+c\right) / 2 \\Ax\end{array}\right\|_{2}\leq\left(1-b^{T} x-c\right) / 2 \notag\]</span></p><h3 id="随机线性规划">3.2 随机线性规划</h3><p>问题模型为 <span class="math display">\[\begin{align}\text{minize}\quad&amp; c^{T} x \notag\\\text{subject to}\quad&amp; \mathbb{P}\left(a_{i}^{T} x \leqb_{i}\right) \geq p, \quad i=1, \ldots, m \notag\end{align}\notag\]</span> 问题转化可参考<ahref="https://en.wikipedia.org/wiki/Second-order_cone_programming">维基百科</a></p><h2 id="问题求解">4. 问题求解</h2><p>二阶锥规划可以应用<strong>内点法</strong>快速求解，且比<strong>半正定规划</strong>(semidefiniteprogramming)更有效。</p><p>Matlab 有专门的凸优化工具包，<ahref="http://cvxr.com/cvx/">下载地址</a>在这里，安装教程在官网上有。使用方法如下，只需要修改优化目标和约束条件即可</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs matlab">m = <span class="hljs-number">20</span>; n = <span class="hljs-number">10</span>; p = <span class="hljs-number">4</span>;<br>A = <span class="hljs-built_in">randn</span>(m,n); b = <span class="hljs-built_in">randn</span>(m,<span class="hljs-number">1</span>);<br>C = <span class="hljs-built_in">randn</span>(p,n); d = <span class="hljs-built_in">randn</span>(p,<span class="hljs-number">1</span>); e = <span class="hljs-built_in">rand</span>;<br>cvx_begin<br>    variable x(n)<br>    minimize( norm( A * x - b, <span class="hljs-number">2</span> ) )<br>    subject to<br>        C * x == d<br>        norm( x, Inf ) &lt;= e<br>cvx_end<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>Convex Optimization</category>
      
    </categories>
    
    
    <tags>
      
      <tag>SOCP</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>笔记本选购指南</title>
    <link href="/2020/02/09/software/laptop/"/>
    <url>/2020/02/09/software/laptop/</url>
    
    <content type="html"><![CDATA[<p>根据网上的资料总结了一些笔记本选购过程中需要注意的一些参数。</p><span id="more"></span><h2 id="确定需求类型">1. 确定需求类型</h2><p>笔记本大致可以分为三类：</p><ul><li><strong>游戏本</strong>：性能高、厚重。</li><li><strong>轻薄本</strong>：性能略低，轻薄，适合平时主要需求为办公的人群。</li><li><strong>全能本</strong>：兼顾重量与性能，但是为了降低重量可能导致散热效果等不好。</li></ul><h2 id="主要关注参数">2. 主要关注参数</h2><ul><li><p><strong>处理器</strong></p><ul><li><strong>核数</strong>：</li><li><strong>主频</strong>：</li></ul></li><li><p><strong>内存</strong></p></li><li><p><strong>硬盘</strong></p><ul><li><strong>机械硬盘</strong>（HDD）：<strong>容量大</strong>，读写速度慢，有噪音，抗震能力弱，功耗大，但是<strong>相对便宜</strong>。</li><li><strong>固态硬盘</strong>（SSD）：容量小，<strong>读写速度快</strong>，<strong>无噪音</strong>，<strong>抗震能力强</strong>，<strong>功耗小</strong>，但是相对要贵。</li><li><strong>混合硬盘</strong></li></ul></li><li><p><strong>显卡</strong></p><ul><li><strong>集成显卡</strong>：</li><li><strong>独立显卡</strong>：</li></ul></li><li><p><strong>屏幕</strong></p><ul><li><strong>类型</strong>：主要是TN屏与IPS屏。能不选TN屏就<strong>不选TN屏</strong>。IPS的优点：亮度高，对比度高，视角广，缺点：响应时间长（目前可以控制在5ms）。TN屏优点：响应时间短（一般都2ms），缺点：亮度中，对比度中，视角小</li><li><strong>分辨率</strong>：分辨率越高，显示效果就越精细和细腻。大部分至少为1080P（1920*1080）</li><li><strong>色域</strong>：屏幕所能显示的色彩范围区域。色域越高，屏幕呈现出的色彩越丰富、艳丽。平面设计、服装设计等，<strong>对色彩有要求</strong>的同学需要特别注意，一定要选择<strong>高色域屏幕（72%NTSC/100%sRGB以上）</strong>。</li><li><strong>刷新率</strong>：刷新率越高，所显示的图象（画面）稳定性就越好。常见的屏幕多为60Hz。</li></ul></li><li><p><strong>电池</strong></p></li><li><p><strong>笔记本接口</strong></p><ul><li>外接设备，如USB、Type-C、网线、HDMI等</li></ul></li></ul>]]></content>
    
    
    <categories>
      
      <category>电子产品</category>
      
    </categories>
    
    
    <tags>
      
      <tag>电脑</tag>
      
      <tag>电子产品</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>矩阵分析学习笔记</title>
    <link href="/2020/02/03/linear-algebra/matrix/"/>
    <url>/2020/02/03/linear-algebra/matrix/</url>
    
    <content type="html"><![CDATA[<p>在网上自学矩阵分析的一些笔记，主要是总结一些结论性的东西，并没有太多证明。对于非数学专业的学生，笔者认为抛开证明的细节，从更加具象的角度理解矩阵可能会有更清晰的理解。</p><p>未完待续，更新中 ...</p><p>参考资料：<ahref="https://zhuanlan.zhihu.com/matrix-learning">知乎专栏</a></p><span id="more"></span><hr /><h2 id="线性代数基础空间">1. 线性代数基础——空间</h2><ul><li><p>几个基本的概念</p><ul><li><p><strong>数域</strong>：对<strong>加减乘除</strong>四则基本<strong>运算封闭</strong>的<strong>数集</strong></p><ul><li>注意：首先<strong>数域</strong>的概念针对的是<strong>数集</strong>，不是向量也不是矩阵；其次要求对四则基本运算封闭。</li></ul></li><li><p><strong>线性空间</strong>：需满足以下条件 <spanclass="math display">\[\begin{alignat}{1}&amp;1)\ \alpha+\beta=\beta+\alpha     &amp;5)\ 1 a=\alpha\notag\\&amp;2)\ (\alpha+\beta)+\gamma=\alpha+(\beta+\gamma)   &amp;6)\ k(l\alpha)=(k l) \alpha\notag\\&amp;3)\ \exists 0 \in V, \forall \alpha \in V, 有 \alpha+0=\alpha&amp;7)\ (k+l) \alpha=k \alpha+l \alpha\notag\\&amp;4)\ \forall \alpha \in V, \exists \beta \in V,s.t.\  \alpha+\beta=0 \qquad &amp;8)\ k(\alpha+\beta)=k \alpha+l\beta\notag\\\end{alignat}\notag\]</span></p></li><li><p><strong>子空间</strong>：</p></li><li><p>空间的<strong>维数</strong>：基的个数</p></li><li><p><strong>平凡子空间</strong>：V 空间的子空间只有 0 空间和 V空间本身</p></li><li><p><strong>非平凡子空间</strong>：除了平凡子空间，其他所有子空间</p></li><li><p>子空间的<strong>直和</strong>：<span class="math inline">\(V_1\cap V_2=\{0\}\)</span> 时，直和可定义为 <span class="math inline">\(V_1\bigoplusV_2\)</span>，主要是为了保证<strong>分解的唯一性</strong>。可以推广到多个子空间<span class="math inline">\(V_i (\sum_{j\ne i}V_j) = \{0\}\)</span></p><ul><li>注：<span class="math inline">\(V_1,V_2\)</span>相互可能不是正交的，比如二维平面中不正交的两个基</li></ul></li><li><p><strong>酉空间</strong>：欧几里得空间推广到<strong>复数域</strong></p></li></ul></li></ul><hr /><h2 id="投影">2. 投影</h2><ul><li><strong>变换</strong>：线性空间到自身的映射 <spanclass="math inline">\(T:V(C)\to V(C)\)</span></li><li><strong>线性变换</strong>：<ul><li><span class="math inline">\(T(\alpha+\beta) =T(\alpha)+T(\beta)\)</span></li><li><span class="math inline">\(T(k\alpha) = kT(\alpha)\)</span></li></ul></li><li><strong>投影</strong>：<span class="math inline">\(T\)</span> 是<span class="math inline">\(V(C)\)</span> 上的投影， <spanclass="math inline">\(\iff T^2=T\)</span></li></ul><blockquote><p><strong>定理 1</strong>：设 <span class="math inline">\(T\)</span> 是<span class="math inline">\(V(C)\)</span> 上的投影，则 <spanclass="math inline">\(V(C) = R(T)\bigoplus N(T)\)</span></p><p><strong>定理 2</strong>：设 <span class="math inline">\(V(C) =V_1\bigoplus V_2\)</span>，则存在投影 <spanclass="math inline">\(T\)</span> 使得 <spanclass="math inline">\(R(T)=V_1, N(T)=V_2\)</span></p></blockquote><blockquote><p><strong>Remark</strong>：根据投影的定义 <spanclass="math inline">\(T^2=T\)</span>，可以形象理解为<strong>降维</strong>操作，也即投影过程不可逆，投影一次后即进入<strong>值域</strong><span class="math inline">\(R(T)\)</span>，也即是 <spanclass="math inline">\(V(C)\)</span> 的一个低维子空间。</p></blockquote><ul><li><p><strong>投影矩阵</strong>：投影 <spanclass="math inline">\(T\)</span> 为线性变换，可以用矩阵 <spanclass="math inline">\(A\)</span> 表示 <imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2019/proj.jpg"alt="线性变换" /></p></li><li><p><strong>幂等矩阵</strong>：满足 <spanclass="math inline">\(A^2=A\)</span>，有如下性质</p><ul><li><span class="math inline">\(A^H\)</span> 与 <spanclass="math inline">\((E-A)\)</span> 也是幂等矩阵</li><li><span class="math inline">\(A\)</span> 的特征值只有 0 和1，且可以对角化</li><li><span class="math inline">\(rank(A)=tr(A)\)</span></li><li><span class="math inline">\(A(E-A)=(E-A)A\)</span></li><li><span class="math inline">\(Aa = a, \iff a\in R(A)\)</span></li><li><span class="math inline">\(N(A)=R(E-A), R(A)=N(E-A)\)</span></li></ul><blockquote><p>上面的性质均可由<strong>幂等矩阵</strong>的性质导出</p></blockquote></li><li><p><strong>正交投影</strong>：<span class="math inline">\(\iffR^{\perp}(T) = N(T) \iff A^H=A\)</span></p></li></ul><blockquote><p><strong>Remark</strong>：</p><ul><li>实际上对于正交投影 <spanclass="math inline">\(A\)</span>，可以写成以下形式</li></ul><figure><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2019/decom.jpg"alt="正交投影分解" /><figcaption aria-hidden="true">正交投影分解</figcaption></figure><ul><li>是否存在<strong>非正交投影</strong>呢？非正交投影又是什么形式呢？只需要将中间的对角阵换成Jordan标准型的形式？</li></ul></blockquote><hr /><h2 id="jordan标准型">3. Jordan标准型</h2><p>注：此部分是矩阵论的基本定理之一，非常重要！！！</p><blockquote><p><strong>定理 1</strong>：任意 n 阶矩阵 <spanclass="math inline">\(A\)</span>，一定存在 n 阶<strong>可逆矩阵</strong>P 使得 <span class="math display">\[P^{-1} A P=\left(\begin{array}{cccc}{J_{1}} &amp; {} &amp; {} &amp; {} \\{} &amp; {J_{2}} &amp; {} &amp; {} \\{} &amp; {} &amp; {\ddots} &amp; {} \\{} &amp; {} &amp; {} &amp; {J_{k}}\end{array}\right)=J \notag\]</span> 其中 <span class="math inline">\(J_i\)</span> 为 Jordan块。有以下几个结论</p><ol type="1"><li>Jordan 块的个数是<strong>线性无关特征向量的个数</strong></li><li>矩阵可<strong>对角化</strong>当且仅当 <spanclass="math inline">\(k=n\)</span></li><li>对于某个特征值，Jordan 块个数为<strong>几何重数</strong>，所有Jordan块的阶数之和为<strong>代数重数</strong>（特征值多项式根的阶数即为代数重数，永远有几何重数不大于代数重数）</li><li>特征值的几何重数不大于代数重数</li><li>矩阵不同特征值对应的<strong>特征向量线性无关</strong></li></ol></blockquote><hr /><h2 id="初等矩阵与酉矩阵">4. 初等矩阵与酉矩阵</h2><h3 id="初等变换矩阵">4.1 初等变换矩阵</h3><blockquote><p><strong>定义</strong>：设 <spanclass="math inline">\(\boldsymbol{u,v}\in \mathbb{C}^n,\sigma\in\mathbb{C}\)</span>，则称 <spanclass="math inline">\(E(\boldsymbol{u,v},\sigma)=E-\sigma\boldsymbol{uv}^H\)</span>为<strong>初等变换矩阵</strong></p></blockquote><ul><li><p><strong>初等变换</strong>矩阵性质</p><ul><li>特征向量<ul><li>若 <span class="math inline">\(\boldsymbol{u\inv^{\perp}}\)</span>，设 <spanclass="math inline">\(\boldsymbol{u_1,...,u_{n-1}}\)</span> 是 <spanclass="math inline">\(v^\perp\)</span> 的一组基，则 <spanclass="math inline">\(E(\boldsymbol{u,v},\sigma)\)</span>的一组<strong>线性无关</strong>的特征向量为 <spanclass="math inline">\(\boldsymbol{u_1,...,u_{n-1}}\)</span></li><li>若 <span class="math inline">\(\boldsymbol{u\notinv^{\perp}}\)</span>，设 <spanclass="math inline">\(\boldsymbol{u_1,...,u_{n-1}}\)</span> 是 <spanclass="math inline">\(v^\perp\)</span> 的一组基，则 <spanclass="math inline">\(E(\boldsymbol{u,v},\sigma)\)</span>的一组<strong>线性无关</strong>的特征向量为 <spanclass="math inline">\(\boldsymbol{u,u_1,...,u_{n-1}}\)</span></li></ul></li><li>特征值 <spanclass="math inline">\(\lambda(E(\boldsymbol{u,v},\sigma))=\{1,...,1,1-\sigmav^H u\}\)</span></li><li>行列式 <spanclass="math inline">\(det(E(\boldsymbol{u,v},\sigma))=1-\sigma v^Hu\)</span></li><li>逆矩阵 <span class="math inline">\(E(u, v, \sigma)^{-1}=E\left(u, v,\frac{\sigma}{\sigma v^{H} u-1}\right),\left(1-\sigma v^{H} u \neq0\right)\)</span></li><li>非零向量 <spanclass="math inline">\(\boldsymbol{a,b}\in\mathbb{C}^n\)</span>，存在<span class="math inline">\(\boldsymbol{u,v},\sigma\)</span> 使得 <spanclass="math inline">\(E(u, v, \sigma) a=b,\left(\sigmau=\frac{a-b}{v^{H} a}\right)\)</span></li></ul><blockquote><p><strong>Remarks</strong></p><ol type="1"><li>前两个性质可以根据 <span class="math inline">\(u,v\)</span>的垂直关系直观想象。当 <span class="math inline">\(u\perp v\)</span>时，此时 <span class="math inline">\(E\)</span> 对于特征值 <spanclass="math inline">\(1\)</span> 的代数重数为 <spanclass="math inline">\(n\)</span>，而几何重数为 <spanclass="math inline">\(n-1\)</span>（注意此时出现了代数重数大于几何重数的情况！）；否则，<spanclass="math inline">\(E\)</span> 对于特征值 <spanclass="math inline">\(1\)</span> 的代数重数和几何重数为 <spanclass="math inline">\(n-1\)</span>，且有另一个特征值 <spanclass="math inline">\(1-\sigma v^H u\)</span></li></ol></blockquote></li><li><p>所有初等变换可以用上述定义表示</p><ul><li>置换 <span class="math inline">\({E_{ij}=E-\left(e_{i}-e_{j}\right)\left(e_{i}-e_{j}\right)^{T}=E\left(e_{i}-e_{j},e_{i}-e_{j}, 1\right)}\)</span></li><li>相消 <span class="math inline">\({E_{i j}(k)=E+k e_{j}e_{i}^{T}=E\left(e_{j}, e_{i},-k\right)}\)</span></li><li>数乘 <span class="math inline">\({E_{i}(k)=E-(1-k) e_{i}e_{i}^{T}=E\left(e_{i}, e_{i}, 1-k\right)}\)</span></li></ul></li></ul><h3 id="初等酉矩阵">4.2 初等酉矩阵</h3><blockquote><p><strong>定义</strong>：设 <spanclass="math inline">\(\boldsymbol{u}\in \mathbb{C}^n\)</span> 且 <spanclass="math inline">\(u^H u =1\)</span>，则称 <spanclass="math inline">\(H(U)=E(\boldsymbol{u,U},2)=E-2\boldsymbol{uu}^H\)</span>为<strong>初等酉矩阵</strong>，或者<strong>Householder矩阵</strong></p></blockquote><ul><li><strong>Householder</strong>变换性质<ul><li><span class="math inline">\(H^H=H=H^{-1}\)</span></li><li><spanclass="math inline">\(H(\boldsymbol{u})(\boldsymbol{a}+r\boldsymbol{u})=\boldsymbol{a}-r\boldsymbol{u},\forall a\in v^\perp, r\in\mathbb{C}\)</span>（镜像变换）</li><li>范数不变性：<span class="math inline">\(||Hx||=||x||\)</span></li><li>保持随机向量的协方差</li><li>可用于数值算法构造正交基</li></ul></li></ul><h3 id="酉变换">4.3 酉变换</h3><ul><li><strong>酉变换与酉矩阵</strong><ol type="1"><li>保持<strong>内积</strong>不变</li><li>保持长度不变</li><li>保持夹角不变</li><li>保持形状不变</li></ol></li><li>内积的定义，比如连续区间中对连续函数的定义</li></ul><hr /><h2 id="欧氏空间中的度量">5. 欧氏空间中的度量（？）</h2><ul><li><p><strong>内积</strong>：满足 4 条性质</p><ol type="1"><li><span class="math inline">\((x,x)\ge0,且(x,x)=0\iffx=0\)</span></li><li><span class="math inline">\((x,y)=\overline{(y,x)},\forall x,y\inV(P)\)</span></li><li><span class="math inline">\((\lambda x,y)=\bar{\lambda}(x,y),\forall\lambda\in P,\forall x,y\in V(P)\)</span></li><li><span class="math inline">\((x+y,z)=(x,z)+(y,z),\forall x,y,z\inV(P)\)</span></li></ol></li><li><p><strong>线性流形</strong>：<spanclass="math inline">\(P=r_{0}+V_{1}=\left\{r_{0}+\alpha | \alpha \inV_{1}\right\}\)</span></p><ul><li>实际上就是将子空间进行平移</li></ul></li><li><p>n 维空间中的<strong>体积</strong></p><ol type="1"><li><span class="math inline">\(V(\alpha_1)=||\alpha_1||\)</span></li><li><span class="math inline">\(V\left(\alpha_{1}, \alpha_{2}, \cdots,\alpha_{n}\right)=V\left(\alpha_{1}, \alpha_{2}, \cdots,\alpha_{n-1}\right) \bullet h_{n}\)</span>，其中 <spanclass="math inline">\(h_n\)</span> 是 <spanclass="math inline">\(\alpha_n\)</span> 到 <spanclass="math inline">\(L(\alpha_{1}, \alpha_{2}, \cdots,\alpha_{n-1})\)</span> 的距离</li></ol></li><li><p>Gram 行列式 <span class="math display">\[G\left(\alpha_{1}, \cdots, \alpha_{k}\right)=\left| \begin{array}{cccc}{\left(\alpha_{1}, \alpha_{1}\right)} &amp; {\left(\alpha_{1},\alpha_{2}\right)} &amp; {\cdots} &amp; {\left(\alpha_{1},\alpha_{k}\right)} \\{\left(\alpha_{2}, \alpha_{1}\right)} &amp; {\left(\alpha_{2},\alpha_{2}\right)} &amp; {\cdots} &amp; {\left(\alpha_{2},\alpha_{k}\right)} \\{\cdots} &amp; {\cdots} &amp; {\cdots} &amp; {\cdots} \\{\left(\alpha_{k}, \alpha_{1}\right)} &amp; {\left(\alpha_{k},\alpha_{2}\right)} &amp; {\cdots} &amp; {\left(\alpha_{k},\alpha_{k}\right)}\end{array}\right|\notag\]</span></p></li><li><p>将线性无关向量组 <span class="math inline">\(\alpha_{1},\alpha_{2}, \cdots, \alpha_{n}\)</span> 正交化之后，Gram 行列式不变，即<span class="math inline">\(G\left(\alpha_{1}, \alpha_{2}, \cdots,\alpha_{k}\right)=G\left(\beta_{1}, \beta_{2}, \cdots,\beta_{k}\right)\)</span></p></li><li><p>体积 <span class="math inline">\(V\left(\alpha_{1}, \alpha_{2},\cdots, \alpha_{n}\right)=\sqrt{G\left(\alpha_{1}, \alpha_{2}, \cdots,\alpha_{n}\right)}\)</span></p></li><li><p>定理 1：设 <span class="math inline">\(\alpha_{1}, \alpha_{2},\cdots, \alpha_{k}\)</span> 是 <span class="math inline">\(V_1\)</span>的一组基，向量 <span class="math inline">\(\alpha\)</span> 到流形 <spanclass="math inline">\(P=\alpha_0+V_1\)</span> 的距离为 <spanclass="math inline">\(d^{2}=\frac{G\left(\alpha_{1}, \cdots, \alpha_{k},\alpha-\alpha_{0}\right)}{G\left(\alpha_{1}, \cdots,\alpha_{k},\right)}\)</span></p></li><li><p>定理 2：线性流形 <spanclass="math inline">\(P_1=\alpha_0+V_1\)</span> 和 <spanclass="math inline">\(P_2=\alpha_0+V_1\)</span> 之间的距离等于 <spanclass="math inline">\(\alpha_1-\alpha_2\)</span> 关于线性子空间 <spanclass="math inline">\(V=V_1+V_2\)</span> 的正交分量长度</p></li></ul><hr /><h2 id="kronecker积">6. Kronecker积</h2><ul><li>性质<ul><li><span class="math inline">\(E_m\bigotimes E_n = E_{mn}\)</span></li><li></li></ul></li></ul><hr /><h2 id="范数">7. 范数</h2><h3 id="向量范数">7.1 向量范数</h3><ul><li>范数：刻画向量大小的度量，需要满足以下三条性质<ol type="1"><li>正定性：<span class="math inline">\(||x||\ge0,且||x||=0\iffx=0\)</span></li><li>齐次性：<span class="math inline">\(||\lambda x||=|\lambda|\cdot||x||,\lambda\in R,x\in C^n\)</span></li><li>三角不等式：<span class="math inline">\(||x+y||\le||x||+||y||,\forall x,y\in C^n\)</span></li></ol></li><li>范数与内积的关系是什么？</li><li>导出性质<ul><li><span class="math inline">\(||0||=0\)</span></li><li><spanclass="math inline">\(x\ne0时,||\frac{1}{||x||}x||=1\)</span></li><li><span class="math inline">\(||-x||=||x||,\forall x\inC^n\)</span></li><li><span class="math inline">\(\vert \Vert x\Vert-\Vert y\Vert \vert\le \Vert x-y \Vert\)</span></li></ul></li><li>常用范数<ul><li>1范数：<spanclass="math inline">\(\|x\|_{1}=\sum_{i=1}^{n}\left|x_{i}\right|\)</span></li><li>2范数：<spanclass="math inline">\(\|x\|_{2}=\left(\sum_{i=1}^{n}\left|x_{i}\right|^{2}\right)^{1/ 2}\)</span></li><li><span class="math inline">\(\infty\)</span>范数：<spanclass="math inline">\(\|x\|_{\infty}=\max _{1 \leq i \leqn}\left|x_{i}\right|\)</span></li><li>p范数(Holder范数)：<spanclass="math inline">\(\|x\|_{p}=\left(\sum_{i=1}^{n}\left|x_{i}\right|^{p}\right)^{1/ p} \quad 1 \leq p&lt;\infty\)</span><ul><li>p可取<strong>正整数</strong></li><li>可验证满足三角不等式，需要用到Young不等式和Holder不等式</li></ul></li></ul></li><li>向量序列的<strong>收敛性</strong></li><li>向量范数的<strong>等价性</strong><ul><li><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2019/norm%20equality.jpg"alt="范数等价性" /> 等价性表示不同范数的量级是相同的，只差一个系数</li><li><strong>定理</strong>：<span class="math inline">\(V(P)\)</span>上的任意两个向量范数均等价</li><li><strong>范数等价保证了向量序列的收敛性与范数选取无关</strong>。无穷范数收敛，其他范数一定收敛。其他范数收敛，无穷范数一定收敛。</li></ul></li></ul><h3 id="矩阵范数">7.2 矩阵范数</h3><ul><li><p>矩阵可以转化为向量表示</p></li><li><p>矩阵范数：<span class="math inline">\(A\in P^{m\timesn}\)</span>，需满足以下条件</p><ol type="1"><li>正定性：<span class="math inline">\(||A||\ge0,且||A||=0\iffA=0\)</span></li><li>齐次性：<span class="math inline">\(||\lambda A||=|\lambda|\cdot||A||,\lambda\in R,A\in P^{m\times n}\)</span></li><li>三角不等式：<span class="math inline">\(||A+B||\le||A||+||B||,\forall A,B\in P^{m\times n}\)</span></li><li><strong>相容性</strong>：<span class="math inline">\(\Vert AB \Vert\le \Vert A\Vert\cdot \Vert B\Vert\)</span></li></ol><blockquote><p><strong>Remarks</strong>：这里相容性的定义目的是什么呢？为了放缩方便？</p></blockquote></li><li><p>例如</p><ul><li>（自相容）<span class="math inline">\(\|A\|_{m_{1}}=\sum_{j=1}^{n}\sum_{i=1}^{m}\left|a_{i j}\right|\)</span></li><li>（不相容）<span class="math inline">\(\|A\|_{m_{\infty}}=\max _{i,j}\left\{\left|a_{i j}\right|\right\} \quad 1 \leq i \leq m \quad 1 \leqj \leq n\)</span></li><li>（自相容）Frobenius范数：<spanclass="math inline">\(\|A\|_{m_{2}}=\left(\sum_{j=1}^{n}\sum_{i=1}^{m}\left|a_{i j}\right|^{2}\right)^{\frac{1}{2}}\)</span><ul><li><spanclass="math inline">\(\|\boldsymbol{A}\|_{m_{2}}^{2}=\operatorname{tr}\left(\boldsymbol{A}^{\boldsymbol{H}}\boldsymbol{A}\right)=\sum_{i=1}^{n}\lambda_{i}\left(\boldsymbol{A}^{\boldsymbol{H}}\boldsymbol{A}\right)\)</span></li><li>对任意酉矩阵<span class="math inline">\(U,V\)</span>，<spanclass="math inline">\(\|\boldsymbol{A}\|_{m_{2}}^{2}=\left\|\boldsymbol{U}^{\boldsymbol{H}}\boldsymbol{A} \boldsymbol{V}\right\|_{m_{2}}^{2}=\left\|\boldsymbol{U}\boldsymbol{A}\boldsymbol{V}^{\boldsymbol{H}}\right\|_{m_{2}}^{2}\)</span></li></ul></li></ul></li></ul><h3 id="算子范数">7.3 算子范数</h3><ul><li><p>向量范数与矩阵范数的相容性：<span class="math inline">\(\|Ax\|_{m} \leq\|A\|_{m}\|x\|_{m}\)</span> 是否成立</p><ul><li><strong>定义</strong>：设 <spanclass="math inline">\(\|\cdot\|_a\)</span> 是 <spanclass="math inline">\(P^n\)</span> 上的向量范数，<spanclass="math inline">\(\|\cdot\|_m\)</span> 是 <spanclass="math inline">\(P^{n\times n}\)</span> 上的矩阵范数，且 <spanclass="math display">\[\|A x\|_{a} \leq\|A\|_{m}\|x\|_{a}\notag\]</span> 则称 <span class="math inline">\(\|\cdot\|_m\)</span>为与向量范数 <span class="math inline">\(\|\cdot\|_a\)</span>相容的矩阵范数</li></ul></li><li><p>算子范数</p><ul><li><p>设 <span class="math inline">\(\|\cdot\|_a\)</span> 是 <spanclass="math inline">\(P^n\)</span> 上的向量范数，<spanclass="math inline">\(A\in P^{n\times n}\)</span>，则 <spanclass="math display">\[\|\boldsymbol{A}\|_{a}=\underset{\boldsymbol{x} \neq\boldsymbol{\theta}}{\max } \frac{\|\boldsymbol{A}\boldsymbol{x}\|_{a}}{\|\boldsymbol{x}\|_{a}}\left(=\max_{\|u\|_{a}=1}\|A u\|_{a}\right) \notag\]</span> 是与向量范数 <span class="math inline">\(\|\cdot\|_a\)</span>相容的矩阵范数</p></li><li><p>推论：算子范数也是相容的矩阵范数，即 <spanclass="math inline">\(\|AB\|_a\le\|A\|_a\|B\|_a\)</span></p></li></ul></li><li><p>常用算子范数</p><ul><li>极大列和范数：<spanclass="math inline">\(\|\boldsymbol{A}\|_{\mathbf{1}}=\mathbf{m}_{\boldsymbol{j}}\mathbf{x}\left(\sum_{\boldsymbol{i}=1}^{\boldsymbol{n}}\left|\boldsymbol{a}_{ij}\right|\right)\)</span></li><li>极大行和范数：<span class="math inline">\(\|A\|_{\infty}=\max_{i}\left(\sum_{j=1}^{n}\left|a_{i j}\right|\right)\)</span></li><li>谱范数：<spanclass="math inline">\(\|\boldsymbol{A}\|_{2}=\sqrt{r\left(\boldsymbol{A}^{\boldsymbol{H}}\boldsymbol{A}\right)}\)</span><ul><li>谱半径：<span class="math inline">\(r(A)=\max_{i}\left|\lambda_{i}\right|\)</span></li><li><spanclass="math inline">\(\|A\|_{2}=\left\|A^{H}\right\|_{2}=\left\|A^{T}\right\|_{2}=\|\bar{A}\|_{2}\)</span></li><li><span class="math inline">\(\left\|A^{H} A\right\|_{2}=\left\|AA^{H}\right\|_{2}=\|A\|_{2}^{2}\)</span></li><li>对任意酉矩阵<span class="math inline">\(U,V\)</span>，<spanclass="math inline">\(\|\boldsymbol{U}\boldsymbol{A}\|_{2}=\|\boldsymbol{A}\boldsymbol{V}\|_{2}=\|\boldsymbol{U} \boldsymbol{A}\boldsymbol{V}\|_{2}=\|\boldsymbol{A}\|_{2}\)</span></li></ul></li></ul></li><li><p>定理</p><ul><li><span class="math inline">\(\|\boldsymbol{A}\|_{2}=\max_{\|x\|_{2}=\|y\|_{2}=\mathbf{1}}\left|\boldsymbol{y}^{\boldsymbol{H}}\boldsymbol{A} \boldsymbol{x}\right|\)</span></li><li><span class="math inline">\(\|\boldsymbol{A}\|_{2}^{2}\leq\|\boldsymbol{A}\|_{1}\|\boldsymbol{A}\|_{\infty}\)</span></li></ul></li></ul><hr /><h2 id="矩阵分解">8. 矩阵分解</h2><h3 id="三角分解">8.1 三角分解</h3><ul><li>三角矩阵<ul><li>逆矩阵仍然是三角矩阵</li><li>三角矩阵的积仍是三角矩阵</li></ul></li></ul><blockquote><p><strong>定理(LU分解)</strong>：设 <span class="math inline">\(A\inC^{n\times n}\)</span>，则 <span class="math inline">\(A\)</span>可<strong>唯一的</strong>分解为 <span class="math display">\[A=U_1 R \notag\]</span> 其中 <span class="math inline">\(U_1\)</span> 为酉矩阵，<spanclass="math inline">\(R\)</span> 为正线上三角矩阵；或者 A可以<strong>唯一的</strong>分解为 <span class="math display">\[A = L U_2 \notag\]</span> 其中 <span class="math inline">\(U_2\)</span> 为酉矩阵，<spanclass="math inline">\(L\)</span> 为正线下三角矩阵。</p><p><strong>推论 1</strong>：对于实数域，则有类似的<strong>QR分解</strong></p><p><strong>推论2.1</strong>：对于<strong>实对称</strong>矩阵，存在唯一上三角实矩阵<span class="math display">\[A = R^T R \notag\]</span> <strong>推论 2.2</strong>：正定 <strong>Hermite</strong>矩阵，存在唯一上三角复矩阵 <span class="math display">\[A = R^H R \notag\]</span></p></blockquote><ul><li>任意矩阵的三角分解（非方阵）</li></ul><h3 id="谱分解">8.2 谱分解</h3><ul><li><strong>单纯矩阵</strong>：代数重数等于几何重数</li></ul><blockquote><p><strong>定理</strong>：设 <span class="math inline">\(A\in C^{n\timesn}\)</span> 是<strong>单纯矩阵</strong>，则 <spanclass="math inline">\(A\)</span>可以分解为一系列<strong>幂等矩阵</strong> <spanclass="math inline">\(A_i\)</span> 的加权和 <spanclass="math display">\[A = \sum_{i=1}^n \lambda_i A_i \notag\]</span> 其中 <span class="math inline">\(\lambda_i\)</span> 是 <spanclass="math inline">\(A\)</span> 的特征值</p><p><strong>证明</strong>：由单纯矩阵可知 <span class="math display">\[A=P\Lambda P^{-1}=\left(v_{1}, v_{2}, \cdots,v_{n}\right)\left[\begin{array}{cccc}{\lambda_{1}} &amp; {0} &amp;{\cdots} &amp; {0} \\{0} &amp; {\lambda_{2}} &amp; {\cdots} &amp; {0}\\{\cdots} &amp; {\cdots} &amp; {\cdots} &amp; {\cdots} \\{0} &amp; {0}&amp; {\cdots} &amp;{\lambda_{n}}\end{array}\right]\left(\begin{array}{c}{\omega_{1}^{T}}\\{\omega_{2}^{T}} \\{\vdots} \\{\omega_{n}^{T}}\end{array}\right)\notag\]</span> 取 <span class="math inline">\(A_i = v_i w_i^T\)</span>，<spanclass="math inline">\(A_i\)</span> 的性质：</p><ul><li>幂等性：<span class="math inline">\(A_i^2=A_i\)</span></li><li>分离性：<span class="math inline">\(A_i A_j=0(i\ne0)\)</span></li><li>可加性：<span class="math inline">\(\sum_{i=1}^n A_i =E_n\)</span></li></ul><blockquote><p><strong>Remarks</strong></p><p>这里的幂等矩阵 <span class="math inline">\(A_i\)</span>可以看作是正交<strong>基</strong>的概念</p><p>由前面投影矩阵的定义可知，<strong>每一个 <spanclass="math inline">\(A_i\)</span>都是一个投影矩阵</strong>，将任意一个向量 <spanclass="math inline">\(x\)</span> 投影到 <spanclass="math inline">\(v_i\)</span> 张成的子空间 <spanclass="math inline">\(L(v_i)\)</span>上。因此上面的幂等矩阵分解实际上可以理解为“<strong>特征空间分解</strong>”（笔者瞎想的名词），如何理解呢？把<strong>每个<span class="math inline">\(A_i\)</span> 看作是矩阵 <spanclass="math inline">\(A\)</span>的一个特征子空间（的投影基）</strong>，<spanclass="math inline">\(Ax\)</span> 实际上就是把 <spanclass="math inline">\(x\)</span>投影到各个特征子空间中，然后根据对应的<strong>特征值</strong>进行伸缩，最后再合成一个作用后的向量，即表示<span class="math inline">\(A\)</span> 对 <spanclass="math inline">\(x\)</span> 的线性变换。</p></blockquote><p><strong>定理</strong>：设 <span class="math inline">\(A\in C^{n\timesn}\)</span>，有 <span class="math inline">\(k\)</span> 个相异的特征值<span class="math inline">\(\lambda_i(i=1,...,k)\)</span>，则 <spanclass="math inline">\(A\)</span>是<strong>单纯矩阵</strong>的充要条件是，存在 <spanclass="math inline">\(k\)</span> 个矩阵矩阵 <spanclass="math inline">\(A_i\)</span> 满足</p><ol type="1"><li><span class="math inline">\(A_{i}A_{j}=\left\{\begin{array}{ll}{A_{i}} &amp; {i=j} \\ {0} &amp; {i \neqj}\end{array}\right.\)</span></li><li><span class="math inline">\(\sum_{i=1}^k A_i = E_n\)</span></li><li><span class="math inline">\(A = \sum_{i=1}^k \lambda_iA_i\)</span></li></ol></blockquote><ul><li><strong>正规矩阵</strong>：满足 <spanclass="math inline">\(A^HA=AA^H\)</span> 的矩阵 <imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2019/normal%20matrix.jpg"alt="正规矩阵" /></li></ul><blockquote><p><strong>引理</strong>：设 <span class="math inline">\(A\)</span>为正规矩阵，<span class="math inline">\(A\)</span> 与 <spanclass="math inline">\(B\)</span> <strong>酉相似</strong>，则 <spanclass="math inline">\(B\)</span> 为正规矩阵</p><blockquote><p><strong>定理</strong>：任意矩阵 <span class="math inline">\(A\inC^{n\times n}\)</span>，存在酉矩阵 <spanclass="math inline">\(U\)</span> 使得 <span class="math display">\[A=URU^H \notag\]</span> 其中 <span class="math inline">\(R\)</span>为<strong>上三角矩阵</strong>且主对角线元素为 <spanclass="math inline">\(A\)</span> 的特征值</p></blockquote><p><strong>引理</strong>：设 <span class="math inline">\(A\)</span>为正规矩阵且为三角矩阵，则 <span class="math inline">\(A\)</span>为对角矩阵</p><blockquote><p><strong>Remarks</strong>：</p><p><strong>任意矩阵 <span class="math inline">\(A\)</span> 都与三角阵<span class="math inline">\(R\)</span> 酉相似</strong>，因此若矩阵 <spanclass="math inline">\(A\)</span> 为正规阵，则 <spanclass="math inline">\(R\)</span>既是正规阵，又是三角阵，则一定是对角阵。</p><p>因此，<strong>正规阵一定可以对角化</strong>，由下面的定理可知，可以<strong>酉对角化</strong>的矩阵一定是正规矩阵。</p><p>这与普通的可对角化矩阵的区别是什么呢？普通矩阵可对角化的充要条件是代数重数等于几何重数，也即只需要<strong>n 个线性无关的特征向量</strong>即可(<spanclass="math inline">\(A=PJP^{-1}\)</span>)。而正规矩阵则要求<strong>所有特征向量正交</strong>(<spanclass="math inline">\(A=U\Lambda U^H\)</span>)！</p></blockquote><blockquote><p><strong>Remarks</strong></p><p>那么<strong>正定矩阵</strong>与<strong>正规矩阵</strong>的区别是什么呢？先看正定矩阵的定义：特征值全部为正数。区别很明显了，一个是从特征值角度，另一个是从特征向量角度，牢记这一点就不会弄混两者了。</p><p>凡是具有 <span class="math inline">\(A^HA\)</span>形式的矩阵，既是<strong>正规矩阵</strong>，又是<strong>正定矩阵</strong>！</p></blockquote><p><strong>定理</strong>：<span class="math inline">\(A\)</span>为正规矩阵的充要条件是存在酉矩阵 <span class="math inline">\(U\)</span>使 <span class="math display">\[A = U \text{diag}(\lambda_1,...,\lambda_n)U^H \notag\]</span> 其中 <span class="math inline">\(\lambda_i\)</span> 是 <spanclass="math inline">\(A\)</span> 的特征值</p><p><strong>定理</strong>：<span class="math inline">\(A\)</span> 有<span class="math inline">\(k\)</span> 个相异特征值，则 <spanclass="math inline">\(A\)</span> 是正规矩阵的充要条件是存在 <spanclass="math inline">\(k\)</span> 个矩阵 <spanclass="math inline">\(A_i\)</span> 满足</p><ol type="1"><li><span class="math inline">\(A_{i}A_{j}=\left\{\begin{array}{ll}{A_{i}} &amp; {i=j} \\ {0} &amp; {i \neqj}\end{array}\right.\)</span></li><li><span class="math inline">\(\sum_{i=1}^k A_i = E_n\)</span></li><li><span class="math inline">\(A = \sum_{i=1}^k \lambda_iA_i\)</span></li><li><span class="math inline">\(A_i^H = A_i(i=1,...,k)\)</span></li></ol></blockquote><h3 id="最大秩分解">8.3 最大秩分解</h3><ul><li><strong>定理</strong>：设 <span class="math inline">\(A\inC^{m\times n}_r\)</span>，则存在矩阵 <span class="math inline">\(B\inC^{m\times r}_r, D\in C^{r\times n}_r\)</span>，使得 <spanclass="math inline">\(A=BD\)</span><ul><li>注：可以理解为 <span class="math inline">\(B\)</span> 取出了 <spanclass="math inline">\(r\)</span> 线性无关的列向量，或者 <spanclass="math inline">\(D\)</span> 取出了 <spanclass="math inline">\(r\)</span> 个线性无关的行向量</li><li><span class="math inline">\((B^HB)^{-1}B^HB=E_r\)</span>，可以用于求<span class="math inline">\(B\)</span> 的左逆，<spanclass="math inline">\(D\)</span> 同理</li></ul></li></ul><h3 id="奇异值分解">8.4 奇异值分解</h3><ul><li><strong>奇异值</strong>：设 <span class="math inline">\(A\inC^{m\times n}_r\)</span>，<span class="math inline">\(A^HA\)</span>的特征值为 <span class="math inline">\(\lambda_{1} \geq \lambda_{2} \geq\cdots \geq\lambda_{r}&gt;\lambda_{r+1}=\cdots=\lambda_{n}=\mathbf{0}\)</span>，则称<span class="math inline">\(\sigma_{i}=\sqrt{\lambda_{i}}(i=1,2, \cdots,r)\)</span> 为 <span class="math inline">\(A\)</span>的正奇异值（实际上就相当于 A 的“绝对特征值”）</li><li><strong>定理</strong>：设 <span class="math inline">\(A\inC^{m\times n}_r\)</span>，则有<ol type="1"><li><spanclass="math inline">\(rank(A)=rank(A^HA)=rank(AA^H)\)</span></li><li><span class="math inline">\(A^HA,AA^H\)</span>的特征值均为非负实数</li><li><span class="math inline">\(A^HA,AA^H\)</span> 的特征值相同</li></ol></li><li><strong>酉等价</strong>：<span class="math inline">\(A,B\inC^{m\times n}\)</span>，存在酉矩阵 <spanclass="math inline">\(U,V\)</span> 使得 <spanclass="math inline">\(A=UBV\)</span></li><li><strong>定理</strong>：若 <span class="math inline">\(A,B\)</span>酉等价，则它们有相同的奇异值</li></ul><blockquote><p><strong>定理</strong>：设 <span class="math inline">\(A\in C^{m\timesn}_r\)</span>，<spanclass="math inline">\(\sigma_1,...,\sigma_r\)</span> 是 <spanclass="math inline">\(A\)</span> 的 <spanclass="math inline">\(r\)</span> 个奇异值，则存在酉矩阵 <spanclass="math inline">\(U\in C^{m\times m},V\in C{n\timesn}\)</span>，使得 <span class="math display">\[A=U\left[\begin{array}{ll}{D} &amp; {0} \\ {0} &amp;{0}\end{array}\right] V \notag\]</span> 其中 <spanclass="math inline">\(\boldsymbol{D}=\operatorname{diag}\left(\delta_{1},\delta_{2}, \cdots,\delta_{r}\right),\left|\delta_{i}\right|=\sigma_{i}\)</span></p></blockquote><hr /><h2 id="特征值估计">9. 特征值估计</h2><h3 id="几个不等式">9.1 几个不等式</h3><ul><li><strong>定理 1(Schur 不等式)</strong>：设 <spanclass="math inline">\(A\in C^{n\times n}\)</span> 的特征值为 <spanclass="math inline">\(\lambda_1,...,\lambda_n\)</span>，则 <spanclass="math inline">\(\sum_{i=1}^{n}\left|\lambda_{i}\right|^{2} \leq\sum_{i=1}^{n} \sum_{j=1}^{n}\left|a_{ij}\right|^{2}=\|A\|_{F}^{2}\)</span>，等号成立当且仅当 <spanclass="math inline">\(A\)</span> 为正规矩阵</li><li><strong>定理 2(Hirsch)</strong>：设 <span class="math inline">\(A\inC^{n\times n}\)</span>，记 <spanclass="math inline">\(B=\frac{A+A^H}{2},C=\frac{A-A^H}{2}\)</span>，<spanclass="math inline">\(A,B,C\)</span> 特征值分别为 <spanclass="math inline">\(\{\lambda_i\},\{\mu_i\},\{i\gamma_i\}\)</span>，均从大到小排列。则有<ol type="1"><li><span class="math inline">\(\left|\lambda_{i}\right| \leq n \max_{i, j}\left|a_{i j}\right|\)</span></li><li><span class="math inline">\(\left|\mathbf{R e} \lambda_{i}\right|\leq n \max _{i, j}\left|b_{i j}\right|\)</span></li><li><span class="math inline">\(\left|\mathbf{I m} \lambda_{i}\right|\leq \boldsymbol{n} \max _{i, j}\left|\boldsymbol{c}_{ij}\right|\)</span></li></ol></li><li><strong>定理 3(Bendixson)</strong>：设 <spanclass="math inline">\(A\in R^{n\times n}\)</span>，则 <spanclass="math inline">\(A\)</span> 的任一特征值满足 <spanclass="math inline">\(\left|\mathbf{I m} \lambda_{i}\right| \leq\sqrt{\frac{n(n-1)}{2}} \max _{i, j}\left|c_{i j}\right|\)</span></li></ul><h3 id="盖尔圆盘定理">9.2 盖尔圆盘定理</h3><ul><li><strong>定义 1</strong>：设 <span class="math inline">\(A\inC^{n\times n}\)</span><ul><li>行盖尔圆盘：<span class="math inline">\(S_{i}=\left\{z \inC:\left|z-a_{i i}\right| \leq R_{i}=\sum_{j \neq i}\left|a_{ij}\right|\right\}\)</span></li><li>列盖尔圆盘：<span class="math inline">\(G_{i}=\left\{z \inC:\left|z-a_{i i}\right| \leq C_{i}=\sum_{j \neq i}\left|a_{ji}\right|\right\}\)</span></li></ul></li></ul><blockquote><p><strong>定理 1(圆盘定理)</strong>：设 <spanclass="math inline">\(A\in C^{n\times n}\)</span>，则 <spanclass="math inline">\(A\)</span> 的任一特征值 <spanclass="math display">\[\lambda_{i} \in \boldsymbol{S}=\bigcup_{j=1}^{n} \boldsymbol{S}_{j}\quad(\boldsymbol{i}=\mathbf{1}, 2, \cdots, \boldsymbol{n}) \notag\]</span> 类似的，有 <span class="math display">\[\lambda_{i} \in \left(\bigcup_{j=1}^{n} \boldsymbol{S}_{j}\right)\bigcap \left(\bigcup_{j=1}^{n} \boldsymbol{G}_{j}\right)\quad(\boldsymbol{i}=\mathbf{1}, 2, \cdots, \boldsymbol{n}) \notag\]</span> <strong>定理 2</strong>：设 <spanclass="math inline">\(n\)</span> 阶方阵 <spanclass="math inline">\(A\)</span> 的 <spanclass="math inline">\(n\)</span> 个盖尔圆盘中有 <spanclass="math inline">\(k\)</span>个圆盘的并形成一个<strong>连通区域</strong> <spanclass="math inline">\(G\)</span>（圆盘相切也算连通），且它与余下的 <spanclass="math inline">\(n-k\)</span> 个圆盘都不相交，则在该区域中恰好有<span class="math inline">\(A\)</span> 的 <spanclass="math inline">\(k\)</span> 个特征值</p><p><strong>证明</strong>：取 <spanclass="math inline">\(A_{\varepsilon}=D+\varepsilon B,\ \varepsilon\in[0,1]\)</span>，而 <span class="math inline">\(A_\varepsilon\)</span>的特征值 <span class="math inline">\(\lambda_i(A_\varepsilon) =\lambda_i(\varepsilon)\)</span> 时关于 <spanclass="math inline">\(\varepsilon\)</span>的<strong>连续函数</strong>，在圆盘随着 <spanclass="math inline">\(\varepsilon\)</span>扩大过程中，特征值一直都处于圆盘内部</p><figure><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2020/gerschgorin.jpg"alt="gerschgorin" /><figcaption aria-hidden="true">gerschgorin</figcaption></figure><p><strong>推论 1</strong>：设 <span class="math inline">\(n\)</span>阶方阵 <span class="math inline">\(A\)</span> 的 <spanclass="math inline">\(n\)</span> 个盖尔圆盘两两互不相交，则 <spanclass="math inline">\(A\)</span> 相似于对角阵</p><p><strong>推论 2</strong>：设 <span class="math inline">\(n\)</span>阶<strong>实矩阵</strong> <span class="math inline">\(A\)</span> 的<span class="math inline">\(n\)</span> 个盖尔圆盘两两互不相交，则 <spanclass="math inline">\(A\)</span> 的特征值全部为实数</p><p><strong>改进</strong>：可以取 <spanclass="math inline">\(D=diag(p_1,...,p_n),\ \ p_i&gt;0\)</span>，则有<span class="math inline">\(D^{-1}AD\)</span> 与 <spanclass="math inline">\(A\)</span><strong>相似</strong>，因此他们有相同的特征值，可以用 <spanclass="math inline">\(D^{-1}AD\)</span> 的特征值来估计 <spanclass="math inline">\(A\)</span>。此时可以将某些盖尔圆变小，但是代价就是其他盖尔圆会变大。</p></blockquote><ul><li><strong>行对角占优</strong>：<spanclass="math inline">\(\left|a_{ii}\right| \geq R_{i}=\sum_{j=1, j \nei}^{n}\left|a_{i j}\right| \quad(i=1,2, \cdots, n)\)</span></li><li><strong>列对角占优</strong>：<spanclass="math inline">\(\left|a_{ii}\right| \geq C_{i}=\sum_{j=1, j \nei}^{n}\left|a_{ji}\right| \quad(i=1,2, \cdots, n)\)</span></li></ul><blockquote><p><strong>定理 3</strong>：设 <span class="math inline">\(A\inC^{n\times n}\)</span> <strong>严格</strong>行对角占优，则</p><ol type="1"><li><span class="math inline">\(A\)</span> 可逆</li><li>若 <span class="math inline">\(A\)</span> 所有主对角元都为正数，则<span class="math inline">\(A\)</span> 的特征值都有正实部</li><li>若 <span class="math inline">\(A\)</span> 为 Hermite矩阵，且所有主对角元都为正数，则 <span class="math inline">\(A\)</span>的特征值都为正数</li></ol></blockquote><h3 id="hermite矩阵特征值的变分特性">9.3Hermite矩阵特征值的变分特性</h3><p>因为Hermite矩阵 <span class="math inline">\(A\in C^{n\timesn}\)</span> 的特征值均为实数，所以可以把他们记作（按照大小进行排序）：<span class="math display">\[\lambda_{\min }=\lambda_{n} \leq \lambda_{n-1} \ldots \leq \lambda_{2}\leq \lambda_{1}=\lambda_{\max } \notag\]</span></p><ul><li><strong>Rayleigh 商</strong>：<spanclass="math inline">\(R(x)=\frac{x^{H} A x}{x^{H} x} \quad x \neq0\)</span><ul><li><span class="math inline">\(\lambda_{n} x^{H} x \leq x^{H} A x \leq\lambda_{1} x^{H} x \quad\left(\forall x \in C^{n}\right)\)</span></li><li><span class="math inline">\(\lambda_{\max }=\lambda_{1}=\max _{x\neq 0} R(x)=\max _{x^{H}} x^{H} A x\)</span></li><li><span class="math inline">\(\lambda_{\min }=\lambda_{n}=\min _{x\neq 0} R(x)=\min _{x^{H} x=1} x^{H} A x\)</span></li></ul></li><li><strong>定理(Courant-Fischer)</strong>：设特征值 <spanclass="math inline">\(\lambda_1 \le \lambda_2 \le \cdots \le\lambda_n\)</span>，则<ul><li><span class="math inline">\(\begin{array}{ccc}{\min } &amp; {\max }&amp; {R(x)=\lambda_{k}} \\ {\omega_{1}, \omega_{2}, \cdots,\omega_{n-k} \in C^{n}} &amp; {x \neq 0, x \in C^{n} \atop {x \perp\omega_{1}, \omega_{2}, \cdots, \omega_{n-k}}} &amp; {}\end{array}\)</span></li><li><span class="math inline">\(\begin{array}{ccc}{\max } &amp; {\min }&amp; {R(x)=\lambda_{k}} \\ {\omega_{1}, \omega_{2}, \cdots,\omega_{n-k} \in C^{n}} &amp; {x \neq 0, x \in C^{n} \atop {x \perp\omega_{1}, \omega_{2}, \cdots, \omega_{n-k}}} &amp; {}\end{array}\)</span></li></ul></li><li><strong>定理(Weyl)</strong>：<spanclass="math inline">\(\lambda_k(A)+\lambda_n(B)\le\lambda_k(A+B)\le\lambda_k(A)+\lambda_1(B)\)</span></li></ul><hr /><h2 id="矩阵分析">10. 矩阵分析</h2><h3 id="矩阵序列与矩阵级数">10.1 矩阵序列与矩阵级数</h3><ul><li>矩阵序列<ul><li><strong>定理</strong>：设 <spanclass="math inline">\(\Vert\cdot\Vert\)</span> 是 <spanclass="math inline">\(C^{m\times n}\)</span> 上的任一矩阵范数，矩阵序列<span class="math inline">\(\{A^{(k)}\}\)</span> 收敛于 <spanclass="math inline">\(A\)</span> 的充要条件是 <spanclass="math inline">\(\lim _{k\rightarrow+\infty}\left\|A^{(k)}-A\right\|=0\)</span></li><li><strong>定理</strong>：设 <span class="math inline">\(\lim _{k\rightarrow+\infty} A^{(k)}=A, \lim _{k \rightarrow+\infty} B^{(k)}=B .\alpha, \beta \in C\)</span>，则<ul><li><span class="math inline">\(\lim _{k \rightarrow+\infty}\left(\alphaA^{(k)}+\beta B^{(k)}\right)=\alpha A+\beta B\)</span></li><li><span class="math inline">\(\lim _{k \rightarrow+\infty} A^{(k)}B^{(k)}=A B\)</span></li><li>当 <span class="math inline">\(A^{(k)}\)</span> 与 <spanclass="math inline">\(A\)</span> 都可逆时，<spanclass="math inline">\(\lim _{k\rightarrow+\infty}\left(A^{(k)}\right)^{-1}=A^{-1}\)</span></li></ul></li></ul></li><li><strong>收敛矩阵</strong>：设 <span class="math inline">\(A\inC^{n\times n}\)</span>，若 <span class="math inline">\(\lim _{k\rightarrow \infty} A^{k}=0\)</span>，则称 <spanclass="math inline">\(A\)</span> 为收敛矩阵<ul><li><strong>定理</strong>：设 <span class="math inline">\(A\inC^{n\times n}\)</span>，则 <span class="math inline">\(A\)</span>为收敛矩阵的充要条件是 <spanclass="math inline">\(r(A)&lt;1\)</span></li></ul></li><li><strong>矩阵级数</strong>：<spanclass="math inline">\(\sum_{k=1}^{\infty}A^{(k)}=A^{(1)}+A^{(2)}+\cdots+A^{(k)}+\cdots\)</span>，称 <spanclass="math inline">\(\boldsymbol{S}^{(\boldsymbol{N})}=\sum_{\boldsymbol{k}=1}^{\boldsymbol{N}}\boldsymbol{A}^{(\boldsymbol{k})}\)</span> 为矩阵级数的部分和，若 <spanclass="math inline">\(\lim _{N \rightarrow \infty} S^{(N)}=S\)</span>则称级数<strong>收敛</strong><ul><li><strong>定理</strong>：在 <span class="math inline">\(C^{n\timesn}\)</span> 中，<span class="math inline">\(\sum_{k=1}^{\infty}A^{(k)}\)</span> 绝对收敛的充要条件是正项级数 <spanclass="math inline">\(\sum_{k=1}^{\infty}\left\|A^{(k)}\right\|\)</span>收敛</li><li><strong>定理</strong>：方阵 <span class="math inline">\(A\)</span>的 Neumann 级数 <span class="math inline">\(\sum_{k=0}^{\infty}A^{k}=I+A+A^{2}+\cdots+A^{k}+\cdots\)</span> 收敛的充要条件是 <spanclass="math inline">\(r(A)&lt;1\)</span>，且收敛时，其和为 <spanclass="math inline">\((I-A)^{-1}\)</span></li></ul></li></ul><h3 id="矩阵函数">10.2 矩阵函数</h3><ul><li><p>幂级数：设幂级数 <span class="math inline">\(\sum_{k=0}^{\infty}c_{k} z^{k}\)</span> 收敛半径为 <spanclass="math inline">\(r\)</span>，且当 <spanclass="math inline">\(|z|&lt;r\)</span> 时，幂级数收敛于函数 <spanclass="math inline">\(f(z)\)</span>，即 <spanclass="math inline">\(f(z)=\sum_{k=0}^{\infty} c_{k} z^{k},\quad|z|&lt;r\)</span></p></li><li><p>矩阵幂级数：如果 <span class="math inline">\(A\in C^{n\timesn}\)</span> 满足 <spanclass="math inline">\(r(A)&lt;r\)</span>，则称收敛矩阵的矩阵幂级数 <spanclass="math inline">\(\sum_{k=0}^{\infty} a_{k} A^{k}\)</span>为矩阵函数，记为 <span class="math inline">\(f(A)\)</span>，即 <spanclass="math inline">\(f(A)=\sum_{k=0}^{\infty} c_{k}A^{k}\)</span>，考虑参数 <span class="math inline">\(t\)</span>，有<span class="math inline">\(f(At)=\sum_{k=0}^{\infty} c_{k}(At)^{k}\)</span></p><ul><li>常用矩阵函数：</li><li><span class="math inline">\(e^{A}=\sum_{k=0}^{\infty} \frac{1}{k !}A^{k}, \quad A \in C^{n \times n}\)</span></li><li><span class="math inline">\(\sin A=\sum_{k=0}^{\infty}\frac{(-1)^{k}}{(2 k+1) !} A^{2 k+1}, \quad A \in C^{n \timesn}\)</span></li><li><span class="math inline">\(\cos A=\sum_{k=0}^{\infty}\frac{(-1)^{k}}{(2 k) !} A^{2 k}, \quad A \in C^{n \timesn}\)</span></li><li><span class="math inline">\((E-A)^{-1}=\sum_{k=0}^{\infty} A^{k},\quad r(A)&lt;1\)</span></li><li><span class="math inline">\(\ln (E+A)=\sum_{k=0}^{\infty}\frac{(-1)^{k}}{k+1} A^{k+1}, \quad r(A)&lt;1\)</span></li></ul></li><li><p>矩阵函数值计算</p><ul><li><p>相似对角化：设 <spanclass="math inline">\(P^{-1}AP=diag(\lambda_1,...,\lambda_n)=D\)</span>，则<span class="math inline">\(f(At) = P\cdot diag(f(\lambda_1t),...,f(\lambda_n t))\cdot P^{-1}\)</span></p></li><li><p>Jordan标准型：设 <spanclass="math inline">\(P^{-1}AP=diag(J_1,...,J_s)\)</span>，则 <spanclass="math display">\[f(A)=P\left(\begin{array}{ccc}{f\left(J_{1}\right)} &amp; {} &amp; {} \\{} &amp; {\ddots} &amp; {} \\{} &amp; {} &amp; {f\left(J_{s}\right)}\end{array}\right) P^{-1} \notag\]</span></p></li></ul></li><li><p>矩阵函数性质</p><ul><li>如果 <span class="math inline">\(AB=BA\)</span>，则<ul><li><span class="math inline">\(e^{A} e^{B}=e^{B}e^{A}=e^{A+B}\)</span></li><li><span class="math inline">\(\cos (A+B)=\cos A \cos B-\sin A \sinB\)</span></li><li><span class="math inline">\(\sin (A+B)=\sin A \cos B+\cos A \sinB\)</span></li></ul></li></ul></li></ul><hr /><h2 id="矩阵求逆">11 矩阵求逆</h2><hr /><h2 id="hermite矩阵的性质">Hermite矩阵的性质</h2><ul><li>一般 Hermite 矩阵<ul><li>Hermite矩阵本身就是<strong>正规矩阵</strong>，因此可以对角化(几何重数等于代数重数)，不同特征向量<strong>正交</strong></li><li>特征值均为<strong>实数</strong>（反 Hermite矩阵的特征值全为虚数）</li></ul></li><li>正定 Hermite 矩阵<ul><li>主对角线元素全部大于 0</li><li>存在正定 Hermite 矩阵 <span class="math inline">\(B\)</span> 使得<span class="math inline">\(A=B^2\)</span>（可以无穷分解）</li><li><span class="math inline">\(A\)</span> 的任意 k 行和对应的 k列组成的主子阵是正定的</li></ul></li></ul>]]></content>
    
    
    <categories>
      
      <category>Linear Algebra</category>
      
    </categories>
    
    
    <tags>
      
      <tag>矩阵分析</tag>
      
      <tag>线性代数</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>统计推断(十一)  Sum-product algorithm</title>
    <link href="/2020/02/03/statistic/SI_Ch11_Sumproduct/"/>
    <url>/2020/02/03/statistic/SI_Ch11_Sumproduct/</url>
    
    <content type="html"><![CDATA[<p>和积算法/信念传播算法</p><span id="more"></span><h2 id="sum-productmessage-passing-on-trees">1. Sum-product(Messagepassing) on trees</h2><ul><li><p>目的是为了计算边缘分布，相比于 elimination的优势在于可以用较少的计算次数计算所有随机变量的边缘分布，关键在于复用message</p></li><li><p>algorithm</p><ul><li><p>Step 1: Compute messages <span class="math display">\[m_{i \rightarrow j}\left(x_{j}\right)=\sum_{x_{i}}\phi_{i}\left(x_{i}\right) \psi_{i j}\left(x_{i}, x_{j}\right) \prod_{k\in N(i) \backslash\{j\}} m_{k \rightarrow i}\left(x_{i}\right)\]</span></p></li><li><p>Step 2: Compute marginals <span class="math display">\[p_{\times i}\left(x_{i}\right) \propto \phi_{i}\left(x_{i}\right)\prod_{j \in N(i)} m_{j \rightarrow i}\left(x_{i}\right)\]</span></p></li></ul></li><li><p>Remarks</p><ul><li><p>什么是 message？</p></li><li><p>tree的一枝表示什么？实际上就是一个<strong>条件分布</strong>，如下图中实际上就是<spanclass="math inline">\(m_2(x_1)=\sum_{x_2,x_4,x_5}p(x_2,x_4,x_5|x_1)\)</span></p><figure><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2019/message.PNG"alt="message" /><figcaption aria-hidden="true">message</figcaption></figure></li></ul></li></ul><h2 id="sum-product-algorithm-on-factor-trees">2. Sum-product algorithmon factor trees</h2><ul><li><p>algorithm</p><ul><li><p>Message from variable to factor <span class="math display">\[m_{i \rightarrow a}\left(x_{i}\right)=\prod_{b \in N(i) \backslash\{a\}}m_{b \rightarrow i}\left(x_{i}\right)\]</span></p></li><li><p>Message from factor to variable <span class="math display">\[m_{a \rightarrow i}\left(x_{i}\right)=\sum_{\mathbf{x}_{N(a)\backslash\{i\}}} f_{a}\left(x_{i}, \mathbf{x}_{N(a)\backslash\{i\}}\right) \prod_{j \in N(a) \backslash\{i\}} m_{j\rightarrow a}\left(x_{j}\right)\]</span></p></li></ul></li></ul><h2 id="max-product-for-undirected-treefactor-tree">3. Max-Product forundirected tree/factor tree</h2><h2 id="parallel-max-product">4. Parallel Max-Product</h2><ul><li><p>所有节点同时运算，至多需要 d(最长path的length)次迭代即可</p></li><li><p>trick: 整体的减少乘法次数 <span class="math display">\[\begin{align}\tilde{m}_{i}^{t}\left(x_{i}\right)&amp;=\prod_{k \in N(i)} m_{k\rightarrow i}^{t}\left(x_{i}\right) \\m_{i \rightarrow j}^{t+1}\left(x_{j}\right)&amp;=\max _{x_{i} \in\mathcal{X}} \phi_{i}\left(x_{i}\right) \psi_{i j}\left(x_{i},x_{j}\right) \frac{\tilde{m}_{i}^{t}\left(x_{i}\right)}{m_{j \rightarrowi}^{t}\left(x_{i}\right)}\end{align}\]</span></p></li></ul>]]></content>
    
    
    <categories>
      
      <category>统计推断</category>
      
    </categories>
    
    
    <tags>
      
      <tag>信念传播算法</tag>
      
      <tag>和积算法</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>统计推断(十) Elimination algorithm</title>
    <link href="/2020/02/03/statistic/SI_Ch10_Elimination/"/>
    <url>/2020/02/03/statistic/SI_Ch10_Elimination/</url>
    
    <content type="html"><![CDATA[<p>消去算法</p><span id="more"></span><hr /><h2 id="elimination-algorithm">1. Elimination algorithm</h2><ul><li><p>主要目的是为了计算边缘分布</p></li><li><p>Reconstituted graph: 若消去的随机变量为 <spanclass="math inline">\(x_k\)</span>，则所有与 <spanclass="math inline">\(x_k\)</span> 连接的随机变量会形成一个新的clique</p><figure><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2019/elimination_1.PNG"alt="elimination" /><figcaption aria-hidden="true">elimination</figcaption></figure></li><li><p>复杂度</p><ul><li>Brute-force marginalization：<spanclass="math inline">\(O\left(|\mathcal{X}|^N\right)\)</span></li><li>Zig-zag elimination：<spanclass="math inline">\(O\left(|\mathcal{X}|^{\sqrt{N}}\right)\)</span></li></ul></li></ul><figure><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2019/elimination_2.PNG"alt="elimination" /><figcaption aria-hidden="true">elimination</figcaption></figure><h2 id="map-elimination-algorithm">2. MAP elimination algorithm</h2><ul><li><p>计算 MAP <span class="math inline">\(\boldsymbol{x}^{*} \in \arg\max _{\boldsymbol{x} \in \mathcal{X}^{N}}p_{\mathbf{x}}(\boldsymbol{x})\)</span> <span class="math display">\[\begin{array}{l}{\max _{x, y} f(x) g(x, y)=\max _{x}\left(f(x) \max _{y}g(x, y)\right)} \\ {\sum_{x, y} f(x) g(x, y)=\sum_{x}\left(f(x) \sum_{y}g(x, y)\right)}\end{array}\]</span></p></li><li><p>example <span class="math display">\[p_{\mathbf{x}}(\boldsymbol{x}) \propto \exp \left(x_{1} x_{2}-x_{1}x_{3}-x_{2} x_{4}+x_{3} x_{4}+x_{3} x_{5}\right)\]</span> <imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2019/map_elimination_1.PNG"alt="map_elimination" /></p></li><li><p>algorithm</p><figure><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2019/map_elimination_2.PNG"alt="map_elimination" /><figcaption aria-hidden="true">map_elimination</figcaption></figure></li><li><p>complexicity <span class="math display">\[\text { overall cost } \leq|\mathcal{C}|\sum_{i}|\mathcal{X}|^{\left|S_{i}\right|+1} \leqN|\mathcal{C}||\mathcal{X}|^{\max _{i}\left|S_{i}\right|+1}\]</span></p></li></ul>]]></content>
    
    
    <categories>
      
      <category>统计推断</category>
      
    </categories>
    
    
    <tags>
      
      <tag>消去算法</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>统计推断(九) Graphical models</title>
    <link href="/2020/02/03/statistic/SI_Ch9_GraphModels/"/>
    <url>/2020/02/03/statistic/SI_Ch9_GraphModels/</url>
    
    <content type="html"><![CDATA[<h2 id="undirected-graphical-modelsmarkov-random-fields">1. Undirectedgraphical models(Markov random fields)</h2><ul><li><p>节点表示随机变量，边表示与节点相关的势函数 <spanclass="math display">\[p_{\mathbf{x}}(\mathbf{x}) \propto \varphi_{12}\left(x_{1}, x_{2}\right)\varphi_{13}\left(x_{1}, x_{3}\right) \varphi_{25}\left(x_{2},x_{5}\right) \varphi_{345}\left(x_{3}, x_{4}, x_{5}\right)\]</span> <imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2019/undirected_graph.PNG"alt="undirected_graph" /></p></li><li><p><strong>clique</strong>：全连接的节点集合</p></li><li><p><strong>maximal clique</strong>：不是其他 clique的真子集</p></li></ul><blockquote><p><strong>Theorem (Hammersley-Cliﬀord) </strong>: A strictly positivedistribution <spanclass="math inline">\(p_{\mathsf{x}}(\mathbf{x})&gt;0\)</span> satisﬁesthe graph separation property of undirected graphical models if and onlyif it can be represented in the factorized form <spanclass="math display">\[p_{\mathsf{x}}(\mathbf{x}) \propto \prod_{\mathcal{A} \in \mathcal{C}}\psi_{\mathbf{x}_{\mathcal{A}}}\left(\mathbf{x}_{\mathcal{A}}\right)\]</span></p></blockquote><ul><li><strong>conditional independence</strong>：<spanclass="math inline">\(\mathbf{x}_{\mathcal{A}_{1}} \perp\mathbf{x}_{\mathcal{A}_{2}} |\mathbf{x}_{\mathcal{A}_{3}}\)</span></li></ul><span id="more"></span><h2 id="directed-graphical-modelsbayesian-network">2. Directed graphicalmodels(Bayesian network)</h2><ul><li><p>节点表示随机变量，有向边表示条件关系 <spanclass="math display">\[p_{\mathrm{x}_{1}, \ldots,\mathrm{x}_{n}}=p_{\mathrm{x}_{1}}\left(x_{1}\right) p_{\mathrm{x}_{2} |\times_{1}}\left(x_{2} | x_{1}\right) \cdots p_{\mathrm{x}_{n} | x_{1},\ldots, x_{n-1}}\left(x_{n} | x_{1}, \ldots, x_{n-1}\right)\]</span> <imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2019/directed_graph.PNG"alt="directed_graph" /></p></li><li><p>Directed acyclic graphs (<strong>DAG</strong>)</p></li><li><p>Fully-connected DAG</p></li><li><p><strong>conditional independence</strong>：<spanclass="math inline">\(\mathbf{x}_{\mathcal{A}_{1}} \perp\mathbf{x}_{\mathcal{A}_{2}} | \mathbf{x}_{\mathcal{A}_{3}}\)</span></p><figure><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2019/conditional_independence.PNG"alt="conditional_independence" /><figcaption aria-hidden="true">conditional_independence</figcaption></figure></li><li><p>Bayes ball algorithm</p><ul><li>primary shade: <span class="math inline">\(\mathcal{A_3}\)</span>中的节点</li><li>secondary shade: primary shade 的节点，以及 secondary shade的父节点</li></ul><figure><imgsrc="C:\Users\1\AppData\Roaming\Typora\typora-user-images\1574319393095.png"alt="1574319393095" /><figcaption aria-hidden="true">1574319393095</figcaption></figure></li></ul><h2 id="factor-graph">3. Factor graph</h2><ul><li><p>有 variable nodes 和 factor nodes，是 bipartitie graph <spanclass="math display">\[p_{\mathbf{x}}(\mathbf{x}) \propto \prod_{j}f_{j}\left(\mathbf{x}_{f_{j}}\right)\]</span> <imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2019/factor_graph.PNG"alt="factor_graph" /></p></li><li><p>因子图比 directed graph 和 undirected graph 的表示能力更强，比如<spanclass="math inline">\(p(x)=\frac{1}{Z}\phi_{12}(x_1,x_2)\phi_{13}(x_1,x_3)\phi_{23}(x_2,x_3)\)</span></p></li><li><p>因子图可以与 DAG 相互转化(根据 <spanclass="math inline">\(x_1,...,x_n\)</span> 依次根据 conditionalindependence 决定父节点)，DAG又可以转化为 undirected graph</p></li></ul><h2 id="measuring-goodness-of-graphical-representations">4. Measuringgoodness of graphical representations</h2><ul><li>给定分布 D 和图 G，他们之间没必要有联系</li><li><span class="math inline">\(CI(D)\)</span>：the set of conditionalindependencies satisﬁed by <span class="math inline">\(D\)</span></li><li><span class="math inline">\(CI(G)\)</span>： the set of allconditional independencies implied by <spanclass="math inline">\(G\)</span></li><li><strong>I-map</strong>：<span class="math inline">\(C I(\mathcal{G})\subset C I(D)\)</span></li><li><strong>D-map</strong>: ：<span class="math inline">\(CI(\mathcal{G}) \supset C I(D)\)</span></li><li><strong>P-map</strong>：<span class="math inline">\(C I(\mathcal{G})= C I(D)\)</span></li><li>minimal I-map: AminimalI-mapisanI-mapwiththepropertythatremovinganysingle edge would cause thegraph to no longer be an I-map. <strong>Remarks</strong>: G中去掉一个边会使该 map 中有更多的 conditional independence，也即 <spanclass="math inline">\(CI(G)\)</span> 更大，更不易满足 I-map条件。I-map可以表示分布 D，但是 D-map 不能</li></ul>]]></content>
    
    
    <categories>
      
      <category>统计推断</category>
      
    </categories>
    
    
    <tags>
      
      <tag>图模型</tag>
      
      <tag>因子图</tag>
      
      <tag>DAG</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>统计推断(八) Model Selection</title>
    <link href="/2020/02/03/statistic/SI_Ch8_ModelSelection/"/>
    <url>/2020/02/03/statistic/SI_Ch8_ModelSelection/</url>
    
    <content type="html"><![CDATA[<p>模型选择</p><span id="more"></span><h2 id="bayesian-approach">1.Bayesian Approach</h2><ul><li><p>Consider a nested sequence of model classes</p><p><span class="math display">\[\mathcal{P}_{1} \subset \mathcal{P}_{2} \subset \mathcal{P}_{3} \subset\cdots\]</span></p></li><li><p>ML decision rule: <span class="math display">\[\hat{m}=\arg \max _{m}\left\{\max _{p \in \mathcal{P}_{m}}p(\boldsymbol{y})\right\}=\arg \max _{m}\left\{\max _{a} p_{y | x,H}\left(\boldsymbol{y} | a, H_{m}\right)\right\}\]</span></p></li></ul><h2 id="laplaces-method">2. Laplace’s Method</h2><ul><li><p>连续分布</p><p><span class="math display">\[p_{\times}(x)=\frac{p_{0}(x)}{Z_{p}}\]</span></p></li><li><p>用 taylor 级数近似似然函数 <span class="math display">\[\ln p_{0}(x) \approx \ln p(\hat{x})+\left.(x-\hat{x})\frac{\mathrm{d}}{\mathrm{d} x} \lnp_{0}(x)\right|_{x=\hat{x}}+\left.\frac{1}{2}(x-\hat{x})^{2}\frac{\mathrm{d}^{2}}{\mathrm{d} x^{2}} \ln p_{0}(x)\right|_{x=\hat{x}}\\p_{0}(x) \approx p_{0}(\hat{x}) \exp \left[-\frac{1}{2}J_{\mathbf{y}=\boldsymbol{y}}(\hat{x})(x-\hat{x})^{2}\right]\]</span></p></li></ul><h2 id="bayes-information-criterion">3. Bayes Information Criterion</h2><ul><li>MAP decision rule: <span class="math display">\[\hat{m}=\arg \max _{m} p_{\mathbf{y} | \mathbf{H}}\left(\boldsymbol{y} |H_{m}\right)\]</span> 其中 <span class="math display">\[p_{\mathbf{y} | \mathbf{H}}\left(\boldsymbol{y} | H_{m}\right)=\intp_{\mathbf{y} | \mathbf{x}, \mathbf{H}}\left(\boldsymbol{y} | x,H_{m}\right) p_{\mathbf{x} | \mathbf{H}}\left(x | H_{m}\right)\mathrm{d} x\]</span> 令 <span class="math display">\[q_{0}(x)=p_{\mathbf{y} | \mathbf{x}, \mathbf{H}}\left(\boldsymbol{y} |x, H_{m}\right) p_{\mathbf{x} | \mathbf{H}}\left(x | H_{m}\right)\propto p_{\mathbf{x} | \mathbf{y}, \mathbf{H}}\left(x | \boldsymbol{y},H_{m}\right)\]</span> 可以有 <span class="math display">\[p_{\mathrm{y} | \mathrm{H}}(\boldsymbol{y} | H)=\int q_{0}(x) \mathrm{d}x \approx p_{\mathrm{y} | x, \mathrm{H}}(\boldsymbol{y} | \hat{x}, H)p_{\mathrm{x} | \mathrm{H}}(\hat{x} | H) \sqrt{2 \piJ_{\mathrm{y}}^{-1}(\hat{x})}\]</span> 其中最后一项为 <strong>Occam’s razor factor</strong></li></ul>]]></content>
    
    
    <categories>
      
      <category>统计推断</category>
      
    </categories>
    
    
    <tags>
      
      <tag>模型选择</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>统计推断(七)  Typical Sequence</title>
    <link href="/2020/02/03/statistic/SI_Ch7_TypicalSequence/"/>
    <url>/2020/02/03/statistic/SI_Ch7_TypicalSequence/</url>
    
    <content type="html"><![CDATA[<p>典型集</p><span id="more"></span><h2 id="一些定理">1. 一些定理</h2><blockquote><p><strong>Markov inequality</strong>: <span class="math inline">\(r.v.\ \ \mathsf{x}\ge0\)</span> <span class="math display">\[\mathbb{P}(x\ge\mu)\le \frac{\mathbb{E}[x]}{\mu}\]</span> <strong>Proof</strong>: omit...</p><p><strong>Weak law of large numbers(WLLN)</strong>: <spanclass="math inline">\(\vec{y}=[y_1,y_2,...,y_N]^T, \ \ \ \ y_i \sim p \\ \ i.i.d\)</span> <span class="math display">\[\lim_{N\to\infty}\mathbb{P}(|L_p(\vec{y})+H(p)|&gt;\varepsilon)=0, \ \\forall \varepsilon&gt;0\]</span> <strong>Proof</strong>: omit...</p></blockquote><h2 id="typical-set">2. Typical set</h2><ul><li><p>Definition: <spanclass="math inline">\(\mathcal{T}_\varepsilon(p;N)=\{\vec{y}\in\mathcal{Y}^N:|L_p(\vec{y})+H(p)|&lt;\varepsilon\}\)</span></p></li><li><p>Properties</p><ul><li>WLLN <span class="math inline">\(\LongrightarrowP\left(\vec{y}\in\mathcal{T}_\varepsilon(p;N)\right)\simeq1\)</span>,<span class="math inline">\(N\)</span> large</li><li><span class="math inline">\(L_p(\vec{y})\simeq H(p) \Longrightarrowp_y(\vec{y})\simeq 2^{-NH(p)}\)</span></li><li><span class="math inline">\(\Longrightarrow|\mathcal{T}_\varepsilon(p;N)|\simeq 2^{NH(p)}\)</span></li><li>当 p 不是均匀分布的时候，<spanclass="math inline">\(\frac{|\mathcal{T}_\varepsilon(p;N)|}{|\mathcal{Y}^N|}\to0\)</span>，也就是说典型集中元素(序列)个数在所有可能的元素(序列)中所占比例趋于0，但是典型集中元素概率的和却趋近于 1</li></ul></li><li><p>Theorem</p></li></ul><blockquote><p><strong>Asymptotic Equipartition Property(AEP)</strong></p><ul><li><span class="math display">\[\lim_{N\to\infty}P(\mathcal{T}_\varepsilon(p;N))=1 \\\]</span> <span class="math display">\[2^{-N(H(p)+\epsilon)} \leq p_{\mathrm{y}}(\boldsymbol{y}) \leq2^{-N(H(p)-\epsilon)}, \forall \boldsymbol{y} \in\mathcal{T}_{\epsilon}(p ; N)\]</span></li><li>for a sufficient large <span class="math inline">\(N\)</span> <spanclass="math display">\[(1-\epsilon) 2^{N(H(p)-\epsilon)} \leq\left|\mathcal{T}_{\epsilon}(p ;N)\right| \leq 2^{N(H(p)+\epsilon)}\]</span> <strong>Proof</strong>: <span class="math display">\[\begin{aligned}\left|\mathcal{T}_{\epsilon}(p ; N)\right|&amp;=\sum_{\boldsymbol{y} \in \mathcal{T}_{\epsilon}(p ; N)} 1 \\&amp;=2^{N(H(p)+\epsilon)} \sum_{\boldsymbol{y} \in\mathcal{T}_{\epsilon}(p ; N)} 2^{-N(H(p)+\epsilon)} \\ &amp; \leq2^{N(H(p)+\epsilon)} \sum_{\boldsymbol{y} \in \mathcal{T}_{\epsilon}(p ;N)} p_{\mathbf{y}}(\boldsymbol{y}) \\ &amp;=2^{N(H(p)+\epsilon)}P\left\{\mathcal{T}_{\epsilon}(p ; N)\right\} \\ &amp; \leq2^{N(H(p)+\epsilon)} \end{aligned}\]</span></li></ul><figure><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2019/typical_set.PNG"alt="typical_set" /><figcaption aria-hidden="true">typical_set</figcaption></figure></blockquote><h2 id="divergence-varepsilon-typical-set">3. <strong>Divergence <spanclass="math inline">\(\varepsilon\)</span>-typical set</strong></h2><ul><li><p>WLLN: <span class="math inline">\(\vec{y}=[y_1,y_2,...,y_N]^T, \\ \ \ y_i \sim p \ \ \ i.i.d\)</span> $$ L_{p | q}()= = _{n=1}^{N} \</p><p><em>{N } (|L</em>{p | q}()-D(p | q)|&gt;)=0 $$<strong>Remarks</strong>:前面只考虑的均值，这里还考虑了另一个分布</p></li><li><p>Definition: <spanclass="math inline">\(\vec{\boldsymbol{y}}=[y_1,y_2,...,y_N]^T, \ \ \ \y_i \sim p \ \ \ i.i.d\)</span> <span class="math display">\[\mathcal{T}_{\epsilon}(p | q ; N)=\left\{\boldsymbol{y} \in\mathcal{Y}^{N}:\left|L_{p | q}(\boldsymbol{y})-D(p \| q)\right| \leq\epsilon\right\}\]</span></p></li><li><p>Properties</p><ul><li>WLLN <span class="math inline">\(\Longrightarrowq_{\mathbf{y}}(\boldsymbol{y}) \approx p_{\mathbf{y}}(\boldsymbol{y})2^{-N D(p \| q)}\)</span></li><li><span class="math inline">\(Q\left\{\mathcal{T}_{\epsilon}(p | q ;N)\right\} \approx 2^{-N D(p \| q)} \to0\)</span></li><li><strong>Remarks</strong>: p 的典型集可能是 q 的非典型集，在 <spanclass="math inline">\(N\)</span> 很大的时候，不同分布的 typical set是正交的</li></ul></li><li><p>Theorem <span class="math display">\[(1-\epsilon) 2^{-N(D(p \| q)+\epsilon)} \leqQ\left\{\mathcal{T}_{\epsilon}(p \| q ; N)\right\} \leq 2^{-N(D(p \|q)-\epsilon)}\]</span></p></li></ul><h2 id="large-deviation-of-sample-averages">4. Large deviation of sampleaverages</h2><blockquote><p><strong>Theorem (Cram´er’s Theorem)</strong>: <spanclass="math inline">\(\vec{\boldsymbol{y}}=[y_1,y_2,...,y_N]^T, \ \ \y_i \sim q \ \ \ i.i.d\)</span> with mean <spanclass="math inline">\(\mu&lt;\infty\)</span> and <spanclass="math inline">\(\gamma&gt;\mu\)</span> <spanclass="math display">\[\lim _{N \rightarrow \infty}-\frac{1}{N} \log\mathbb{P}\left(\frac{1}{N} \sum_{n=1}^{N} y_{n} \geq\gamma\right)=E_{C}(\gamma)\]</span> where <span class="math inline">\(E_C(\gamma)\)</span> isreferred as <strong>Chernoﬀ exponent</strong> <spanclass="math display">\[E_{C}(\gamma) \triangleq D(p(\cdot ; x) \| q),\ \ \ p(\cdot ; x)=q(y)e^{x y-\alpha(x)}\]</span> and with <span class="math inline">\(x&gt;0\)</span> chosensuch that <span class="math display">\[\mathbb{E}_{p(\cdot;x)}[y]=\gamma\]</span> <strong>Proof</strong>:</p><ol type="1"><li><span class="math inline">\(\begin{aligned}\mathbb{P}\left(\frac{1}{N} \sum_{n=1}^{N} y_{n} \geq \gamma\right)&amp;=\mathbb{P}\left(e^{x \sum_{n=1}^{N} y_{n}} \geq e^{N x\gamma}\right) \\ &amp; \leq e^{-N x \gamma} \mathbb{E}\left[e^{x\sum_{n=1}^{N} y_{n}}\right] \\ &amp;=e^{-N x\gamma}\left(\mathbb{E}\left[e^{x y}\right]\right)^{N} \\ &amp; \leqe^{-N\left(x_{*} \gamma-\alpha\left(x_{*}\right)\right)}\end{aligned}\)</span></li><li><span class="math inline">\(\varphi(x)=x\gamma-\alpha(x)\)</span>是凸的，最大值取在 <span class="math inline">\(\mathbb{E}_{p\left(\cdot; x_{*}\right)}[y]=\dot{\alpha}\left(x_{*}\right)=\gamma\)</span></li><li>可以证明 <span class="math inline">\(x_{*}\gamma-\alpha\left(x_{*}\right)=x_{*}\dot{\alpha}\left(x_{*}\right)-\alpha\left(x_{*}\right)=D\left(p\left(\cdot; x_{*}\right) \| q\right)\)</span></li><li>于是有 <span class="math inline">\(\mathbb{P}\left(\frac{1}{N}\sum_{n=1}^{N} y_{n} \geq \gamma\right) \leq e^{-NE_{C}(\gamma)}\)</span></li><li><em>下界的证明，暂时略...</em></li></ol><blockquote><p>用到的两个事实：<spanclass="math inline">\(p(y;x)=q(y)\exp(xy-\alpha(x))\)</span></p><ol type="1"><li><span class="math inline">\(D(p(y;x)||q(y))\)</span> 随着 x单调增加</li><li><span class="math inline">\(\mathbb{E}_{p(;x)}[y]\)</span> 随着 x单调增加</li></ol></blockquote><p><strong>Remarks</strong>:</p><ol type="1"><li>这个定理也相当于表达了 <spanclass="math inline">\(\mathbb{P}\left(\frac{1}{N} \sum_{n=1}^{N} y_{n}\geq \gamma\right) \cong 2^{-N E_{\mathrm{C}}(\gamma)}\)</span></li><li>相当于是分布 <strong>q</strong> 向由 <spanclass="math inline">\(\mathbb{E}[y]=\sum_{n=1}^{N} y_{n} \geq\gamma\)</span> 所定义的一个凸集中投影，恰好投影到边界(线性分布族) <spanclass="math inline">\(\mathbb{E}[y]=\gamma\)</span> 上，而 <spanclass="math inline">\(q\)</span> 向线性分布族的投影恰好就是 (10)中的指数族表达式</li></ol><figure><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2019/cramer_thm.PNG"alt="cramer_thm" /><figcaption aria-hidden="true">cramer_thm</figcaption></figure></blockquote><h2 id="types-and-type-classes">5. Types and type classes</h2><ul><li><p>Definition: <spanclass="math inline">\(\vec{\boldsymbol{y}}=[y_1,y_2,...,y_N]^T\)</span>(不关心真实服从的是哪个分布)</p><ul><li><strong>type</strong>(实质上就是一个<strong>经验分布</strong>)定义为</li></ul><p><span class="math display">\[\hat{p}(b ; \mathbf{y})=\frac{1}{N} \sum_{n=1}^{N}\mathbb{1}_{b}\left(y_{n}\right)=\frac{N_{b}(\mathbf{y})}{N}\]</span></p><ul><li><span class="math inline">\(\mathcal{P}_{N}^{y}\)</span> 表示长度为<span class="math inline">\(N\)</span> 的序列所有可能的 types</li><li><strong>type class</strong>: <spanclass="math inline">\(\mathcal{T}_{N}^{y}(p)=\left\{\mathbf{y} \iny^{N}: \hat{p}(\cdot ; \mathbf{y}) \equiv p(\cdot)\right\},\ \ \p\in\mathcal{P}_{N}^{y}\)</span></li></ul></li><li><p>Exponential Rate Notation: <span class="math inline">\(f(N)\doteq 2^{N \alpha}\)</span> <span class="math display">\[\lim _{N \rightarrow \infty} \frac{\log f(N)}{N}=\alpha\]</span> <strong>Remarks</strong>: <spanclass="math inline">\(\alpha\)</span> 表示了指数上面关于 <spanclass="math inline">\(N\)</span> 的阶数(log、线性、二次 ...)</p></li><li><p>Properties</p><ul><li><span class="math inline">\(\left|\mathcal{P}_{N}^{y}\right|\leq(N+1)^{|y|}\)</span></li><li><span class="math inline">\(q^{N}(\mathbf{y})=2^{-N(D(\hat{p}(\cdot\mathbf{y}) \| q)+H(\hat{p}(\cdot ; \mathbf{y})))}\)</span> <spanclass="math inline">\(p^{N}(\mathbf{y})=2^{-N H(p)} \quad \text { for }\mathbf{y} \in \mathcal{T}_{N}^{y}(p)\)</span></li><li><span class="math inline">\(c N^{-|y|} 2^{N H(p)}\leq\left|\mathcal{T}_{N}^{y}(p)\right| \leq 2^{N H(p)}\)</span></li></ul></li><li><p>Theorem <span class="math display">\[c N^{-|y|} 2^{-N D(p \| q)} \leq Q\left\{\mathcal{T}_{N}^{y}(p)\right\}\leq 2^{-N D(p \| q)} \\Q\left\{\mathcal{T}_{N}^{y}(p)\right\} \doteq 2^{-N D(p \| q)}\]</span></p></li></ul><h2 id="large-deviation-analysis-via-types">6. Large Deviation Analysisvia Types</h2><ul><li>Definition: <spanclass="math inline">\(\mathcal{R}=\left\{\mathbf{y} \in y^{N}:\hat{p}(\cdot ; \mathbf{y}) \in \mathcal{S} \cap\mathcal{P}_{N}^{y}\right\}\)</span></li></ul><blockquote><p><strong>Sanov’s Theorem</strong>: <span class="math display">\[Q\left\{\mathrm{S} \cap \mathcal{P}_{N}^{y}\right\} \leq(N+1)^{|y|}2^{-N D\left(p_{*} \| q\right)} \\Q\left\{\mathrm{S} \cap \mathcal{P}_{N}^{y}\right\} \dot\leq 2^{-ND\left(p_{*} \| q\right)} \\p_{*}=\underset{p \in \mathcal{S}}{\arg \min } D(p \| q)\]</span></p></blockquote><h2 id="asymptotics-of-hypothesis-testing">7. Asymptotics of hypothesistesting</h2><ul><li>LRT: <span class="math inline">\(L(\boldsymbol{y})=\frac{1}{N} \log\frac{p_{1}^{N}(\boldsymbol{y})}{p_{0}^{N}(\boldsymbol{y})}=\frac{1}{N}\sum_{n=1}^{N} \log\frac{p_{1}\left(y_{n}\right)}{p_{0}\left(y_{n}\right)}\frac{&gt;}{&lt;} \gamma\)</span></li><li><span class="math inline">\(P_{F}=\mathbb{P}_{0}\left\{\frac{1}{N}\sum_{n=1}^{N} t_{n} \geq \gamma\right\} \approx 2^{-N D\left(p^{*} \|p_{0}^{\prime}\right)}\)</span></li><li><span class="math inline">\(P_{M}=1-P_{D} \approx 2^{-N D\left(p^{*}\| p_{1}^{\prime}\right)}\)</span></li><li><span class="math inline">\(D\left(p^{*} \|p_{0}^{\prime}\right)-D\left(p^{*} \| p_{1}^{\prime}\right)=\intp^{*}(t) \log \frac{p_{1}^{\prime}(t)}{p_{0}^{\prime}(t)} \mathrm{d}t=\int p^{*}(t) t \mathrm{d}t=\mathbb{E}_{p^{*}}[\mathrm{t}]=\gamma\)</span></li></ul><figure><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2019/asymptotic.PNG"alt="asymptotic" /><figcaption aria-hidden="true">asymptotic</figcaption></figure><h2 id="asymptotics-of-parameter-estimation">8.Asymptotics of parameterestimation</h2><blockquote><p><strong>Strong Law of Large Numbers(SLLN)</strong>: <spanclass="math display">\[\mathbb{P}\left(\lim _{N \rightarrow \infty} \frac{1}{N} \sum_{n=1}^{N}w_{n}=\mu\right)=1\]</span> <strong>Central Limit Theorem(CLT)</strong>: <spanclass="math display">\[\lim _{N \rightarrow \infty} \mathbb{P}\left(\frac{1}{\sqrt{N}}\sum_{n=1}^{N}\left(\frac{w_{n}-\mu}{\sigma}\right) \leqb\right)=\Phi(b)\]</span> 以下三个强度依次递减</p><ol type="1"><li><p>依概率 1 收敛(SLLN)：<span class="math inline">\(\mathsf{x}_{N}\stackrel{w . p .1}{\longrightarrow} a\)</span></p></li><li><p>概率趋于 0(WLLN):</p></li><li><p>依分布收敛: <span class="math inline">\(\mathsf{x}_{N}\stackrel{d}{\longrightarrow} p\)</span></p></li></ol></blockquote><ul><li><p>Asymptotics of ML Estimation</p><blockquote><p><strong>Theorem</strong>: <span class="math display">\[\hat{x}_{N}=\arg \max _{x} L_{N}(x ; \mathbf{y})\]</span> 在满足某些条件下(mild conditions)，有 <spanclass="math display">\[\begin{array}{c}{\hat{x}_{N} \stackrel{w \cdot p \cdot1}{\longrightarrow} x_{0}} \\{\sqrt{N}\left(\hat{x}_{N}-x_{0}\right) \stackrel{d}{\longrightarrow}\mathcal{N}\left(0, J_{y}\left(x_{0}\right)^{-1}\right)}\end{array}\]</span></p></blockquote></li></ul>]]></content>
    
    
    <categories>
      
      <category>统计推断</category>
      
    </categories>
    
    
    <tags>
      
      <tag>典型集</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>统计推断(六) Modeling</title>
    <link href="/2020/02/03/statistic/SI_Ch6_Modeling/"/>
    <url>/2020/02/03/statistic/SI_Ch6_Modeling/</url>
    
    <content type="html"><![CDATA[<p>模型选择</p><span id="more"></span><h2 id="modeling-problem">1. Modeling problem</h2><ul><li><p>formulation</p><ul><li><p>a set of distributions <span class="math display">\[\mathcal{P}=\left\{p_{\mathrm{y}}(\cdot ; x) \in \mathcal{P}^{y}: x \in\mathcal{X}\right\}\]</span></p></li><li><p>approximation <span class="math display">\[\min _{q \in \mathcal{P}^{y}} \max _{x \in \mathcal{X}}D\left(p_{\mathrm{y}}(\cdot ; x) \| q(\cdot)\right)\]</span></p></li></ul></li><li><p>solution</p></li></ul><blockquote><p><strong>Theorem</strong>: 对任意 <span class="math inline">\(q \in\mathcal{P}^{y}\)</span> 都存在一个混合模型 <spanclass="math inline">\(q_w(\cdot) = \sum_{x \in \mathcal{X}} w(x)p_{y}(\cdot ; x)\)</span> 满足 <span class="math display">\[D\left(p_{y}(\cdot ; x) \| q_{w}(\cdot)\right) \leq D\left(p_{y}(\cdot ;x) \| q(\cdot)\right) \quad \text { for all } x \in \mathcal{X}\]</span> <strong>Proof</strong>: 应用 Pythagoras 定理</p><p>然后很容易有</p><p><span class="math display">\[\max _{x \in \mathcal{X}} \min _{q \in \mathcal{P}^{y}}D\left(p_{y}(\cdot ; x) \| q(\cdot)\right)=\max _{x \in \mathcal{X}} 0=0\\\]</span></p><p><span class="math display">\[\min _{q \in \mathcal{P}} \max _{x \in \mathcal{X}}D\left(p_{\mathrm{y}}(\cdot ; x) \| q(\cdot)\right)=\min _{q \in\mathcal{P}} \max _{w \in \mathcal{P}^{\mathcal{X}}} \sum_{x} w(x)D\left(p_{\mathrm{y}}(\cdot ; x) \| q(\cdot)\right)\]</span></p><p><strong>Theorem</strong> (Redundancy-Capacity Theorem):以下等式成立，且两侧最优的 <span class="math inline">\(w,q\)</span>s是相同的 <span class="math display">\[\begin{aligned} R^{+} \triangleq \min _{q \in \mathcal{P}^{\mathcal{Y}}}\max _{w \in \mathcal{P}^{\mathcal{X}}} &amp; \sum_{x} w(x)D\left(p_{\mathrm{y}}(\cdot ; x) \| q(\cdot)\right) \\ &amp;=\max _{w\in \mathcal{P}} \min _{q \in \mathcal{P}} \sum_{x} w(x)D\left(p_{\mathrm{y}}(\cdot ; x) \| q(\cdot)\right) \triangleq R^{-}\end{aligned}\]</span> <strong>Proof</strong>:</p><ol type="1"><li>利用后面的 Equidistance property 证明 <spanclass="math inline">\(R^+ \le R^-\)</span></li><li>根据 minimax 和 maxmini 的性质，有 <span class="math inline">\(R^+\ge R^-\)</span></li><li>一定有 <span class="math inline">\(R^+ \ge R^-\)</span></li><li>证明两个不等式的取等条件是在同样的 <spanclass="math inline">\(w,q\)</span> 处取到</li></ol></blockquote><h2 id="model-capacity">2. Model capacity</h2><blockquote><p>首先计算 <span class="math inline">\(R^-\)</span> 内部的 min <spanclass="math display">\[\begin{aligned} &amp; \min _{q \in \mathcal{P}^{\mathcal{Y}}} \sum_{x}w(x) D\left(p_{\mathbf{y}}(\cdot ; x) \| q(\cdot)\right) \\=&amp; \min_{q \in \mathcal{P}^{\mathcal{Y}}} \sum_{x, y} w(x) p_{\mathbf{y}}(y ;x) \log \frac{p_{y}(y ; x)}{q(y)} \\=&amp; \text { constant }-\max _{q\in \mathcal{P}^{\mathcal{Y}}} \sum_{y} q_{w}(y) \log q(y) \\=&amp;\text { constant }-\max _{q \in \mathcal{P}^{\mathcal{Y}}}\mathbb{E}_{q_{w}}[\log q(y)] \end{aligned}\]</span></p>根据 Gibbs 不等式 <span class="math display">\[q^*(\cdot) = q_{w}(\cdot) \triangleq \sum_{x \in \mathcal{X}} w(x)p_{y}(\cdot ; x)\]</span> 再考虑 <span class="math inline">\(R^-\)</span> 外部的max，此时可以转化为 <strong>Bayesian</strong> 角度！ $$<span class="math display">\[\begin{aligned} R^{-} &amp;=\max _{w \in\mathcal{P}^{\mathcal{X}}} \sum_{x} w(x) D\left(p_{y}(\cdot ; x) \|q_{w}(\cdot)\right) \\ &amp;=\max _{w \in \mathcal{P}^{\mathcal{X}}}\sum_{x, y} w(x) p_{y}(y ; x) \log \frac{p_{y}(y ; x)}{\sum_{x^{\prime}}w\left(x^{\prime}\right) p_{y}\left(y ; x^{\prime}\right)} \\&amp;\overset{\text{Bayesian}}{=}\max _{p_{\mathbf{x}}} \sum_{x}p_{\mathbf{x}}(x) D\left(p_{y | \mathbf{x}}(\cdot | x) \|p_{y}(\cdot)\right) \\ &amp;=\max _{p_{\mathbf{x}}} \sum_{x, y}p_{\mathbf{x}}(x) p_{\mathbf{y} | \mathbf{x}}(y | x) \log \frac{p_{y |x}(y | x)}{p_{\mathbf{y}}(y)} \\ &amp;=\max _{p_{\mathbf{x}}} \sum_{x,y} p_{\mathbf{x}, \mathbf{y}}(x, y) \log \frac{p_{\mathbf{x},\mathbf{y}}(x, y)}{p_{\mathbf{x}}(x) p_{y}(y)}=\max _{p_{\mathbf{x}}}I(x ; y)=C\end{aligned}\]</span><p>$$</p><p><strong>Definition</strong>: 对一个模型 <spanclass="math inline">\(p_{\mathsf{y|x}}\)</span>，有 <spanclass="math display">\[C \triangleq \max _{p_{x}} I(x ; y)\]</span></p><ul><li><p><strong>Model capacity</strong>: C</p></li><li><p><strong>least informative prior</strong>: <spanclass="math inline">\(p_x^*\)</span></p></li></ul><p><strong>Theorem</strong>(Equidistance property): C对应的最优的 <spanclass="math inline">\(p^*\)</span> 和 <spanclass="math inline">\(w^*\)</span> 满足 <span class="math display">\[D(p_y(\cdot;x)||q^*(\cdot)) \le C \ \ \ \ \ \forall x\in\mathcal{X}\]</span> 其中等号对于满足 <spanclass="math inline">\(w^*(x)&gt;0\)</span> 的 x 成立</p><p><strong>Proof</strong>:</p><ol type="1"><li><span class="math inline">\(I(x,y)\)</span> 关于 <spanclass="math inline">\(p_x(a)\ \ \forall a\)</span> 是 concave 的</li><li>构造拉格朗日函数 <span class="math inline">\(\mathcal{L}=I(x,y) -\lambda(\sum_x p_x(x)-1)\)</span>，也关于 <spanclass="math inline">\(p_x(a)\)</span> concave</li><li><span class="math inline">\(\min_{p_x}I(x,y)\)</span> 的极值点应满足<span class="math inline">\(\left.\frac{\partial I(x ; y)}{\partialp_{x}(a)}\right|_{p_{x}=p_{x}^{*}}-\lambda=0, \quad \text { for all } a\in \mathcal{X} \text { such that } p_{x}^{*}(a)&gt;0\)</span>，或者<span class="math inline">\(\left.\frac{\partial I(x ; y)}{\partialp_{x}(a)}\right|_{p_{x}=p_{x}^{*}}-\lambda\le0, \quad \text { for all }a \in \mathcal{X} \text { such that } p_{x}^{*}(a)=0\)</span></li><li><span class="math inline">\(\frac{\partial I(x ; y)}{\partialp_{x}(a)} = D\left(p_{y | x}(\cdot ; a) \| p_{y}\right)-\log e\)</span>并根据 3 中取等号的特点恰好可以得到定理中的式子</li></ol></blockquote><h2 id="inference-with-mixture-models">3. Inference with mixturemodels</h2><ul><li><p>Formulation: 有观测 <spanclass="math inline">\(y_-\)</span>，想要预测 <spanclass="math inline">\(y_+\)</span></p></li><li><p>Solution</p><ul><li><p>根据前面得到的最优先验 <span class="math inline">\(w^*\)</span>来估计 <span class="math inline">\(y=[y_-,y_+]\)</span> 的分布 <spanclass="math display">\[q_{\mathbf{y}}^{*}(\mathbf{y})=\sum_{x} w^{*}(x)p_{\mathbf{y}}(\mathbf{y} ; x)\]</span></p></li><li><p>然后可以获得后验概率 <span class="math display">\[\begin{aligned} q_{\mathrm{y}+| \mathrm{y}_{-}}^{*}\left(\cdot |y_{-}\right) &amp; \triangleq \frac{q_{\mathrm{y}}^{*}\left(y_{+},y_{-}\right)}{q_{\mathrm{y}-}^{*}\left(y_{-}\right)}=\frac{\sum_{x}w^{*}(x) p_{\mathrm{y}}\left(y_{+}, y_{-} ; x\right)}{\sum_{a} w^{*}(a)p_{\mathrm{y}_{-}}\left(y_{-} ; a\right)} \\&amp;=\sum_{x} w^{*}\left(x | y_{-}\right) p_{\mathrm{y}_{+} |y_{-}}\left(y_{+} | y_{-} ; x\right) \end{aligned}\]</span></p></li><li><p>相当于是做了 soft decision，因为 ML 估计中只会取 <spanclass="math inline">\(p_{\mathrm{y}_{+} | y_{-}}(\cdot|y_-;\hat{x}_{ML})\)</span></p></li></ul></li></ul><h2 id="maximum-entropy-distribution">4. Maximum entropydistribution</h2><ul><li>最大熵等价于<strong>均匀分布</strong>向对应的模型集合上的<strong>I-projection</strong> <span class="math display">\[D(p \| U)=\sum_{y} p(y) \log p(y)+\log |\mathcal{Y}|=\log|\mathcal{Y}|-H(p) \\p^{*}=\underset{p \in \mathcal{L}_{\mathrm{t}}}{\arg \max }H(p)=\underset{p \in \mathcal{L}_{\mathrm{t}}}{\arg \min } D(p \| U)\]</span></li></ul>]]></content>
    
    
    <categories>
      
      <category>统计推断</category>
      
    </categories>
    
    
    <tags>
      
      <tag>熵</tag>
      
      <tag>信息容量</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>统计推断(五)  EM algorithm</title>
    <link href="/2020/02/03/statistic/SI_Ch5_EMAlgorithm/"/>
    <url>/2020/02/03/statistic/SI_Ch5_EMAlgorithm/</url>
    
    <content type="html"><![CDATA[<p>EM 算法</p><span id="more"></span><h2 id="em-ml-algorithm">1. EM-ML algorithm</h2><ul><li>formulation<ul><li>complete data : <spanclass="math inline">\(\mathsf{z=[y,w]}\)</span></li><li>observation : <spanclass="math inline">\(\boldsymbol{y}\)</span></li><li>hidden variable : <spanclass="math inline">\(\boldsymbol{w}\)</span></li><li>estimation : <span class="math inline">\(\mathcal{x}\)</span></li></ul></li><li>Derivation</li></ul><blockquote><p>期望获得 ML 估计，但是实际中 <spanclass="math inline">\(p(y;x)\)</span> 可能很难计算(比如 mixture gaussianmodel，相乘后再求和) <span class="math display">\[\hat{x}_{ML}(y)=\arg\max_x \ln p(y;x) \\\]</span> 引入 complete data <spanclass="math inline">\(\mathsf{z=[y,w]}\)</span>，令 <spanclass="math inline">\(y=g(z)\)</span> <span class="math display">\[p(z;x)=\sum_y p(z|y;x)p(y;x)=p(z|g(z);x)p(g(z);x) \\\hat{x}_{ML}(y) = \arg\max_x \ln p(z;x) - \ln p(z|y;x)\]</span> 由于 <span class="math inline">\(\hat{x}_{ML}(y)\)</span> 与 z无关，因此右边可以对 <span class="math inline">\(p(z|y;x&#39;)\)</span>求期望 <span class="math display">\[\begin{align}\ln p(y;x) &amp;= \ln p(z;x) - \ln p(z|y;x) \\&amp;= \mathbb{E}[\ln p(z;x)|\mathsf{y}=y;x&#39;] - \mathbb{E}[\lnp(z|y;x)|\mathsf{y}=y;x&#39;] \\&amp;= U(x,x&#39;) + V(x,x&#39;)\end{align}\]</span> 其中 <span class="math inline">\(V(x,x&#39;)\)</span> 根据Gibbs 不等式可以知道恒有 <span class="math inline">\(V(x,x&#39;) \geV(x&#39;,x&#39;)\)</span></p><p>因此要使 <span class="math inline">\(\ln p(y;x)\)</span>最大，只需要使 <span class="math inline">\(U(x,x&#39;)\)</span>最大(可以放松要求，只要每次<spanclass="math inline">\(U(x,x&#39;)\)</span>增大就可以了，这就是<strong>GeneralizedEM</strong>)</p><p><strong>E-step</strong>: compute <spanclass="math inline">\(U(x,\hat{x}^{n-1})=\mathbb{E}[\lnp_\mathsf{z}(z;x)|\mathsf{y}=y;\hat{x}^{n-1}]\)</span></p><p><strong>M-step</strong>: maximize <spanclass="math inline">\(\hat{x}^n = \arg\max_xU(x,\hat{x}|^{n-1})\)</span></p></blockquote><h3 id="em-map-推导待完成"><strong>EM-MAP 推导</strong>：待完成！</h3><h2 id="em-for-linear-exponential-family">2. EM for linear exponentialfamily</h2><ul><li>derivation</li></ul><blockquote><p>指数分布 <span class="math display">\[p(z;x)=\exp\left(x^Tt(z)-\alpha(x)+\beta(z)\right) \\U(x,x^n) = \mathbb{E}[\ln p(z;x)|y;x^n] \\\]</span> EM 算法迭代过程中每次要找 <spanclass="math inline">\(U(x,x&#39;)\)</span> 的最大值点，因此有 <spanclass="math display">\[\frac{\partial}{\partial x}U(x,\hat{x}^n) \Big|_{x=\hat{x}^{n+1}} =\mathbb{E}[t(z)|y;\hat{x}^n] - \mathbb{E}[\dot{\alpha}(x)|y;\hat{x}^n]=\mathbb{E}[t(z)|y;\hat{x}^n] -  \dot{\alpha}(x)|_{x=\hat{x}^{n+1}}=0\]</span> 同时由于 linear exponential family 本身的性质，有 <spanclass="math display">\[\mathbb{E}[t(z);\hat{x}^{n+1}] = \dot{\alpha}(x)|_{x=\hat{x}^{n+1}}\]</span> 因此实际上每一步迭代过程中都满足 <span class="math display">\[\mathbb{E}[t(z);\hat{x}^{n+1}] = \mathbb{E}[t(z)|y;\hat{x}^n]\]</span> 最终收敛于不动点 <span class="math display">\[\mathbb{E}[t(z);\hat{x}^{*}] = \mathbb{E}[t(z)|y;\hat{x}^*]\]</span> 此时有 <span class="math display">\[\frac{\partial \ln p(y;x)}{\partial x} = ... =\mathbb{E}[t(z)|y;\hat{x}^*]-\mathbb{E}[t(z);\hat{x}^*] = 0\]</span></p></blockquote><h2 id="empirical-ditribution">3. Empirical ditribution</h2><ul><li>observation: <spanclass="math inline">\(\boldsymbol{y}=[y_1,...,y_N]^T\)</span></li><li>empirical ditribution: <spanclass="math inline">\(\hat{p}_\mathsf{y}(b;\boldsymbol{y}) =\frac{1}{N}\sum_n \mathbb{I}_b(y_n)\)</span></li></ul><blockquote><p><strong>Porperties 1</strong>: <spanclass="math inline">\(\frac{1}{N}\sum_n f(y_n)=\sum_yf(y)\hat{p}_\mathsf{y}(y;\boldsymbol{y})\)</span></p><p><strong>Properties 2</strong>: Let the set of models be <spanclass="math inline">\(\mathcal{P}=\{p_y(\cdot;x),x\in\mathcal{X}\}\)</span>, then the <strong>ML</strong> can be written as<span class="math display">\[\hat{x}_{ML}(y)=\arg\min_{p\in\mathcal{P}}D(\hat{p}_y(\cdot;y) || p) =\arg\min_{x\in\mathcal{X}}D(\hat{p}_y(\cdot;y) || p(\cdot;x))\]</span> which is the <strong>reverse I-projection</strong></p><p><strong>Remark</strong>：</p><ol type="1"><li>这个性质表明<strong>最大似然</strong>实际上是在找与<strong>经验分布</strong>最接近(相似)的分布对应的参数</li><li><strong>给定经验分布(观察)后，实际上就相当于给定了一个线性族(想一下对应的<span class="math inline">\(t_k(y)\)</span>的如何表示，提示：用元素为1或0的矩阵)</strong>，这个在此处适用，在后面对<span class="math inline">\(p_z\)</span> 的约束也适用</li><li>求 <strong>ML</strong> 就是在求<strong>逆投影(reverseI-proj)</strong>，这对后面理解 EM 算法的 alernating projcetions有用</li></ol></blockquote><h2 id="em-ml-alternating-projections">4. EM-ML Alternatingprojections</h2><blockquote><p>根据 #3 中的性质2可以获得 ML 的表达式，但是该式子过于复杂，考虑</p><p><strong>DPI</strong>(Data processing inequality): <spanclass="math inline">\(y=g(z)\)</span> <span class="math display">\[D(p(z)||q(z)) \ge D(p(y)||q(y)) \\&quot;=&quot; \iff \frac{p_z(z)}{q_z(z)} = \frac{p_y(g(z))}{q_y(g(z))}\\ \ \ \forall z\]</span> 因此根据(12)式要想最小化 <spanclass="math inline">\(D(\hat{p}_y(\cdot;\boldsymbol{y}) ||p(y;x))\)</span> 可以考虑最小化 <spanclass="math inline">\(D(\hat{p}_z(\cdot;\boldsymbol{z}) ||p(z;x))\)</span></p><p>因为 <span class="math inline">\(p(y;x)\)</span>的表达式很可能很复杂，但是 <span class="math inline">\(p(z;x)\)</span>可以简化很多</p><p><strong>即最大似然转化为<em>最小化</em></strong> <spanclass="math display">\[\min D(\hat{p}_z(\cdot;z) || p(\cdot;x))\]</span></p><p><span class="math display">\[\mathcal{P^Z}(y) \triangleq \left\{ \hat{p}_Z(\cdot): \sum_{g(c)=y}\hat{p}_z(c) = \hat{p}_y(b;\boldsymbol{y})\ \ \ \forall b\in \mathcal{y}\right\} \\\]</span></p><blockquote><p><strong>Remarks</strong>：这里最小化过程中对两个分布都要考虑：</p><ol type="1"><li>由于 <span class="math inline">\(\hat{p}_z\)</span>实际上在一定约束下(<strong>线性分布族</strong>，参考 #3 中的 reverseI-proj)可以任取，因此要优化 <spanclass="math inline">\(\hat{p}_z\)</span> 使散度最小；</li><li>由于 <span class="math inline">\(p(\cdot;x)\)</span>实际上就是我们要求的东西(我们要找到一个 x 使观测值 y的似然最大)，因此也要优化 <spanclass="math inline">\(p(\cdot;x)\)</span> 使散度最小；</li></ol><figure><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2019/EM-ML.jpg"alt="EM-ML" /><figcaption aria-hidden="true">EM-ML</figcaption></figure></blockquote><p>要想最小化 (14) 式，可以分解为 2 步：</p><ol type="1"><li><p>第一步(<strong>I-projection</strong>) <spanclass="math display">\[  \hat{p}_{z}^{*}(\cdot ; \hat{x}^{(n-1)})=\underset{\hat{p}_{z} \in\hat{\mathcal{P^Z}}(\mathbf{y})}{\arg \min } D\left(\hat{p}_{z}(\cdot)\| p_{z}(\cdot ; \hat{x}^{(n-1)})\right)\]</span></p></li><li><p>第二步(<strong>reverse I-projection</strong>) <spanclass="math display">\[  \hat{x}_{ML}^{(n)} = \underset{x}{\arg \min }D\left(\hat{p}_{z}^{*}\left(\cdot ; \hat{x}^{(n-1)}\right) \|p_{z}(\cdot ; x)\right)\]</span></p></li></ol><p>这实际上就是 EM-ML 算法，证明如下：</p><p>上面两步分别对应 EM 中的 E-step 和 M-step</p><p>E-step： <span class="math display">\[\begin{align}\frac{1}{N}U(x,\hat{x}^{(n-1)}) &amp;= \frac{1}{N}\mathbb{E}\left[\lnp(\boldsymbol{z};x)|\boldsymbol{y};\hat{x}^{(n-1)}\right] \\&amp;= \frac{1}{N}\sum_n \mathbb{E}\left[\lnp(z_n;x)|\boldsymbol{y};\hat{x}^{(n-1)}\right] \\&amp;= \frac{1}{N}\sum_n \sum_z \ln p(z;x)p\left(z|y_n;\hat{x}^{(n-1)}\right) \\&amp;= \sum_y \hat{p}_y(y;\boldsymbol{y}) \sum_zp\left(z|y;\hat{x}^{(n-1)}\right)\ln p(z;x) \\&amp;= \sum_y \hat{p}_y(y;\boldsymbol{y}) \sum_z\frac{\hat{p}^*(z;\hat{x}^{(n-1)})}{\hat{p}_y(g(z);\boldsymbol{y})} \lnp_z(z;x) \\&amp;= \sum_z \hat{p}^*(z;\hat{x}^{(n-1)}) \ln p_z(z;x) \\&amp;= -D\left(\hat{p}^*(z;\hat{x}^{(n-1)})||p(z;x)\right) -H\left(\hat{p}_Z^*(z;\hat{x}^{(n-1)})\right)\end{align}\]</span> M-step：</p><p><strong>Remarks</strong>:</p><ol type="1"><li>EM-ML 即在第二步中采用 ML 来估计 x，由于 ML 本身即与 reverseI-projection 等价，因此整体就是不断地在相互投影；</li><li>如果是 EM-MAP 就只需要将 M-step 中的 ML 估计换成 MAP 估计，但是由于MAP 估计当中先验对于整个分布族会产生一个加权，计算复杂且没有闭式解</li></ol><figure><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2019/EM-MAP.jpg"alt="EM-MAP" /><figcaption aria-hidden="true">EM-MAP</figcaption></figure></blockquote><h2 id="remarks">5. Remarks</h2><blockquote><p>EM算法实质上可以看作一个<strong>升维</strong>的处理过。这是指将低维空间中的<span class="math inline">\(\mathcal{Y}\)</span> 映射到高维空间 <spanclass="math inline">\(\mathcal{Z}\)</span> 中</p><ol type="1"><li>根据 <span class="math inline">\(y\)</span> 的 empiricaldistribution，在 <span class="math inline">\(\mathcal{P^Z}\)</span>中同样得到一个约束 <span class="math inline">\(z\)</span> 的线性族</li><li>由预先定义的模型 <span class="math inline">\(p(z|\theta)\)</span>再指定另一个 <span class="math inline">\(\mathcal{P^Z}\)</span>中的集合，比如线性指数族</li></ol><p>最终的目标是在 <span class="math inline">\(\mathcal{P^Z}\)</span>空间中获得一个最大似然估计，即 <spanclass="math inline">\(\hat{\theta}_{ML} = \arg\min D(\hat{p}_z ||p(z,\theta))\)</span>。 因此整个 EM 算法就是重复下面的过程</p><figure><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2019/EM-proj.jpg"alt="EM-proj" /><figcaption aria-hidden="true">EM-proj</figcaption></figure></blockquote>]]></content>
    
    
    <categories>
      
      <category>统计推断</category>
      
    </categories>
    
    
    <tags>
      
      <tag>参数估计</tag>
      
      <tag>EM算法</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>统计推断(四) Information Geometry</title>
    <link href="/2020/02/03/statistic/SI_Ch4_InformationGeometry/"/>
    <url>/2020/02/03/statistic/SI_Ch4_InformationGeometry/</url>
    
    <content type="html"><![CDATA[<p>信息几何</p><span id="more"></span><h2 id="generalized-bayesian-decision">1. Generalized Bayesiandecision</h2><ul><li><p>Formulation</p><ul><li>Soft decision: <spanclass="math inline">\(q_x(\cdot|y)\)</span></li><li>Cost function: <span class="math inline">\(C(x,q_x)\)</span></li></ul></li><li><p>Cost function</p><ul><li><strong>proper</strong>: <spanclass="math inline">\(p_{x|y}(\cdot|y)=\arg\min\limits_{\{q_x\ge0:\sum_aq(a)=1\}} E[C(x,q_x(\cdot))|\mathsf{y}=y]\)</span></li><li><strong>local</strong>: <spanclass="math inline">\(C(x,q_x)=\phi(x,q_x(x))\)</span></li></ul></li><li><p>Log-loss criterion: <span class="math inline">\(C(x,q)=-A\logq_x(x) + B(x), \ \ \ A&gt;0\)</span></p><ul><li><em>proper</em> and <em>local</em></li></ul><blockquote><p><strong>Theorem</strong>: When the alphabet <spanclass="math inline">\(\mathcal{X}\)</span> consists of at least 3 values(<span class="math inline">\(|\mathcal{X}| \triangleq L ≥ 3\)</span>),then the log-loss is the <strong>only</strong> smooth local, proper costfunction.</p><p><strong>Proof</strong>: Let <span class="math inline">\(q_{l}\triangleq q_{\times}\left(x_{l}\right), p_{l} \triangleq p_{x |y}\left(x_{l} | y\right), \phi_{l}(\cdot) \triangleq \phi\left(x_{l},\cdot\right)\)</span></p><ul><li><p><span class="math display">\[proper \Longrightarrow p_{1}, \ldots, p_{L}=\underset{\left\{q_{1},\ldots, q_{L} \geq 0: \sum_{l=1}^{L} q_{l}=1\right\}} {\arg\min}\sum_{l=1}^{L} p_{l} \phi_{l}\left(q_{l}\right)\]</span></p></li><li><p><span class="math display">\[拉格朗日乘子法 \Longrightarrowp_{1}, \ldots, p_{L}=\underset{q_{1}, \ldots, q_{L}}{\arg \min }\varphi, \quad \text { with } \varphi=\sum_{l=1}^{L} p_{l}\phi_{l}\left(q_{l}\right)+\lambda\left(p_{1}, \ldots,p_{L}\right)\left[\sum_{l=1}^{L} q_{l}-1\right]\]</span></p></li><li><p><span class="math display">\[proper \Longrightarrow \left.\frac{\partial \varphi}{\partialq_{k}}\right|_{q=p_{l}, l=1, \ldots, L}=p_{k}\dot{\phi}_{k}\left(p_{k}\right)+\lambda\left(p_{1}, \ldots,p_{L}\right)=0, \quad k=1, \ldots, L\]</span></p></li><li><p>由 locality 可推出 <span class="math inline">\(\lambda\)</span>为常数，<span class="math inline">\(\phi_k(q)=-\lambda \ln q + c_k, \ \\ k=1,...,L\)</span></p></li></ul></blockquote></li><li><p>Gibbs inequality <span class="math display">\[if \ \ \ x\sim p_x(\cdot),\ \ \  \forall q(\cdot) \\we\ \ have \ \ E_x[\log p(x)] \ge E[\log q(x)] \\\sum_x p(x)\log p(x) \ge \sum_x p(x)\log q(x) \\&quot;=&quot; \iff p(x)=q(x)\]</span></p></li></ul><h2 id="discrete-information-theory">2. Discrete information theory</h2><ul><li><p><strong>Entropy</strong>: <spanclass="math inline">\(H(\mathrm{x}) \triangleq \min _{q_{\mathrm{x}}}\mathbb{E}\left[C\left(\mathrm{x},q_{\mathrm{x}}\right)\right]\)</span></p></li><li><p><strong>Conditional entropy</strong>: <spanclass="math inline">\(H(\mathrm{x} | \mathrm{y}) \triangleq \sum_{y}p_{\mathrm{y}}(y) H(\mathrm{x} | \mathrm{y}=y)\)</span> <spanclass="math inline">\(H(x | y=y) \triangleq \min _{q_{x}}\mathbb{E}\left[C\left(x, q_{x}\right) | y=y\right]\)</span></p></li><li><p><strong>Mutual information</strong>: <spanclass="math inline">\(I(\mathrm{x} ; \mathrm{y}) \triangleqH(\mathrm{x})-H(\mathrm{x} | \mathrm{y}) =H(x)+H(y)-H(xy)\)</span></p></li><li><p><strong>Conditional mutual information</strong>: <spanclass="math inline">\(I(\mathrm{x} ; \mathrm{y} | \mathrm{z}) \triangleqH(\mathrm{x} | \mathrm{z})-H(\mathrm{x} | \mathrm{y},\mathrm{z})\)</span></p></li><li><p>Chain rule: <span class="math inline">\(I(x ; y, z)=I(x ; z)+I(x; y | z)\)</span></p></li><li><figure><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2019/venn.jpg"alt="venn" /><figcaption aria-hidden="true">venn</figcaption></figure></li><li><p><strong>Information divergence</strong>(KL distance)</p><ul><li>Definition</li></ul><p><span class="math display">\[\begin{aligned} D\left(p_{\times} \| q_{\mathbf{x}}\right) &amp;\triangleq \mathbb{E}_{p_{\mathbf{x}}}\left[-\logq_{\mathbf{x}}(\mathbf{x})\right]-\mathbb{E}_{p_{\mathbf{x}}}\left[-\logp_{\mathbf{x}}(\mathbf{x})\right] \\ &amp;=\sum_{a} p_{\mathbf{x}}(a)\log \frac{p_{\mathbf{x}}(a)}{q_{\mathbf{x}}(a)} \end{aligned}\]</span></p><ul><li><p>Properties</p><ul><li><p><span class="math inline">\(\ge 0\)</span>（<em>只有 p=q的时候才能取 = 吗？</em>）</p></li><li><p><span class="math inline">\(I(x;y) = D(p_{x,y}||p_xp_y)\)</span></p></li><li><p><span class="math display">\[\lim _{\delta \rightarrow 0} \frac{D\left(p_{y}(\cdot ; x) \|p_{y}(\cdot ; x+\delta)\right)}{\delta^{2}}=\frac{1}{2} J_{y}(x)​\]</span></p></li></ul></li></ul></li><li><p>Data processing inequality (<strong>DPI</strong>)</p></li></ul><blockquote><p><strong>Theorem</strong>: if <span class="math inline">\(x\leftrightarrow y \leftrightarrow t\)</span> is a<strong>Markov</strong> chain, then <span class="math display">\[I(x;y) \ge I(x;t)\]</span> with "=" <span class="math inline">\(\iff\)</span> <spanclass="math inline">\(x \leftrightarrow t \leftrightarrow y\)</span> isa Markov chain</p><p><strong>Corollary</strong>: deterministic <spanclass="math inline">\(g(\cdot)\)</span>, <spanclass="math inline">\(I(x;y) \ge I(x;g(y))\)</span></p><p><strong>Corollary</strong>: t=t(y) is <strong>sufficient</strong><span class="math inline">\(\iff I(x;y)=I(x;t)\)</span></p><p><strong>Proof</strong>: 应用互信息链式法则</p><p><strong>Remark</strong>: 证明不等式的时候注意取等号的条件 <spanclass="math inline">\(I(x;y|t)=0\)</span></p><hr /><p><strong>Theorem</strong>: 若 <spanclass="math inline">\(q_{\mathrm{x}^{\prime}}(b)=\sum_{a \in\mathcal{X}} W(b | a) p_{\mathrm{x}}(a), \quadq_{\mathrm{y}^{\prime}}(b)=\sum_{a \in \mathcal{X}} W(b | a)p_{\mathrm{y}}(a)\)</span> 那么对任意 <spanclass="math inline">\(W(\cdot|\cdot)\)</span> 有 <spanclass="math inline">\(D(q_{x&#39;}||q_{y&#39;}) \leD(p_x||p_y)\)</span></p><p><strong>Proof</strong>: 待完成 ...</p><p><strong>Theorem</strong>: 对确定性函数 <spanclass="math inline">\(\phi(\cdot)\)</span>，<spanclass="math inline">\(\mathsf{w}=\phi(\mathsf{z})\)</span>，有 <spanclass="math inline">\(J_{\mathsf{w}}(x)=J_{\mathsf{z}}(x)\)</span></p><p><strong>Proof</strong>: 待完成 ...</p></blockquote><h2 id="information-geometry">3. Information geometry</h2><ul><li><p>Probability simplex</p><ul><li>若字符集有 M 个字符，则概率单形为 <strong>M-1维</strong>的超平面，且只位于第一象限</li></ul><figure><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2019/probability_simplex.jpg"alt="probability_simplex" /><figcaption aria-hidden="true">probability_simplex</figcaption></figure></li><li><p>Boundary</p><ul><li>根据 p,q 是否位于边界(即存在 <spanclass="math inline">\(p(y&#39;)=0\)</span>) 可决定 <spanclass="math inline">\(D(p||q)&lt;\infty\)</span> 还是 <spanclass="math inline">\(D(p||q)=\infty\)</span></li></ul></li><li><p>Local information geometry</p><blockquote><p>取 <span class="math inline">\(p_0 \in\text{int}(\mathcal{P^Y})\)</span>，对任意分布(向量) <spanclass="math inline">\(p\)</span> 定义其归一化表示 <spanclass="math display">\[\phi(y)=\frac{p(y)-p_0(y)}{\sqrt{2p_0(y)}}\]</span> <span class="math inline">\(p_0\)</span> 的邻域被定义为一个球<span class="math display">\[\{p: |\phi_p(y)|\le B, \ \ \forall y \}\]</span> 那么对小邻域内的两个分布 <spanclass="math inline">\(p_1,p_2\)</span> 有 <span class="math display">\[D(p_1 || p_2) = \sum_y |\phi_1(y)-\phi_2(y)|^2(1+o(1)) \approx||\phi_1-\phi_2||^2\]</span> 证明：代入散度公式，应用泰勒级数展开化简。其中需要注意到 <spanclass="math display">\[\sum_y \sqrt{2p_0(y)}\phi(y)=\sum_y p(y)-p_0(y) = 0\]</span></p><p><strong>Remark</strong>：直观理解就是小邻域内散度近似为欧氏距离</p></blockquote></li></ul><h2 id="information-projection">4. Information projection</h2><ul><li>Definition: q 向<strong>闭集</strong> <spanclass="math inline">\(\mathcal{P}\)</span> 内的投影 <spanclass="math inline">\(p*=\arg\min_{p\in\mathcal{P}}D(p||q)\)</span><ul><li>存在性：由于 <span class="math inline">\(D(p||q)\)</span> 非负且对 p连续，而 <span class="math inline">\(\mathcal{P}\)</span>非空且为闭集，因此一定存在</li><li>唯一性：不一定唯一，但如果 <spanclass="math inline">\(\mathcal{P}\)</span> 为<strong>凸集</strong>，则p* 唯一</li></ul></li><li>Pythagoras’ Theorem</li></ul><blockquote><p><strong>Theorem(Pythagoras’ Theorem)</strong>: p* 是 q向非空<strong>闭凸集</strong> <spanclass="math inline">\(\mathcal{P}\)</span> 上的投影，那么任意 <spanclass="math inline">\(p\in\mathcal{P}\)</span> 有 <spanclass="math display">\[D(p||q) \ge D(p||p^*) + D(p^*||q)\]</span> <strong>Proof</strong>: 取 <spanclass="math inline">\(p_{\lambda}=\lambda p + (1-\lambda)p^* \in\mathcal{P}\)</span></p><p>由投影定义可知 <span class="math inline">\(\frac{\partial}{\partial\lambda} D(p_\lambda||q) \Big|_{\lambda=0} \ge 0\)</span></p><p>代入化简可得证</p><p><strong>Remark</strong>:直观理解就是不可能通过多次中间投影，使整体的<strong>KL距离</strong>(散度)减小</p><hr /><p><strong>Corollary</strong>: 如果 q 不在 <spanclass="math inline">\(\mathcal{P^y}\)</span>的边界上，那么其在<strong>线性分布族</strong> <spanclass="math inline">\(\mathcal{P}\)</span> 上的投影 <spanclass="math inline">\(p^*\)</span> 也不可能在 <spanclass="math inline">\(\mathcal{P^y}\)</span> 的边界上，除非 <spanclass="math inline">\(\mathcal{P}\)</span>中的所有元素都在某个边界上</p><p><strong>Proof</strong>: 应用散度的 Boundary、毕达哥拉斯定理</p></blockquote><ul><li><p><strong>Linear families</strong></p><ul><li><p>Definition: <span class="math inline">\(\mathcal{L}\)</span>是一个线性分布族，如果对于一组映射函数 <spanclass="math inline">\(t(\cdot)=[t_1(), ..., t_K()]^T\)</span>和对应的常数 <span class="math inline">\(\bar t = [\bar t_1, ..., \bart_K]^T\)</span>，有 <spanclass="math inline">\(\mathbb{E}_{p}\left[t_{i}(\mathrm{y})\right]=\bar{t}_{i},\quad i=1, \ldots, K \quad\)</span> for all <spanclass="math inline">\(p \in \mathcal{L}\)</span> <spanclass="math display">\[\underbrace{\left[\begin{array}{ccc}{t_{1}(1)-\bar{t}_{1}} &amp;{\cdots} &amp; {t_{1}(M)-\bar{t}_{1}} \\ {\vdots} &amp; {\ddots} &amp;{\vdots} \\ {t_{K}(1)-\bar{t}_{K}} &amp; {\cdots} &amp;{t_{K}(M)-\bar{t}_{K}}\end{array}\right]}_{\triangleq\mathbf{T}}\left[\begin{array}{c}{p(1)} \\ {\vdots} \\{p(M)}\end{array}\right]=\mathbf{0}\]</span></p></li><li><p>性质</p><ul><li><span class="math inline">\(\mathcal{L}\)</span> 的维度为M-rank(T)-1</li><li><span class="math inline">\(\mathcal{L}\)</span>是一个闭集、凸集</li><li><span class="math inline">\(p_1,p_2 \in \mathcal{L}\)</span>，那么<span class="math inline">\(p=\lambda p_{1}+(1-\lambda) p_{2} \in\mathcal{P}^{\mathcal{Y}}, \ \ \lambda\in R\)</span>，注意 <spanclass="math inline">\(\lambda\)</span> 可以取 [0,1] 之外的数</li></ul><blockquote><p><strong>Theorem(Pythagoras’ Identity)</strong>: q 向线性分布族 <spanclass="math inline">\(\mathcal{L}\)</span> 的投影 <spanclass="math inline">\(p^*\)</span> 满足以下性质 <spanclass="math display">\[D(p \| q)=D\left(p \| p^{*}\right)+D\left(p^{*} \| q\right), \quad \text{ for all } p \in \mathcal{L}\]</span> <strong>Proof</strong>: 类似前面不等式的证明，只不过现在由于<span class="math inline">\(\lambda\in R\)</span>所以不等号变成了等号</p></blockquote><blockquote><p><strong>Theorem(Orthogonal families)</strong>: <spanclass="math inline">\(p*\in\mathcal{P^Y}\)</span>为任一分布，则向线性分布族 <spanclass="math inline">\(\mathcal{L_t}(p^*)\)</span> 的投影为 <spanclass="math inline">\(p^*\)</span> 的所有分布都属于一个指数分布 <spanclass="math inline">\(\mathcal{\varepsilon}_t(p^*)\)</span> $$_{}(p^{<em>}) {p ^{}: <em>{p}[()]= </em>{p^{</em>}}[()]} \</p><span class="math display">\[\begin{aligned}\mathcal{E}_{\mathbf{t}}\left(p^{*}\right) \triangleq\left\{q \in\mathcal{P}^{\mathcal{Y}}: q(y)=p^{*}(y) \exp\left\{\mathbf{x}^{\mathrm{T}}\mathbf{t}(y)-\alpha(\mathbf{x})\right\}\right.\\ \text { for all}\left.y \in \mathcal{Y}, \text { some } \mathbf{x} \in\mathbb{R}^{K}\right\} \end{aligned}\]</span><p>$$ 其中需要注意的是 <spanclass="math inline">\(\mathcal{L}_{\mathbf{t}}\left(p^{*}\right),\mathcal{E}_{\mathbf{t}}\left(p^{*}\right)\)</span>的表达形式并不唯一，括号内的 <span class="math inline">\(p^*\)</span>均可以替换为对应集合内的任意一个其他分布，他们表示的是同一个集合</p><figure><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2019/exp_projection_linear.jpg"alt="exp_projection_linear" /><figcaption aria-hidden="true">exp_projection_linear</figcaption></figure><p><strong>Remarks</strong>：</p><ol type="1"><li>根据上面的定理，可以由 <span class="math inline">\(t(\cdot), \bart\)</span> 求出 q 向线性分布族的投影 p*</li><li>在小邻域范围内，可以发现 <spanclass="math inline">\(\mathcal{L}_{\mathbf{t}}\left(p^{*}\right),\mathcal{E}_{\mathbf{t}}\left(p^{*}\right)\)</span>的正规化表示 <span class="math inline">\(\phi_\mathcal{L}^T\phi_\mathcal{E}=0\)</span>，即二者是正交的</li></ol></blockquote></li></ul></li></ul>]]></content>
    
    
    <categories>
      
      <category>统计推断</category>
      
    </categories>
    
    
    <tags>
      
      <tag>信息几何</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>统计推断(三) Exponential Family</title>
    <link href="/2020/02/03/statistic/SI_Ch3_ExponentialFamily/"/>
    <url>/2020/02/03/statistic/SI_Ch3_ExponentialFamily/</url>
    
    <content type="html"><![CDATA[<p>指数族</p><span id="more"></span><h2 id="exponential-family">1. Exponential family</h2><ul><li><p>Definition</p><ul><li>PDF: <span class="math inline">\(p(y;x)=\exp(\lambda(x)^Tt(y)-\alpha(x)+\beta(y))\)</span> <span class="math inline">\(y\sim\varepsilon(x;\lambda(\cdot),t(\cdot),\beta(\cdot))\)</span></li><li>nature statistic: <span class="math inline">\(t(y)\)</span></li><li>nature parameter: <spanclass="math inline">\(\lambda(x)\)</span></li><li>log-partition function: <spanclass="math inline">\(\alpha(x)\)</span></li><li>partition function: <spanclass="math inline">\(Z(x)=\exp(\alpha(x))\)</span></li><li>distribution: <spanclass="math inline">\(\exp(\beta(y))\)</span></li></ul></li><li><p><strong>正则条件(regular)</strong>：若分布族中的任意一个分布<span class="math inline">\(p(y;x)\)</span> 都有其支集(support)与 x无关，则为正则</p><ul><li>实质上是要求 CRB 正则条件中<strong>求导和积分可换序</strong> <spanclass="math display">\[\mathbb{E}\left[\frac{\partial}{\partial x}\lnp(y;x)\right]=\int\frac{\partial}{\partial x}p(y;x)dy =\frac{\partial}{\partial x}\int_a^b p(y;x)dy = 0\]</span></li></ul></li><li><p>指数分布族可以有多种获得方式</p><ul><li><p>很多分布本身可以写成指数分布族形式</p><ul><li>Bernulli distribution: <span class="math inline">\(y\sim\mathcal{B}(x)\)</span></li></ul><p><span class="math display">\[p(y;x)=x^y (1-x)^{(1-y)} \\\ln p(y;x)=\left(\ln(\frac{x}{1-x})\right)y-(-\ln(1-x))\]</span></p><ul><li>Gaussian <span class="math inline">\(y=[y_1,y_2]^T\sim\mathcal{N}(x,1)\)</span> <span class="math display">\[p(y;x)=\frac{1}{\sqrt{2\pi}}\exp\left((y_1+y_2)x-x^2-\frac{y_1^2+y_2^2}{2}\right)\]</span></li></ul></li><li><p>多个分布的<strong>几何均值</strong> <span class="math display">\[p(y;x)=\frac{p_1^x(y)*p_2^{(1-x)}(y)}{Z(x)} \\\ln p(y;x)=x\ln\left(\frac{p_1(y)}{p_2(y)}\right)-\ln Z(x)+\ln p_2(y)\]</span></p><ul><li>例如 <span class="math inline">\(p_1(y)\sim\mathcal{B}(\frac{1}{1+e^{-1}}), p_2(y)\sim \mathcal{B}(1/2)\)</span><span class="math display">\[p(y;x)=(\frac{1}{1+e^{-1}})^{xy}(\frac{e^{-1}}{1+e^{-1}})^{x(1-y)}(1/2)^{(1-x)}\sim\mathcal{B}(\frac{1}{1+e^{-x}}) \\\frac{p(y=1;x)}{p(y=0;x)}=e^x\]</span></li></ul></li><li><p><strong>Tilting</strong> <span class="math display">\[p(y;x)=\frac{p(y)e^{xy}}{Z(x)} \\\ln p(y;x)=xy - \ln Z(x) + \ln p(y)\]</span></p><ul><li>例如 <span class="math inline">\(p(y)\sim\mathcal{N}(0,1)\)</span>，<span class="math inline">\(p(y;x)\sim\mathcal{N}(x,1)\)</span></li></ul></li></ul></li><li><p><strong>linear exponential family</strong></p><ul><li>定义：<span class="math inline">\(t(x)=x\)</span>，<spanclass="math inline">\(\ln p(y;x)=x\ t(y) -\alpha(x)+\beta(y)\)</span></li><li>性质：<span class="math inline">\(\dot{\alpha}(x)=\mathbb{E}[t(y)],\ \\dot{\dot{\alpha}}(x)=\mathbb{E}[t^2(y)]-\mathbb{E}[t(y)]^2=Var(t(y)) =J_y(x)\)</span></li></ul><blockquote><p><strong>Proof</strong>： <span class="math display">\[\begin{align}Z(x) &amp;= e^{\alpha(x)}=\int e^{x t(y)+\beta(y)}dy \\\frac{\partial}{\partial x}Z(x) &amp;= e^{\alpha(x)}\cdot \dot\alpha(x)= \int t(y)e^{xt(y)+\beta(y)}dy \\\dot{\alpha}(x) &amp;= \int t(y)p(y;x)dy = \mathbb{E}[t(y)]\end{align}\]</span></p><p><span class="math display">\[\dot{\dot{\alpha}}(x)=\int t(y)\cdot p(y;x)\cdot(t(y)-\dot{\alpha}(x))dy \\J_y(x) = \mathbb{E}\left[-\frac{\partial^2}{\partial x^2} \lnp(y;x)\right]=\dot{\dot{\alpha}}(x)\]</span></p></blockquote></li><li><p>指数族分布与有效统计量(efficient statistics)</p><ul><li><strong>必要条件</strong>：若有效统计量存在，则可以写成指数族分布形式，且有<span class="math display">\[t(x)=\int^x J_y(u)du, \ \ \ \alpha(x)=\int^x u J_y(u) du\]</span></li></ul><blockquote><p><strong>Proof</strong>： <span class="math display">\[\begin{align}\hat {x}_{eff}(y) &amp;= x+\frac{1}{J_y(x)}\frac{\partial}{\partialx}\ln p(y;x) \\\frac{\partial}{\partial x}\ln p(y;x) &amp;= J_y(x)\hat{x}_{eff}(y) - xJ_y(x) \\\ln p(y;x) &amp;= \int^x J_y(u)du \cdot \hat{x}_{ML}(y) - \int^x uJ_y(u) du\end{align}\]</span></p></blockquote><ul><li><strong>充分条件</strong>：对于<strong>线性指数分布族</strong>，若有<span class="math inline">\(J_y(x)\)</span> 不依赖于 x，也即 <spanclass="math inline">\(J_y(x)\)</span>等于一个常数时，有效统计量存在</li></ul><blockquote><p><strong>Proof</strong>：<span class="math inline">\(J_y(x)=J\)</span><span class="math display">\[\dot{\dot{\alpha}}(x)=J, \ \ \ \dot{\alpha}(x)=Jx-c \\\hat x_{eff}(y) = x + \frac{1}{J}\frac{\partial}{\partial x}\ln p(y;x) =x + \frac{1}{J} (t(y)-\dot{\alpha}(x)) = x +\frac{1}{J}(t(y)-Jx+c)=\frac{t(y)}{J}+\frac{c}{J}\]</span> 由于 <span class="math display">\[\frac{\partial}{\partial x}\ln p(y;x)|_{x=\hat x_{ML}} = 0 = t(y) -\dot{\alpha}(x)|_{x=\hat x_{ML}}\]</span> 有 <span class="math display">\[\hat x_{eff}(y) = c/J + \frac{1}{J}\dot{\alpha}(x)|_{x=\hat x_{ML}} =\hat x_{ML}(y)\]</span></p></blockquote></li></ul><h2 id="sufficient-statistics">2. Sufficient statistics</h2><h3 id="non-bayesian-case">2.1 Non-Bayesian case</h3><ul><li>Definition：t(y) 是关于分布 <spanclass="math inline">\(p_{\mathsf{y}}(\cdot;x)\)</span>的充分统计量，如果 <span class="math inline">\(p(y|t(y);x)\)</span> 与 x无关</li></ul><blockquote><p><strong>Theorem 1</strong>(likelihood characterization)：</p><p><span class="math inline">\(t(y)\)</span> is sufficient w.r.t <spanclass="math inline">\(p(y;x)\)</span> <span class="math inline">\(\iff \\frac{p_{y}(y;x)}{p_t(t(y);x)}\)</span> doesn't depend on x, for all xand y</p><p><strong>Proof</strong>：omit...</p><p><strong>Theorem 2</strong>(Neyman Factorization theorem)：</p><p><span class="math inline">\(t(y)\)</span> is sufficient w.r.t <spanclass="math inline">\(p(y;x)\)</span> <span class="math inline">\(\iff \存在a(\cdot,\cdot)和b(\cdot)使得 \ \  p(y;x)=a\left(t(y),x\right) \cdotb(y)\)</span></p><p><strong>Proof</strong>：omit...</p></blockquote><ul><li><strong>minimum sufficient statistic</strong>：<spanclass="math inline">\(t^*\)</span> 是 minimal的，如果对任意其他充分统计量 t ，都存在 g() 使得 <spanclass="math inline">\(t^*=g(t)\)</span></li><li><strong>complete</strong>：<span class="math inline">\(t^*\)</span>是 complete 的如果对任意函数 <spanclass="math inline">\(\phi(\cdot)\)</span>，有 <spanclass="math inline">\(E[\phi(t^*(y))]=0 \ \ \forall x \iff \phi(\cdot)\equiv 0\)</span></li></ul><blockquote><p><strong>Theorem</strong>：complete <spanclass="math inline">\(\Longrightarrow\)</span> minimal</p><p><strong>Proof</strong>：假设 t 为complete，s 为 minimal，存在 <spanclass="math inline">\(s=g(t)\)</span>，<spanclass="math inline">\(E[t]=E\left[E\left[t|s=s\right]\right]\)</span></p><p><spanclass="math inline">\(E[t|s=s]=f(s)=f(g(t))=\tilde{f}(t)\)</span></p><p>取 <span class="math inline">\(\phi(t)=t-\tilde{f}(t)\)</span>，有<span class="math inline">\(E[\phi(t)] = 0\)</span></p><p>根据 complete 的定义，有 <span class="math inline">\(\phi(t)\equiv0\Longrightarrow t = \tilde{f}(t)=f(s)\)</span></p><p>故 t 也是 minimal</p></blockquote><h3 id="bayesian-case">2.2 Bayesian case</h3><ul><li>Definition：t(y) 是关于分布 <spanclass="math inline">\(p_{\mathsf{y,x}}(\cdot,\cdot)\)</span>的充分统计量，如果 <spanclass="math inline">\(p_{\mathsf{y|t,x}}(y|t(y),x)=p_\mathsf{y|t}(y|t(y))\)</span>与 x 无关</li></ul><blockquote><p><strong>Theorem</strong>(Belief characterization)：</p><p><span class="math inline">\(t(y)\)</span> is sufficient w.r.t <spanclass="math inline">\(p(y,x)\)</span> <span class="math inline">\(\iff \p(x|y)=p(x|t(y))\)</span>, for all x and y</p><p><strong>Proof</strong>：omit...</p><p><strong>Theorem</strong>(Neyman Factorization theorem)：</p><p><span class="math inline">\(t(y)\)</span> is sufficient w.r.t <spanclass="math inline">\(p(y,x)\)</span> <span class="math inline">\(\iff \p(y|x)=p(t(y)|x)\cdot p(y|t(y))\)</span>, for all x and y</p><p><strong>Proof</strong>：omit...</p></blockquote><h2 id="conjugate-priors">3. Conjugate priors</h2><ul><li>Idea: Given a model <spanclass="math inline">\(p_\mathsf{y|x}\)</span>, look for a family ofprior <span class="math inline">\(p_\mathsf{x}\)</span> such that theinduced posterior <span class="math inline">\(p_\mathsf{x|y}\)</span>also in this family</li><li>Definition: a family of distribution <spanclass="math inline">\(q(\cdot;\theta)\)</span> is<strong>conjugate</strong> to a model <spanclass="math inline">\(p_{y|x}\)</span> if<ul><li><span class="math inline">\(p_{y|x}(y_1,...,y_N|x) \proptoq(x;\theta)\)</span></li><li><span class="math inline">\(q(x;\theta_1)q(x;\theta_2)\proptoq(x;\theta_3)\)</span></li></ul></li><li><strong>Theorem</strong>: 对于采样数 N，联合分布 <spanclass="math inline">\(p^N_{y|x}()\)</span>有充分统计量，且其维度不依赖于 N，则对该模型存在共轭先验分布</li></ul>]]></content>
    
    
    <categories>
      
      <category>统计推断</category>
      
    </categories>
    
    
    <tags>
      
      <tag>指数族</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>统计推断(二) Estimation Problem</title>
    <link href="/2020/02/03/statistic/SI_Ch2_Estimation/"/>
    <url>/2020/02/03/statistic/SI_Ch2_Estimation/</url>
    
    <content type="html"><![CDATA[<p>参数估计</p><span id="more"></span><h2 id="bayesian-parameter-estimation">1. Bayesian parameterestimation</h2><ul><li><p>Formulation</p><ul><li>Prior distribution <spanclass="math inline">\(p_{\mathsf{x}}(\cdot)\)</span></li><li>Observation <spanclass="math inline">\(p_{\mathsf{y|x}}(\cdot|\cdot)\)</span></li><li>Cost <span class="math inline">\(C(a,\hat a)\)</span></li></ul></li><li><p>Solution</p><ul><li><span class="math inline">\(\hat x(\cdot) = \arg\min_{f(\cdot)}\mathbb E[C(x,f(y))]\)</span></li><li><spanclass="math inline">\(\hat{\mathbf{x}}(\mathbf{y})=\underset{\mathbf{a}}{\arg\min } \int_{\mathcal{X}} C(\mathbf{x}, \mathbf{a}) p_{\mathbf{x} |\mathbf{y}}(\mathbf{x} | \mathbf{y}) \mathrm{d} \mathbf{x}\)</span></li></ul></li><li><p>Specific case</p><ul><li><p><strong>MAE</strong>(Minimum absolute-error)</p><ul><li><span class="math inline">\(C(a,\hat a)=|a-\hat a|\)</span></li><li><span class="math inline">\(\hat x\)</span> is the<strong>median</strong> of the belief <spanclass="math inline">\(p_{\mathsf{x|y}}(x|y)\)</span></li></ul></li><li><p><strong>MAP</strong>(Maximum a posteriori)</p><ul><li><span class="math display">\[C(a,\hat a) = \left\{\begin{array}{ll}{1,} &amp; {|a-\hat a|&gt;\varepsilon} \\{0,} &amp; {otherwise}\end{array}\right.\]</span></li><li><span class="math inline">\(\hat x_{MAP}(y) = \arg \max_ap_{\mathsf{x|y}}(a|y)\)</span></li></ul></li><li><p><strong>BLS</strong>(Bayes’ least-squares)</p><ul><li><p><span class="math inline">\(C(a,\hat a)=||a-\hata||^2\)</span></p></li><li><p><span class="math inline">\(\hat x_{BLS}(y) = \mathbb E[\mathsf{x|y}]\)</span></p></li><li><p>proposition</p><ul><li><p>unbiased: <span class="math inline">\(b = \mathbbE[\mathsf{e(x,y)}]=E[\mathsf{\hat x(y)-x}]=0\)</span></p></li><li><p>误差的协方差矩阵就是<strong>belief</strong>（后验分布？）的协方差阵的期望 <spanclass="math display">\[\Lambda_{BLS}=\mathbb E[\mathsf{\Lambda_{x|y}(y)}]\]</span></p></li></ul></li></ul></li></ul></li><li><p>Orthogonality <span class="math display">\[      \hat x(\cdot)\ is\ BLS \iff \mathbb E\left[ \mathsf{[\hatx(y)-x]g^T(y)}\right]=0  \]</span></p><pre><code class="hljs">&gt; **Proof**:  omit</code></pre></li></ul><h2 id="linear-least-square-estimation">2. Linear least-squareestimation</h2><ul><li><p>Drawback of BLS <span class="math inline">\(\hatx_{BLS}(y)=E[x|y]\)</span></p><ul><li>requires posterior <span class="math inline">\(p(x|y)\)</span>,which needs <span class="math inline">\(p(x)\)</span> and <spanclass="math inline">\(p(y|x)\)</span></li><li>calculating posterior is complicated</li><li>estimator is <strong>nonlinear</strong></li></ul></li><li><p>Definition of LLS</p><ul><li><span class="math inline">\(\hat {\mathbf{x}}_{LLS}(y) = \arg\min\limits_{f(\cdot) \in \mathcal{B}}E\left[||\mathsf{x-f(y)}||^2\right] \\\mathcal{B}=\{f(\cdot):f(y)=Ay+d\}\)</span></li><li>注意 <span class="math inline">\(\hat{\mathbf{x}}(\mathsf{y})\)</span> 是一个随机变量，是关于 <spanclass="math inline">\(\mathsf{y}\)</span> 的一个函数</li><li>LLS 与 BLS 都是假设 x 为一个随机变量，有先验分布，不同之处在于 LLS要求估计函数为关于观测值 y 的线性函数，因此 LLS 只需要知道二阶矩，而 BLS需要知道后验均值</li></ul></li><li><p>Property</p><ul><li><p>Orthogonality <span class="math display">\[\hat {\mathbf{x}}(\cdot)\ is\ LLS \iff E[\hat{\mathbf{x}}(\mathsf{y})-\mathsf{x}]=0\ \ and\ \ E[(\hat{\mathbf{x}}(\mathsf{y})-\mathsf{x})\mathsf{y}^T]=0\]</span></p></li><li><p>推论：由正交性可得到</p><ul><li><span class="math inline">\(\hatx_{LLS}(y)=\mu_X+\Lambda_{xy}\Lambda_y^{-1}(y-\mu_y)\)</span></li><li><span class="math inline">\(\Lambda_{\mathrm{LLS}} \triangleq\mathbb{E}\left[\left(\mathbf{x}-\hat{\mathbf{x}}_{\mathrm{LLS}}(\mathbf{y})\right)\left(\mathbf{x}-\hat{\mathbf{x}}_{\mathrm{LLS}}(\mathbf{y})\right)^{\mathrm{T}}\right]=\Lambda_{\mathrm{x}}-\Lambda_{\mathrm{xy}}\Lambda_{\mathrm{y}}^{-1}\Lambda_{\mathrm{xy}}^{\mathrm{T}}\)</span></li></ul></li></ul><blockquote><p><strong>Proof</strong>: x 可以是向量</p><p><span class="math inline">\(\Longrightarrow\)</span>：反证法</p><ol type="1"><li><p>suppose <span class="math inline">\(E[\hatx_{LLS}(y)-x]=\mathbb{b} \ne 0\)</span>，take <spanclass="math inline">\(\hat x&#39;=\hat x_{LLS} - b\)</span> then <spanclass="math inline">\(E\left[||\hat x&#39; - x||^2\right]=E\left[||\hatx - x||^2\right]-b^2 &lt; E\left[||\hat x - x||^2\right]\)</span> 与 LLS的定义矛盾；</p></li><li><p><span class="math inline">\(e=\hat x(y)-x\)</span> Take <spanclass="math inline">\(\hat x&#39; = \hat x_{LLS} -\Lambda_{ey}\Lambda_y^{-1}(y-\mu_y)\)</span> <spanclass="math display">\[\begin{align}M &amp;= E\left[(\hat x&#39; -x)(\hat x&#39; -x)^T \right] \\&amp;= E\left[(\hat x-x)(\hatx-x)^T\right]-\Lambda_{ey}\Lambda_y^{-1}\Lambda_{ey}^T\end{align}\]</span> 由于 <spanclass="math inline">\(E\left[||\mathsf{x-f(y)}||^2\right] =tr\{M\}\)</span>，LLS 的 MSE 应当最小 由于 <spanclass="math inline">\(\Lambda_y\)</span> 正定，因此应有 <spanclass="math inline">\(\Lambda_{ey}\Lambda_y^{-1}\Lambda_{ey}^T=0\)</span>故 <span class="math inline">\(E\left[(\hat x-\mu_x)(y-\mu_y)^T\right]=0 \Longrightarrow E[(\hat{\mathbf{x}}(\mathsf{y})-\mathsf{x})\mathsf{y}^T]=0\)</span></p></li></ol><p><span class="math inline">\(\Longleftarrow\)</span>：suppose anotherlinear estimator <span class="math inline">\(\hat x&#39;\)</span> <spanclass="math display">\[\begin{align}E\left[(\hat x&#39;-x)(\hat x&#39;-x)^T\right] &amp;= E[(\hatx&#39;-\hat x+\hat x-x)(\hat x&#39;-\hat x+\hat x-x)^T] \\&amp;= E[(\hat x&#39;-\hat x)(\hat x&#39;-\hat x)^T] + E[(\hat x-x)(\hatx-x)^T] \\&amp;\ \ \ \ \  - 2E[(\hat x-x)(\hat x&#39;-\hat x)^T] \\&amp;= E[(\hat x&#39;-\hat x)(\hat x&#39;-\hat x)^T] + E[(\hat x-x)(\hatx-x)^T]\end{align}\]</span> 第三个等号是由于 <span class="math inline">\(\hat x&#39;-\hatx = A&#39;y+d&#39;\)</span></p><p>同样的根据上面 <span class="math inline">\(MSE=tr\{M\}\)</span>可得到 <span class="math inline">\(\hat x\)</span> 有最小的 MSE</p></blockquote></li><li><p>联合高斯分布的情况</p><ul><li>定理：如果 x 和 y 是联合高斯分布的，那么 <spanclass="math display">\[\hat x_{BLS}(y) = \hat x_{LLS}(y)\]</span></li></ul><blockquote><p>证明：<span class="math inline">\(e_{LLS}=\hat x_{LLS}-x\)</span>也是高斯分布</p><p>由于 <span class="math inline">\(E[e_{LLS}\ y^T]=0\)</span>，故 <spanclass="math inline">\(e_{LLS}\)</span> 与 y 相互独立</p><p><span class="math inline">\(E[e_{LLS}|y]=E[e_{LLS}]=0 \to E[\hatx_{LLS}|y]=\hat x_{LLS} = E[x|y]\)</span></p></blockquote><ul><li>通常如果只有联合二阶矩信息，那么 LLS 是 minmax</li></ul></li></ul><h2 id="non-bayesian-formulation">3. Non-Bayesian formulation</h2><ul><li><p>Formulation</p><ul><li>observation: distribution of y <strong>parameterized</strong> by x,<span class="math inline">\(p_\mathsf{y}(\mathbf{y;x})\)</span> not<strong>conditioned</strong> on x, <spanclass="math inline">\(p_\mathsf{y|x}(\mathbf{y|x})\)</span> 此时 x不再是一个随机变量，而是未知的一个参数</li><li>bias: <span class="math inline">\(b(x)=E[\hatx(y)-\mathbf{x}]\)</span></li><li>误差协方差矩阵 <spanclass="math inline">\(\Lambda_{\mathrm{e}}(\mathrm{x})=\mathbb{E}\left[(\mathrm{e}(\mathrm{x},\mathrm{y})-\mathrm{b}(\mathrm{x}))(\mathrm{e}(\mathrm{x},\mathrm{y})-\mathrm{b}(\mathrm{x}))^{\mathrm{T}}\right]\)</span></li></ul></li><li><p><strong>有效(valid)</strong>估计器不应当显式地依赖于 x</p></li><li><p><strong>MVU</strong>: Minimum-variance unbiased estimator</p><ul><li>在 MMSE 条件下最优估计就是 MVU 估计 <span class="math display">\[\begin{align}MSE &amp;= E[e^2]=E[(\hat x-x)^2]=E[(\hat x-\mu_{\hat x}+\mu_{\hat x}-x)^2] \\&amp; =E[(\hat x-\mu_{\hat x})^2]+b^2= \Lambda_{\hat x}(x) + b^2\\\end{align}\]</span></li></ul></li><li><p>MVU 可能不存在</p><ul><li>可能不存在无偏估计，即 <spanclass="math inline">\(\mathcal{A}=\varnothing\)</span></li><li>存在无偏估计 <span class="math inline">\(\mathcal{A} \ne\varnothing\)</span>，但是不存在某个估计量在所有情况（任意x）下都是最小方差</li></ul></li></ul><h2 id="crb">4. CRB</h2><p><strong>定理</strong>：满足正规条件时 <span class="math display">\[\mathbb{E}\left[\frac{\partial}{\partial x} \ln p_{y}(\mathbf{y} ; x)\right] = 0 \ \ \ \ for \ all \ \ x\]</span> 有 <span class="math display">\[\lambda_{\hat x}(X) \ge \frac{1}{J_y(x)}\]</span> 其中 Fisher 信息为 <span class="math display">\[J_{y}(x)=\mathbb{E}\left[\left(\frac{\partial}{\partial x} \lnp_{y}(\mathbf{y} ;x)\right)^{2}\right]=-\mathbb{E}\left[\frac{\partial^{2}}{\partialx^{2}} \ln p_{y}(\mathbf{y} ; x)\right]\]</span> <strong>证明</strong>：取 <spanclass="math inline">\(f(y)=\frac{\partial}{\partial x} \lnp_{y}(\mathbf{y} ; x)\)</span>，有 <spanclass="math inline">\(E[f(y)]=0\)</span></p><p><span class="math display">\[cov(e(y),f(y))=\int (\hat x(y)-x)\frac{\partial}{\partial x}p_{y}(\mathbf{y} ; x)dy=1\]</span></p><p><span class="math display">\[1=cov(e,f)\le Var(e)Var(f)\]</span></p><p><strong>备注</strong></p><ul><li>正规条件不满足时，CRB 不存在</li><li>Fisher 信息可以看作 <span class="math inline">\(p_{y}(\mathbf{y} ;x)\)</span> 的曲率</li></ul><h2 id="有效估计量">4. 有效估计量</h2><ul><li><p>定义：可以达到 CRB 的无偏估计量</p></li><li><p>有效估计量一定是 MVU 估计量</p></li><li><p>MVU 估计量不一定是有效估计量，也即 CRB不一定是紧致（tight）的，有时没有估计量可以对所有的 x 达到 CRB</p></li><li><p>性质：（唯一的、无偏的，可以达到 CRB） <spanclass="math display">\[\hat x \ \ is \ \ efficient \iff \hatx(y)=x+\frac{1}{J_y(x)}\frac{\partial}{\partial x} \ln p_{y}(\mathbf{y}; x)\]</span></p></li></ul><blockquote><p><strong>证明</strong>：有效估计量 <spanclass="math inline">\(\iff\)</span> 可以达到 CRB <spanclass="math inline">\(\iff\)</span> 取等号 <spanclass="math inline">\(Var(e)Var(f)=1\)</span> <spanclass="math inline">\(\iff\)</span> 取等号 <spanclass="math inline">\(e(y)=k(x)f(y)\)</span> <spanclass="math inline">\(\iff\)</span> <spanclass="math inline">\(e(y)=x+k(X)f(y)\)</span> <spanclass="math display">\[\frac{1}{J_y(x)}=E[e^2(y)]=k(x)E[e(y)f(y)]=k(x)\]</span></p></blockquote><h2 id="ml-estimation">5. ML estimation</h2><ul><li>Definition <span class="math display">\[\hat x_{ML}(\cdot)=\arg\max_{a} p(y|a)\]</span></li></ul><blockquote><p><strong>Proposition</strong>: if efficient estimator exists, it's MLestimator <span class="math display">\[\hat x_{eff}(\cdot)=\hat x_{ML}(\cdot)\]</span> <strong>Proof</strong>: <span class="math display">\[\hat x_{eff}(y)=x+\frac{1}{J_y(x)}\frac{\partial}{\partial x}\ln p(y;x)\]</span> 由于有效(valid)估计器不应当依赖于 x，因此上式中 x取任意一个值都应当是相等的，可取 <span class="math inline">\(\hatx_{ML}(y)\)</span> <span class="math display">\[\hat x_{eff}(y)=\hat x_{ML}(y) + \frac{1}{J_y(x)}\frac{\partial \lnp(y;x)}{\partial x}\Big|_{x=\hat x_{ML}}=\hat x_{ML}(y)\]</span> <strong>备注</strong>：反之不一定成立，即 ML估计器不一定是有效的，比如有时候全局的有效估计器(efficientestimator)不存在，也即此时按公式计算得到的 <spanclass="math inline">\(\hat x_{eff}(y)\)</span> 实际上是依赖于 x的，那么此时就不存在一个全局最优的估计器，此时的 ML估计器也没有任何好的特性。</p></blockquote>]]></content>
    
    
    <categories>
      
      <category>统计推断</category>
      
    </categories>
    
    
    <tags>
      
      <tag>参数估计</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>统计推断(一) Hypothesis Test</title>
    <link href="/2020/02/03/statistic/SI_Ch1_Hypothesis%20Test/"/>
    <url>/2020/02/03/statistic/SI_Ch1_Hypothesis%20Test/</url>
    
    <content type="html"><![CDATA[<p>假设检验</p><span id="more"></span><h2 id="binary-bayesian-hypothesis-testing">1. Binary Bayesianhypothesis testing</h2><h3 id="problem-setting">1.0 Problem Setting</h3><ul><li>Hypothesis<ul><li>Hypothesis space <span class="math inline">\(\mathcal{H}=\{H_0,H_1\}\)</span></li><li>Bayesian approach: Model the valid hypothesis as an RV H</li><li>Prior <span class="math inline">\(P_0 = p_\mathsf{H}(H_0),P_1=p_\mathsf{H}(H_1)=1-P_0\)</span></li></ul></li><li>Observation<ul><li>Observation space <spanclass="math inline">\(\mathcal{Y}\)</span></li><li>Observation Model <spanclass="math inline">\(p_\mathsf{y|H}(\cdot|H_0),p_\mathsf{y|H}(\cdot|H_1)\)</span></li></ul></li><li>Decision rule <span class="math inline">\(f:\mathcal{Y\toH}\)</span></li><li>Cost function <span class="math inline">\(C: \mathcal{H\times H} \to\mathbb{R}\)</span><ul><li>Let <span class="math inline">\(C_{ij}=C(H_j,H_i), correct hypo isH_j\)</span></li><li><span class="math inline">\(C\)</span> is <em>valid</em> if <spanclass="math inline">\(C_{jj}&lt;C_{ij}\)</span></li></ul></li><li>Optimum decision rule <span class="math inline">\(\hat{H}(\cdot) =\arg\min\limits_{f(\cdot)}\mathbb{E}[C(\mathsf{H},f(\mathsf{y}))]\)</span></li></ul><h3 id="binary-bayesian-hypothesis-testing-1">1.1 Binary Bayesianhypothesis testing</h3><blockquote><p><strong>Theorem</strong>: The optimal Bayes' decision takes the form<span class="math display">\[L(\mathsf{y}) \triangleq\frac{p_\mathsf{y|H}(\cdot|H_1)}{p_\mathsf{y|H}(\cdot|H_0)}\overset{H_1} \gtreqless\frac{P_0}{P_1} \frac{C_{10}-C_{00}}{C_{01}-C_{11}}\triangleq \eta\]</span></p><p><strong>Proof</strong>: <span class="math display">\[\begin{align}\varphi(f) &amp;=\mathbb{E} [C(H, f(y))] \\&amp;= \int_{y*} \mathbb{E} [C(H,f(y^*) | \mathsf{y}=y^*)] \\\end{align}\]</span></p><p>Given <span class="math inline">\(y^*\)</span></p><ul><li>if <span class="math inline">\(f(y^*)=H_0\)</span>, <spanclass="math inline">\(\mathbb{E}=C_{00}p_{\mathsf{H|y}}(H_0|y^*)+C_{01}p_{\mathsf{H|y}}(H_1|y^*)\)</span></li><li>if <span class="math inline">\(f(y^*)=H_1\)</span>, <spanclass="math inline">\(\mathbb{E}=C_{10}p_{\mathsf{H|y}}(H_0|y^*)+C_{11}p_{\mathsf{H|y}}(H_1|y^*)\)</span></li></ul><p>So <span class="math display">\[\frac{p_\mathsf{H|y}(H_1|y^*)}{p_\mathsf{H|y}(H_0|y^*)}\overset{H_1} \gtreqless\frac{C_{10}-C_{00}}{C_{01}-C_{11}}\]</span></p><p><strong>备注</strong>：证明过程中，注意贝叶斯检验为<strong>确定性检验</strong>，因此对于某个确定的y，<span class="math inline">\(f(y)=H_1\)</span> 的概率要么为 0 要么为1。因此对代价函数求期望时，把 H 看作是随机变量，而把 <spanclass="math inline">\(f(y)\)</span>看作是确定的值来<strong>分类讨论</strong></p></blockquote><h4 id="special-cases">Special cases</h4><ul><li>Maximum a posteriori (MAP)<ul><li><spanclass="math inline">\(C_{00}=C_{11}=0,C_{01}=C_{10}=1\)</span></li><li><spanclass="math inline">\(\hat{H}(y)==\arg\max\limits_{H\in\{H_0,H_1\}}p_\mathsf{H|y}(H|y)\)</span></li></ul></li><li>Maximum likelihood (ML)<ul><li><span class="math inline">\(C_{00}=C_{11}=0,C_{01}=C_{10}=1,P_0=P_1=0.5\)</span></li><li><spanclass="math inline">\(\hat{H}(y)==\arg\max\limits_{H\in\{H_0,H_1\}}p_\mathsf{y|H}(y|H)\)</span></li></ul></li></ul><h3 id="likelyhood-ratio-test">1.2 Likelyhood Ratio Test</h3><p>Generally, LRT <span class="math display">\[L(\mathsf{y}) \triangleq\frac{p_\mathsf{y|H}(\cdot|H_1)}{p_\mathsf{y|H}(\cdot|H_0)}\overset{H_1} \gtreqless\eta\]</span></p><ul><li>Bayesian formulation gives a method of calculating <spanclass="math inline">\(\eta\)</span></li><li><span class="math inline">\(L(y)\)</span> is a <strong>sufficientstatistic</strong> for the decision problem</li><li><span class="math inline">\(L(y)\)</span>的可逆函数也是充分统计量</li></ul><blockquote><p><strong>充分统计量</strong></p></blockquote><h3 id="roc">1.3 ROC</h3><ul><li>Detection probability <span class="math inline">\(P_D =P(\hat{H}=H_1 | \mathsf{H}=H_1)\)</span></li><li>False-alarm probability <span class="math inline">\(P_F =P(\hat{H}=H_1 | \mathsf{H}=H_0)\)</span></li></ul><p><strong>性质（重要！）</strong></p><ul><li>LRT 的 ROC 曲线是单调不减的</li><li></li></ul><figure><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2019/roc.jpg"alt="ROC" /><figcaption aria-hidden="true">ROC</figcaption></figure><h2 id="non-bayesian-hypo-test">2. Non-Bayesian hypo test</h2><ul><li>Non-Bayesian不需要<strong>先验概率</strong>或者<strong>代价函数</strong></li></ul><h3 id="neyman-pearson-criterion">Neyman-Pearson criterion</h3><p><span class="math display">\[\max_{\hat{H}(\cdot)}P_D \ \ \ s.t. P_F\le \alpha\]</span></p><blockquote><p><strong>Theorem</strong>(Neyman-Pearson Lemma)：NP 准则的最优解由 LRT得到，其中 <span class="math inline">\(\eta\)</span> 由以下公式得到<span class="math display">\[P_F=P(L(y)\ge\eta | \mathsf{H}=H_0) = \alpha\]</span></p><p><strong>Proof</strong>： <imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2019/np_proof.jpg"alt="proof" /></p><p><strong>物理直观</strong>：同一个 <spanclass="math inline">\(P_F\)</span> 时 LRT 的 <spanclass="math inline">\(P_D\)</span> 最大。物理直观来看，LRT 中判决为 H1的区域中 <span class="math inline">\(\frac{p(y|H_1)}{p(y|H_0)}\)</span>都尽可能大，因此 <span class="math inline">\(P_F\)</span> 相同时 <spanclass="math inline">\(P_D\)</span> 可最大化</p><p><strong>备注</strong>：NP 准则最优解为 LRT，原因是</p><ul><li>同一个 <span class="math inline">\(P_F\)</span> 时， LRT 的 <spanclass="math inline">\(P_D\)</span> 最大</li><li>LRT 取不同的 <span class="math inline">\(\eta\)</span> 时，<spanclass="math inline">\(P_F\)</span> 越大，则 <spanclass="math inline">\(P_D\)</span> 也越大，即 ROC 曲线单调不减</li></ul></blockquote><h2 id="randomized-test">3. Randomized test</h2><h3 id="decision-rule">3.1 Decision rule</h3><ul><li><p>Two deterministic decision rules <spanclass="math inline">\(\hat{H&#39;}(\cdot),\hat{H&#39;&#39;}(\cdot)\)</span></p></li><li><p>Randomized decision rule <spanclass="math inline">\(\hat{H}(\cdot)\)</span> by time-sharing <spanclass="math display">\[\hat{\mathrm{H}}(\cdot)=\left\{\begin{array}{ll}{\hat{H}^{\prime}(\cdot),}&amp; {\text { with probability } p} \\ {\hat{H}^{\prime\prime}(\cdot),} &amp; {\text { with probability }1-p}\end{array}\right.\]</span></p><ul><li>Detection prob <spanclass="math inline">\(P_D=pP_D&#39;+(1-p)P_D&#39;&#39;\)</span></li><li>False-alarm prob <spanclass="math inline">\(P_F=pP_F&#39;+(1-P)P_F&#39;&#39;\)</span></li></ul></li><li><p>A randomized decision rule is <strong>fully described</strong> by<span class="math inline">\(p_{\mathsf{\hat{H}|y}}(H_m|y)\)</span> form=0,1</p></li></ul><h3 id="proposition">3.2 Proposition</h3><ol type="1"><li><p>Bayesian case: <strong>cannot</strong> achieve a lower <em>Bayes'risk</em> than the optimum LRT</p><blockquote><p><strong>Proof</strong>: Risk <strong>for each y</strong> is linear in<span class="math inline">\(p_{\mathrm{H} | \mathbf{y}}\left(H_{0} |\mathbf{y}\right)\)</span>, so the minima is achieved at 0 or 1, whichdegenerate to deterministic decision <span class="math display">\[\begin{align}\varphi(\mathbf{y})&amp;=\sum_{i, j} C_{i j}\mathbb{P}\left(\mathrm{H}=H_{j}, \hat{\mathrm{H}}=H_{i} |\mathbf{y}=\mathbf{y}\right)=\sum_{i, j} C_{i j} p_{\mathrm{\hat H} |y}\left(H_{i} | \mathbf{y}\right) p_{\mathrm{H} | \mathbf{y}}\left(H_{j}| \mathbf{y}\right) \\&amp;= \Delta(y) + P(\hat H=H_0|y)\frac{P(y|H_0)}{p(y)}P_1(C_{01}-C_{11})(L(y)-\eta)\end{align}\]</span></p></blockquote></li><li><p>Neyman-Pearson case:</p><ol type="1"><li><strong>continuous-valued</strong>: For a given <spanclass="math inline">\(P_F\)</span> constraint, randomized test<strong>cannot</strong> achieve <strong>a larger <spanclass="math inline">\(P_D\)</span></strong> than optimum LRT</li><li><strong>discrete-valued</strong>: For a given <spanclass="math inline">\(P_F\)</span> constraint, randomized test<strong>can</strong> achieve <strong>a larger <spanclass="math inline">\(P_D\)</span></strong> than optimum LRT.Furthermore, the optimum rand test corresponds to simple<strong>time-sharing</strong> between the <strong>two LRTsnearby</strong></li></ol></li></ol><h3 id="efficient-frontier">3.3 Efficient frontier</h3><p>Boundary of region of achievable <spanclass="math inline">\((P_D,P_F)\)</span> operation points</p><ul><li><strong>continuous-valued</strong>: ROC of LRT</li><li><strong>discrete-valued</strong>: LRT points and the straight linesegments</li></ul><p><strong>Facts</strong></p><ul><li><span class="math inline">\(P_D \ge P_F\)</span></li><li>efficient frontier is <strong>concave</strong> function</li><li><span class="math inline">\(\frac{dP_D}{dP_F}=\eta\)</span></li></ul><figure><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2019/efficient_frontier.jpg"alt="efficient frontier" /><figcaption aria-hidden="true">efficient frontier</figcaption></figure><h2 id="minmax-hypo-testing">4. Minmax hypo testing</h2><p>prior: unknown, cost fun: known</p><h3 id="decision-rule-1">4.1 Decision rule</h3><ul><li><p>minmax approach <span class="math display">\[\hat H(\cdot)=\arg\min_{f(\cdot)}\max_{p\in[0,1]} \varphi(f,p)\]</span></p></li><li><p>optimal decision rule <span class="math display">\[\hat H(\cdot)=\hat{H}_{p_*}(\cdot) \\p_* = \arg\max_{p\in[0,1]} \varphi(\hat H_p, p)\]</span></p><blockquote><p>要想证明上面的最优决策，首先引入 mismatch Bayes decision <spanclass="math display">\[\hat{\mathrm{H}}_q(y)=\left\{\begin{array}{ll}{H_1,} &amp; {L(y) \ge\frac{1-q}{q}\frac{C_{10}-C_{00}}{C_{01}-C_{11}}} \\{H_0,} &amp; {otherwise}\end{array}\right.\]</span> 代价函数如下，可得到 <span class="math inline">\(\varphi(\hatH_q,p)\)</span> 与概率 <span class="math inline">\(p\)</span> 成线性关系<span class="math display">\[\varphi(\hat H_q,p)=(1-p)[C_{00}(1-P_F(q))+C_{10}P_F(q)] +p[C_{01}(1-P_D(q))+C_{11}P_D(q)]\]</span></p><p><strong>Lemma</strong>: Max-min inequality <spanclass="math display">\[\max_x\min_y g(x,y) \le \min_y\max_x g(x,y)\]</span> <strong>Theorem</strong>:<br /><span class="math display">\[\min_{f(\cdot)}\max_{p\in[0,1]}\varphi(f,p)=\max_{p\in[0,1]}\min_{f(\cdot)}\varphi(f,p)\]</span> <strong>Proof of Lemma</strong>: Let <spanclass="math inline">\(h(x)=\min_y g(x,y)\)</span> <spanclass="math display">\[\begin{aligned}g(x) &amp;\leq f(x, y), \forall x \forall y \\\Longrightarrow \max _{x} g(x) &amp; \leq \max _{x} f(x, y), \forall y\\ \Longrightarrow \max _{x} g(x) &amp; \leq \min _{y} \max _{x} f(x, y)\end{aligned}\]</span> <strong>Proof of Thm</strong>: 先取 <spanclass="math inline">\(\forall p_1,p_2 \in [0,1]\)</span>，可得到 <spanclass="math display">\[\varphi(\hat H_{p_1},p_1)=\min_f \varphi(f,p_1) \le \max_p \min_f\varphi(f,p) \le \min_f \max_p \varphi(f, p) \le \max_p \varphi(\hatH_{p_2}, p)\]</span> 由于 <span class="math inline">\(p_1,p_2\)</span>任取时上式都成立，因此可以取 <spanclass="math inline">\(p_1=p_2=p_*=\arg\max_p \varphi(\hat H_p,p)\)</span></p><p>要想证明定理则只需证明 <span class="math inline">\(\varphi(\hatH_{p_*},p_*)=\max_p \varphi(\hat H_{p_*}, p)\)</span></p><p>由前面可知 <span class="math inline">\(\varphi(\hat H_q,p)\)</span>与 <span class="math inline">\(p\)</span> 成线性关系，因此要证明上式</p><ul><li>若 <span class="math inline">\(p_* \in (0,1)\)</span>，只需 <spanclass="math inline">\(\left.\frac{\partial \varphi\left(\hat{H}_{q^{*}},p\right)}{\partial p}\right|_{\text {for any }p}=0\)</span>，等式自然成立</li><li>若 <span class="math inline">\(p_* = 1\)</span>，只需 <spanclass="math inline">\(\left.\frac{\partial \varphi\left(\hat{H}_{q^{*}},p\right)}{\partial p}\right|_{\text {for any } p} &gt;0\)</span>，最优解就是 <span class="math inline">\(p=1\)</span>；<spanclass="math inline">\(q_*=0\)</span> 同理</li></ul><p>根据下面的引理，可以得到最优决策就是 Bayes 决策 <spanclass="math inline">\(p_*=\arg\max_p \varphi(\hat H_p, p)\)</span>，其中<span class="math inline">\(p_*\)</span> 满足 <spanclass="math display">\[\begin{aligned} 0 &amp;=\frac{\partial \varphi\left(\hat{H}_{p_{*}},p\right)}{\partial p} \\&amp;=\left(C_{01}-C_{00}\right)-\left(C_{01}-C_{11}\right)P_{\mathrm{D}}\left(p_{*}\right)-\left(C_{10}-C_{00}\right)P_{\mathrm{F}}\left(p_{*}\right) \end{aligned}\]</span> <strong>Lemma</strong>: <span class="math display">\[\left.\frac{\mathrm{d} \varphi\left(\hat{H}_{p}, p\right)}{\mathrm{d}p}\right|_{p=q}=\left.\frac{\partial \varphi\left(\hat{H}_{q},p\right)}{\partial p}\right|_{p=q}=\left.\frac{\partial\varphi\left(\hat{H}_{q}, p\right)}{\partial p}\right|_{\text {for any }p}\]</span> <imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2019/mismatch_bayes_risk.jpg"alt="bayes risk" /></p></blockquote></li></ul>]]></content>
    
    
    <categories>
      
      <category>统计推断</category>
      
    </categories>
    
    
    <tags>
      
      <tag>假设检验</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Windows任务栏右侧小图标显示不完整</title>
    <link href="/2020/01/08/software/taskbar/"/>
    <url>/2020/01/08/software/taskbar/</url>
    
    <content type="html"><![CDATA[<span id="more"></span><p>之前发现windows电脑右侧小图标显示不完整</p><figure><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2019/taskbar_before.png"alt="before" /><figcaption aria-hidden="true">before</figcaption></figure><p>百度了一下，只需要新建一个<code>bat</code>文件，内容是</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">cd</span> /d %userprofile%\AppData\Local\Microsoft\Windows\Explorer<br>taskkill /f /im explorer.exe<br>attrib -h iconcache_*.db<br>del iconcache_*.db /a<br>start explorer<br>pause<br></code></pre></td></tr></table></figure><p>以管理员身份运行后就好了，中间屏幕会闪一下蓝屏2s，不用担心。然后就可以变成下面这样</p><figure><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2019/taskbar_after.png"alt="after" /><figcaption aria-hidden="true">after</figcaption></figure><p>参考资料：https://jingyan.baidu.com/article/ae97a64608ba0cbbfd461d8f.html</p>]]></content>
    
    
    <categories>
      
      <category>Software</category>
      
    </categories>
    
    
    <tags>
      
      <tag>windows</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Git 工作原理(二)</title>
    <link href="/2019/12/29/git/git-principle-2/"/>
    <url>/2019/12/29/git/git-principle-2/</url>
    
    <content type="html"><![CDATA[<blockquote><p>在上一篇文章<ahref="https://glooow1024.github.io/2019/12/29/git/git-principle-1/#more">Git工作原理（一）</a>中，我们介绍了简单的git 版本控制，上一篇文章中并没有牵涉到分支 branch相关的内容，这篇文章将会介绍：当我们创建不同的分支时，git做了些什么？</p></blockquote><span id="more"></span><p>[TOC]</p><h2 id="master-分支">1. <code>master</code> 分支</h2><p>上一篇文章结束后，我们查看仓库的历史</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta">$</span><span class="bash"> git ls-files --stage</span><br>100644 445a69c00e48288ac420a2ead9ae5a1cb4cd36d4 0       a.txt<br>100644 c200906efd24ec5e783bee7f23b5d7c941b0c12c 0       dir/b.txt<br><span class="hljs-meta"></span><br><span class="hljs-meta">$</span><span class="bash"> git cat-file --batch-check --batch-all-objects</span><br>0ed6427de6990a17351bf0e0fd648b642e15f967 tree 63<br>38f74e0a07955212bdb02699f6d73cd7420cd823 commit 175<br>445a69c00e48288ac420a2ead9ae5a1cb4cd36d4 blob 7<br>58c9bdf9d017fcd178dc8c073cbfcbb7ff240d6c blob 4<br>aef06e3d27cc6b17730daf473499ab58b68e772d tree 33<br>b00f88d6e09fd9e767fc3246c971bf0d14f0621e commit 223<br>b02b1164ed5a571b723cb25d978780b15d826d62 tree 63<br>c200906efd24ec5e783bee7f23b5d7c941b0c12c blob 4<br><span class="hljs-meta"></span><br><span class="hljs-meta">$</span><span class="bash"> git <span class="hljs-built_in">log</span></span><br>commit b00f88d6e09fd9e767fc3246c971bf0d14f0621e (HEAD -&gt; master)<br>Author: Glooow1024 &lt;glooow1024@gmail.com&gt;<br>Date:   Sun Dec 29 16:07:08 2019 +0800<br><br>    commit 2<br><br>commit 38f74e0a07955212bdb02699f6d73cd7420cd823<br>Author: Glooow1024 &lt;glooow1024@gmail.com&gt;<br>Date:   Sun Dec 29 15:42:55 2019 +0800<br><br>    commit 1<br>    <br><span class="hljs-meta">$</span><span class="bash"> git cat-file -p b00f</span><br>tree 0ed6427de6990a17351bf0e0fd648b642e15f967<br>parent 38f74e0a07955212bdb02699f6d73cd7420cd823<br>author Glooow1024 &lt;glooow1024@gmail.com&gt; 1577606828 +0800<br>committer Glooow1024 &lt;glooow1024@gmail.com&gt; 1577606828 +0800<br><br>commit 2<br></code></pre></td></tr></table></figure><p>当前 <code>.git/</code> 文件夹下我们主要关注以下内容</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs shell">.git<br>├── HEAD<br>├── refs<br>│   └── tags<br>│   └── heads<br>│   └── master<br>├── logs<br>│   └── HEAD<br>│   └── refs<br>│   └── heads<br>│   └── master<br>...<br></code></pre></td></tr></table></figure><h3 id="githead">1.1 <code>.git/HEAD</code></h3><p>如果查看当前的 <code>HEAD</code> 就可以看到他指向了仓库<code>master</code> 最后一次 <code>commit</code></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta">$</span><span class="bash"> cat .git/HEAD</span><br>ref: refs/heads/master<br><span class="hljs-meta"></span><br><span class="hljs-meta">$</span><span class="bash"> cat .git/refs/heads/master</span><br>b00f88d6e09fd9e767fc3246c971bf0d14f0621e<br></code></pre></td></tr></table></figure><h3 id="gitlogs">1.2 <code>.git/logs</code></h3><p>如果再查看 <code>.git/logs/</code> 中的文件，可以看到这里也保存一个<code>HEAD</code>，但是内容跟之前差很多</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta">$</span><span class="bash"> cat ./.git/logs/HEAD</span><br>0000000000000000000000000000000000000000 38f74e0a07955212bdb02699f6d73cd7420cd823 Glooow1024 &lt;glooow1024@gmail.com&gt; 1577605375 +0800    commit (initial): commit 1<br>38f74e0a07955212bdb02699f6d73cd7420cd823 b00f88d6e09fd9e767fc3246c971bf0d14f0621e Glooow1024 &lt;glooow1024@gmail.com&gt; 1577606828 +0800    commit: commit 2<br><br></code></pre></td></tr></table></figure><p>第一列是上一次提交的 <code>commit</code> 哈希值，第二列是本次<code>commit</code> 哈希值，后面是用户信息，最后一列则是每次<code>commit</code> 的附加的消息 message。</p><p>再看 <code>logs</code> 中的 <code>master</code>，可以看到跟前面<code>HEAD</code> 中的内容一样</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta">$</span><span class="bash"> cat .git/logs/refs/heads/master</span><br>0000000000000000000000000000000000000000 38f74e0a07955212bdb02699f6d73cd7420cd823 Glooow1024 &lt;glooow1024@gmail.com&gt; 1577605375 +0800    commit (initial): commit 1<br>38f74e0a07955212bdb02699f6d73cd7420cd823 b00f88d6e09fd9e767fc3246c971bf0d14f0621e Glooow1024 &lt;glooow1024@gmail.com&gt; 1577606828 +0800    commit: commit 2<br></code></pre></td></tr></table></figure><h2 id="git-的分支管理">2. Git 的分支管理</h2><h3 id="git-branch">2.1 <code>git branch</code></h3><p>现在让我们新建一个分支</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta">$</span><span class="bash"> git branch br1</span><br><span class="hljs-meta">$</span><span class="bash"> cat ./.git/HEAD</span><br>ref: refs/heads/master<br></code></pre></td></tr></table></figure><p><code>HEAD</code>的内容当然没有改变，因为我们没有转移到新的分支。但是 <code>.git/</code>发生了哪些变化呢？他变成了这样</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs shell">.git<br>├── HEAD<br>├── refs<br>│   └── tags<br>│   └── heads<br>│   └── br1<br>│   └── master<br>├── logs<br>│   └── HEAD<br>│   └── refs<br>│   └── heads<br>│   └── br1<br>│   └── master<br>...<br></code></pre></td></tr></table></figure><p>来看看内容</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta">$</span><span class="bash"> cat ./.git/refs/heads/br1</span><br>b00f88d6e09fd9e767fc3246c971bf0d14f0621e<br><span class="hljs-meta"></span><br><span class="hljs-meta">$</span><span class="bash"> cat .git/logs/refs/heads/br1</span><br>0000000000000000000000000000000000000000 b00f88d6e09fd9e767fc3246c971bf0d14f0621e Glooow1024 &lt;glooow1024@gmail.com&gt; 1577615247 +0800    branch: Created from master<br></code></pre></td></tr></table></figure><p><code>refs/</code> 中的 <code>br1</code> 只是记录了产生分支的最近一次<code>commit</code> 的哈希值，而 <code>logs/</code>中的信息第一列变成了空，也就是说分支后不能向更早的版本回退，最多回退到分支时的那个版本，同时最后一项信息记录了这个分支信息。</p><blockquote><p><strong>敲黑板！重点</strong></p><ul><li><code>.git/refs/master</code> 只记录了当前分支最后一个<code>commit</code> 的哈希值；</li><li><code>.git/logs/refs/master</code> 记录了当前分支所有<code>commit</code> 的哈希值，构成一个可以向旧版本回溯的单向链表；</li><li><code>.git/HEAD</code> 只记录了当前工作区所在分支对应的<code>refs/</code> 中的文件；</li><li><code>.git/logs/HEAD</code> 记录了 <code>.git/HEAD</code>的变化历程；</li></ul></blockquote><h3 id="git-checkout">2.2 <code>git checkout</code></h3><p>现在让我们转移到新的分支</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta">$</span><span class="bash"> git checkout br1</span><br>Switched to branch &#x27;br1&#x27;<br><span class="hljs-meta"></span><br><span class="hljs-meta">$</span><span class="bash"> cat ./.git/HEAD</span><br>ref: refs/heads/br1<br><br></code></pre></td></tr></table></figure><p>只是修改了当前的 <code>HEAD</code>就表示我们转移到了新的分支，原来的主分支 <code>master</code> 还在<code>ref: refs/heads/master</code> 中保存，所以不会有信息丢失。</p><p>假如我们在分支上修改了内容呢？</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta">$</span><span class="bash"> <span class="hljs-built_in">echo</span> <span class="hljs-string">&#x27;hello&#x27;</span> &gt;&gt; a.txt</span><br><span class="hljs-meta">$</span><span class="bash"> cat a.txt</span><br>hahaha<br>hello<br><br></code></pre></td></tr></table></figure><p>然后查看暂存区 <code>index</code> 文件，可以看到 <code>a.txt</code>的哈希值已经改变了</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta">$</span><span class="bash"> git ls-files --stage</span><br>100644 63db897b879aac027311451ea6d8158daab3ac39 0       a.txt<br>100644 c200906efd24ec5e783bee7f23b5d7c941b0c12c 0       dir/b.txt<br><br></code></pre></td></tr></table></figure><h3 id="git-commit">2.3 <code>git commit</code></h3><p>然后我们提交一哈，不出意外的话用 <code>$ git cat-file --batch-check--batch-all-objects</code> 会发现多了一个 <code>commit</code> 和一个<code>tree</code>文件，这是我们在上一篇文章中所讲的，忘记的可以再回顾一下。</p><p>再看当前 <code>br1</code> 已经被修改了</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta">$</span><span class="bash"> cat .git/refs/heads/br1</span><br>4b60ac6ea7ebab972920f84bd07de3d20d7d5804<br><span class="hljs-meta"></span><br><span class="hljs-meta">$</span><span class="bash"> cat .git/logs/refs/heads/br1</span><br>0000000000000000000000000000000000000000 b00f88d6e09fd9e767fc3246c971bf0d14f0621e Glooow1024 &lt;glooow1024@gmail.com&gt; 1577615247 +0800branch: Created from master<br>b00f88d6e09fd9e767fc3246c971bf0d14f0621e 4b60ac6ea7ebab972920f84bd07de3d20d7d5804 Glooow1024 &lt;glooow1024@gmail.com&gt; 1577616495 +0800commit: commit br 1<br><br></code></pre></td></tr></table></figure><p>重要的是 <code>logs/HEAD</code></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta">$</span><span class="bash"> cat .git/logs/HEAD</span><br>0000000000000000000000000000000000000000 38f74e0a07955212bdb02699f6d73cd7420cd823 Glooow1024 &lt;glooow1024@gmail.com&gt; 1577605375 +0800commit (initial): commit 1<br>38f74e0a07955212bdb02699f6d73cd7420cd823 b00f88d6e09fd9e767fc3246c971bf0d14f0621e Glooow1024 &lt;glooow1024@gmail.com&gt; 1577606828 +0800commit: commit 2<br>b00f88d6e09fd9e767fc3246c971bf0d14f0621e b00f88d6e09fd9e767fc3246c971bf0d14f0621e Glooow1024 &lt;glooow1024@gmail.com&gt; 1577615776 +0800checkout: moving from master to br1<br>b00f88d6e09fd9e767fc3246c971bf0d14f0621e 4b60ac6ea7ebab972920f84bd07de3d20d7d5804 Glooow1024 &lt;glooow1024@gmail.com&gt; 1577616495 +0800commit: commit br 1<br><br></code></pre></td></tr></table></figure><p>可以看到这里记录了我们转移分支并提交的记录。</p><h3 id="小结">小结</h3><blockquote><p><strong>敲黑板！重点</strong></p><ol type="1"><li>实质上我们的每个 branch 都相当于维护了一个 <code>commit</code>文件的单项链表；</li><li>命令 <code>git branch</code> 实际上就是在<code>.git/refs/heads</code> 和 <code>.git/logs/refs/heads</code>分别创建一个对应的文件，文件名就是分支名，文件中保存了这个分支对应的<code>commit</code> 链表的各项；</li><li>我们通过 <code>git checkout</code> 实际上就是修改<code>.git/HEAD</code> 使其指向对应的分支在 <code>.git/refs/</code>中的文件；</li></ol></blockquote><h3 id="git-merge">2.4 <code>git merge</code></h3><p>现在让我们合并一下分支</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta">$</span><span class="bash"> git merge br1</span><br>Updating b00f88d..4b60ac6<br>Fast-forward<br> a.txt | 1 +<br> 1 file changed, 1 insertion(+)<br></code></pre></td></tr></table></figure><p>我们再来看一下 <code>HEAD</code> 文件</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta">$</span><span class="bash"> cat .git/logs/HEAD</span><br>0000000000000000000000000000000000000000 38f74e0a07955212bdb02699f6d73cd7420cd823 Glooow1024 &lt;glooow1024@gmail.com&gt; 1577605375 +0800    commit (initial): commit 1<br>38f74e0a07955212bdb02699f6d73cd7420cd823 b00f88d6e09fd9e767fc3246c971bf0d14f0621e Glooow1024 &lt;glooow1024@gmail.com&gt; 1577606828 +0800    commit: commit 2<br>b00f88d6e09fd9e767fc3246c971bf0d14f0621e b00f88d6e09fd9e767fc3246c971bf0d14f0621e Glooow1024 &lt;glooow1024@gmail.com&gt; 1577615776 +0800    checkout: moving from master to br1<br>b00f88d6e09fd9e767fc3246c971bf0d14f0621e 4b60ac6ea7ebab972920f84bd07de3d20d7d5804 Glooow1024 &lt;glooow1024@gmail.com&gt; 1577616495 +0800    commit: commit br 1<br>4b60ac6ea7ebab972920f84bd07de3d20d7d5804 b00f88d6e09fd9e767fc3246c971bf0d14f0621e Glooow1024 &lt;glooow1024@gmail.com&gt; 1577625498 +0800    checkout: moving from br1 to master<br>b00f88d6e09fd9e767fc3246c971bf0d14f0621e 4b60ac6ea7ebab972920f84bd07de3d20d7d5804 Glooow1024 &lt;glooow1024@gmail.com&gt; 1577625944 +0800    merge br1: Fast-forward<br></code></pre></td></tr></table></figure><p>这里的 <code>merge</code> 过程实际上就是把 master 对应的指针移到了<code>br1</code> 对应的指针处，看下图很容易理解（图片来自于https://git-scm.com/book/zh/v2/Git-%E5%88%86%E6%94%AF-%E5%88%86%E6%94%AF%E7%9A%84%E6%96%B0%E5%BB%BA%E4%B8%8E%E5%90%88%E5%B9%B6）</p><figure><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2019/basic-branching-3.png"alt="git branch" /><figcaption aria-hidden="true">git branch</figcaption></figure><p>删除分支实质上也就是删除了分支文件 <code>.git/refs/heads/br1</code>和 <code>.git/logs/refs/heads/br1</code></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta">$</span><span class="bash"> git branch -d br1</span><br></code></pre></td></tr></table></figure><h2 id="git-的标签管理">3. Git 的标签管理</h2><p>我们先看一下</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta">$</span><span class="bash"> git <span class="hljs-built_in">log</span> --pretty=oneline</span><br>4b60ac6ea7ebab972920f84bd07de3d20d7d5804 (HEAD -&gt; master) commit br 1<br>b00f88d6e09fd9e767fc3246c971bf0d14f0621e commit 2<br>38f74e0a07955212bdb02699f6d73cd7420cd823 commit 1<br></code></pre></td></tr></table></figure><h3 id="git-tag">3.1 <code>git tag</code></h3><p>打个标签</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta">$</span><span class="bash"> git tag -a v0.1 b00f</span><br></code></pre></td></tr></table></figure><p>然后就会发现 <code>.git/refs/tags/</code> 中多了一个<code>v0.1</code> 文件，实际上就是一个指针（<code>commit</code>文件的哈希值），跟 <code>.git/refs/heads/master</code>中的指针没有区别</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta">$</span><span class="bash"> cat .git/refs/tags/v0.1</span><br>3ad673290fa12aecc5bb66e7c7d3f83157914957<br></code></pre></td></tr></table></figure><p>需要注意的是增加 tag 并不会修改 <code>.git/logs</code>中的文件，因为这个文件夹是维护版本更新历史的，打标签并没有产生新的版本。</p>]]></content>
    
    
    <categories>
      
      <category>Git</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Git</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Git 工作原理(一)</title>
    <link href="/2019/12/29/git/git-principle-1/"/>
    <url>/2019/12/29/git/git-principle-1/</url>
    
    <content type="html"><![CDATA[<p>今天讲一下 Git 工作原理，本文主要目的不是讲解如何使用各种 git命令，而是关于一些常用 git 命令之后仓库中会出现什么变化，以及 git是如何进行仓库的版本控制的。</p><span id="more"></span><p>[TOC]</p><h2 id="git-的文件管理">1. Git 的文件管理</h2><h3 id="git-文件存储">1.1 Git 文件存储</h3><p>git 是怎么管理文件的呢？首先我们需要理解 git对文件的保存逻辑，这很重要：</p><blockquote><p><strong>git 根据文件内容来管理文件，而不是文件名</strong>！</p><p>比如某个仓库中，完全相同的两个文件我们保存了 2份，只不过文件名不同，那么在 git看来这两个是同一个文件，他会根据文件内容经过SHA1算法计算出一个对应的哈希值，然后根据哈希值来索引文件。</p><p>注：这么做的好处是显而易见的，相同的两个文件不再需要多存储一份。</p></blockquote><p>这是怎么体现出来的呢？其实 git会把我们仓库中的原始文件压缩成二进制文件，然后都保存在<code>.git/objects/</code>文件夹下，每个文件的命名就是计算出来的哈希值。我们可以用如下命令来查看git 给我们保存的所有文件。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">git cat-file --batch-check -batch-all-objects<br></code></pre></td></tr></table></figure><p>现在我们新建一个仓库试试吧</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta">$</span><span class="bash"> git init</span><br><span class="hljs-meta">$</span><span class="bash"> <span class="hljs-built_in">echo</span> <span class="hljs-string">&#x27;111&#x27;</span> &gt; a.txt</span><br>mkdir dir<br><span class="hljs-meta">$</span><span class="bash"> <span class="hljs-built_in">echo</span> <span class="hljs-string">&#x27;222&#x27;</span> &gt; dir/b.txt</span><br></code></pre></td></tr></table></figure><p>好，我们来看看 <code>.git/objects/</code>文件夹。咦？怎么是空的？什么也没有。哦我们只是修改了工作区，还没添加修改呢，来添加一下</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta">$</span><span class="bash"> git add .</span><br></code></pre></td></tr></table></figure><p>好，现在来看看 <code>.git/objects/</code> 吧</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta">$</span><span class="bash"> git cat-file --batch-check --batch-all-objects</span><br>58c9bdf9d017fcd178dc8c073cbfcbb7ff240d6c blob 4<br>c200906efd24ec5e783bee7f23b5d7c941b0c12c blob 4<br></code></pre></td></tr></table></figure><h3 id="git-文件类型">1.2 Git 文件类型</h3><p>应用上述命令后，三列分别表示文件的哈希值、<strong>文件类型</strong>、长度。注意这里出现了git 的文件类型，主要有 4种：<code>blob</code>、<code>tree</code>、<code>commit</code>、<code>tag</code>。</p><p>我们可以用以下命令查看文件类型</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">git cat-file -t 58c9<br></code></pre></td></tr></table></figure><p>可以用以下命令查看内容</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">git cat-file -p 58c9<br></code></pre></td></tr></table></figure><p>前面我们只看到了 <code>blob</code> 文件，什么情况下会出现<code>tree</code> 和 <code>commit</code> 呢？注意我们现在只是新建 txt 并add 了，还没有提交，那我们 commit 一下吧</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta">$</span><span class="bash"> git commit -m <span class="hljs-string">&quot;commit 1&quot;</span></span> <br></code></pre></td></tr></table></figure><p>然后再查看一下 <code>.git/objects/</code> 文件夹</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta">$</span><span class="bash"> git cat-file --batch-check --batch-all-objects</span><br>38f74e0a07955212bdb02699f6d73cd7420cd823 commit 175<br>58c9bdf9d017fcd178dc8c073cbfcbb7ff240d6c blob 4<br>aef06e3d27cc6b17730daf473499ab58b68e772d tree 33<br>b02b1164ed5a571b723cb25d978780b15d826d62 tree 63<br>c200906efd24ec5e783bee7f23b5d7c941b0c12c blob 4<br></code></pre></td></tr></table></figure><p>咦，他们出现了！！！让我们分别看看他们是什么东西~</p><h4 id="blob-文件">1.2.1 <code>blob</code> 文件</h4><p>如果是 <code>blob</code> 文件我们可以直接看到文件的内容</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta">$</span><span class="bash"> git cat-file -p 58c9</span><br>111<br></code></pre></td></tr></table></figure><h4 id="tree-文件">1.2.2 <code>tree</code> 文件</h4><p>如果是 <code>tree</code> 文件我们可以看到目录信息</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta">$</span><span class="bash"> git cat-file -p b02b</span><br>100644 blob 58c9bdf9d017fcd178dc8c073cbfcbb7ff240d6c    a.txt<br>040000 tree aef06e3d27cc6b17730daf473499ab58b68e772d    dir<br></code></pre></td></tr></table></figure><p>四列内容分别为文件权限、文件类型、哈希值、文件名。再查看最后一个<code>tree</code> 文件的内容</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta">$</span><span class="bash"> git cat-file -p aef0</span><br>100644 blob c200906efd24ec5e783bee7f23b5d7c941b0c12c    b.txt<br></code></pre></td></tr></table></figure><p>这不就是我们工作空间中的文件结构嘛！</p><blockquote><p>注意我们工作空间中的文件对应的<strong>文件名</strong>和权限等信息是保存在<code>tree</code> 类型的文件中，而不是 <code>blob</code> 文件中哦！</p></blockquote><h4 id="commit-文件">1.2.3 <code>commit</code> 文件</h4><p>让我们再看看这个 <code>commit</code></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta">$</span><span class="bash"> git cat-file -p 38f7</span><br>tree b02b1164ed5a571b723cb25d978780b15d826d62<br>author Glooow1024 &lt;glooow1024@gmail.com&gt; 1577605375 +0800<br>committer Glooow1024 &lt;glooow1024@gmail.com&gt; 1577605375 +0800<br><br>commit 1<br></code></pre></td></tr></table></figure><p>其实 <code>commit</code> 就是指向了当前仓库的根目录所对应的<code>tree</code> 文件嘛。</p><h4 id="tag-文件">1.2.4 <code>tag</code> 文件</h4><p>这个我们以后再说。</p><h4 id="index-文件">1.2.5 <code>index</code> 文件</h4><p>细心的话可以发现我们 add 以后 <code>.git/</code> 文件夹下的<code>index</code> 文件也会被修改，我们可以用以下命令查看他的内容</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta">$</span><span class="bash"> git ls-files --stage</span><br>100644 58c9bdf9d017fcd178dc8c073cbfcbb7ff240d6c 0       a.txt<br>100644 c200906efd24ec5e783bee7f23b5d7c941b0c12c 0       dir/b.txt<br></code></pre></td></tr></table></figure><p>其实它的内容跟 <code>tree</code>是类似的，不过多了一列，这个我们后面再说</p><h4 id="小结">小结</h4><blockquote><p><strong>敲黑板</strong>！各种文件的作用是</p><ul><li><code>blob</code>：工作区的任何文件都会被 git 压缩后以<code>blob</code> 形式保存一个副本在 <code>.git/objects/</code>文件夹下，文件名就是计算的哈希值；</li><li><code>tree</code>：这个其实就是目录文件，描述当前文件夹结构；注意文件名和权限等信息是保存在<code>tree</code> 文件中而不是 <code>blob</code>文件，后者只保存文件内容；</li><li><code>commit</code>：记录提交的信息，指向仓库当前根目录的<code>tree</code> 文件；</li><li><code>tag</code>：记录标签信息。</li></ul></blockquote><h2 id="git-的版本控制">2. Git 的版本控制</h2><h3 id="git-add-会发生什么">2.1 <code>git add</code> 会发生什么</h3><p>假如我们现在修改了其中一个文件呢？比如</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta">$</span><span class="bash"> <span class="hljs-built_in">echo</span> <span class="hljs-string">&#x27;hahaha&#x27;</span> &gt; a.txt</span><br><span class="hljs-meta">$</span><span class="bash"> git add .</span><br></code></pre></td></tr></table></figure><p>再看一下 <code>.git/objects/</code> 文件夹</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta">$</span><span class="bash"> git cat-file --batch-check --batch-all-objects</span><br>38f74e0a07955212bdb02699f6d73cd7420cd823 commit 175<br>445a69c00e48288ac420a2ead9ae5a1cb4cd36d4 blob 7<br>58c9bdf9d017fcd178dc8c073cbfcbb7ff240d6c blob 4<br>aef06e3d27cc6b17730daf473499ab58b68e772d tree 33<br>b02b1164ed5a571b723cb25d978780b15d826d62 tree 63<br>c200906efd24ec5e783bee7f23b5d7c941b0c12c blob 4<br></code></pre></td></tr></table></figure><p>增加了什么？</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">445a69c00e48288ac420a2ead9ae5a1cb4cd36d4 blob 7<br></code></pre></td></tr></table></figure><p>我们来看看这个文件，他就是一个 <code>blob</code> 文件</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta">$</span><span class="bash"> git cat-file -p 445a</span><br>hahaha<br></code></pre></td></tr></table></figure><p>看来就是把我们修改后的文件又存储了一个 <code>blob</code>文件，注意修改前的文件并没有删除哦，也就是修改前的 <code>a.txt</code>对应的 <code>58c9bdf9d017fcd178dc8c073cbfcbb7ff240d6c blob 4</code>还在，方便我们以后版本回退嘛。</p><p>那么我们再看看 <code>index</code> 文件</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta">$</span><span class="bash"> git ls-files --stage</span><br>100644 445a69c00e48288ac420a2ead9ae5a1cb4cd36d4 0       a.txt<br>100644 c200906efd24ec5e783bee7f23b5d7c941b0c12c 0       dir/b.txt<br></code></pre></td></tr></table></figure><p>咦，<code>a.txt</code> 文件的指针已经修改了！！！指向了最新的<code>blob</code> 文件。好了我们知道了</p><blockquote><p><code>index</code> 文件在执行 <code>git add</code>之后就会被修改，总是保存最新的仓库根目录信息。事实上，这也<strong>是我们下次<code>commit</code> 所要提交的信息</strong>！！！</p><p>事实上，<code>index</code> 就是我们常说的 git的<strong>暂存区</strong>！！！</p></blockquote><h3 id="git-commit-会发生什么">2.2 <code>git commit</code>会发生什么</h3><p>如果再提交一下修改呢？</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta">$</span><span class="bash"> git commit -m <span class="hljs-string">&quot;commit 2&quot;</span></span><br><span class="hljs-meta">$</span><span class="bash"> git cat-file --batch-check --batch-all-objects</span><br>0ed6427de6990a17351bf0e0fd648b642e15f967 tree 63<br>38f74e0a07955212bdb02699f6d73cd7420cd823 commit 175<br>445a69c00e48288ac420a2ead9ae5a1cb4cd36d4 blob 7<br>58c9bdf9d017fcd178dc8c073cbfcbb7ff240d6c blob 4<br>aef06e3d27cc6b17730daf473499ab58b68e772d tree 33<br>b00f88d6e09fd9e767fc3246c971bf0d14f0621e commit 223<br>b02b1164ed5a571b723cb25d978780b15d826d62 tree 63<br>c200906efd24ec5e783bee7f23b5d7c941b0c12c blob 4<br></code></pre></td></tr></table></figure><p>好了，新增加的有</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">0ed6427de6990a17351bf0e0fd648b642e15f967 tree 63<br>b00f88d6e09fd9e767fc3246c971bf0d14f0621e commit 223<br></code></pre></td></tr></table></figure><p>我们可以很容易推断，新的 <code>tree</code>文件就描述了更新后的根目录信息，可以看出 <code>a.txt</code>文件的指针（哈希值）变了，但是由于 dir文件夹中的内容没有任何修改，所以他的指针不变</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta">$</span><span class="bash"> git cat-file -p 0ed6</span><br>100644 blob 445a69c00e48288ac420a2ead9ae5a1cb4cd36d4    a.txt<br>040000 tree aef06e3d27cc6b17730daf473499ab58b68e772d    dir<br></code></pre></td></tr></table></figure><p>我们再看看新的 <code>commit</code> 文件，可以发现还多了一个<code>parent</code> 选项，也就是指向了上一次提交对应的的<code>commit</code> 文件。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta">$</span><span class="bash"> git cat-file -p b00f</span><br>tree 0ed6427de6990a17351bf0e0fd648b642e15f967<br>parent 38f74e0a07955212bdb02699f6d73cd7420cd823<br>author Glooow1024 &lt;glooow1024@gmail.com&gt; 1577606828 +0800<br>committer Glooow1024 &lt;glooow1024@gmail.com&gt; 1577606828 +0800<br><br>commit 2<br></code></pre></td></tr></table></figure><h3 id="小结-1">小结</h3><blockquote><p><strong>重点来了，敲黑板</strong>！</p><ul><li><code>git add</code><ul><li>对每个修改后的文件压缩，并保存一个新的 <code>blob</code> 文件在<code>.git/objects/</code> 文件夹下，用哈希值命名文件；</li><li>修改 <code>.git/index</code> 保存最新的根目录信息；</li></ul></li><li><code>git commit</code><ul><li>生成新的 <code>tree</code> 文件保存在 <code>.git/objects/</code>目录下，记录新的仓库文件结构信息；</li><li>生成新的 <code>commit</code> 文件保存在 <code>.git/objects/</code>目录下，指向当前最新的根目录的 <code>tree</code>文件；同时该文件中还存在以一项 <code>parent</code> 指向上一次的<code>commit</code> 文件；</li></ul></li></ul><p>实际上，只需要<strong>1 个 <code>commit</code>，若干个<code>tree</code> 和若干个 <code>blob</code>文件</strong>就可以<strong>完整描述</strong>仓库的当前提交版本。因此 git只需要用一个单向链表记录 <code>commit</code>文件之间的指向关系，就可以描述版本变化。</p></blockquote>]]></content>
    
    
    <categories>
      
      <category>Git</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Git</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Particle Filter</title>
    <link href="/2019/12/10/signal-processing/particle%20filter/"/>
    <url>/2019/12/10/signal-processing/particle%20filter/</url>
    
    <content type="html"><![CDATA[<p>今天我们来讲一下粒子滤波算法，这也是我在学习过程中的一个笔记，由于有很多的个人理解，有不对的地方欢迎大家批评指正。</p><span id="more"></span><p>[TOC]</p><h2 id="贝叶斯滤波">1. 贝叶斯滤波</h2><p>贝叶斯滤波是我们理解粒子滤波的基础。假设我们有如下图的隐马尔科夫模型(HiddenMarkov Model)，并且有如下的系统方程与观测方程，我们只有观测值 <spanclass="math inline">\(\boldsymbol{y}_{1:T}\)</span>，但是现在想要根据观测值估计隐变量<spanclass="math inline">\(\boldsymbol{x}_{1:T}\)</span>，也就是<strong>滤波</strong>所要做的事情。<span class="math display">\[\begin{align}\text{System Model}&amp;: x_{k}=f_{k}\left(x_{k-1}, v_{k-1}\right) \\\text{Observation Model}&amp;: \mathrm{y}_{k}=h_{k}\left(\mathrm{x}_{k},\mathrm{n}_{k}\right)\end{align}\]</span> <imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2019/pf_hmm.PNG"alt="hmm" /></p><p>假设我们现在已经处于 <spanclass="math inline">\(t_{k-1}\)</span>，且已经获得了 <spanclass="math inline">\(p({x}_{k-1}|\boldsymbol{y}_{1:k-1})\)</span>，这个概率分布的含义是什么呢？我们现在已经有了前<span class="math inline">\(k-1\)</span> 个时刻的观测值 <spanclass="math inline">\(\boldsymbol{y}_{1:k-1}\)</span>，并且根据这些观测值估计了<span class="math inline">\(k-1\)</span> 时刻隐变量 <spanclass="math inline">\(x_{k-1}\)</span>的<strong>后验概率</strong>分布，也即 <spanclass="math inline">\(p({x}_{k-1}|\boldsymbol{y}_{1:k-1})\)</span>。那么接下来到<span class="math inline">\(k\)</span> 时刻，我们又获得了一个观测 <spanclass="math inline">\(y_k\)</span>，要怎么估计新的后验概率分布 <spanclass="math inline">\(p({x}_{k}|\boldsymbol{y}_{1:k})\)</span>呢？我们通过<strong>预测</strong>和<strong>更新</strong>两个阶段来估计，下面我就解释一下这两个阶段的含义。</p><h3 id="预测">1.1 预测</h3><p>前面说了我们有系统模型和观测模型，首先根据系统模型，我们有了 <spanclass="math inline">\(k-1\)</span> 时刻的后验，就可以根据 <spanclass="math inline">\(x_{k-1}\)</span> 到 <spanclass="math inline">\(x_k\)</span> 的转移模型得到 <spanclass="math inline">\(x_k\)</span>对应的概率分布，这个过程就叫做<strong>预测(Update)</strong>。通过预测阶段，我们可以获得<strong>先验概率</strong>分布(注意这里我们将<span class="math inline">\(p({x}_k|\boldsymbol{y}_{1:k-1})\)</span>称为先验概率分布) <span class="math display">\[\begin{align}p({x}_k|\boldsymbol{y}_{1:k-1})=\intp({x}_k|x_{k-1})p(x_{k-1}|\boldsymbol{y}_{1:k-1})dx_{k-1}\end{align}\]</span> 也就是说，我们即使没有观测值，也能对 <spanclass="math inline">\(x_k\)</span>的分布进行估计，但是由于没有利用观测值 <spanclass="math inline">\(y_k\)</span>带来的信息，因此这个估计是不准确的，下面我们就需要用观测值对这个先验概率分布进行纠正，也就是<strong>更新</strong>阶段。</p><h3 id="更新">1.2 更新</h3><p>有了<strong>先验</strong>，又有了观测，根据贝叶斯公式，我们可以很容易得到<strong>后验概率</strong>分布<span class="math inline">\(p\left(x_{k} | \boldsymbol{y}_{1:k}\right)\)</span>。怎么理解下面一个式子呢？我们有似然函数 <spanclass="math inline">\(p\left(y_{k} | x_{k}\right)\)</span>，现在有了观测<span class="math inline">\(y_k\)</span>，那么似然值越大，表明对应的<span class="math inline">\(x_k\)</span> 的概率应该也越大，就是用<strong>似然函数</strong>对<strong>先验概率</strong>进行<strong>加权</strong>就得到了<strong>后验概率</strong>。<span class="math display">\[\begin{align}p\left(x_{k} | \boldsymbol{y}_{1: k}\right)&amp;=\frac{p\left(y_{k} |x_{k},\boldsymbol{y}_{1: k-1}\right) p\left(x_{k} | \boldsymbol{y}_{1:k-1}\right)}{p\left(y_{k} | \boldsymbol{y}_{1: k-1}\right)} \\&amp;\propto p\left(y_{k} | x_{k},\boldsymbol{y}_{1: k-1}\right)p\left(x_{k} | \boldsymbol{y}_{1: k-1}\right) \\&amp;= p\left(y_{k} | x_{k}\right) p\left(x_{k} | \boldsymbol{y}_{1:k-1}\right)\end{align}\]</span> &gt; 怎么理解这个加权呢？举个栗子 &gt; &gt; 比如</p><h3 id="总结">总结</h3><p>总结起来，我们滤波分为两个阶段 <span class="math display">\[\begin{align}\text{Prediction}&amp;: p({x}_k|\boldsymbol{y}_{1:k-1})=\intp({x}_k|x_{k-1})p(x_{k-1}|\boldsymbol{y}_{1:k-1})dx_{k-1} \\\text{Update}&amp;: p\left(x_{k} | \boldsymbol{y}_{1: k}\right)\proptop\left(y_{k} | x_{k}\right) p\left(x_{k} | \boldsymbol{y}_{1:k-1}\right)\end{align}\]</span>可以看到，上面的预测阶段含有<strong>积分</strong>，这在实际当中往往是很难计算的，而对于那些非常规的PDF，甚至不能给出解析解。解决这种问题一般有两种思路：</p><ul><li>建立简单的模型，获得解析解，如卡尔曼滤波(KalmanFilter)及EKF、UKF等；</li><li>建立复杂的模型，获得近似解，如粒子滤波(Particle Filter)等。</li></ul><h2 id="卡尔曼滤波">2. 卡尔曼滤波</h2><p>卡尔曼滤波的思路就是将系统建模<strong>线性模型</strong>，隐变量、控制变量、控制噪声与观测噪声均为高斯分布，那么观测变量也是随机变量，整个模型中所有的随机变量都是<strong>高斯</strong>的！高斯分布是我们最喜欢的分布，因为在前面贝叶斯滤波的<strong>预测阶段</strong>我们可以不用积分了，只需要计算均值和协方差就可以了！根据系统模型和观测模型，我们可以获得滤波的闭式解，这就是卡尔曼滤波的思想。<span class="math display">\[\begin{align}\text{System Model}&amp;: \mathrm{x}_{k}=A\mathrm{x}_{k-1} +B\mathrm{u}_{k-1} + v_{k-1} \\\text{Observation Model}&amp;: \mathrm{y}_{k}=C\mathrm{x}_{k}+\mathrm{n}_{k}\end{align}\]</span>但实际中要求线性系统模型往往是很困难的，对于非线性模型，如果我们还想应用卡尔曼滤波该怎么办呢？线性近似，也就是求一个雅可比矩阵(Jacobi)，这就是扩展卡尔曼滤波(EKF)。</p><h2 id="大数定律">3. 大数定律</h2><p>粒子滤波是什么是意思呢？我们可以用大量的采样值来描述一个概率分布，当我们按照一个概率分布进行采样的时候，某个点的概率密度越高，这个点被采到的概率越大，当采样数目足够大(趋于无穷)的时候，粒子出现的频率就可以用来表示对应的分布，实际中我们可以理解一个粒子就是一个采样。</p><figure><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2019/pf_particle.png"alt="particle" /><figcaption aria-hidden="true">particle</figcaption></figure><p>但是对于<strong>离散型</strong>的随机变量还好，可以很容易的求出来状态空间中每个状态的频率。但如果对于<strong>连续分布</strong>，其实是很不方便的，所幸实际中我们也不需要获得概率分布的全部信息，一般只需要求出<strong>期望</strong>就可以了。</p><p>下面为了公式书写和推导方便，以离散型随机变量为例，假设状态空间为<span class="math inline">\(\mathcal{Z}=\{1,2,...,K\}\)</span>，有 <spanclass="math inline">\(N\)</span> 个采样样本 <spanclass="math inline">\(z_i \in \mathcal{Z}\)</span>，服从概率分布 <spanclass="math inline">\(q(\mathbf{z})\)</span>。我们将根据 <spanclass="math inline">\(N\)</span> 个采样样本 <spanclass="math inline">\(\boldsymbol{z}_{1:N}\)</span>得到的分布记为<strong>经验分布</strong> <spanclass="math inline">\(\hat{p}(b|\boldsymbol{z}_{1:N}) =\frac{1}{N}\sum_i \mathbb{I}(b-z_i)\)</span>，其中 <spanclass="math inline">\(\mathbb{I}(\cdot)\)</span> 为指示函数，那么当<span class="math inline">\(N\)</span> 足够大的时候，经验分布 <spanclass="math inline">\(\hat{p}(b|\boldsymbol{z}_{1:N})\)</span>就足够接近真实分布 <spanclass="math inline">\(q(\mathbf{z})\)</span>。现在我们想估计随机变量<span class="math inline">\(\mathsf{t}=g(\mathsf{z})\)</span> 的期望，即<span class="math display">\[\begin{align}\mathbb{E}[\mathsf{t}] &amp;=\mathbb{E}[g(\mathsf{z})]=\sum_{b\in\mathcal{Z}}g(b)q(b) \notag\\&amp;\approx \sum_b g(b)\hat{p}(b|\boldsymbol{z}_{1:N}) \notag\\&amp;= \sum_b g(b)\frac{1}{N}\sum_i \mathbb{I}(b-z_i) \notag\\&amp;= \frac{1}{N}\sum_i g(z_i)\end{align}\]</span>也就是说，我们只需要对样本进行<strong>简单求和</strong>就可以了！连续型随机变量也是类似的，所以在后面的粒子滤波中，我们利用粒子估计了概率密度分布，要想求期望就只需要进行求和平均就可以了。</p><h2 id="粒子滤波简单实例">4. 粒子滤波简单实例</h2><p>好了，有了前面的预备知识，我们可以先看一个粒子滤波的简单例子。</p><p>假设我们现在有采样好的 <span class="math inline">\(N\)</span> 个粒子<span class="math inline">\(\{x_{k-1}^i\}_{i=1}^N\)</span>，他们服从分布<spanclass="math inline">\(p({x}_{k-1}|\boldsymbol{y}_{1:k-1})\)</span>，那么我们现在如何进行贝叶斯滤波中的<strong>预测</strong>和<strong>更新</strong>阶段呢？</p><h3 id="预测-1">4.1 预测</h3><p>回顾一下预测的公式 <span class="math display">\[\text{Prediction}: p({x}_k|\boldsymbol{y}_{1:k-1})=\intp({x}_k|x_{k-1})p(x_{k-1}|\boldsymbol{y}_{1:k-1})dx_{k-1} \\\]</span> 想一下：只要我们让每个粒子 <spanclass="math inline">\(x_{k-1}^i\)</span>“<strong>进化</strong>”一步，也就是说按照分布 <spanclass="math inline">\(p(x_k|x_{k-1})\)</span> 进行采样，使得 <spanclass="math inline">\(x_k^i \simp(x_k|x_{k-1}^i)\)</span>，这样我们就获得了 <spanclass="math inline">\(N\)</span> 个新的粒子 <spanclass="math inline">\(\{x_k^i\}_{i=1}^N\)</span>。很容易验证，如果 <spanclass="math inline">\(\{x_{k-1}^i\}_{i=1}^N\)</span> 能够很好的表示<span class="math inline">\(p({x}_{k-1}|\boldsymbol{y}_{1:k-1})\)</span>的话，那么 <span class="math inline">\(\{x_k^i\}_{i=1}^N\)</span>也能很好的表示 <spanclass="math inline">\(p({x}_k|\boldsymbol{y}_{1:k-1})\)</span>(这一部分可以凭直观感觉来理解，这是一个很自然的事情，也可以用前面的经验分布的思路进行公式推导)。</p><p>这样做的好处是什么呢？我们<strong>避免了积分</strong>！只需要对一个已知的分布<span class="math inline">\(p(x_k|x_{k-1}^i)\)</span>进行采样，而这个分布是我们假设的系统模型，可以是很简单的，因此采样也很方便。</p><h3 id="更新-1">4.2 更新</h3><p>通过预测我们获得了 <span class="math inline">\(x_k^i \simp(x_k|x_{k-1}^i)\)</span>，这 <span class="math inline">\(N\)</span>个粒子就描述了<strong>先验概率</strong>分布。接下来就是更新，再回顾一下更新的公式<span class="math display">\[\text{Update}: p\left(x_{k} | \boldsymbol{y}_{1: k}\right)\proptop\left(y_{k} | x_{k}\right) p\left(x_{k} | \boldsymbol{y}_{1:k-1}\right)\]</span>更新是什么呢？前面提到了：更新就是用<strong>似然函数</strong>对<strong>先验概率</strong>进行<strong>加权</strong>就得到了<strong>后验概率</strong>。如果简单的把<span class="math inline">\(x_k^i\)</span>带入到上面的公式里，就可以得到下面的式子 <span class="math display">\[p\left(x_{k}^i | \boldsymbol{y}_{1: k}\right)\propto p\left(y_{k} |x_{k}^i\right) p\left(x_{k}^i | \boldsymbol{y}_{1: k-1}\right)\]</span>实际上就表示每个<strong>粒子</strong>有不同的<strong>权重</strong>。</p><blockquote><p>这里怎么理解呢？想一下前面提到的<strong>经验分布</strong>，我们只需要用粒子出现的<strong>频率</strong>来表示对应的概率，实际上就是在统计频率的时候每个粒子的权重都是相同的，出现一次计数就加一。</p><p>而这里的区别是什么呢？由于我们有一个观测值 <spanclass="math inline">\(y_k\)</span>，根据 <spanclass="math inline">\(y_k\)</span> 来反推，某一个粒子 <spanclass="math inline">\(i_1\)</span> 的导致 <spanclass="math inline">\(y_k\)</span>出现的概率更大，那么我们在统计频率的时候，就给这个粒子加一个更大的权重，以表示我们更相信/重视这个粒子。</p></blockquote><p>那么问题来了，前面我们说了滤波过程中要想求期望，只需要简单求和就可以了<span class="math display">\[\mathbb{E}[\mathsf{t}] = \frac{1}{N}\sum_i g(z_i)\]</span>现在粒子有了权重怎么办呢，同理，加个权就好了(推导也很简单，相信大家都会)，下面的式子里对权重进行了归一化<span class="math display">\[\mathbb{E}[\mathsf{t}] = \sum_i \frac{w_i}{\sum_j w_j}g(z_i)\]</span></p><h3 id="递推">4.3 递推</h3><p>前面只讲了一次预测和一次更新的过程，注意到我们前面只是从 <spanclass="math inline">\(k-1\)</span> 到 <spanclass="math inline">\(k\)</span>时刻的滤波过程，但每一轮循环原理都是相同的。</p><p>不过细心的朋友们可能会觉得不太对劲，前面一个阶段的例子里，预测之前我们有采样<spanclass="math inline">\(\{x_{k-1}^i\}_{i=1}^N\)</span>，推导过程中我们是默认这些粒子的权重都是相同的，然后我们进行了预测和更新，但是更新之后我们给每个粒子加权了呀，到下一个阶段怎么办？！！！也很简单，预测阶段不必要求每个粒子的权重都相同，也加上一个权重就好了。也就是说我们时时刻刻都保存有每个粒子的权重信息。</p><p>这样我们就可以得到一个完整的粒子滤波算法了！但是还有问题！</p><h3 id="重采样">重采样</h3><p>但是呢，有人发现了上面的算法不好啊！不是因为麻烦，而是滤波到最后会发现只有少数一部分粒子有很大的权重，而其他绝大部分粒子的权重几乎为0，这就意味着对于那些“不重要”的粒子，他们在我们求期望的时候贡献并不大，但是我们却花费了大量的计算精力来维护这些粒子，这样不好不好！于是就有人提出了<strong>重采样</strong>。</p><p>重采样什么意思呢？你们粒子的权重不是不同吗，那我就采取手段给你们整相同了！简单理解，有两个粒子，粒子<span class="math inline">\(a\)</span> 的权重是 8，粒子 <spanclass="math inline">\(b\)</span> 权重是 2，那我就把粒子 <spanclass="math inline">\(a\)</span> 复制 8 份，粒子 <spanclass="math inline">\(b\)</span> 复制 2 份，这样得到的 10个粒子权重就都是 1 了。但是另一个问题是一开始我们只有 2个粒子，这样弄完我们就有 10个粒子了，如果一直这么做我们的粒子数会越来越多，算力跟不上。那就从这 10个粒子里均匀分布地随机抽 2 个！那么粒子 <spanclass="math inline">\(a\)</span> 的概率就是 <spanclass="math inline">\(0.8\)</span>，这就成了。</p><figure><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2019/pf_resample.png"alt="resample" /><figcaption aria-hidden="true">resample</figcaption></figure><p>至此，加上重采样我们就获得了一个完整的比较好用的粒子滤波算法</p><figure><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2019/pf_sir.PNG"alt="sir" /><figcaption aria-hidden="true">sir</figcaption></figure><h2 id="粒子滤波原理推导">5. 粒子滤波原理推导</h2><p>但是还有一个问题，就是前面我们直接说有 <spanclass="math inline">\(N\)</span> 个粒子 <spanclass="math inline">\(x_{k-1}^i \simp({x}_{k-1}|\boldsymbol{y}_{1:k-1})\)</span>，但是第 1步(刚开始)的时候我们怎么获得这些粒子来描述 <spanclass="math inline">\(p(x_1|y_1)\)</span>啊？如果是高斯分布还好，我们可以很方便的对高斯分布进行采样，但是如果是一个特别特别特别复杂的分布呢？我们甚至不能写出解析表达式，更没办法按照这个分布进行随机采样，那我们是不是就凉了？不！我们前面不是讲了粒子可以有权重嘛。</p><p>假如我们现在有另一个分布 <spanclass="math inline">\(q(\mathbf{x}_{1:k}|\mathbf{y}_{1:k})\)</span>，这个分布是我们自己指定的，可以很简单，而且我们可以按照这个分布来进行采样，那么我们就有<span class="math inline">\(x_{k-1}^i \simq(\mathbf{x}_{1:k}|\mathbf{y}_{1:k})\)</span>，那么我们怎么用这些粒子来表示我们想要得到的真正的分布<spanclass="math inline">\(p(\mathbf{x}_{0:k}|\mathbf{y}_{1:k})\)</span>呢？再加个权就行了，就像前面用似然函数进行加权。 <spanclass="math display">\[\begin{align}p(\mathbf{x}_{0:k}|\mathbf{y}_{1:k})&amp;\approx\sum_{i=1}^{N}w_k^i\delta(\mathbf{x}_{0:k}-\mathbf{x}_{0:k}^i) \notag \\w_{k}^{i} &amp;\propto \frac{p\left(\mathbf{x}_{0: k}^{i} |\mathbf{y}_{1: k}\right)}{q\left(\mathbf{x}_{0: k}^{i} | \mathbf{y}_{1:k}\right)}\notag\end{align}\]</span>再考虑前面提到的的<strong>预测</strong>和<strong>更新</strong>两个递推进行的阶段，就有<span class="math display">\[\begin{align}q\left(\mathbf{x}_{0: k} | \mathbf{y}_{1:k}\right)&amp;=q\left(\mathbf{x}_{k} | \mathbf{x}_{0: k-1},\mathbf{y}_{1: k}\right) q\left(\mathbf{x}_{0: k-1} | \mathbf{y}_{1:k-1}\right) \notag\\            &amp;= q\left(\mathbf{x}_{k} | \mathbf{x}_{k-1},\mathbf{y}_{ k}\right) q\left(\mathbf{x}_{0: k-1} | \mathbf{y}_{1:k-1}\right) \notag \\            w_{k}^{i} &amp;\propto w_{k-1}^{i}\frac{p\left(\mathbf{y}_{k} | \mathbf{x}_{k}^{i}\right)p\left(\mathbf{x}_{k}^{i} |\mathbf{x}_{k-1}^{i}\right)}{q\left(\mathbf{x}_{k}^{i} |\mathbf{x}_{k-1}^{i}, \mathbf{y}_{k}\right)} \label{eq_sis}            \end{align}\]</span> 然后我们就得到了一个更加 universal/generic的粒子滤波算法(下面图片所示算法中没加重采样步骤)。</p><figure><imgsrc="https://raw.githubusercontent.com/Glooow1024/ImgHosting/master/hexo/2019/pf_sis.PNG"alt="sis" /><figcaption aria-hidden="true">sis</figcaption></figure><h2 id="总结-1">6. 总结</h2><p>这篇文章主要是自己学习粒子滤波之后的一些理解，主要参考了文章 <ahref="https://ieeexplore.ieee.org/document/978374">A Tutorial onParticle Filters for Online Nonlinear/Non-Gaussian BayesianTracking</a>，但是这篇文章中是从 general的情况开始讲，然后举了一些常用的特例，个人感觉不利于初学者理解，因此本文写作过程中的思路是从简单的特例开始再到更一般的情况。</p><p>最后一部分 <a href="##%20粒子滤波原理推导">粒子滤波原理推导</a>其实写的并没有很清楚，主要是因为自己太懒，到最后懒得一个个手敲公式了，如果想更清楚地了解其中的细节，可以阅读上面那篇论文。</p><h2 id="reference">7. Reference</h2><ol type="1"><li>M. S. Arulampalam, S. Maskell, N. Gordon and T. Clapp, "A tutorialon particle filters for online nonlinear/non-Gaussian Bayesiantracking," in <em>IEEE Transactions on Signal Processing</em>, vol. 50,no. 2, pp. 174-188, Feb. 2002.</li></ol>]]></content>
    
    
    <categories>
      
      <category>Signal Processing</category>
      
    </categories>
    
    
    <tags>
      
      <tag>滤波算法</tag>
      
      <tag>粒子滤波</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Mathematica激活</title>
    <link href="/2003/06/04/software/mathematica/"/>
    <url>/2003/06/04/software/mathematica/</url>
    
    <content type="html"><![CDATA[<p>Mathematica激活方法：安装好之后启动软件，选择其他方式激活 &gt;&gt;手动激活 &gt;&gt; 输入激活密钥和密码。</p><p>根据 Math ID 生成激活密钥和密码的<ahref="ibug.io/blog/2019/05/mathematica-keygen/">链接</a>，Math ID在需要输入激活密钥和密码的那里可以看到。</p>]]></content>
    
    
    <categories>
      
      <category>Software</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Mathematica</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Adobe Acrobat Pro DC更新后提示登录激活问题</title>
    <link href="/2002/08/05/software/acrobat/"/>
    <url>/2002/08/05/software/acrobat/</url>
    
    <content type="html"><![CDATA[<p>Adobe Acrobat Pro DC 更新之后不能直接用 AMTEmu v0.9.2 激活了。</p><p>不过只需要修改以下注册表再重新激活就可以了。</p><p>通过 <code>win+R</code> 输入 <code>regedit</code>打开注册表，在以下位置处</p><figure class="highlight taggerscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs taggerscript">[HKEY_LOCAL_MACHINE<span class="hljs-symbol">\S</span>OFTWARE<span class="hljs-symbol">\W</span>OW6432Node<span class="hljs-symbol">\A</span>dobe<span class="hljs-symbol">\A</span>dobe Acrobat<span class="hljs-symbol">\D</span>C<span class="hljs-symbol">\A</span>ctivation] <br></code></pre></td></tr></table></figure><p>创建一个 <code>DWORD(32位)</code> 类型的项，数值为十六进制0x00000001。</p><p>然后就可以用 AMTEmu v0.9.2 重新激活了。</p>]]></content>
    
    
    <categories>
      
      <category>Software</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Adobe</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
